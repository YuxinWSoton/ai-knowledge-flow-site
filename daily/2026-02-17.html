<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>知识流日报 2026-02-17：softmax</title>
<style>
  * { box-sizing: border-box; }
  body {
    font-family: system-ui, sans-serif;
    max-width: 720px;
    margin: 0 auto;
    padding: 2rem 1rem;
    color: #fff;
    min-height: 100vh;
    background: #0a0e1a;
    background-image:
      radial-gradient(2px 2px at 20px 30px, rgba(255,255,255,0.9), transparent),
      radial-gradient(2px 2px at 40px 70px, rgba(255,255,255,0.6), transparent),
      radial-gradient(1.5px 1.5px at 90px 40px, rgba(255,255,255,0.8), transparent),
      radial-gradient(2px 2px at 130px 80px, rgba(255,255,255,0.5), transparent),
      radial-gradient(1.5px 1.5px at 160px 120px, rgba(255,255,255,0.7), transparent),
      radial-gradient(ellipse 120% 100% at 50% 0%, rgba(88,60,120,0.25), transparent 50%),
      radial-gradient(ellipse 80% 80% at 80% 20%, rgba(40,60,100,0.2), transparent 40%);
    background-size: 200px 200px;
    background-repeat: repeat;
  }
  a { color: #a8d4ff; text-decoration: none; }
  a:hover { text-decoration: underline; }
 h1,h2,h3{margin-top:1.5rem;color:#fff;} pre{white-space:pre-wrap;color:rgba(255,255,255,0.9);} .toolbar{margin:0.5rem 0;color:rgba(255,255,255,0.8);} .content{color:rgba(255,255,255,0.95);} .content a{color:#a8d4ff;} .meta{color:rgba(255,255,255,0.65);font-size:0.9em;} .content p,.content div,.content h2,.content h3,.content h4,.content li,.content pre{cursor:pointer;-webkit-tap-highlight-color:rgba(255,255,255,0.15);}</style>
</head>
<body>
<p><a href="https://YuxinWSoton.github.io/ai-knowledge-flow-site/">← 返回首页</a></p>
<h1>知识流日报 2026-02-17：softmax</h1>
<p class="meta" style="margin-top:0;">最后更新：2026-02-17 11:27</p>
<p class="toolbar"><button id="btnNext" onclick="nextArticle()">下一篇</button> <button id="btnSel" onclick="readSelected()">朗读这段</button> <span id="readStatus"></span></p>
<p class="meta" style="margin-top:0;">（点任意段落即可朗读，手机/触屏友好；也可选中后点「朗读这段」或点「下一篇」按条朗读）</p>
<div class="content">
<h1>知识流日报 2026-02-17：softmax</h1>
<p>共 3 条（来自百度学术 / Google / Bing 等，仅含正文抓取成功的条目；按正文长度从短到长排列，便于先听短的）。</p>
<p>（以下含抓取正文，便于阅读。未调用任何 AI API。）</p>
<h2>1. Categorical Reparameterization with Gumbel-Softmax</h2>
<ul>
<li>链接：https://xueshu.baidu.com/usercenter/paper/show?paperid=1d3c47dd063c77ba9add305a71a07c5d&amp;site=xueshu_se</li>
<li>来源：baidu_scholar</li>
</ul>
<h3>正文（抓取，非 AI）</h3>
<p>Categorical Reparameterization with Gumbel-Softmax - 百度学术  意见反馈 登录 注册 高级搜索 包含全部检索词 包含精确检索词 包含至少一个检索词 不包含检索词 出现检索词的位置 文章任何位置 位于文章标题 作者 机构 出版物 期刊 会议 发表时间 - 语言检索范围 不限 不限 英文 中文  文献 期刊 学者 订阅 收藏 论文查重 优惠  论文查重 开题分析 单篇购买 文献互助 用户中心 Categorical Reparameterization with Gumbel-Softmax 来自 arXiv.org  喜欢 0 阅读量： 2972 作者： E Jang ， S Gu ， B Poole 展开  摘要： We show a connection between the Fourier spectrum of Boolean functions and the REINFORCE gradient estimator for binary latent variable models. We show that REINFORCE estimates (up to a factor) the degree-1 Fourier coefficients of a Boolean function. Using this connection we offer a new perspective on variance reduction in gradient estimation for latent variable models: namely, that variance... 展开  关键词： Statistics - Machine Learning Computer Science - Learning DOI： 10.48550/arXiv.1611.01144 被引量： 458 年份： 2016  收藏  引用  批量引用  报错  分享 全部来源 免费下载 求助全文 Semantic Scholar Semantic Scholar (全网免费下载) arXiv.org arXiv.org (全网免费下载) ui.adsabs.harvard.edu 查看更多 adsabs.harvard.edu ResearchGate ResearchGate (全网免费下载) scienceopen.com openreview.net (全网免费下载) bayesiandeeplearning.org (全网免费下载) openreview.net research.google.com 128.84.21.199 (全网免费下载) science-open.com 钛学术 (全网免费下载) 钛学术 Semantic Scholar (全网免费下载) arXiv.org (全网免费下载) ResearchGate (全网免费下载) 128.84.21.199 (全网免费下载) openreview.net (全网免费下载) bayesiandeeplearning.org (全网免费下载) 钛学术 (全网免费下载) 通过 文献互助 平台发起求助，成功后即可免费获取论文全文。 请先登入 我们已与文献出版商建立了直接购买合作。 你可以通过身份认证进行实名认证，认证成功后本次下载的费用将由您所在的图书馆支付 您可以直接购买此文献，1~5分钟即可下载全文，部分资源由于网络原因可能需要更长时间，请您耐心等待哦~ 身份认证 全文购买 相似文献 参考文献 引证文献 来源期刊 arXiv e-prints 11/2016 研究点推荐 Gumbel-Softmax REINFORCE gradient estimator Categorical Reparameterization binary latent variable models Boolean functions 引用走势 站内活动 辅助模式 0 引用 文献可以 批量引用 啦~ 欢迎点我试用！ 关于我们 百度学术集成海量学术资源，融合人工智能、深度学习、大数据分析等技术，为科研工作者提供全面快捷的学术服务。在这里我们保持学习的态度，不忘初心，砥砺前行。 了解更多&gt;&gt; 友情链接 联系我们 合作与服务 期刊合作 图书馆合作 下载产品手册 意见反馈 ©2026 Baidu 百度学术声明 使用百度前必读</p>
<h2>2. 一文揭秘Softmax函数：解锁机器学习多类分类之门</h2>
<ul>
<li>链接：https://www.zhihu.com/tardis/bd/art/683697682</li>
<li>来源：bing</li>
<li>摘要：2024年2月24日 · 1. 引言 Softmax函数的定义和基本概念 Softmax函数，也称为归一化指数函数，是一个将向量映射到另一个向量的函数，其中输出向量的元素值代表了一个概率分布。 在机器学习中，特 …</li>
</ul>
<h3>正文（抓取，非 AI）</h3>
<p>省流版 这篇文章介绍了在机器学习多酚类问题中非常重要的一类函数：softmax函数。我们介绍了其数学原理、特点、应用以及python实现方法，非常值得你收藏起来反复学习。在保研考研、数据分析、算法等面试环节均有可能出现。 文中部分内容来自GPT生成，他已经成为我最重要的生产力工具。但我了解到还有部分朋友苦于不知道怎么在国内使用正版GPT，可以参考我的这篇博客： GPT4.0使用教程 或者直接从下方链接登陆： WildCard | 一分钟注册，轻松订阅海外软件服务 创作不易，感谢你的三联和支持~ 1. 引言 Softmax函数的定义和基本概念 Softmax函数，也称为归一化指数函数，是一个将向量映射到另一个向量的函数，其中输出向量的元素值代表了一个概率分布。在机器学习中，特别是在处理多类分类问题时，Softmax函数扮演着至关重要的角色。它可以将未归一化的数值转换成一个概率分布，使得每个类别都有一个对应的概率值，且所有类别的概率之和为1。 Softmax在机器学习中的重要性 在机器学习的多类分类问题中，我们经常需要预测一个实例属于多个类别中的哪一个。Softmax函数正是为了满足这一需求而设计。它不仅提供了一种将模型输出转换为概率解释的方法，而且由于其输出的概率性质，Softmax函数也使得模型的结果更易于理解和解释。 Softmax函数的广泛应用包括但不限于神经网络的输出层，在深度学习模型中，尤其是分类任务中，Softmax函数经常被用作最后一个激活函数，用于输出预测概率。 2. Softmax函数的数学原理 函数的数学表达式和解释 Softmax函数将一个含任意实数的K维向量z转换成另一个K维实向量σ(z)，其中每一个元素的范围都在(0, 1)之间，并且所有元素的和为1。函数的数学表达式如下： 其中，i表示向量z中的元素索引，K是向量z的维度。 分子e^{z_i}是元素z_i的指数函数，保证了输出值的非负性。 分母是所有元素指数值的总和，确保了所有输出值之和为1，从而形成一个概率分布。 Softmax与逻辑回归的联系 Softmax函数可以被看作是逻辑回归（或称作Logistic函数）在多类分类问题上的推广。在二分类问题中，逻辑回归输出一个实例属于某一类的概率，而Softmax则扩展到了多个类别，使得模型能够输出多个类别的概率预测 指数函数的作用 在Softmax函数中，指数函数e^{z_i}用于确保每个输出值都是正数，这对于将输出解释为概率是必要的。指数函数还能够放大差异，即使是很小的输入值差异，在经过指数函数处理后，也会在输出概率中反映为较大的差异，这有助于模型在多个类别之间做出更加明确的决策。 3. Softmax函数的应用 Softmax函数在机器学习和深度学习中有着广泛的应用，尤其是在解决多类分类问题时。 在多类分类问题中的应用 多类分类是指将实例分类到三个或更多的类别中。Softmax函数在这类问题中非常有用，因为它能够为每个类别生成一个概率分布。这意味着模型不仅能够预测每个实例最有可能属于哪个类别，还能给出相对于其他类别的概率评估，提供了更多的决策信息。 与神经网络的结合 在神经网络中，Softmax函数通常被用作输出层的激活函数，特别是在进行多类分类时。它将神经网络最后一层的线性输出转换为概率分布，每个节点（或神经元）对应一个特定类别的概率。这样，神经网络不仅能够识别输入数据最可能属于的类别，还能以概率形式表达对各个类别的预测信心。 示例：使用Softmax进行手写数字识别 一个典型的应用示例是使用Softmax函数和神经网络进行手写数字识别，如MNIST数据集。在这种场景下，网络的最后一层是一个含有10个节点的Softmax层，每个节点对应一个数字（0到9）。网络的输出是一个10维向量，表示输入图像属于每个数字的概率。选择概率最高的节点所对应的数字作为预测结果。 在这个简化的示例中，我们使用TensorFlow构建和训练一个简单的神经网络，其中最后一层是Softmax层，用于对手写数字图像进行分类。 4. Softmax函数的优缺点 优点 概率解释 ：Softmax函数的输出可以被解释为一个概率分布，每个类别都有一个对应的概率。这种概率输出使得模型的预测结果更容易被理解和解释。 扩展性 ：Softmax函数适用于二类分类和多类分类问题，非常灵活。它可以无缝地扩展到任意数量的类别，使得模型设计更加通用。 与交叉熵损失的结合 ：在训练阶段，Softmax函数通常与交叉熵损失函数结合使用，这种组合在数学上具有良好的性质，有助于模型的优化和训练。 缺点 对异常值敏感 ：由于Softmax函数使用了指数函数，它对异常值非常敏感。一个很大的负输入值在经过Softmax转换后可能会接近于零，而一个很大的正输入值可能会导致其它类别的概率显著降低。 计算成本 ：Softmax函数涉及指数运算，这在计算上可能比线性或其他简单函数更昂贵，尤其是当类别数量很大时。 数值稳定性问题 ：在实际计算中，Softmax函数可能遇到数值稳定性问题，特别是当输入值非常大或非常小时。这可能导致数值溢出或下溢，影响模型的稳定性和性能。 5. Softmax的变种和改进 为了解决Softmax函数的一些局限性，研究人员提出了几种变种和改进方法： 引入温度参数 ： 通过在Softmax函数中引入一个温度参数T，可以控制输出分布的平滑程度。温度较高时，输出概率分布更加平滑；温度较低时，输出分布更加尖锐。 使用Log-Softmax ： Log-Softmax是Softmax的对数版本，它在数学上更稳定，尤其是与交叉熵损失结合使用时。 稀疏Softmax ： 为了提高处理大量类别的效率，稀疏Softmax对于只有少数几个输出有显著概率的情况进行了优化。 这些改进使得Softmax函数在不同的应用场景中更加灵活和鲁棒。 6. 实现Softmax函数 实现Softmax函数需要注意的一个关键问题是数值稳定性。由于指数函数的特性，在处理很大的输入值时，直接计算会导致数值溢出。下面提供了一个考虑数值稳定性的Softmax函数的Python实现。 这段代码展示了如何计算一个向量或矩阵的Softmax。注意，在计算指数前，从输入值中减去了最大值，这是为了提高数值稳定性，防止计算指数时发生溢出。 数值稳定性问题和解决方案 数值稳定性问题主要是由于指数函数在处理很大的数时可能导致数值溢出。解决这个问题的一个常见技巧是，在进行指数运算前，先从输入值中减去其最大值。 这个操作不会改变Softmax函数的输出，因为我们同时从分子和分母中减去了相同的值，但它可以有效地减少计算指数时可能遇到的数值问题。 7. Softmax与其他激活函数的比较 Softmax函数通常与Sigmoid函数比较，尤其是在二分类问题中。Sigmoid函数将单个输入映射到(0, 1)区间，适用于二分类，而Softmax适用于多类分类。 Sigmoid ： 适用于二分类问题，输出一个代表正类概率的值。 Softmax ： 扩展到多类分类，为每个类别提供概率分布。 在选择激活函数时，考虑任务的性质（二分类还是多分类）以及模型的具体需求。 8. 总结 Softmax函数是机器学习和深度学习中的一个重要概念，特别是在处理分类问题时。它通过提供一个概率分布，使得模型的输出更加直观和易于解释。虽然实现时需要考虑数值稳定性问题，但正确使用Softmax函数可以大大提高多类分类问题的处理效率和准确性。 文中部分内容来自GPT生成，他已经成为我最重要的生产力工具。但我了解到还有部分朋友苦于不知道怎么在国内使用正版GPT，可以参考我的这篇博客： GPT4.0使用教程 或者直接从下方链接登陆： WildCard | 一分钟注册，轻松订阅海外软件服务 创作不易，感谢你的三联和支持~</p>
<h2>3. 损失函数｜交叉熵损失函数</h2>
<ul>
<li>链接：https://www.zhihu.com/tardis/zm/art/35709485</li>
<li>来源：bing</li>
<li>摘要：2022年3月28日 · 该得分经过 sigmoid (或softmax)函数 获得概率输出； 模型预测的类别概率输出与真实类别的one hot形式进行交叉熵损失函数的计算。 学习任务分为二分类和多分类情况，我们分别讨论 …</li>
</ul>
<h3>正文（抓取，非 AI）</h3>
<p>这篇文章中，讨论的Cross Entropy损失函数常用于分类问题中，但是为什么它会在分类问题中这么有效呢？我们先从一个简单的分类例子来入手。 1. 图像分类任务 我们希望根据图片动物的轮廓、颜色等特征，来预测动物的类别，有三种可预测类别：猫、狗、猪。假设我们当前有两个模型（参数不同），这两个模型都是通过sigmoid/softmax的方式得到对于每个预测结果的概率值： 模型1 ： 预测 真实 是否正确 0.3 0.3 0.4 0 0 1 (猪) 正确 0.3 0.4 0.3 0 1 0 (狗) 正确 0.1 0.2 0.7 1 0 0 (猫) 错误 模型1 对于样本1和样本2以非常微弱的优势判断正确，对于样本3的判断则彻底错误。 模型2 ： 预测 真实 是否正确 0.1 0.2 0.7 0 0 1 (猪) 正确 0.1 0.7 0.2 0 1 0 (狗) 正确 0.3 0.4 0.3 1 0 0 (猫) 错误 模型2 对于样本1和样本2判断非常准确，对于样本3判断错误，但是相对来说没有错得太离谱。 好了，有了模型之后，我们需要通过定义损失函数来判断模型在样本上的表现了，那么我们可以定义哪些损失函数呢？ 1.1 Classification Error（分类错误率） 最为直接的损失函数定义为： 模型1： 模型2： 我们知道， 模型1 和 模型2 虽然都是预测错了1个，但是相对来说 模型2 表现得更好，损失函数值照理来说应该更小，但是，很遗憾的是， 并不能判断出来，所以这种损失函数虽然好理解，但表现不太好。 1.2 Mean Squared Error (均方误差) 均方误差损失也是一种比较常见的损失函数，其定义为： 模型1： 对所有样本的loss求平均： 模型2： 对所有样本的loss求平均： 我们发现，MSE能够判断出来 模型2 优于 模型1 ，那为什么不采样这种损失函数呢？主要原因是在分类问题中，使用sigmoid/softmx得到概率，配合MSE损失函数时，采用梯度下降法进行学习时，会出现模型一开始训练时，学习速率非常慢的情况（ MSE损失函数 ）。 有了上面的直观分析，我们可以清楚的看到，对于分类问题的损失函数来说，分类错误率和均方误差损失都不是很好的损失函数，下面我们来看一下交叉熵损失函数的表现情况。 1.3 Cross Entropy Loss Function（交叉熵损失函数） 1.3.1 表达式 (1) 二分类 在二分的情况下，模型最后需要预测的结果只有两种情况，对于每个类别我们的预测得到的概率为 和 ，此时表达式为（ 的底数是 ）： 其中： - —— 表示样本 的label，正类为 ，负类为 - —— 表示样本 预测为正类的概率 (2) 多分类 多分类的情况实际上就是对二分类的扩展： 其中： - ——类别的数量 - ——符号函数（ 或 ），如果样本 的真实类别等于 取 ，否则取 - ——观测样本 属于类别 的预测概率 现在我们利用这个表达式计算上面例子中的损失函数值： 模型1 ： 对所有样本的loss求平均： 模型2： 对所有样本的loss求平均： 上述计算可以使用python的sklearn库 可以发现，交叉熵损失函数可以捕捉到 模型1 和 模型2 预测效果的差异。 2. 函数性质 可以看出，该函数是凸函数，求导时能够得到全局最优值。 3. 学习过程 交叉熵损失函数经常用于分类问题中，特别是在神经网络做分类问题时，也经常使用交叉熵作为损失函数，此外，由于交叉熵涉及到计算每个类别的概率，所以交叉熵几乎每次都和 sigmoid(或softmax)函数 一起出现。 我们用神经网络最后一层输出的情况，来看一眼整个模型预测、获得损失和学习的流程： 神经网络最后一层得到每个类别的得分 scores（也叫logits） ； 该得分经过 sigmoid(或softmax)函数 获得概率输出； 模型预测的类别概率输出与真实类别的one hot形式进行交叉熵损失函数的计算。 学习任务分为二分类和多分类情况，我们分别讨论这两种情况的学习过程。 3.1 二分类情况 二分类交叉熵损失函数学习过程 如上图所示，求导过程可分成三个子过程，即拆成三项偏导的乘积： 3.1.1 计算第一项： - 表示样本 预测为正类的概率 - 为符号函数，样本 为正类时取 ，否则取 3.1.2 计算第二项： 这一项要计算的是sigmoid函数对于score的导数，我们先回顾一下sigmoid函数和分数求导的公式： 3.1.3 计算第三项： 一般来说，scores是输入的线性函数作用的结果，所以有： 3.1.4 计算结果 可以看到，我们得到了一个非常漂亮的结果，所以，使用交叉熵损失函数，不仅可以很好的衡量模型的效果，又可以很容易的的进行求导计算。 3.2 多分类情况 多分类交叉熵损失函数学习过程 如上图所示，求导过程可以分为三个子过程： 和二分类区别在于： 因为多分类只有一个类别为 ，其他为 ，不失一般性，我们可以假设 为 ，其他为 ，所以损失函数求和式子中只有 这项不为 ，即 这一项求导时，需要针对 是否等于 进行分类讨论（这里 表示的是样本真实类别为 ， 表示的是对我们想对输入到 的参数 求导） 3.2.1 计算第一项： 不失一般性，我们可以假设 为 ，其他为 ，则 求导： 3.2.2 计算第二项： 这一项要计算的是softmax函数对于得分的导数，我们先回顾一下softmax函数和分数求导的公式： 这里 表示的是样本真实类别为 ， 表示的是对输入到 的参数 求导，这时候存在两种情况： 情况1: 则第二项的求导式子，可以写成： 求导后得 情况2: 此时 这一项只在分母中存在，求导后得： 3.2.3 计算第三项： 一般来说，scores是输入的线性函数作用的结果，所以有： 3.2.4 计算结果 情况1: 情况2: 不失一般性，我们上述假设样本的真实类别为 ，则有: 我们求导时，对不同情况带入 的值后，得到了一致的表达式，如果采用向量化的形式，那么导数就不用再分情况写了，统一成： 可以看出，交叉熵损失函数对于二分类和多分类求导时，采用向量化的形式后，求导结果的形式是一致的。 4. 优缺点 4.1 优点 在用梯度下降法做参数更新的时候，模型学习的速度取决于两个值：一、 学习率 ；二、 偏导值 。其中，学习率是我们需要设置的超参数，所以我们重点关注偏导值。从上面的式子中，我们发现，偏导值的大小取决于 和 ，我们重点关注后者，后者的大小值反映了我们模型的错误程度，该值越大，说明模型效果越差，但是该值越大同时也会使得偏导值越大，从而模型学习速度更快。所以，使用逻辑函数得到概率，并结合交叉熵当损失函数时，在模型效果差的时候学习速度比较快，在模型效果好的时候学习速度变慢。 4.2 缺点 Deng [4]在2019年提出了ArcFace Loss，并在论文里说了Softmax Loss的两个缺点：1、随着分类数目的增大，分类层的线性变化矩阵参数也随着增大；2、对于封闭集分类问题，学习到的特征是可分离的，但对于开放集人脸识别问题，所学特征却没有足够的区分性。对于人脸识别问题，首先人脸数目(对应分类数目)是很多的，而且会不断有新的人脸进来，不是一个封闭集分类问题。 另外，sigmoid(softmax)+cross-entropy loss 擅长于学习类间的信息，因为它采用了类间竞争机制，它只关心对于正确标签预测概率的准确性，忽略了其他非正确标签的差异，导致学习到的特征比较散。基于这个问题的优化有很多，比如对softmax进行改进，如L-Softmax、SM-Softmax、AM-Softmax等。 5. 参考 [1]. 博客 - 神经网络的分类模型 LOSS 函数为什么要用 CROSS ENTROPY [2]. 博客 - Softmax as a Neural Networks Activation Function [3]. 博客 - A Gentle Introduction to Cross-Entropy Loss Function [4]. Deng, Jiankang, et al. "Arcface: Additive angular margin loss for deep face recognition." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.</p>
</div>
<script>
var articles=[]; var currentArticleIdx=-1; var maxSpeakChars=3500;
function buildArticles(){ var c=document.querySelector('.content'); if(!c) return; var h2s=c.querySelectorAll('h2'); for(var i=0;i<h2s.length;i++){ var start=h2s[i], end=i+1<h2s.length?h2s[i+1]:null; var r=document.createRange(); r.setStart(start,0); if(end) r.setEnd(end,0); else { var last=c.lastElementChild||c; r.setEndAfter(last); } var t=r.toString().replace(/\s+/g,' ').trim(); if(t.length>maxSpeakChars) t=t.slice(0,maxSpeakChars)+'…（内容过长已截断）'; articles.push({h2:start,text:t}); }
 articles.sort(function(a,b){ return a.text.length-b.text.length; }); }
function speakText(t){ if(!t){ document.getElementById('readStatus').textContent=''; return; }
 speechSynthesis.cancel(); var status=document.getElementById('readStatus'); status.textContent='准备中…';
 var chunks=[]; var maxLen=280; for(var i=0;i<t.length;i+=maxLen){ var s=t.slice(i,i+maxLen); var j=s.lastIndexOf('。'); if(j>80){ chunks.push(s.slice(0,j+1)); i-=s.length-(j+1); } else chunks.push(s); }
 if(chunks.length===0) chunks=[t]; var idx=0; function speakNext(){ if(idx>=chunks.length){ status.textContent=''; return; } var u=new SpeechSynthesisUtterance(chunks[idx]); u.lang='zh-CN'; u.rate=0.95; var v=speechSynthesis.getVoices().filter(function(x){ return x.lang.indexOf('zh')>=0; })[0]; if(v) u.voice=v;
 u.onend=function(){ idx++; setTimeout(speakNext,80); }; u.onerror=function(){ idx++; setTimeout(speakNext,80); }; status.textContent='朗读中 '+(idx+1)+'/'+chunks.length+'…'; speechSynthesis.speak(u); }
 if(speechSynthesis.getVoices().length) speakNext(); else speechSynthesis.onvoiceschanged=function(){ speechSynthesis.onvoiceschanged=null; speakNext(); }; }
function nextArticle(){ if(articles.length===0) buildArticles(); if(articles.length===0){ document.getElementById('readStatus').textContent='无可读内容'; return; }
 speechSynthesis.cancel(); currentArticleIdx++; if(currentArticleIdx>=articles.length){ currentArticleIdx=0; document.getElementById('readStatus').textContent='已读完，共 '+articles.length+' 篇。再按从第 1 篇开始'; return; }
 var a=articles[currentArticleIdx]; a.h2.scrollIntoView({behavior:'smooth',block:'start'}); document.getElementById('readStatus').textContent='第 '+(currentArticleIdx+1)+' / '+articles.length+' 篇'; speakText(a.text); }
function readSelected(){ var sel=window.getSelection(); var t=(sel&&sel.toString)?sel.toString():''; t=t.replace(/\\s+/g,' ').trim(); if(!t){ document.getElementById('readStatus').textContent='请先选中要朗读的段落'; return; } speechSynthesis.cancel(); document.getElementById('readStatus').textContent='朗读选中内容…'; speakText(t); }
function getBlockForTap(el){ var c=document.querySelector('.content'); var blockTags=['P','DIV','H2','H3','H4','LI','PRE']; while(el&&el!==c){ if(c.contains(el)&&blockTags.indexOf(el.tagName)!==-1) return el; el=el.parentElement; } return null; }
function onContentTap(e){ if(e.target.closest&&e.target.closest('a')) return; var block=getBlockForTap(e.target); if(block){ var t=(block.innerText||'').trim().replace(/\\s+/g,' '); if(t){ e.preventDefault(); speechSynthesis.cancel(); document.getElementById('readStatus').textContent='朗读本段…'; speakText(t); } } }
if(document.readyState==='loading'){ document.addEventListener('DOMContentLoaded', function(){ buildArticles(); var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }); } else { buildArticles(); var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }
</script>
</body>
</html>
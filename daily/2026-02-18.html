<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>知识流日报 2026-02-18：Neural Scaling Laws</title>
<style>
  * { box-sizing: border-box; }
  body {
    font-family: system-ui, sans-serif;
    max-width: 720px;
    margin: 0 auto;
    padding: 2rem 1rem;
    color: #fff;
    min-height: 100vh;
    background: #0a0e1a;
    background-image:
      radial-gradient(2px 2px at 20px 30px, rgba(255,255,255,0.9), transparent),
      radial-gradient(2px 2px at 40px 70px, rgba(255,255,255,0.6), transparent),
      radial-gradient(1.5px 1.5px at 90px 40px, rgba(255,255,255,0.8), transparent),
      radial-gradient(2px 2px at 130px 80px, rgba(255,255,255,0.5), transparent),
      radial-gradient(1.5px 1.5px at 160px 120px, rgba(255,255,255,0.7), transparent),
      radial-gradient(ellipse 120% 100% at 50% 0%, rgba(88,60,120,0.25), transparent 50%),
      radial-gradient(ellipse 80% 80% at 80% 20%, rgba(40,60,100,0.2), transparent 40%);
    background-size: 200px 200px;
    background-repeat: repeat;
  }
  a { color: #a8d4ff; text-decoration: none; }
  a:hover { text-decoration: underline; }
 h1,h2,h3{margin-top:1.5rem;color:#fff;} pre{white-space:pre-wrap;color:rgba(255,255,255,0.9);} .toolbar{margin:0.5rem 0;color:rgba(255,255,255,0.8);} .content{color:rgba(255,255,255,0.95);} .content a{color:#a8d4ff;} .meta{color:rgba(255,255,255,0.65);font-size:0.9em;} .content p,.content div,.content h2,.content h3,.content h4,.content li,.content pre{cursor:pointer;-webkit-tap-highlight-color:rgba(255,255,255,0.15);} .content .insight-summary{color:#c9a0dc;margin:0.5em 0 0.8em 0;} .content .insight-detail,.content .insight-detail li{color:#8dd4e8;list-style:disc;margin-left:1.2em;padding-left:0.3em;} .content .article-body-details{margin:0.8em 0;} .content .article-body-details summary{cursor:pointer;color:rgba(255,255,255,0.85);}</style>
</head>
<body>
<p><a href="https://YuxinWSoton.github.io/ai-knowledge-flow-site/">← 返回首页</a></p>
<h1>知识流日报 2026-02-18：Neural Scaling Laws</h1>
<p class="meta" style="margin-top:0;">最后更新：2026-02-18 21:11</p>
<p class="toolbar"><button id="btnNext" onclick="nextArticle()">下一篇</button> <button id="btnSel" onclick="readSelected()">朗读这段</button> <span id="readStatus"></span></p>
<p class="meta" style="margin-top:0;">（点任意段落即可朗读，手机/触屏友好；也可选中后点「朗读这段」或点「下一篇」按条朗读）</p>
<div class="content">
<h1>知识流日报 2026-02-18：Neural Scaling Laws</h1>
<p>共 10 条（来自百度学术 / Google / Bing 等，仅含正文抓取成功的条目；按正文长度从短到长排列，便于先听短的）。</p>
<p>（以下含抓取正文，便于阅读。未调用任何 AI API。）</p>
<p>（部分条目含模型提取的「易漏细节」关键点，页面上以颜色区分。）</p>
<h2>1. 如何简单形象又有趣地讲解神经网络是什么？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/22553761</li>
<li>来源：bing</li>
<li>摘要：这里面的概念并不是整个网络的输出，是网络中间层神经元的偏好，它们为后面的神经元服务。虽然每一个神经元都傻不拉几的（只会切一刀），但是65万个神经元能学到的东西还真是深邃呢。 [1] …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，中间层神经元的偏好是关键，每个神经元仅执行简单的操作，这使得它们能够专注于特定的特征或模式。其次，尽管单个神经元的功能有限，但通过大量的神经元协同工作，它们能够共同学习和识别复杂的信息。因此，成千上万的神经元通过组合和协作，能够处理和理解更为复杂的输入，从而实现高级别的认知功能。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>中间层神经元的偏好</li>
<li>每个神经元只会执行简单的操作</li>
<li>万个神经元能学到复杂的信息</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3>正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2>2. 如何评价:neural network期刊和neurocomputing期刊，应该 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/557868478</li>
<li>来源：bing</li>
<li>摘要：2022年10月6日 · 这两者性价比最高的是neunet。 1.尽管两者JCI在接近，但是neunet占个神经科学区，而neucom只有人工智能分区导致JCR只是2区期刊； 2.跟我同领域的文章在这两家期刊上看过，感 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，神经网络期刊在神经科学领域占据重要地位，这表明它们在该领域的研究具有较高的影响力和认可度。其次，相比之下，Neucom专注于人工智能领域，仅包含人工智能分区的内容，这意味着它的研究范围更为狭窄，主要集中在人工智能相关课题上。此外，Neunet则以其高性价比脱颖而出，为研究人员提供了在神经科学领域发表高质量论文的经济实惠选择。因此，对于希望在神经科学领域发表研究的学者来说，Neunet不仅是一个值得考虑的选择，而且是性价比最高的期刊之一。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>neural network期刊占神经科学区</li>
<li>neucom只有人工智能分区</li>
<li>neunet是性价比最高的期刊</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3>正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2>3. TNNLS和Neural Networks哪个更难？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/7614764831</li>
<li>来源：bing</li>
<li>摘要：2025年3月2日 · TNNLS和Neural Networks哪个更难？ 这两个都是CCF B，JCR和中科院一区，TNNLS影响因子高一些，哪一个更难发？ 听说IEEE Trans很难发，是真的吗？ 显示全部 关注者 11</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，TNNLS（IEEE Transactions on Neural Networks and Learning Systems）和Neural Networks都是CCF B级别期刊，这意味着它们在神经网络领域具有较高的学术地位。其次，虽然TNNLS的影响因子略高，但这一差异并不显著，更多反映了期刊在特定时间段内的引用情况。此外，有人认为在TNNLS上发表论文相对困难，这可能与期刊的严格审稿标准和较高的投稿门槛有关。因此，对于希望在神经网络领域发表高质量研究的学者来说，TNNLS是一个值得努力的目标，尽管过程可能会较为艰难。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>TNNLS和Neural Networks都是CCF B级别期刊</li>
<li>TNNLS影响因子高一些</li>
<li>有人认为IEEE Trans很难发</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3>正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2>4. 如何理解ZNN（zeroing neural network）神经网络？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/397432475/answers/updated</li>
<li>来源：bing</li>
<li>摘要：2024年12月10日 · This general concept for solving parameter-dependent matrix equations is, in this context, known as Zeroing Neural Networks or Zhang Neural Networks (ZNN). We exploit this idea to …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">解决参数依赖矩阵方程是确保神经网络训练过程稳定性和高效性的关键步骤。为了实现这一目标，研究人员开发了多种方法，其中Zeroing Neural Networks（ZNN）和Zhang Neural Networks（ZNN）是两种重要的技术。ZNN通过设计特定的神经网络结构，使得网络中的参数能够自动调整，从而有效解决参数依赖问题。而ZNN进一步优化了ZNN的方法，通过引入新的机制，使得网络在处理参数依赖问题时更加高效和准确。这两种方法共同的目标都是提高神经网络的性能，确保其在复杂任务中的表现更加出色。因此，通过采用ZNN和ZNN，可以显著提升神经网络的训练效果和泛化能力，从而在实际应用中获得更好的结果。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>解决参数依赖矩阵方程</li>
<li>Zeroing Neural Networks</li>
<li>Zhang Neural Networks (ZNN)</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3>正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2>5. deepmind发表的neural processes (神经过程)，这个是怎么 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/285664896</li>
<li>来源：bing</li>
<li>摘要：deepmind发表的neural processes (神经过程)，这个是怎么实现的呢？ 看了好久没看懂，具体是怎么操作的？ 过程是什么样的 显示全部 关注者 117</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">模型能够学习数据的生成过程，通过学习潜在函数以生成新数据点，从而适用于回归和分类任务。这一特性使得模型无需为每个新任务重新训练整个模型，能够处理少量样本的学习任务。潜在函数通过上下文数据点进行近似，能够适应不同数量的数据点，处理高维输入数据，甚至非结构化数据。此外，模型易于并行化处理数据点，能够处理动态数据和非平稳数据，适用于时间序列预测和在线学习。模型能够处理大规模数据集，适用于生成任务，如生成新的数据样本、图像和文本数据，以及用于推荐系统和强化学习。此外，模型能够处理多模态数据、异质数据、复杂数据结构和半监督学习，甚至用于无监督学习和弱监督学习。因此，模型能够处理多种类型的数据，包括动态、非平稳、多模态和异质数据，适用于多种学习任务，如迁移学习、因果推理和多任务学习。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>模型能够学习数据的生成过程。</li>
<li>学习潜在函数以生成新数据点。</li>
<li>可以用于回归和分类任务。</li>
<li>不需要为每个新任务重新训练整个模型。</li>
<li>能够处理少量样本的学习任务。</li>
<li>潜在函数通过上下文数据点进行近似。</li>
<li>能够适应不同数量的数据点。</li>
<li>可以用于不确定性建模。</li>
<li>易于并行化处理数据点。</li>
<li>能够处理高维输入数据。</li>
<li>可以与其他模型结合使用。</li>
<li>能够生成新的数据样本。</li>
<li>能够处理非结构化数据。</li>
<li>可以用于跨域学习。</li>
<li>能够处理动态数据。</li>
<li>可以用于在线学习。</li>
<li>能够处理大规模数据集。</li>
<li>可以用于生成任务。</li>
<li>能够处理非平稳数据。</li>
<li>可以用于时间序列预测。</li>
<li>能够处理多模态数据。</li>
<li>可以用于图像生成。</li>
<li>能够处理文本数据。</li>
<li>可以用于推荐系统。</li>
<li>能够处理复杂数据结构。</li>
<li>可以用于强化学习。</li>
<li>能够处理异质数据。</li>
<li>可以用于因果推理。</li>
<li>能够处理多任务学习。</li>
<li>可以用于迁移学习。</li>
<li>能够处理半监督学习。</li>
<li>可以用于无监督学习。</li>
<li>能够处理弱监督学习。</li>
<li>可以用于强化学习。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3>正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2>6. 如何学习分析神经流形（neural manifold）？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/511528279?write</li>
<li>来源：bing</li>
<li>摘要：神经流形（Neural manifold）这个概念的提出和神经科学实验技术的进步紧密相关。双光子钙成像技术 [1] 和高密度电极探针（如Neuropixels [2]）的发明，使得同时记录大量神经元的活动数据成为可能。由 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">双光子钙成像技术与高密度电极探针（如Neuropixels）的结合，使得同时记录大量神经元的活动数据成为可能。首先，双光子钙成像技术能够非侵入性地检测神经元内的钙离子浓度变化，从而反映神经元的活动状态。其次，高密度电极探针，如Neuropixels，能够密集地记录多个神经元的电生理信号，进一步增强了对神经网络动态变化的全面了解。因此，这两种技术的结合极大地提高了神经科学研究的分辨率和深度，使得研究人员能够更准确地捕捉和分析神经网络的复杂活动模式。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>双光子钙成像技术</li>
<li>高密度电极探针（如Neuropixels）</li>
<li>同时记录大量神经元的活动数据成为可能</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3>正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2>7. 如何看待神经架构搜索（Neural Architecture Search）的发展？</h2>
<ul>
<li>链接：https://www.zhihu.com/question/359162202</li>
<li>来源：bing</li>
<li>摘要：2019年12月5日 · 比较有代表性的就是weight sharing加速validation的 Efficient Neural Architecture Search via Parameter Sharing [ICML'18] (咦，还是Google的Quoc V. Le他们)，大概思路就是将NAS …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，Google的Quoc V. Le团队在2018年的ICML会议上提出了Efficient Neural Architecture Search via Parameter Sharing（通过参数共享进行高效神经网络结构搜索），这一方法旨在加速神经网络的验证过程。其次，该方法的核心在于“weight sharing”，即通过共享权重来减少计算量，从而使得在验证阶段能够更快速地进行模型评估。因此，这种方法不仅提高了验证效率，还为神经网络结构的搜索提供了更高效的途径。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>weight sharing加速validation</li>
<li>Efficient Neural Architecture Search via Parameter Sharing [ICML'18]</li>
<li>Google的Quoc V. Le团队</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3>正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2>8. Tnnls发文难度怎么样？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/328114643</li>
<li>来源：bing</li>
<li>摘要：2020年8月10日 · Tnnls发文难度怎么样？ 小白一个，最近准备毕业，想投稿 IEEE Transactions on Neural Networks and Learning Systems ,… 显示全部 关注者 156 被浏览</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，Tnnls作为IEEE下属期刊，发文难度较高，投稿前需确保论文质量，准备充分的实验结果，并进行详细且严谨的理论分析，以确保论文的创新性。其次，投稿前应仔细阅读指南，了解期刊的特定格式要求和范围，这有助于避免审稿过程中的延误。此外，需注意参考文献的格式，确保符合期刊的要求。因此，投稿前的准备工作至关重要，只有充分准备，才能提高论文被接受的可能性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Tnnls发文难度较高</li>
<li>Tnnls是IEEE下属期刊</li>
<li>投稿前需确保论文质量</li>
<li>需遵循期刊特定格式要求</li>
<li>审稿过程可能较长</li>
<li>投稿前应了解期刊范围</li>
<li>需准备充分的实验结果</li>
<li>理论分析需详细且严谨</li>
<li>结论需有创新性</li>
<li>需注意参考文献格式</li>
<li>投稿前应仔细阅读指南</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3>正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2>9. Neural Operator算是PINN范畴里面吗？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/629992250</li>
<li>来源：bing</li>
<li>摘要：Neural Operator算是PINN范畴里面吗，比如FNO，DeepONet这些？还是说只有狭义的PINN(Raissi最初提出的，…</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，Neural Operator与Physics-Informed Neural Network (PINN)存在交集，但并不完全等同。其次，狭义的PINN特指Raissi最初提出的模型，其核心在于将物理定律转化为神经网络的损失函数，从而实现对物理系统的建模。此外，FNO（Fourier Neural Operator）和DeepONet均属于PINN范畴，它们通过不同的机制实现了对物理过程的建模，其中FNO利用傅里叶变换来捕捉数据的频率信息，而DeepONet则通过主干网络和分支网络的组合来实现对复杂函数的逼近。因此，尽管Neural Operator与PINN有交集，但它们在具体实现和应用场景上有所区别。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Neural Operator与PINN有交集但不完全等同。</li>
<li>狭义的PINN指Raissi最初提出的模型。</li>
<li>FNO属于PINN范畴。</li>
<li>DeepONet属于PINN范畴。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3>正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2>10. NEURAL NETWORKS - SCI期刊点评 - 小木虫论坛-学术科研 ...</h2>
<ul>
<li>链接：https://muchong.com/bbs/journal.php?view=detail&amp;jid=6154</li>
<li>来源：bing</li>
<li>摘要：2020年8月31日 · 小木虫论坛-SCI期刊点评专栏：拥有来自国内各大院校、科研院所的博硕士研究生和企业研发人员对期刊的专业点评，覆盖了8000+ SCI期刊杂志的专业点评信息，为国内外学术科研人员 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">期刊《NEURAL NETWORKS》（ISSN：0893-6080）每月出版一次，由PERGAMON-ELSEVIER SCIENCE LTD出版，读者可以通过其官方网站（http://www.elsevier.com/wps/find/journal/a ... ome/841/description）获取更多信息。投稿者可直接通过在线投稿网址（http://ees.elsevier.com/neunet/）提交稿件，该期刊的投稿录用比例为75%，但审稿过程相对较长，平均耗时10.2个月。此外，该期刊的处理速度对于修回稿件而言较为缓慢。尽管如此，只要论文具有创新点，即使未能一次性通过审稿人的意见，经过修改后仍有可能被接受。值得注意的是，该期刊对细节的要求比IEEE trans更为严格，投稿者需特别关注格式等细节。因此，尽管投稿周期较长，但只要论文质量足够，仍有机会被录用。该期刊的档次介于1区和2区之间，因此投稿者需确保论文质量以符合其要求。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>期刊名称：NEURAL NETWORKS</li>
<li>出版周期：Monthly</li>
<li>ISSN：0893-6080</li>
<li>通讯地址：PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND, OX5 1GB</li>
<li>期刊主页：http://www.elsevier.com/wps/find/journal/a ... ome/841/description</li>
<li>在线投稿网址：http://ees.elsevier.com/neunet/</li>
<li>投稿录用比例：75%</li>
<li>审稿速度：平均10.2个月</li>
<li>审稿费用：-</li>
<li>版面费用：-</li>
<li>投稿周期：约3-6个月</li>
<li>录用情况：已投修改后录用或被拒</li>
<li>期刊档次：介于1区和2区之间</li>
<li>注重细节：格式等细节比IEEE trans要求还要严格</li>
<li>处理速度：针对修回稿件处理速度比较慢</li>
<li>创新点：只要论文创新点够，解决审稿人意见就可以被接收</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3>正文（抓取，非 AI）</h3>
<p>NEURAL NETWORKS - SCI期刊点评 - 小木虫论坛-学术科研互动平台 版块导航 正在加载中... 客户端APP下载 论文辅导 调剂小程序 登录 注册 帖子 帖子 用户 本版 24小时热门版块排行榜 小木虫论坛-学术科研互动平台 » SCI期刊点评 SCI期刊检索 研究方向 热评期刊 最新点评 我收藏的期刊 我点评的期刊 查阅参考文献 基本资料 该期刊扩展资料，欢迎小木虫资深虫友来补充。一起完善，供大家参考。为了保证质量，目前只有金币大于50个的虫子可以参与期刊点评。 SCI期刊名： NEURAL NETWORKS NEURAL NETWORKS 我要投此期刊 出版周期： Monthly 出版ISSN： 0893-6080 通讯方式： PERGAMON-ELSEVIER SCIENCE LTD, THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND, OX5 1GB 期刊主页网址： http://www.elsevier.com/wps/find ... ome/841/description 在线投稿网址： http://ees.elsevier.com/neunet/ 其他相关链接： Science Citation Index Science Citation Index Expanded Current Contents - Engineering, Computing &amp; Technology BIOSIS Previews 虫友提供资料,仅供参考（ 24 人参与，76841 人阅读） 偏重的研究方向： 信息科学 (9) 自动化 (5) 计算机科学 (4) 计算机应用技术 (3) 模式识别 (2) 自然语言理解与机器翻译 (1) 认知科学及智能信息处理 (1) 控制理论与方法 (1) 人工智能与知识工程 (1) 投稿录用比例： 75 % (计算公式：参与点评网友投稿录用人数/总点评网友人数×100%) 审稿速度： 平均 10.2 个月的审稿周期 (非官方数据) 审稿费用： - (非官方数据) 版面费用： - (非官方数据) 期刊“小木虫投稿价值”历年趋势图（投稿价值趋势图供投稿时选择参考。其中数据不承担真实性） 此期刊相关讨论贴 | 我要收藏此期刊 (取消收藏) | 我要点评两句 | 分享到： 期刊点评列表 #1 作者： 淡如水2012 ( 联系作者 | 作者点评过的期刊 ) 时间：2020-08-31 13:39 纠错举报 对我有帮助 0 第二次中NN了 研究方向: 信息科学 计算机科学 自然语言理解与机器翻译 投稿周期: 约3个月 录用情况: 已投修改后录用 #2 作者： embeddedpeng ( 联系作者 | 作者点评过的期刊 ) 时间：2020-05-27 15:19 纠错举报 对我有帮助 2 19年投稿两篇论文，第一篇经历12个月录用，第二篇快一点儿8个月录用，总体感觉期刊档次应该介于1区和2区之间这个档次，期刊注重格式等细节这方面比IEEE trans要求还要严格，期刊针对修回稿件处理速度比较慢，并没有同期投稿TNNLS的处理快，不知道2020年期刊现在降为2区了，希望期刊能够早日升回1区，就给我个人感受和TNNLS期刊应该同属于一个档次的。 研究方向: 信息科学 自动化 认知科学及智能信息处理 投稿周期: 约12个月 录用情况: 已投修改后录用 #3 作者： srtthree ( 联系作者 | 作者点评过的期刊 ) 时间：2020-05-25 17:01 纠错举报 对我有帮助 6 投稿两个月后修回，然后一个月后录用。只要论文创新点够，把审稿人意见逐条认真解决了，就可以被接收。 研究方向: 信息科学 计算机科学 计算机应用技术 投稿周期: 约3个月 录用情况: 已投修改后录用 #4 作者： forschumi ( 联系作者 | 作者点评过的期刊 ) 时间：2019-07-04 09:16 纠错举报 对我有帮助 4 2019-03-18 Submitted to Journal 2019-03-19 With Editor 2019-03-22 Editor Invited 2019-03-23 Under Review 2019-05-05 Under Review 2019-06-07 Required Reviews Completed (Action Editor is on a holiday) 2019-06-28 Decision in Process 2019-07-03 Completed - Reject 研究方向: 信息科学 自动化 模式识别 投稿周期: 约6个月 录用情况: 已投被拒 #5 作者： dingpan2005 ( 联系作者 | 作者点评过的期刊 ) 时间：2019-02-22 22:10 纠错举报 对我有帮助 0 中科院情报所官方 微信测算2019年该刊物影响因子是5.3，求证 请登录 查看更多...</p></div></details>
</div>
<script>
var articles=[]; var currentArticleIdx=-1; var maxSpeakChars=3500;
function buildArticles(){ var c=document.querySelector('.content'); if(!c) return; var h2s=c.querySelectorAll('h2'); for(var i=0;i<h2s.length;i++){ var start=h2s[i], end=i+1<h2s.length?h2s[i+1]:null; var r=document.createRange(); r.setStart(start,0); if(end) r.setEnd(end,0); else { var last=c.lastElementChild||c; r.setEndAfter(last); } var t=r.toString().replace(/\s+/g,' ').trim(); if(t.length>maxSpeakChars) t=t.slice(0,maxSpeakChars)+'…（内容过长已截断）'; articles.push({h2:start,text:t}); }
 articles.sort(function(a,b){ return a.text.length-b.text.length; }); }
function speakText(t){ if(!t){ document.getElementById('readStatus').textContent=''; return; }
 speechSynthesis.cancel(); var status=document.getElementById('readStatus'); status.textContent='准备中…';
 var chunks=[]; var maxLen=280; for(var i=0;i<t.length;i+=maxLen){ var s=t.slice(i,i+maxLen); var j=s.lastIndexOf('。'); if(j>80){ chunks.push(s.slice(0,j+1)); i-=s.length-(j+1); } else chunks.push(s); }
 if(chunks.length===0) chunks=[t]; var idx=0; function speakNext(){ if(idx>=chunks.length){ status.textContent=''; return; } var u=new SpeechSynthesisUtterance(chunks[idx]); u.lang='zh-CN'; u.rate=0.95; var v=speechSynthesis.getVoices().filter(function(x){ return x.lang.indexOf('zh')>=0; })[0]; if(v) u.voice=v;
 u.onend=function(){ idx++; setTimeout(speakNext,80); }; u.onerror=function(){ idx++; setTimeout(speakNext,80); }; status.textContent='朗读中 '+(idx+1)+'/'+chunks.length+'…'; speechSynthesis.speak(u); }
 if(speechSynthesis.getVoices().length) speakNext(); else speechSynthesis.onvoiceschanged=function(){ speechSynthesis.onvoiceschanged=null; speakNext(); }; }
function nextArticle(){ if(articles.length===0) buildArticles(); if(articles.length===0){ document.getElementById('readStatus').textContent='无可读内容'; return; }
 speechSynthesis.cancel(); currentArticleIdx++; if(currentArticleIdx>=articles.length){ currentArticleIdx=0; document.getElementById('readStatus').textContent='已读完，共 '+articles.length+' 篇。再按从第 1 篇开始'; return; }
 var a=articles[currentArticleIdx]; a.h2.scrollIntoView({behavior:'smooth',block:'start'}); document.getElementById('readStatus').textContent='第 '+(currentArticleIdx+1)+' / '+articles.length+' 篇'; speakText(a.text); }
function readSelected(){ var sel=window.getSelection(); var t=(sel&&sel.toString)?sel.toString():''; t=t.replace(/\\s+/g,' ').trim(); if(!t){ document.getElementById('readStatus').textContent='请先选中要朗读的段落'; return; } speechSynthesis.cancel(); document.getElementById('readStatus').textContent='朗读选中内容…'; speakText(t); }
function getBlockForTap(el){ var c=document.querySelector('.content'); var blockTags=['P','DIV','H2','H3','H4','LI','PRE']; while(el&&el!==c){ if(c.contains(el)&&blockTags.indexOf(el.tagName)!==-1) return el; el=el.parentElement; } return null; }
function onContentTap(e){ if(e.target.closest&&e.target.closest('a')) return; var block=getBlockForTap(e.target); if(block){ var t=(block.innerText||'').trim().replace(/\\s+/g,' '); if(t){ e.preventDefault(); speechSynthesis.cancel(); document.getElementById('readStatus').textContent='朗读本段…'; speakText(t); } } }
if(document.readyState==='loading'){ document.addEventListener('DOMContentLoaded', function(){ buildArticles(); var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }); } else { buildArticles(); var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }
</script>
</body>
</html>
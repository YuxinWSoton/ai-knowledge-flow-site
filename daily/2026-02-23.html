<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>知识流日报 2026-02-23：PPO、PTM、谐振抑制、智能调度、SCFC、ZS-IP、表面燃烧器、稳定性机理、FedZMG、构网型变流器、随机低碳调度、超短期负荷预测、有源和无源阻尼、多阶段优化规划、ChatQDA</title>
<style>
  * { box-sizing: border-box; }
  body {
    font-family: system-ui, sans-serif;
    max-width: 720px;
    margin: 0 auto;
    padding: 2rem 1rem;
    color: #fff;
    min-height: 100vh;
    background: #0a0e1a;
    background-image:
      radial-gradient(2px 2px at 20px 30px, rgba(255,255,255,0.9), transparent),
      radial-gradient(2px 2px at 40px 70px, rgba(255,255,255,0.6), transparent),
      radial-gradient(1.5px 1.5px at 90px 40px, rgba(255,255,255,0.8), transparent),
      radial-gradient(2px 2px at 130px 80px, rgba(255,255,255,0.5), transparent),
      radial-gradient(1.5px 1.5px at 160px 120px, rgba(255,255,255,0.7), transparent),
      radial-gradient(ellipse 120% 100% at 50% 0%, rgba(88,60,120,0.25), transparent 50%),
      radial-gradient(ellipse 80% 80% at 80% 20%, rgba(40,60,100,0.2), transparent 40%);
    background-size: 200px 200px;
    background-repeat: repeat;
  }
  a { color: #a8d4ff; text-decoration: none; }
  a:hover { text-decoration: underline; }
 html{scroll-behavior:smooth;} .content h2,.content h3{scroll-margin-top:1rem;} h1,h2,h3{margin-top:1.5rem;color:#fff;} pre{white-space:pre-wrap;color:rgba(255,255,255,0.9);} .toolbar{margin:0.5rem 0;color:rgba(255,255,255,0.8);} .content{color:rgba(255,255,255,0.95);} .content a{color:#a8d4ff;} .meta{color:rgba(255,255,255,0.65);font-size:0.9em;} .toc{margin:1rem 0;padding:0.8rem 1rem;background:rgba(255,255,255,0.08);border-radius:6px;} .toc .toc-title{margin:0 0 0.5rem 0;font-weight:bold;color:rgba(255,255,255,0.9);} .toc ul{list-style:none;padding-left:0;margin:0;} .toc li{margin:0.35rem 0;} .toc li.toc-h3{padding-left:1em;font-size:0.95em;} .toc a{color:#a8d4ff;text-decoration:none;} .toc a:hover{text-decoration:underline;} .content p,.content div,.content h2,.content h3,.content h4,.content li,.content pre{cursor:pointer;-webkit-tap-highlight-color:rgba(255,255,255,0.15);} .content .insight-summary{color:#c9a0dc;margin:0.5em 0 0.8em 0;} .content .insight-detail,.content .insight-detail li{color:#8dd4e8;list-style:disc;margin-left:1.2em;padding-left:0.3em;} .content .article-body-details{margin:0.8em 0;} .content .article-body-details summary{cursor:pointer;color:rgba(255,255,255,0.85);}</style>
</head>
<body>
<p><a href="https://YuxinWSoton.github.io/ai-knowledge-flow-site/">← 返回首页</a></p>
<h1>知识流日报 2026-02-23：PPO、PTM、谐振抑制、智能调度、SCFC、ZS-IP、表面燃烧器、稳定性机理、FedZMG、构网型变流器、随机低碳调度、超短期负荷预测、有源和无源阻尼、多阶段优化规划、ChatQDA</h1>
<p class="meta" style="margin-top:0;">最后更新：2026-02-23 22:59</p>
<p class="toolbar"><button id="btnFull" onclick="readFullText()">全文朗读</button> <span id="readStatus"></span></p>
<p class="meta" style="margin-top:0;">（点任意段落可朗读该段；「全文朗读」读本页全部内容）</p>
<nav class="toc" aria-label="目录">
<p class="toc-title">目录</p>
<ul>
  <li><a href="#toc-0">1. 深度强化学习SAC、PPO、TD3、DDPG比较？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-1">正文</a></li>
  <li><a href="#toc-2">2. 强化学习的近端策略优化（PPO）中，近端（Proximal）是 ...</a></li>
  <li class="toc-h3"><a href="#toc-3">正文</a></li>
  <li><a href="#toc-4">3. 在强化学习 PPO 算法中，为什么可以把 KL 散度直接放进负 ...</a></li>
  <li class="toc-h3"><a href="#toc-5">正文</a></li>
  <li><a href="#toc-6">4. PPO强化学习如何实现多维度的动作呢？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-7">正文</a></li>
  <li><a href="#toc-8">5. 为什么PPO使用KL散度，而不是交叉熵损失？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-9">正文</a></li>
  <li><a href="#toc-10">6. 强化学习很多ac架构的算法比如ppo，为什么使用状态价值 ...</a></li>
  <li class="toc-h3"><a href="#toc-11">正文</a></li>
  <li><a href="#toc-12">7. 在PPO算法的官方实现中，为什么更新critic网络时用的是Q ...</a></li>
  <li class="toc-h3"><a href="#toc-13">正文</a></li>
  <li><a href="#toc-14">8. 在强化学习中，为什么TRPO和PPO算法属于On-Policy的算法？</a></li>
  <li class="toc-h3"><a href="#toc-15">正文</a></li>
  <li><a href="#toc-16">9. F-P谐振腔的实际应用是什么，工作原理是什么？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-17">正文</a></li>
  <li><a href="#toc-18">10. 品质因数Q如何理解？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-19">正文</a></li>
  <li><a href="#toc-20">11. 哪些调度算法非常经典？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-21">正文</a></li>
  <li><a href="#toc-22">12. 可调度数眼镜的核心技术会是什么？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-23">正文</a></li>
  <li><a href="#toc-24">13. 什么是智能体（AI Bot）？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-25">正文</a></li>
  <li><a href="#toc-26">14. 自动化仓储系统中的智能调度算法如何优化？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-27">正文</a></li>
  <li><a href="#toc-28">15. 近年来，国内外在操作系统智能化（AI for OS）方向有哪些 ...</a></li>
  <li class="toc-h3"><a href="#toc-29">正文</a></li>
  <li><a href="#toc-30">16. 请问研究生方向是智能优化算法，这个方向找的工作是进互联 ...</a></li>
  <li class="toc-h3"><a href="#toc-31">正文</a></li>
  <li><a href="#toc-32">17. 如何用Bode图判断系统的稳定性？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-33">正文</a></li>
  <li><a href="#toc-34">18. 电力系统中，什么是构网型控制? - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-35">正文</a></li>
  <li><a href="#toc-36">19. 构网型逆变器和构网型变流器他们的并网功率同步环的工作原理?</a></li>
  <li class="toc-h3"><a href="#toc-37">正文</a></li>
  <li><a href="#toc-38">20. 构网型储能变流器的基本组成与运行模式，覆盖电池特性 ...</a></li>
  <li class="toc-h3"><a href="#toc-39">正文</a></li>
  <li><a href="#toc-40">21. 构网型逆变器相关方向怎么样? - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-41">正文</a></li>
  <li><a href="#toc-42">22. 计算机里随机数的原理是什么？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-43">正文</a></li>
  <li><a href="#toc-44">23. 什么是伪随机和真随机？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-45">正文</a></li>
  <li><a href="#toc-46">24. Excel表格中如何生成特定平均数的一组数据？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-47">正文</a></li>
  <li><a href="#toc-48">25. 随机变量到底是啥，求一个清晰易懂的理解是啥? - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-49">正文</a></li>
  <li><a href="#toc-50">26. 如何从深刻地理解随机过程的含义？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-51">正文</a></li>
  <li><a href="#toc-52">27. OI里“保证数据随机”意味着题目满足什么隐含条件？</a></li>
  <li class="toc-h3"><a href="#toc-53">正文</a></li>
  <li><a href="#toc-54">28. Win11电池图标消失？全面解决方案来了 - CSDN博客</a></li>
  <li class="toc-h3"><a href="#toc-55">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-56">29. 终于！Windows 11任务栏可以显示电量百分比了_凤凰网</a></li>
  <li class="toc-h3"><a href="#toc-57">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-58">30. qPTM | Home</a></li>
  <li class="toc-h3"><a href="#toc-59">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-60">31. 翻译后修饰之间的交互作用举例 | Cell Signaling Technology</a></li>
  <li class="toc-h3"><a href="#toc-61">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-62">32. PTM</a></li>
  <li class="toc-h3"><a href="#toc-63">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-64">33. 蛋白翻译后修饰（PTM）研究超全指南（上）</a></li>
  <li class="toc-h3"><a href="#toc-65">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-66">34. 微软重构 Windows 11 任务栏电池图标！现已支持红绿橙三 ...</a></li>
  <li class="toc-h3"><a href="#toc-67">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-68">35. PTM翻译后修饰预测工具_netphos-CSDN博客</a></li>
  <li class="toc-h3"><a href="#toc-69">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-70">36. Strong conflict-free connection of graphs</a></li>
  <li class="toc-h3"><a href="#toc-71">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-72">37. MARS: Margin-Aware Reward-Modeling with Self-Refinement</a></li>
  <li class="toc-h3"><a href="#toc-73">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-74">38. Composable Model-Free RL for Navigation with Input-Affine Systems</a></li>
  <li class="toc-h3"><a href="#toc-75">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-76">39. AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection</a></li>
  <li class="toc-h3"><a href="#toc-77">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-78">40. Dynamic Interference Management for TN-NTN Coexistence in the Upper Mid-Band</a></li>
  <li class="toc-h3"><a href="#toc-79">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-80">41. Advancing Analytic Class-Incremental Learning through Vision-Language Calibration</a></li>
  <li class="toc-h3"><a href="#toc-81">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-82">42. TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents</a></li>
  <li class="toc-h3"><a href="#toc-83">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-84">43. Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications</a></li>
  <li class="toc-h3"><a href="#toc-85">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-86">44. MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training</a></li>
  <li class="toc-h3"><a href="#toc-87">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-88">45. Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing</a></li>
  <li class="toc-h3"><a href="#toc-89">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-90">46. Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes</a></li>
  <li class="toc-h3"><a href="#toc-91">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-92">47. Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO</a></li>
  <li class="toc-h3"><a href="#toc-93">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-94">48. C3Box: A CLIP-based Class-Incremental Learning Toolbox</a></li>
  <li class="toc-h3"><a href="#toc-95">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-96">49. PACE: Pretrained Audio Continual Learning</a></li>
  <li class="toc-h3"><a href="#toc-97">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-98">50. Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study</a></li>
  <li class="toc-h3"><a href="#toc-99">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-100">51. Scaling Continual Learning with Bi-Level Routing Mixture-of-Experts</a></li>
  <li class="toc-h3"><a href="#toc-101">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-102">52. FedZMG: Efficient Client-Side Optimization in Federated Learning</a></li>
  <li class="toc-h3"><a href="#toc-103">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-104">53. Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach</a></li>
  <li class="toc-h3"><a href="#toc-105">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-106">54. ExO-PPO: an Extended Off-policy Proximal Policy Optimization Algorithm</a></li>
  <li class="toc-h3"><a href="#toc-107">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-108">55. 微软更新Win11任务栏电池图标 支持彩色提示与百分比显示 ...</a></li>
  <li class="toc-h3"><a href="#toc-109">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-110">56. Conflict-free connections: algorithm and complexity</a></li>
  <li class="toc-h3"><a href="#toc-111">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-112">57. Statistical Confidence in Functional Correctness: An Approach for AI Product Functional Correctness Evaluation</a></li>
  <li class="toc-h3"><a href="#toc-113">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-114">58. MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learning</a></li>
  <li class="toc-h3"><a href="#toc-115">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-116">59. SCOPE: A Training-Free Online 3D Deployment for UAV-BSs with Theoretical Analysis and Comparative Study</a></li>
  <li class="toc-h3"><a href="#toc-117">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-118">60. Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds</a></li>
  <li class="toc-h3"><a href="#toc-119">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-120">61. Revisiting Weight Regularization for Low-Rank Continual Learning</a></li>
  <li class="toc-h3"><a href="#toc-121">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-122">62. Stacked Cross-modal Feature Consolidation Attention Networks for Image Captioning</a></li>
  <li class="toc-h3"><a href="#toc-123">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-124">63. 什么是智能体（AI Bot）？</a></li>
  <li class="toc-h3"><a href="#toc-125">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-126">64. A probabilistic foundation model for crystal structure denoising, phase classification, and order parameters</a></li>
  <li class="toc-h3"><a href="#toc-127">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-128">65. Self-Evolving Multi-Agent Network for Industrial IoT Predictive Maintenance</a></li>
  <li class="toc-h3"><a href="#toc-129">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-130">66. Compact LLM Deployment and World Model Assisted Offloading in Mobile Edge Computing</a></li>
  <li class="toc-h3"><a href="#toc-131">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-132">67. Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study</a></li>
  <li class="toc-h3"><a href="#toc-133">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-134">68. Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets</a></li>
  <li class="toc-h3"><a href="#toc-135">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-136">69. 内外兼修 尼康Z f详细评测_器材_色影无忌</a></li>
  <li class="toc-h3"><a href="#toc-137">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-138">70. 大模型优化利器：RLHF之PPO、DPO</a></li>
  <li class="toc-h3"><a href="#toc-139">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-140">71. 知乎盐选 | 7.2 谐振法测量元件参数</a></li>
  <li class="toc-h3"><a href="#toc-141">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-142">72. 尼康（中国） - Z f - 产品介绍</a></li>
  <li class="toc-h3"><a href="#toc-143">正文（抓取，非 AI）</a></li>
</ul>
</nav>
<div class="content">
<h1>知识流日报 2026-02-23：PPO、PTM、谐振抑制、智能调度、SCFC、ZS-IP、表面燃烧器、稳定性机理、FedZMG、构网型变流器、随机低碳调度、超短期负荷预测、有源和无源阻尼、多阶段优化规划、ChatQDA</h1>
<p>共 72 条（来自百度学术 / Google / Bing 等，仅含正文抓取成功的条目；按正文长度从短到长排列，便于先听短的）。</p>
<p>（以下含抓取正文，便于阅读。未调用任何 AI API。）</p>
<p>（仅前 50 条含模型提取的「易漏细节」关键点，页面上以颜色区分；第 51 条及之后未调用模型，故无易漏细节。可在 config 中调大 extract_insights_max_items 以增加条数。）</p>
<h2 id="toc-0">1. 深度强化学习SAC、PPO、TD3、DDPG比较？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/6699179413</li>
<li>来源：bing</li>
<li>摘要：该页面讨论了深度强化学习中SAC、PPO、TD3和DDPG算法的比较，适合对相关领域感兴趣的读者深入了解。</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">SAC算法基于软Q学习，具有更好的探索能力，其“软”目标网络更新策略使得它在策略更新时更加平滑，从而避免了硬更新可能带来的不稳定问题。PPO算法通过多步采样和策略梯度，提高了样本利用效率，并通过clip机制平衡了策略更新的稳定性和效率，使得策略更新更加平滑。TD3算法通过双Q网络，缓解了价值过估计问题，同时通过延迟策略更新避免了过拟合问题。DDPG算法通过Actor-Critic结构，适用于连续动作空间问题，其经验回放机制增强了学习的稳定性和泛化能力。因此，SAC、PPO、TD3和DDPG各有侧重点，选择时需根据具体应用场景来决定，以确保算法能够有效地解决特定问题。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>SAC算法基于软Q学习，具有更好的探索能力。</li>
<li>PPO算法通过多步采样和策略梯度，提高了样本利用效率。</li>
<li>TD3算法通过双Q网络，缓解了价值过估计问题。</li>
<li>DDPG算法通过Actor-Critic结构，适用于连续动作空间问题。</li>
<li>SAC、PPO、TD3和DDPG各有侧重点，选择时需考虑具体应用场景。</li>
<li>SAC算法中的“软”意味着它使用了软目标网络更新策略。</li>
<li>PPO算法通过clip机制，平衡了策略更新的稳定性和效率。</li>
<li>TD3算法通过延迟策略更新，避免了过拟合问题。</li>
<li>DDPG算法通过经验回放，增强了学习的稳定性和泛化能力。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-1">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-2">2. 强化学习的近端策略优化（PPO）中，近端（Proximal）是 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/564398062</li>
<li>来源：bing</li>
<li>摘要：但是客观的说，PPO算法的原文作者 John Schulman等人并未在该论文中对PPO整个算法的数学推导做太多论述，而更多的是从目标函数的设计思路与实现来说的（我打算给作者致函问一下） …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">PPO算法作为强化学习领域的一种策略优化方法，其核心思想在于通过平衡策略的探索与利用来提升性能，然而，其背后的数学推导在原文中较少涉及，作者也未对PPO算法的数学细节进行深入解释。这使得对于PPO算法的数学推导部分，读者可能会感到较为模糊，难以全面理解算法的运作机制。因此，对于希望深入了解PPO算法的读者而言，有必要进一步查阅相关资料，以弥补这一部分的不足，从而更加全面地掌握PPO算法的原理和应用。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>PPO算法的数学推导在原文中较少涉及；作者对PPO算法的数学细节未做深入解释。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-3">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-4">3. 在强化学习 PPO 算法中，为什么可以把 KL 散度直接放进负 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/629107126</li>
<li>来源：bing</li>
<li>摘要：2025年2月12日 · 在强化学习 PPO 算法中，为什么可以把 KL 散度直接放进负奖励？ 众所周知 KL divergence 所涉及优化在 PPO 算法里面有2种方式，PPO-Penalty and PPO-Clip。 前者将 KL …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">KL 散度的直接控制有助于稳定训练过程，而PPO算法通过奖励机制间接调整了策略的KL散度，这种机制使得新策略与旧策略的分布尽可能接近，从而避免了过度拟合。PPO-Clip方法通过限制策略更新的幅度间接影响了KL散度，而PPO-Penalty方法则直接惩罚超出期望KL散度的策略更新，这进一步确保了模型的行为在期望范围内。此外，KL散度的优化目标是使新策略与旧策略的分布尽可能接近，因此，通过奖励机制，PPO算法能够灵活调整KL散度的控制方式，从而更有效地管理模型的行为。因此，KL散度的控制对于避免过度拟合至关重要，而PPO算法通过负奖励的方式间接控制了模型的行为，KL 散度直接放进负奖励可以将模型的 KL 散度控制在期望范围内。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>KL 散度直接放进负奖励可以将模型的 KL 散度控制在期望范围内。</li>
<li>PPO 算法通过负奖励的方式间接控制了模型的行为。</li>
<li>PPO-Clip 方法通过限制策略更新的幅度间接影响了 KL 散度。</li>
<li>PPO-Penalty 方法直接惩罚超出期望 KL 散度的策略更新。</li>
<li>KL 散度的直接控制有助于稳定训练过程。</li>
<li>KL 散度的优化目标是使新策略与旧策略的分布尽可能接近。</li>
<li>PPO 算法通过奖励机制间接调整了策略的 KL 散度。</li>
<li>KL 散度的控制对于避免过度拟合至关重要。</li>
<li>PPO 算法通过奖励机制可以灵活调整 KL 散度的控制方式。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-5">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-6">4. PPO强化学习如何实现多维度的动作呢？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/417161289</li>
<li>来源：bing</li>
<li>摘要：2021年11月5日 · PPO的强化学习如何实现多维度的动作呢，比如我的action是5维，是Actor根据state输出一个正态分布采样5个…</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">PPO算法通过正态分布采样来实现多维度动作，这一机制使得算法能够在复杂的动作空间中进行有效的探索和优化。正态分布采样能够生成一系列可能的动作，从而使得模型能够从多个角度出发，尝试不同的策略组合。这种多维度的动作采样方式不仅提高了算法的灵活性，还增强了其在处理复杂任务时的适应性，使得模型能够更有效地学习到最优的动作策略。因此，尽管这一过程可能容易被忽视，但正态分布采样在PPO算法中扮演着至关重要的角色。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>PPO算法通过正态分布采样来实现多维度动作。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-7">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-8">5. 为什么PPO使用KL散度，而不是交叉熵损失？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/2004944038659387885</li>
<li>来源：bing</li>
<li>摘要：若在 PPO 中使用交叉熵，则会使其退化为监督学习微调（SFT），仅仅学习标准答案，偏离了强化学习通过最大化期望奖励-reward（或优势函数-adventage）进行探索和优化的本质。 下面 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">PPO（Proximal Policy Optimization）算法使用KL散度作为损失函数，能够保持模型的探索能力，确保模型不仅学习标准答案，还能探索多种可能的解决方案。相比之下，使用交叉熵损失则会导致模型仅学习标准答案，退化为监督学习微调，从而丧失了探索新策略的能力。因此，PPO的目标是最大化期望奖励，而不仅仅是学习正确答案，这使得PPO在长期和复杂任务中表现出色，能够适应不断变化的环境。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>PPO使用KL散度可以保持模型的探索能力；</li>
<li>使用交叉熵损失会导致模型仅学习标准答案；</li>
<li>PPO的目标是最大化期望奖励而非仅仅学习正确答案；</li>
<li>交叉熵损失使模型退化为监督学习微调。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-9">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-10">6. 强化学习很多ac架构的算法比如ppo，为什么使用状态价值 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/667518179</li>
<li>来源：bing</li>
<li>摘要：Step 3：学习PPO，重点理解信任域。 PPO算法的创新点在于它引入了信任域，防止策略变动过大带来的不稳定性。 多看看它的损失函数和策略更新的部分，知道为啥它需要V网络而不是Q网 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">使用状态价值网络（V网络）可以稳定策略更新过程，通过估计状态的价值来帮助控制策略更新的幅度，从而确保策略的改进是逐步且稳定的。然而，Q网络因其设计目的不同，不能直接用于PPO中的策略更新，这表明需要采用不同的方法来实现策略的优化。此外，信任域机制有助于保持旧策略的有效性，防止新策略过于激进，从而在策略更新过程中提供必要的保护，确保整个过程的平滑过渡。因此，通过结合V网络和信任域机制，可以有效地稳定和优化策略更新过程，确保策略改进的稳健性和可靠性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>使用状态价值网络可以稳定策略更新过程。</li>
<li>V网络通过估计状态的价值，帮助控制策略更新的幅度。</li>
<li>Q网络不能直接用于PPO中的策略更新，因为其设计目的不同。</li>
<li>信任域机制有助于保持旧策略的有效性，防止新策略过于激进。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-11">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-12">7. 在PPO算法的官方实现中，为什么更新critic网络时用的是Q ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/626325093</li>
<li>来源：bing</li>
<li>摘要：2025年2月13日 · 在PPO算法的官方实现中，为什么更新critic网络时用的是Q值而不是V值呢？ 在PPO算法的官方实现中，critic网络在更新时使用了value和 (advantage+value)的平方差，前者 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">critic网络更新时使用Q值而非V值，这是因为Q值不仅包含了状态价值，还反映了动作价值的差异。这种差异使得Q值能够更精确地捕捉到动作对价值函数的具体影响，从而有助于更准确地调整critic网络。相比之下，V值仅反映状态的整体价值，未能体现动作的选择性影响。因此，使用Q值可以更好地反映动作对价值函数的影响，进而提高学习算法的效率和准确性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>critic网络更新时使用Q值而非V值；Q值包含了状态价值和动作价值的差异；使用Q值有助于更精确地调整critic网络；Q值考虑了动作的选择性影响；V值仅反映状态的整体价值；Q值能更好地反映动作对价值函数的影响。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-13">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-14">8. 在强化学习中，为什么TRPO和PPO算法属于On-Policy的算法？</h2>
<ul>
<li>链接：https://www.zhihu.com/question/321713509/answers/updated</li>
<li>来源：bing</li>
<li>摘要：2025年9月1日 · RLHF-PPO的四大模型 相比传统PPO算法，RLHF-PPO模型架构更为复杂，一共包含4个模型，比传统PPO多出了 参考模型（Reference Model） 和 奖励模型（Reward …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">On-Policy算法意味着算法更新基于当前策略产生的数据，这与Off-Policy算法不同，后者可以利用旧策略的数据进行更新。参考模型用于评估当前策略的好坏，但不直接参与策略更新，仅提供参考信息。奖励模型则用于生成或调整奖励信号，同样不直接参与策略更新，而是提供额外的反馈机制。TRPO（Trust Region Policy Optimization）和PPO（Proximal Policy Optimization）算法更新基于与当前策略交互获得的数据，而非旧策略的数据，这确保了策略的连续性和稳定性。传统PPO算法仅包含策略模型，而RLHF-PPO（Reinforcement Learning from Human Feedback-PPO）则在此基础上增加了参考模型和奖励模型，使得策略优化过程更加全面和精细，从而提高了策略的质量和适应性。因此，通过引入参考模型和奖励模型，RLHF-PPO能够更有效地利用当前策略的数据进行优化，进一步提升策略的表现。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>On-Policy算法意味着算法更新基于当前策略产生的数据。</li>
<li>参考模型用于评估当前策略的好坏，但不直接参与策略更新。</li>
<li>奖励模型用于生成或调整奖励信号，但不直接参与策略更新。</li>
<li>TRPO和PPO算法更新基于与当前策略交互获得的数据，而非旧策略的数据。</li>
<li>传统PPO算法仅包含策略模型，而RLHF-PPO增加了参考模型和奖励模型。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-15">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-16">9. F-P谐振腔的实际应用是什么，工作原理是什么？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/56707047</li>
<li>来源：bing</li>
<li>摘要：F-P谐振腔是法布里-珀罗（Fabry-Pérot）谐振腔的简称，它是由两个平行的反射镜构成的光学谐振腔。 F-P谐振腔在光学和激光领域有着广泛的应用，用于光学干涉、激光器、传感器、光谱学等方面。 工作 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">F-P谐振腔由两个平行的反射镜构成，这一独特的结构使其在光学和激光领域展现出广泛的应用。首先，F-P谐振腔能够用于光学干涉，通过调节反射镜之间的距离，可以精确控制光的干涉效果。其次，它在激光器中也扮演着重要角色，通过调节腔长，可以有效控制激光的波长和稳定性。此外，F-P谐振腔还被应用于传感器技术，通过检测光的反射强度变化，可以实现对环境参数的精确测量。进一步地，F-P谐振腔在光谱学领域也有重要应用，通过分析不同波长光的传输特性，可以进行物质成分的分析和鉴定。因此，F-P谐振腔不仅结构简单，而且功能多样，是现代光学和激光技术中不可或缺的重要组成部分。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>F-P谐振腔由两个平行的反射镜构成。</li>
<li>F-P谐振腔在光学和激光领域有广泛应用。</li>
<li>F-P谐振腔可用于光学干涉。</li>
<li>F-P谐振腔可用于激光器。</li>
<li>F-P谐振腔可用于传感器。</li>
<li>F-P谐振腔可用于光谱学。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-17">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-18">10. 品质因数Q如何理解？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/635207276</li>
<li>来源：bing</li>
<li>摘要：2023年12月16日 · LC谐振回路的品质因数Q，本质是：谐振回路谐振时，一个振荡周期内，谐振回路内储存的能量与损耗掉的能量之比。 为了使得 Q 与角频率 \omega 容易对应起来，可将两个能量之比乘 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">LC谐振回路的品质因数Q反映了谐振回路内储存的能量与损耗掉的能量的比例，这一特性直接决定了回路的性能。Q值越高，意味着在谐振过程中能量损耗越小，回路的品质也就越好。Q值与角频率\(\omega\)有关，但更直接对应的是能量比，即在谐振周期内的能量变化。因此，通过优化LC谐振回路的设计，可以有效提高其品质因数Q，从而减少能量损耗，提升回路的整体性能。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>LC谐振回路的品质因数Q反映了谐振回路内储存的能量与损耗掉的能量的比例。</li>
<li>Q值越高，表示能量损耗越小，回路的品质越好。</li>
<li>Q值与角频率\omega有关，但直接对应的是能量比。</li>
<li>品质因数Q的计算涉及谐振周期内的能量变化。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-19">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-20">11. 哪些调度算法非常经典？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/638589798</li>
<li>来源：bing</li>
<li>摘要：计算机科学领域有许多经典的调度算法，用于管理资源（如CPU、内存、磁盘等）的分配和利用。以下是一些常见的经典调度算法： 先来先服务调度（First Come First Serve，FCFS）：按照任务到达的顺 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">先来先服务调度会按照任务到达的顺序进行处理，这意味着最早到达的任务会首先被处理。然而，这种调度方式可能导致后续到达的任务需要等待过长的时间，因为它们必须依次等待前面的任务完成。此外，先来先服务调度算法不会考虑任务的优先级或运行时间，因此即使某些任务可能需要更紧迫的处理或耗时更短，它们仍然会按照到达顺序被处理，这进一步加剧了后续任务的等待时间问题。因此，虽然先来先服务调度简单直观，但它可能不适合对任务的处理时间有严格要求的场景。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>先来先服务调度会按照任务到达的顺序进行处理。</li>
<li>该算法可能导致后续到达的任务等待时间过长。</li>
<li>先来先服务调度不会考虑任务的优先级或运行时间。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-21">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-22">12. 可调度数眼镜的核心技术会是什么？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/624648587</li>
<li>来源：bing</li>
<li>摘要：2023年10月3日 · 这些元件可以根据用户需求自动调整眼镜参数，以实现最佳视力效果。 这些核心技术允许可调度数眼镜根据佩戴者的视力需求调节焦距，并为各种应用场景（包括阅读、户外活动或者观 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">可调度数眼镜的核心技术允许根据用户视力需求调节焦距，这一特性使得这些眼镜能够适应不同的应用场景，如阅读和户外活动。更重要的是，核心技术使得眼镜参数可以自动调整以优化视力效果，从而确保用户在各种环境下都能获得最佳的视觉体验。因此，这些眼镜不仅能够满足用户在不同场景下的视力需求，还能提供更加舒适和便捷的使用体验。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>可调度数眼镜的核心技术允许根据用户视力需求调节焦距。</li>
<li>这些眼镜能够适应不同的应用场景，如阅读和户外活动。</li>
<li>核心技术使得眼镜参数可以自动调整以优化视力效果。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-23">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-24">13. 什么是智能体（AI Bot）？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/666089616</li>
<li>来源：bing</li>
<li>摘要：（图2 智能体运行引擎的架构图，简化版） 智能体引擎的主要职责体现在以下几个方面： * 任务编排与执行控制：将复杂任务分解为职责相对单一的、可执行的任务序列，并管理任务间的依赖关系与执行顺 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">智能体引擎作为核心组件，负责管理任务间的依赖关系，其重要职责之一便是分解复杂任务，确保任务执行的顺序正确。通过合理地分解任务，智能体引擎能够有效地处理复杂的业务流程，确保每个任务在正确的时机被执行，从而避免因任务依赖关系不明确而导致的执行顺序错误。因此，智能体引擎在保证任务执行的有序性和高效性方面发挥着关键作用。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>智能体引擎负责管理任务间的依赖关系。</li>
<li>分解复杂任务是智能体引擎的重要职责之一。</li>
<li>智能体引擎需确保任务执行的顺序正确。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-25">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-26">14. 自动化仓储系统中的智能调度算法如何优化？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/655378914</li>
<li>来源：bing</li>
<li>摘要：2024年9月11日 · 4. 合作多智能体系统 在多机器人环境中，智能调度算法需要协调不同机器人的行动，以避免冲突并最大化整体效率。 通过建立一个有效的通信和协作框架，各个智能体可以共享信息，协 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">智能体需要共享信息以避免冲突，这要求它们的行动需协调以最大化整体效率。为此，建立有效的通信和协作框架显得至关重要。这些框架不仅能够帮助智能体之间进行有效沟通，还能提供一个平台，让智能体能够共同制定策略，避免因各自行动而产生的冲突。此外，智能调度算法在这一过程中扮演着关键角色，它需考虑机器人的冲突，从而优化整体效率。因此，通信和协作框架与智能调度算法共同构成了智能体高效协作的基础。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>智能体需要共享信息以避免冲突。</li>
<li>智能体的行动需协调以最大化整体效率。</li>
<li>通信和协作框架对智能体至关重要。</li>
<li>智能调度算法需考虑机器人的冲突。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-27">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-28">15. 近年来，国内外在操作系统智能化（AI for OS）方向有哪些 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/582082244</li>
<li>来源：bing</li>
<li>摘要：2024年4月17日 · 「模型调度」 “杀鸡焉用宰牛刀” ：面对不同难度的任务，千帆ModelBuilder提供模型路由方案，自动调度给合适参数规模的模型，实现效果与成本的最优组合，在效果基本持平的情况下， …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">面对不同难度的任务，应选择合适参数规模的模型，以确保既能满足任务需求，又能实现效果与成本的最优组合。这一原则类似于“杀鸡焉用宰牛刀”的比喻，强调了根据具体任务需求选择合适工具的重要性。通过合理选择模型的参数规模，可以避免资源的过度浪费，同时确保任务能够高效、准确地完成。因此，模型调度方案旨在通过这种匹配策略，实现效果与成本的最优平衡。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>面对不同难度的任务，应选择合适参数规模的模型。</li>
<li>模型调度方案旨在实现效果与成本的最优组合。</li>
<li>“杀鸡焉用宰牛刀”比喻根据任务需求选择合适的工具。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-29">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-30">16. 请问研究生方向是智能优化算法，这个方向找的工作是进互联 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/335929412</li>
<li>来源：bing</li>
<li>摘要：2023年4月16日 · 我导师智能优化算法和传统优化算法都在做，因为智能优化算法让我觉得特别没有安全感hhhhhhh，所以我现在主要做的是传统优化算法，比如SGD,Adam，RMSProp类的优化算法，这 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">传统优化算法如SGD、Adam和RMSProp等提供了稳定可靠的优化方法，确保了模型训练过程的平稳进行。然而，智能优化算法虽然具有创新性和灵活性，但可能带来不稳定性，因此在实际应用中被认为不太安全。对于研究生而言，选择智能优化算法作为研究方向时，其工作领域往往与互联网相关，这主要是因为互联网环境下的数据处理和优化问题更加复杂，需要更灵活和高效的算法来应对。因此，研究生在选择智能优化算法作为研究方向时，不仅要考虑到算法的创新性和灵活性，还要考虑到其在互联网相关领域的应用潜力。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>传统优化算法如SGD, Adam, RMSProp等提供了稳定可靠的优化方法。</li>
<li>智能优化算法可能带来不稳定性，因此被视作不太安全。</li>
<li>研究生方向智能优化算法可能对应的工作领域与互联网相关。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-31">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-32">17. 如何用Bode图判断系统的稳定性？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/20699458</li>
<li>来源：bing</li>
<li>摘要：2016年5月14日 · Z为闭环系统不稳定的极点个数，Z=0代表闭环系统稳定；P为开环函数不稳定极点数，N为完整正负频域的闭合奈奎斯特曲线包围 (-1,j0)的带符号圈数总和，顺时针计为+，逆时针计为- …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">Z=0代表闭环系统稳定，这意味着系统在闭环控制下能够保持稳定运行。开环函数中不稳定极点的数量用P来表示，这些极点的存在表明系统在开环状态下是不稳定的。此外，N代表完整正负频域内闭合奈奎斯特曲线包围(-1,j0)的带符号圈数总和，顺时针方向计为正，逆时针方向计为负。因此，通过分析P和N的值，可以判断闭环系统的稳定性，其中N的正负值与P的值共同决定了系统的稳定性，即Z=0的条件是否满足。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Z=0代表闭环系统稳定。</li>
<li>P为开环函数不稳定极点数。</li>
<li>N为完整正负频域的闭合奈奎斯特曲线包围 (-1,j0)的带符号圈数总和。</li>
<li>顺时针计为+。</li>
<li>逆时针计为-。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-33">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-34">18. 电力系统中，什么是构网型控制? - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/527992992</li>
<li>来源：bing</li>
<li>摘要：2022年4月14日 · 图 3：含同步电机、聚合构网变流器和恒阻抗负荷的 IEEE 九节点测试系统（图片序号为论文中序号）该系统贴近实际输电网络，通过电磁暂态仿真精准捕捉设备动态交互，为控制策略对 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">构网型控制依赖于系统中各设备的动态交互，这使得系统能够根据实时情况灵活调整，从而提高整体效率和稳定性。为了验证这种控制策略的有效性，通常通过电磁暂态仿真进行测试，确保在各种可能的运行条件下都能达到预期效果。此外，含同步电机和聚合构网变流器的系统更贴近实际输电网络，因此在进行仿真验证时能够更好地反映真实情况，从而提高验证结果的可靠性和实用性。因此，通过这些动态交互和仿真验证，构网型控制能够更有效地应用于实际的输电网络中，提高系统的整体性能。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>构网型控制依赖于系统中各设备的动态交互。</li>
<li>该控制策略通过电磁暂态仿真进行验证。</li>
<li>含同步电机和聚合构网变流器的系统更贴近实际输电网络。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-35">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-36">19. 构网型逆变器和构网型变流器他们的并网功率同步环的工作原理?</h2>
<ul>
<li>链接：https://www.zhihu.com/question/638965276</li>
<li>来源：bing</li>
<li>摘要：构网型逆变器和构网型变流器他们的并网功率同步环的工作原理? 前两年包括现在光伏逆变器和储能变流器都是跟网型，并网只需要通过PLL锁相环的，鉴相器PD、低通滤波LPF、压控震荡VCO就能完成和 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">PLL锁相环是实现并网同步的关键组件，能够确保并网功率与电网频率和相位的同步。鉴相器PD用于检测相位差，通过比较输入信号与参考信号之间的相位差异，为PLL提供必要的控制信息。低通滤波LPF则用于滤除高频噪声，确保信号的平滑性和稳定性。压控震荡VCO生成参考信号，其输出信号与电网的频率和相位保持一致。构网型逆变器和变流器通过这些组件实现并网，确保光伏逆变器和储能变流器能够与电网无缝对接，从而实现高效、稳定的并网运行。因此，PLL、鉴相器、低通滤波器和压控震荡器共同协作，确保并网过程的顺利进行。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>PLL锁相环可以实现并网功率同步。</li>
<li>鉴相器PD用于检测相位差。</li>
<li>低通滤波LPF可以滤除高频噪声。</li>
<li>压控震荡VCO用于生成参考信号。</li>
<li>构网型逆变器和变流器通过上述组件实现并网。</li>
<li>光伏逆变器和储能变流器采用类似技术。</li>
<li>PLL是实现并网同步的关键组件。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-37">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-38">20. 构网型储能变流器的基本组成与运行模式，覆盖电池特性 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/616792338</li>
<li>来源：bing</li>
<li>摘要：单级结构的变流器中，直流-交流逆变器和直流-直流变换器都采用单个电力器件实现；而多级结构则采用多个电力器件进行级联，以提高变流器的效率和可靠性。 总结起来，构网型储能变流器的基本组成 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">直流-交流逆变器和直流-直流变换器采用单个电力器件实现以简化结构，从而降低了成本和复杂性。然而，这种简化结构在提高变流器的效率和可靠性方面存在局限性。相比之下，多级结构通过级联多个电力器件，显著提升了变流器的整体性能。构网型储能变流器的基本组成包括电池和变流器，其中单级结构的变流器使用较少的电力器件，而多级结构则使用较多的电力器件，以换取更高的效率和可靠性。因此，选择合适的结构对于优化变流器的性能至关重要。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>直流-交流逆变器和直流-直流变换器都采用单个电力器件实现以简化结构。</li>
<li>多级结构通过级联多个电力器件来提高变流器的效率和可靠性。</li>
<li>构网型储能变流器的基本组成包括电池和变流器。</li>
<li>单级结构的变流器使用较少的电力器件，而多级结构使用较多的电力器件。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-39">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-40">21. 构网型逆变器相关方向怎么样? - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/667268782</li>
<li>来源：bing</li>
<li>摘要：2024年10月6日 · 但是随着分布式PCS发电的渗透率越来高之后，跟网型算法的无法起到可靠支撑大电网，将会对大电网的稳定性构成威胁，因此构网型的逆变器将会逐步成为刚性需求， 这个将会是未 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">构网型逆变器的刚性需求源于大电网稳定性的要求，这是由于大电网需要具备更高的稳定性和可靠性。然而，在高分布式电源转换系统（PCS）渗透率下，传统的跟网型算法难以有效支撑大电网的稳定运行。因此，构网型逆变器将逐步取代跟网型逆变器，以确保大电网的稳定性和可靠性。这一转变不仅是技术上的进步，更是为了满足大电网日益增长的稳定性需求。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>构网型逆变器的刚性需求源于大电网稳定性的要求。</li>
<li>跟网型算法在高分布式PCS渗透率下无法有效支撑大电网。</li>
<li>构网型逆变器将逐步取代跟网型逆变器。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-41">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-42">22. 计算机里随机数的原理是什么？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/1951348550358238843</li>
<li>来源：bing</li>
<li>摘要：2025年9月17日 · 因此,安全随机数可能需要收集很多不确定的信息,例如当前CPU工作频率,网卡ID,当前鼠标轨迹或历史某个键盘按键,以增加其不确定性避免随机数被预测. 当然,最最安全的随机数其实没啥原 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">安全随机数的生成需要收集多种不确定信息，以确保生成的随机数不易被预测。首先，当前CPU的工作频率可以作为收集的信息之一，因为它会随系统负载变化而变化。其次，网卡ID的加入可以进一步增加随机数的不确定性，因为每个设备的网卡ID都是唯一的。此外，当前鼠标轨迹也能为随机数的生成提供帮助，因为它反映了用户的交互行为，增加了随机数的复杂性。历史键盘按键同样能增加随机数的不确定性，因为它们反映了用户的输入模式。因此，最安全的随机数并不依赖于单一原理，而是通过综合多种信息来确保其安全性。这些信息的收集有助于避免随机数被预测，从而提高系统的整体安全性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>安全随机数的生成需要收集多种不确定信息。</li>
<li>这些信息可以包括当前CPU工作频率。</li>
<li>网卡ID可以用于增加随机数的不确定性。</li>
<li>当前鼠标轨迹有助于提高随机数的安全性。</li>
<li>历史键盘按键也能增加随机数的不确定性。</li>
<li>最安全的随机数并不依赖于特定原理。</li>
<li>这些信息的收集可以避免随机数被预测。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-43">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-44">23. 什么是伪随机和真随机？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/406068513</li>
<li>来源：bing</li>
<li>摘要：2020年7月13日 · 伪随机（pseudorandom）就是 由算法生成的随机数，真随机是真正随机的数。真随机数的例子有很多，比如人群身高、零件规格等。而一般由计算机生成的随机数都是伪随机数。 那 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">伪随机数依赖于算法生成，而真随机数则来源于实际物理过程，因此计算机生成的随机数通常是伪随机数。伪随机数并非真正随机，而是由算法生成的，这与真随机数如人群身高、零件规格等有着本质的区别。伪随机数和真随机数的区别在于生成方式，前者是通过算法计算得出，后者则是基于物理过程的真实结果。因此，了解这两种随机数的生成方式对于选择合适的随机数类型至关重要。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>伪随机数依赖于算法生成。</li>
<li>真随机数来源于实际物理过程。</li>
<li>计算机生成的随机数通常是伪随机数。</li>
<li>伪随机数并非真正随机，而是由算法生成的。</li>
<li>真随机数如人群身高、零件规格等。</li>
<li>伪随机数和真随机数的区别在于生成方式。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-45">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-46">24. Excel表格中如何生成特定平均数的一组数据？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/12600806852</li>
<li>来源：bing</li>
<li>摘要：2025年2月18日 · Excel表格中如何生成特定平均数的一组数据？ 比如我想随机生成平均数是n的m个数据，这m个数据还需要满足特定条件，范围为n× 0.85与n×1.15之间，数据保留两位小数，需要怎么填写 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">生成的数据需满足特定的平均数要求，这不仅确保了数据的统计特性，还保证了模型的准确性和可靠性。为了满足这一要求，范围限制需通过调整生成算法实现，确保生成的数据落在预期的范围内。此外，保留两位小数虽然会影响最终结果的精度，但有助于保持数据的可读性和一致性。因此，数据生成需综合考虑随机性和分布特性，以确保生成的数据既符合统计要求，又具有实际应用价值。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>生成的数据需满足特定的平均数要求。</li>
<li>范围限制需通过调整生成算法实现。</li>
<li>保留两位小数会影响最终结果的精度。</li>
<li>数据生成需考虑随机性和分布特性。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-47">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-48">25. 随机变量到底是啥，求一个清晰易懂的理解是啥? - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/624011946</li>
<li>来源：bing</li>
<li>摘要：2023年10月4日 · 之前我也被这个问题困扰，总是尝试从 公理 的角度去理解。 后来觉得从公理出发，对智商要求太高，不如就从最简单最愚蠢最粗糙的角度出发。 你可以把随机变量理解为一张有三列的 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">随机变量并非描述确定事件，而是用于量化不确定性。具体而言，随机变量的取值并不反映实际发生的事件，而是概率意义上的，这与描述确定事件的概念截然不同。进一步解释，随机变量的定义并不依赖于具体数值，而是基于其概率分布。这种概率分布可以通过三列表格来理解，其中第一列代表样本空间中的元素，第二列对应于事件，第三列则表示相应的概率。因此，随机变量的引入是为了更好地处理和分析不确定性，而非描述确定性事件。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>随机变量并非描述确定事件，而是描述不确定性。</li>
<li>随机变量的取值并不反映实际发生的事件。</li>
<li>随机变量的定义并不依赖于具体数值，而是概率分布。</li>
<li>随机变量的三列表格可以理解为样本空间、事件、概率。</li>
<li>随机变量的取值是概率意义上的，而非实际结果。</li>
<li>随机变量的引入是为了量化不确定性，而非确定性事件。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-49">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-50">26. 如何从深刻地理解随机过程的含义？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/26694486</li>
<li>来源：bing</li>
<li>摘要：2021年10月22日 · 理解这个算式特别简单，这个量就是x和y波动乘积的期望，当两个变量是此消彼长，则为负，共生共荣则为正，若两个过程不相关，则为0. 方差： 上述关系当x=y我们得到方差，方差就是 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">波动乘积的期望能够反映两个变量之间的关系，当两个变量此消彼长时，其期望值为负，表明两者存在负相关性；反之，当两个变量共生共荣时，其期望值为正，表明两者存在正相关性。在特定情况下，即x=y时，波动乘积的期望退化为方差，方差则衡量单个变量自身的波动程度。因此，波动乘积的期望不仅揭示了两个变量之间的相互作用，还通过方差这一特例，进一步量化了单个变量的波动性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>波动乘积的期望可以反映两个变量之间的关系。</li>
<li>方差是波动乘积期望在x=y情况下的特例。</li>
<li>两个变量此消彼长时，波动乘积的期望为负。</li>
<li>共生共荣时，波动乘积的期望为正。</li>
<li>不相关时，波动乘积的期望为0。</li>
<li>方差衡量的是单个变量自身的波动程度。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-51">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-52">27. OI里“保证数据随机”意味着题目满足什么隐含条件？</h2>
<ul>
<li>链接：https://www.zhihu.com/question/1936769453896501072</li>
<li>来源：bing</li>
<li>摘要：信息学奥林匹克竞赛 (OI)中，保证数据随机意味着什么？比如一个序列是随机生成，或者一颗树随机生成，或者… 其实包含的隐含条件挺多的，对于这类题目，我们可以使用期望值来计算时间复杂度，而 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">保证数据随机意味着题目中的数据分布符合某种概率模型，这使得可以利用概率论工具来分析算法的表现。具体而言，使用期望值计算时间复杂度基于数据的随机性，从而能够更准确地预测算法在不同情况下的表现。此外，随机生成的数据假设每种可能情况出现的概率相同，这保证了算法在不同情况下的表现一致性。因此，通过确保数据的随机性，可以更好地利用概率论工具进行分析，并确保算法在各种可能情况下的一致性和可靠性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>保证数据随机意味着题目中的数据分布符合某种概率模型。</li>
<li>这意味着可以利用概率论工具分析算法表现。</li>
<li>使用期望值计算时间复杂度基于数据的随机性。</li>
<li>随机生成的数据保证了算法在不同情况下的表现一致性。</li>
<li>随机生成的数据假设每种可能情况出现的概率相同。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-53">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-54">28. Win11电池图标消失？全面解决方案来了 - CSDN博客</h2>
<ul>
<li>链接：https://blog.csdn.net/mmoo_python/article/details/144215163</li>
<li>来源：bing</li>
<li>摘要：2025年6月29日 · Win11电池图标消失？全面解决方案来了 在使用 Windows 11操作系统的笔记本电脑时，突然发现任务栏上的电池图标不见了，这无疑会给用户带来诸多不便。电池图标不仅是了解电脑剩 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">电池图标不仅是了解电脑剩余电量的直观途径，也是监控电池健康状态的重要工具。打开“设备管理器”可以通过右键菜单中的“开始菜单”选项实现，随后在设备管理器中找到并双击“电池”可以查看与电池相关的设备信息。如果遇到电池图标消失的问题，可以尝试禁用并重新启用电池设备，这有助于解决因驱动或系统问题导致的图标消失问题。此外，更新电池驱动程序是修复可能存在的驱动兼容性问题的有效方法。如果上述方法仍无法解决问题，还可以通过任务栏设置重新显示电池图标。因此，通过这些步骤，可以确保电池图标始终正常显示并提供准确的电池信息。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>电池图标不仅是了解电脑剩余电量的直观途径，也是监控电池健康状态的重要工具。</li>
<li>打开“设备管理器”是通过右键菜单中的“开始菜单”选项实现的。</li>
<li>在设备管理器中找到并双击“电池”可以查看与电池相关的设备信息。</li>
<li>禁用并重新启用电池设备可以解决因驱动或系统问题导致的图标消失问题。</li>
<li>更新电池驱动程序有助于修复可能存在的驱动兼容性问题。</li>
<li>通过任务栏设置可以重新显示电池图标。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-55">正文（抓取，非 AI）</h3>
<p>Win11电池图标消失？全面解决方案来了 在使用Windows 11操作系统的笔记本电脑时，突然发现任务栏上的电池图标不见了，这无疑会给用户带来诸多不便。电池图标不仅是了解电脑剩余电量的直观途径，也是监控电池健康状态的重要工具。那么，当Win11电池图标神秘消失时，我们应该如何找回它呢？本文将详细介绍几种有效的解决方法，帮助你轻松应对这一问题。 方法一：通过设备管理器重启电池驱动 右键底部“开始菜单” 首先，我们需要打开开始菜单的右键菜单。这可以通过在任务栏上的开始按钮上点击鼠标右键来实现。 打开“设备管理器” 在右键菜单中，选择“设备管理器”选项。设备管理器是Windows系统中管理硬件设备的工具，通过它可以查看、更新、禁用或启用系统中的硬件设备。 找到并双击“电池” 在设备管理器窗口中，滚动找到“电池”选项，并双击展开。这里会显示与电池相关的所有设备信息。 禁用并重新启用设备 在电池设备下，右键点击电池项，选择“禁用设备”。等待几秒钟后，再次右键点击并选择“启用设备”。这一步操作相当于对电池设备进行了一次重启，有时可以解决因驱动或系统问题导致的图标消失问题。 更新驱动程序 设备重新启用后，右键点击电池项，选择“更新驱动程序”。系统会自动搜索并安装最新的电池驱动程序。按照提示完成更新过程，这有助于修复可能存在的驱动兼容性问题。 通过以上步骤，大多数情况下，电池图标应该能够重新出现在任务栏上。如果问题依旧存在，不妨尝试下面的方法。 方法二：通过任务栏设置显示电池图标 右键“开始菜单”并打开“设置” &lt;</p>
</div></details><h2 id="toc-56">29. 终于！Windows 11任务栏可以显示电量百分比了_凤凰网</h2>
<ul>
<li>链接：https://tech.ifeng.com/c/8gIW4YG0fXL</li>
<li>来源：bing</li>
<li>摘要：快科技1月20日消息，在手机上，查看电量剩余百分比是稀松平常的事情，不过在Windows笔记本上，任务栏的电池图标只是一个图标，并不会直接显示 ...</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，Windows 11任务栏的电池图标默认不显示电量百分比，这使得用户无法直接看到剩余电量的具体数值。其次，若用户希望查看电量百分比，需要手动开启相关设置。值得注意的是，电量百分比仅作为估算值，不具备绝对准确性，因此用户在依赖这些信息时应保持谨慎。此外，Windows 11的更新通常包含一些小的改进和bug修复，这些更新有助于提升系统的稳定性和性能，尽管它们可能不会显著改变电池电量显示的方式。因此，了解并适当设置电池电量显示，可以更好地管理设备的使用。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Windows 11任务栏的电池图标默认不显示电量百分比。</li>
<li>显示电量百分比需要用户手动开启设置。</li>
<li>电量百分比只是估算值，不具备绝对准确性。</li>
<li>Windows 11的更新通常包含一些小的改进和bug修复。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-57">正文（抓取，非 AI）</h3>
<p>终于！Windows 11任务栏可以显示电量百分比了_凤凰网 首页 资讯 视频 直播 凤凰卫视 财经 娱乐 体育 时尚 汽车 房产 科技 军事 文化 旅游 佛教 国学 数码 更多 健康 公益 教育 酒业 美食 科技 &gt; 互联网 &gt; 正文 终于！Windows 11任务栏可以显示电量百分比了 快科技 下载客户端 独家抢先看 2025年01月20日 15:04:07 来自河南 快科技1月20日消息，在手机上，查看电量剩余百分比是稀松平常的事情，不过在Windows笔记本上，任务栏的电池图标只是一个图标，并不会直接显示百分比，还要再点击一下。 根据挖掘发现，最新的Windows 11 Build 26120.2992版本中，隐藏了电池相关的一些改进，其中就包括 可选直接在任务栏显示剩余电量的百分比 ，这样一来就方便多了。 当然，无论手机还是笔记本，电池电量是不可能完全精准的，给出的百分比也只是个估算值，仅供参考。 另外，微软已经向Canary早期内测渠道发放了 Windows 11 Build 27774 ，变化不大。 已知主要更新包括Windows安装过程中新的硬盘分区格式、管理员保护功能确认对话框。 其他就是修正了一些bug，包括窗口边框颜色丢失、窗口阴影渲染错误、Xbox应用启动报错等。 “特别声明：以上作品内容(包括在内的视频、图片或音频)为凤凰网旗下自媒体平台“大风号”用户上传并发布，本平台仅提供信息存储空间服务。 Notice: The content above (including the videos, pictures and audios if any) is uploaded and posted by the user of Dafeng Hao, which is a social media platform and merely provides information storage space services.” 关闭 亲爱的凤凰网用户: 您当前使用的浏览器版本过低，导致网站不能正常访问，建议升级浏览器 第三方浏览器推荐: 谷歌(Chrome)浏览器 下载 360安全浏览器 下载</p>
</div></details><h2 id="toc-58">30. qPTM | Home</h2>
<ul>
<li>链接：https://qptm.omicsbio.info/</li>
<li>来源：bing</li>
<li>摘要：About qPTM qPTM is an advanced version of qPhos, which hosts for 6 types of PTMs including acetylation, glycosylation, methylation, phosphorylation, SUMOylation, ubiquitylation in 4 different …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">PTMs（蛋白质翻译后修饰）的量化对于理解生物过程至关重要，因为PTMs是可逆且动态的，能够显著影响蛋白质的功能和稳定性。为了更好地支持这一研究领域，qPTM数据库应运而生，它不仅更新了qPhos数据库，增加了更多类型的PTMs，还整合了蛋白质组学数据，提供了详尽的数据支持。qPTM数据库包含了来自4种不同生物体（人类、小鼠、大鼠和酵母）的6种PTMs（乙酰化、糖基化、甲基化、磷酸化、SUMO化和泛素化）的数据，共记录了11,482,533个量化的PTM事件，覆盖了40,728种蛋白质上的660,030个位点，这些数据是在2,596种不同条件下获得的。因此，qPTM数据库不仅支持多种生物体和多种PTMs，还为研究人员提供了全面且详尽的数据资源，有助于深入理解蛋白质修饰在生物过程中的作用。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>PTMs 的量化对于理解生物过程至关重要。</li>
<li>PTMs 是可逆且动态的。</li>
<li>qPTM 数据库更新了 qPhos 数据库，增加了更多类型的 PTMs。</li>
<li>qPTM 数据库包含来自 4 种不同生物体的 6 种 PTMs 的数据。</li>
<li>qPTM 数据库整合了蛋白质组学数据。</li>
<li>qPTM 数据库包含 11,482,533 个量化的 PTM 事件。</li>
<li>qPTM 数据库覆盖了 40,728 种蛋白质上的 660,030 个位点。</li>
<li>qPTM 数据库记录了 2,596 种条件下的数据。</li>
<li>数据库支持多种生物体，包括人类、小鼠、大鼠和酵母。</li>
<li>数据库支持多种 PTMs，包括乙酰化、糖基化、甲基化、磷酸化、SUMO 化和泛素化。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-59">正文（抓取，非 AI）</h3>
<p>qPTM | Home q uantification of P ost- T ranslational M odifications Welcome to qPTM Post-translational modifications ( PTMs ) are critical molecular mechanisms that regulate the protein functions temporally and spatially in almost all organisms. Since almost all PTMs are reversible and dynamic, the quantifications of PTM events under different states or conditions are also critical for understanding the biological process. With the rapid development of high-throughput proteomics technologies, massive quantitative PTM proteome datasets have been generated. Thus, a comprehensive one-stop data resource for surfing the big data will be very useful to the community. Previously, we developed the qPhos database to host the quantitative phosphoproteome data in Homo sapiens, here we update it to qPTM database for 6 types of PTMs including acetylation , glycosylation , methylation , phosphorylation , SUMOylation , ubiquitylation in 4 different organisms including human, mouse, rat and yeast. Also, the matched proteome datasets were integrated if available. In total, 11,482,533 quantification events for 660,030 sites on 40,728 proteins under 2,596 conditions are collected and integrated in the qPTM database. #1. Uniprot Accession : P06748 , #2. Gene Name : NPM1 , #3. Protein Name : Nucleophosmin , #4. Function : histone assembly , #5. Sample : HeLa S3 , #6. Condition : AZD1152/Ctr Any Field UniProt Accession Gene Name Protein Name Function Sample Condition All organisms Human Mouse Rat Yeast All modifications Acetylation Glycosylation Metylation Phosphorylation SUMOylation Ubiquitylation Example Clear Submit</p>
</div></details><h2 id="toc-60">31. 翻译后修饰之间的交互作用举例 | Cell Signaling Technology</h2>
<ul>
<li>链接：https://www.cellsignal.cn/pathways/chromatin-crosstalk-pathway</li>
<li>来源：bing</li>
<li>摘要：2 天之前 · 经专家审核且提供 PTM 交互作用信号转导最新概述的相互作用通路。 通路描述： 翻译后修饰 (PTM) 是调节蛋白质功能的关键步骤之一，反过来也是细胞进程的体现。翻译后修饰包括甲基化、乙 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">翻译后修饰可以相互作用，影响基因表达等细胞过程，这种相互作用不是单一修饰的简单叠加，而是涉及多种不同的修饰类型和程度。这些修饰可以通过不同的“读取器”蛋白被识别，甚至同一蛋白的不同“读取器”也能识别这些修饰。翻译后修饰的相互作用可以相互加强，从而影响生物学效应。这些相互作用是通过组蛋白修饰、酶修饰及其相关活性实现的，能够识别和定位到基因组或其他细胞成分。此外，翻译后修饰的相互作用可以被特定的酶“写入”或“擦除”，使其成为疾病治疗的潜在靶标。在癌症等疾病中，翻译后修饰的相互作用更是关键的调控因子。因此，理解这些相互作用对于揭示疾病机制和开发新的治疗策略至关重要。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>翻译后修饰可以相互作用，影响基因表达等细胞过程。</li>
<li>翻译后修饰的相互作用不是单一修饰的简单叠加。</li>
<li>翻译后修饰的相互作用涉及多种不同的修饰类型和程度。</li>
<li>翻译后修饰的相互作用可以被不同的“读取器”蛋白识别。</li>
<li>翻译后修饰的相互作用可以被同一蛋白的不同“读取器”识别。</li>
<li>翻译后修饰的相互作用可以相互加强，影响生物学效应。</li>
<li>翻译后修饰的相互作用是通过组蛋白修饰、酶修饰及其相关活性实现的。</li>
<li>翻译后修饰的相互作用可以识别和定位到基因组或其他细胞成分。</li>
<li>翻译后修饰的相互作用可以被特定的酶“写入”或“擦除”。</li>
<li>翻译后修饰的相互作用是疾病治疗的潜在靶标。</li>
<li>翻译后修饰的相互作用是癌症等疾病的关键调控因子。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-61">正文（抓取，非 AI）</h3>
<p>翻译后修饰之间的交互作用举例 | Cell Signaling Technology 翻译后修饰之间的交互作用举例 © Cell Signaling Technology。版权所有。 查看互动通路 下载通路 图表说明 图示 通路描述： 翻译后修饰 (PTM) 是调节蛋白质功能的关键步骤之一，反过来也是细胞进程的体现。翻译后修饰包括甲基化、乙酰化、磷酸化以及其他多种修饰，其发现和分析为 PTM 确立了其在胞核及非胞核中的作用。随着人们意识到 PTM 的作用后，PTM 列表日益丰富，有关其功能的研究也越来越多。近年来，修饰多样性显著增加，但最重要的是，它们之间的相互作用也显著增加。这种相互作用对适当基因表达、基因组结构、细胞分裂以及 DNA 损伤响应都非常关键。PTM 可以通过组蛋白修饰、酶修饰及其相关活性、组装蛋白复合体，以及在基因组中进行识别和定位或定位到或其他细胞成分，对细胞功能产生直接影响。在单一修饰和基因表达的背景下，某些赖氨酸（例如组蛋白 3 赖氨酸 [9-H3K9]）的乙酰化与激活相关，而在多数情况下，同一残基的三甲基化与结构压缩和基因抑制相关。对于赖氨酸可以是单甲基化、双甲基化或三甲基化；而精氨酸可以是单甲基化，或非对称性或对称性双甲基化。每种程度的赖氨酸和精氨酸甲基化都可作为其自身的 PTM 并影响生物学效应。绝大多数 PTM 都不会在染色质环境中单独存在，并且这些 PTM 状态结合后可以相互加强。例如，对于某蛋白中名为“reader”的结合域，一个 PTM 可充当其对接位点，同时同一蛋白中另一个“reader”则可以识别另一个残基。读取器蛋白 BPTF 即存在这一现象，即同时结合 H3K4me3 和 H4K16 乙酰化。因此，对修饰的不同类型和程度的调节将影响生物学效应。正是由于这些原因，细胞为建立并维持这些 PTM 而产生了一系列重要的酶，通常被称为“writers”（例如组蛋白甲基转移酶、乙酰转移酶等）或是“erasers”（例如组蛋白去甲基化酶、去乙酰化酶等）。这些酶中，许多已经作为疾病治疗的靶标出现，并且已确定为癌症等疾病的关键调控因子。这些发现也让相关的 PTM 候选者作为癌症和其他疾病的生物标记物。 主要文献： Berger SL (2007) The complex language of chromatin regulation during transcription. Nature 447(7143), 407–12. Dawson MA, Kouzarides T (2012) Cancer epigenetics: from mechanism to therapy. Cell 150(1), 12–27. Gardner KE, Allis CD, Strahl BD (2011) Operating on chromatin, a colorful language where context matters. J. Mol. Biol. 409(1), 36–46. Lee JS, Smith E, Shilatifard A (2010) The language of histone crosstalk. Cell 142(5), 682–5. Musselman CA, Kutateladze TG (2011) Handpicking epigenetic marks with PHD fingers. Nucleic Acids Res. 39(21), 9061–71. Yang XJ, Seto E (2008) Lysine acetylation: codified crosstalk with other posttranslational modifications. Mol. Cell 31(4), 449–61. 感谢来自美国马萨诸塞州查尔斯顿哈佛医学院麻省总医院癌症中心的 Johnathan Whetstine 教授审阅了此图。 创建于 2009 年 5 月 修订时间 2014 年 7 月 请求图表许可 查看 PDF 文件 乙酰化酶 代谢酶 接头蛋白 甲基转移酶或 G 蛋白 凋亡/自噬调节分子 磷酸酶 细胞周期调节分子 蛋白复合体 脱乙酰酶或细胞骨架蛋白 泛素/SUMO 连接酶或去泛素化酶 生长因子/细胞因子/发育蛋白 转录因子或翻译因子 GTP 酶/GAP/GEF 受体 激酶 其他 直接过程 暂定过程 易位过程 刺激性修饰 抑制性修饰 转录修饰 选择 产品 了解更多有关 PhosphoSitePlus® 的信息 × 选择您所在的国家/地区 国家/地区 继续 ×</p>
</div></details><h2 id="toc-62">32. PTM</h2>
<ul>
<li>链接：http://funcptm.jysw.suda.edu.cn/</li>
<li>来源：bing</li>
<li>摘要：Herein, we present a new direction leveraging PTM protein isoforms target space to inspire drug design termed as “PTM Inspired Drug Design (PIDD).” In the biological space, PTM protein isoforms play …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">PTMs通过共价修饰蛋白质，贡献了超过670种修饰类型，这些修饰在细胞内动态变化，影响多种细胞信号功能。PTM异常状态与多种人类疾病相关，表明PTMs在疾病发生和发展中扮演着重要角色。PTM蛋白异型体在疾病和生物信号传导中起关键作用，它们通过靶向策略显著扩展了生物空间或增加化合物的可处理性，从而为个性化治疗提供了丰富的可能性。然而，PTM功能分配仍然是修饰组学中的一个瓶颈问题，需要进一步研究以更好地理解其在细胞信号传导中的作用。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>PTMs通过共价修饰蛋白质，贡献了超过670种修饰类型。</li>
<li>PTMs在细胞内动态变化，影响多种细胞信号功能。</li>
<li>PTM异常状态与多种人类疾病相关。</li>
<li>PTM蛋白异型体在疾病和生物信号传导中起关键作用。</li>
<li>PTM蛋白异型体靶向可显著扩展生物空间或增加化合物的可处理性。</li>
<li>PTM蛋白异型体靶向策略将丰富个性化治疗机会。</li>
<li>PTM功能分配是修饰组学中的瓶颈问题。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-63">正文（抓取，非 AI）</h3>
<p>PTM PTMFunc DATABASE PTM Functional Landscape The predominant existence of covalent modifications of proteins by post-translational modification (PTM) enzymes contributes to the diversity of protein functions, involving greater than 670 modification types on approximately 900000 PTM sites (https://www.uniprot.org/docs/ptmlist.txt) . The high dynamic process of PTMs within a cell forms a complex and ever changing nexus of protein modifications, which plays central roles in various cellular signaling functions through different mechanisms, including allosterically regulating enzyme, regulating protein-protein interactions (PPIs), protein localization, degradation, or cleavage. Accumulating evidence has shown that the abnormal status of PTMs is frequently involved in various human diseases, such as cancers, diabetes, and neurodegenerative diseases, making PTMs centrally important for biomarker studies and personalized therapies. Recent advances in different levels of “omics” data have exponentially accelerated the identification of PTM sites. In contrast, PTM functional assignment presents as the bottleneck problem in the modification omics. Phosphosites Functions Modern drug design aims to discover novel lead compounds with attractable chemical profiles to enable further exploration of the intersection of chemical space and biological space. Herein, we present a new direction leveraging PTM protein isoforms target space to inspire drug design termed as “PTM Inspired Drug Design (PIDD).” In the biological space, PTM protein isoforms play vitol roles in various diseases and biological signalings. The directions to elaborate PIDD in drug design including discovering covalent binding inhibitors mimicking PTMs, targeting PTM protein isoforms with allosteric sites from that of wildtype counterpart, targeting protein-protein interactions involving PTMs, and hijacking protein degeneration by ubiquitination for PTM protein isoforms. These directions will lead to a significant expansion of the biological space and/or increase the tractability of compounds, primarily due to precisely targeting PTM protein isoforms or complexes which are highly relevant to biological functions. Importantly, this new avenue will further enrich the personalized treatment opportunity through precision medicine targeting PTM isoforms. Strategies targeting PTM protein isoforms in drug discovery Reference 1. Meng, F., et al., Drug design targeting active posttranslational modification protein isoforms. Med Res Rev, 2021. 41. 1701-1750. 2. Zhang, H., et al., Dynamics of Post-Translational Modification Inspires Drug Design in the Kinase Family. J Med Chem, 2021. 64(20). 15111-15125. 3. Zhu, F., et al., PPICT: an integrated deep neural network for predicting inter-protein PTM cross-talk. Brief Bioinform, 2023. 24(2). 1-11. 4. Liang Z., et al., Deciphering the functional landscape of phosphosites with deep neural network. Cell Rep, 2023. 5. Zhang G., et al., FuncPhos-STR: An integrated deep neural network for functional phosphosite prediction based on AlphaFold protein structure and dynamics. Int J Biol Macromol, 2024. Quick Links EPSD PLMD PTMD dbPTM UniProt iPTMnet PhosphoSitePlus PTMFunc has been visited: times. School of Life Sciences, Soochow University Address: 199 Ren-AiRoad, Suzhou Industrial Park, Suzhou, China PostCode: 215123 Email: zjliang@suda.edu.cn, zhufei@suda.edu.cn</p>
</div></details><h2 id="toc-64">33. 蛋白翻译后修饰（PTM）研究超全指南（上）</h2>
<ul>
<li>链接：https://www.univ-bio.com/article/id-4874.html</li>
<li>来源：bing</li>
<li>摘要：2024年6月14日 · PTM可能发生的位置、数量以及翻译后变化的多样性，将起源于大约21,000个基因的蛋白质组转化为具有独特功能和活性的数百万个蛋白质20-21。 我们对PTM在疾病中发挥作用的了解仍 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">PTM（蛋白质翻译后修饰）的发生可能改变蛋白质的功能和活性，这一过程的多样性进一步影响蛋白质的最终功能。然而，尽管PTM在调控蛋白质功能方面扮演着关键角色，我们对PTM在疾病中的作用仍了解不足。因此，深入研究PTM在疾病中的具体机制，对于全面理解蛋白质功能及其在疾病中的作用至关重要。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>PTM的发生可能改变蛋白质的功能和活性。</li>
<li>PTM的多样性影响蛋白质的最终功能。</li>
<li>了解PTM在疾病中的作用仍不充分。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-65">正文（抓取，非 AI）</h3>
<p>{"l1":"var arg1='5eb18240f2da2b8f873747d5c3718e23faa46a8dd3f19eb41e';", "l2":"GET"} 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</p>
</div></details><h2 id="toc-66">34. 微软重构 Windows 11 任务栏电池图标！现已支持红绿橙三 ...</h2>
<ul>
<li>链接：https://www.xitongzhijia.net/news/20251110/302646.html</li>
<li>来源：bing</li>
<li>摘要：系统之家 11 月 10 日最新消息。微软在最新的 Windows 11 预览版中重构了任务栏电池图标，优化了用户获取电量信息的体验。新设计不仅增加了电量百分比直接显示选项，还引入了彩色状态提示，下面让 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">新设计增加了电量百分比直接显示选项，同时引入了彩色状态提示，使电量信息更加直观。用户可以通过点击图标获取更多信息，而系统会根据电量自动调整图标颜色，以直观反映电量状态。此外，用户还可以选择不同的显示模式，甚至自定义显示模式，以满足个人偏好。虽然具体机制未明，但图标颜色确实会根据电量变化而变化，从而帮助用户更好地监控设备电量。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>新设计增加了电量百分比直接显示选项。</li>
<li>新设计引入了彩色状态提示。</li>
<li>用户可以通过点击图标获取更多信息。</li>
<li>用户可以选择不同的显示模式。</li>
<li>系统会根据电量自动调整图标颜色。</li>
<li>图标颜色会根据电量变化而变化。</li>
<li>图标颜色会根据电量变化而变化，但具体机制未明。</li>
<li>用户可以自定义显示模式。</li>
<li>系统会根据电量自动调整图标颜色，但具体机制未明。</li>
<li>图标颜色会根据电量变化而变化，但具体机制未明。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-67">正文（抓取，非 AI）</h3>
<p>΢���ع� Windows 11 ���������ͼ�꣡����֧�ֺ��̳���ɫ״̬��ʾ - ϵͳ֮�� ϵͳ֮�� - ϵͳ����������վ�� ϵͳ֮�� ��Ѷ �ۺ� Win10 Win7 �̳� ��Ѷ �� �� ���ѣ� win11�ƹ�Ӳ�����ư�װ һ����װWin10ϵͳ ��ɾ���u�������� �����������win7ϵͳ ��ҳ Win10ϵͳ Win7ϵͳ Win11ϵͳ XPϵͳ �칫֮�� һ����װ �̳� ���� IT��Ѷ Win8ϵͳ Linuxϵͳ MacOSϵͳ ���ָ�� IT��Ѷ ���� ҵ�� ���� ΢�� ƻ�� �ȸ� �ֻ� Ӳ�� ��Ϸ ���� ���� ��ǰλ�ã� ϵͳ֮�� &gt; IT��Ѷ &gt; ��ϸҳ�� ΢���ع� Windows 11 ���������ͼ�꣡����֧�ֺ��̳���ɫ״̬��ʾ �༭��alear 2025-11-10 09:57:24 ��Դ�ڣ�ithome �������� ��CAD/����/ý��������Windows11 25H2 64λ רҵ����վ�� ��С��5.03 GB ��� Windows 11ϵͳ ���� ϵͳ֮�� 11 �� 10 ��������Ϣ��΢�������µ� Windows 11 Ԥ�������ع������������ͼ�꣬�Ż����û���ȡ������Ϣ�����顣����Ʋ��������˵����ٷֱ�ֱ����ʾѡ��������˲�ɫ״̬��ʾ������������һ���������ɡ� ��������������û����ٻ�ȡ�豸������Ϣʱ�����飬Ϊ���������ͼ�긳���˲�ɫ״̬��ʾ������ͬʱ�������û��ڴ��Ѿõĵ����ٷֱ�ֱ����ʾѡ� �������º�ԭ�Ⱦ�̬�İ�ɫ���ͼ�꽫��ø��߱����������豸��ͨ��Դ����ͼ����Ϊ��ɫ������һ��������š� �������û�����“����ģʽ”����ǰ��Ϊ“�ڵ�ģʽ”����δ��ͨ��Դʱ��ͼ������ʾΪ��ɫ��ȡ���˹�ȥ���ⲻ��ֱ�۵�Ҷ��ͼ�ꡣ �������⣬���������� 6% ���ٽ�ֵʱ��ͼ����Ϊ��ɫ������Ŀ�ķ�ʽ�����û�������硣 ����������ɫ�仯��΢����������“���ܳ��”���ܵ���ʾ�߼����ù��ܹ�ȥ�ڳ���� 80% ʱ����ʾһ�������ε�������š� ��������������У�ͼ���ڳ���� 80% ǰ������ɫ���ﵽ 80% �����Ϊһ����ͷ���ţ��û���Ҫ�����ͼ����ܼ�������� 100%���Ӷ����û��������ؿ��Ƴ����̡� ����Ϊ�������µİٷֱ����ֺ͸��������Ӿ�Ԫ�أ�΢�������ӳ��˵��ͼ�����������ϵ��������ȡ�΢���ٷ������Ա���ͳƣ���������Ϊ�˸�ͼ����Ӳ㣨������ţ���������ռ䣬�����������ʾ�� ����ͬʱ������Ŀռ�Ҳ�ò�ͬ����ˮƽ֮����Ӿ�����������ԣ���Ϻ졢�ơ���������ɫ���û�ֻ��ɨһ�۾��ܿ����˽���״̬�� ��������ֵ�ù�ע���ǣ� ����ָ��΢�������ù��ܺ�ʱԼ 1.5 ��ʱ�䡣 ����ϵͳ֮��Ԯ�����Ľ��ܣ��û����ڿ��Է���ؿ��������ٷֱ���ʾ��ֻ�����“ϵͳ”�����е�“��Դ����”ҳ�棬�ҵ�����“��ʾ��ذٷֱ�”���¿��ؼ��ɡ������󣬾���ĵ������ֻ���������ʾ���������ĵ��ͼ���ڡ� ��������Ķ� ������ �� BUG��΢��Ϊ���©����Ĭ�Ϲر� Win11 �ļ����������ļ�Ԥ������ �� ������ ΢������ Win11 Beta / Dev 26220.7070 Ԥ���棡����С������ �� ������ Canary ��֧��ʼ���� Windows 11 Build 28000��26H1����26H1 ��ʽ�ǳ� �� ����������ϵͳ֮���ṩ��������Ѷ����л�����Ķ������ྫ���������ע ϵͳ֮�ҹ��� �� ��ǩ Win11 ΢�� &lt; ��һƪ Win10 �û�ע����չ��ȫ���£�ESU������ʱ�������ϰ��������ݲ����� / �����ˡ���ʾ ��һƪ &gt; Win11 ʮ�¸��� KB5066835 �� BUG������ Z400 ��ħ�ľɻ�����ʧ�� ����Ƽ� Windows11 ȫ����ƵĿ�ʼ�˵��Ѿ����� ΢������ Win11 �ļ���Դ������������ ΢�������޸� Outlook ������޷��鿴 33 ����ʷ�ս᣺΢�� Win11 ������ NTL ΢�� PowerToys ���� Win11 �ڶ������� ΢�� Win11 Ԥ���������ԣ� ΢������ Win11 24H2 / 25H2 һ�¿�ѡ Win11 ȫ���û��� 10 �ڣ���ʱ 1576 �� ΢�� PowerToys �����ö����ܽ�����͸ ΢������ 1 �¸����²������� PC ���� ΢������ Win11 24H2 8 ���ۻ����²��� KB5063878��������������־ Windows 11 25H2 �������ذ�װ���� ΢������ Win11 26H1 Canary 28000.1340 Ԥ������£�������������־ ΢������Win11 24H2 �����ۻ����²���KB5053598��������������־ �������� �� 0 �� ��֤�� û�и��������� ���۾���Щ�����ô��Ҳ֪����Ķ��ؼ��� �������� �������Խ������û����˹۵㣬������ϵͳ֮������ ������Ѷ 1 ����Note9������Galaxy Note9�������� 2 ΢��PC Health Check���Խ���״�����Ӧ... 3 ���Զ�̬�����ֽ�����ĸ����ã����Զ�̬... 4 ����8100�����������٣�����8100��ؽ��� 5 ���������ᴦ�����ĸ��ã���������������... 6 �Կ�����ͼ2022��6�°� 2022�����Կ�����... 7 Win11��ʽ���Ϳ�ʼ ���ַ�����������Wind... 8 ����6020��������ô��������6020��������... 9 2022��5��CPU��������ͼ ʷ����ȫ���漶C... 10 ����9000+������8+ѡ��һ���ã��������... Ƶ���ȵ���Ѷ 1 ΢��PC Health Check���Խ���״�����Ӧ... 2 Win11��ʽ���Ϳ�ʼ ���ַ�����������Wind... 3 Win10 22h2�汾ǧ��������ʵ�������... 4 ϵͳ֮�ҹ��� ϵͳ֮�ҹ�����¼��� 5 Win10ϵͳ������ӡ������0x0000011b����... 6 ΢��Win10�汾20H2��ʽ��ٷ�ISO��������... 7 ΢��������Chromium Edge�������ʽ�棨... 8 ΢��Win10�汾22H2��ʽ��ٷ�ISO��������... 9 ����8000�൱������ʲô���ã�������778g... 10 ��ô������Win10 22H2�汾�����ַ�������... ɨ���ע ������ �ٷ�����Ⱥ ������¼ ���ã�����������¼�����뽫����������������������ơ��������ܡ�������ؽ�ͼ������iocn��������Ӫҵִ�գ�����û��Ӫҵִ�����ṩ��Ӧ�Ŀ���������֤�������Լ��ֳ�����֤������Ƭ�������������� xitongzhijia@qq.com ����&gt;&gt;</p>
</div></details><h2 id="toc-68">35. PTM翻译后修饰预测工具_netphos-CSDN博客</h2>
<ul>
<li>链接：https://blog.csdn.net/weixin_62528784/article/details/145813865</li>
<li>来源：bing</li>
<li>摘要：2025年12月8日 · 文章浏览阅读8.1k次，点赞19次，收藏36次。蛋白质组的PTM翻译后修饰参考_netphos 翻译后修饰（PTM），也称为共价修饰，是蛋白质翻译后的化学修饰过程。通过对肽链进行蛋白水解 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">PTM翻译后修饰是蛋白质翻译后的化学修饰过程，这一过程对于蛋白质的功能至关重要。然而，由于缺乏足够的分析数据，只有少数PTM得到了很好的表征。实验鉴定PTM底物及其位点是劳动密集型的工作，这进一步限制了对PTM的全面了解。为了解决这一问题，计算机模拟预测可能是进行初步分析的有前途的策略。然而，预测工具的准确性可能受到假阳性和假阴性的影响，且物种特异性可能限制某些预测工具的应用范围。因此，功能相关性需结合功能实验来验证预测位点。实验验证方法包括质谱、抗体检测和定点突变，这些方法可以提供直接的证据来支持预测结果。此外，交叉验证可以提高预测位点的可靠性，从而增强预测工具的准确性。因此，PTM预测需要结合多种工具和实验数据，以确保预测的可靠性和准确性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>PTM翻译后修饰是蛋白质翻译后的化学修饰过程。</li>
<li>缺乏足够的分析数据导致只有少数PTM得到了很好的表征。</li>
<li>实验鉴定PTM底物及其位点是劳动密集型的。</li>
<li>计算机模拟预测可能是进行初步分析的有前途的策略。</li>
<li>预测工具的准确性可能受到假阳性和假阴性的影响。</li>
<li>物种特异性可能限制某些预测工具的应用范围。</li>
<li>功能相关性需结合功能实验来验证预测位点。</li>
<li>实验验证方法包括质谱、抗体检测和定点突变。</li>
<li>交叉验证可以提高预测位点的可靠性。</li>
<li>PTM预测需要结合多种工具和实验数据。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-69">正文（抓取，非 AI）</h3>
<p>翻译后修饰（PTM），也称为共价修饰，是蛋白质翻译后的化学修饰过程。通过对肽链进行蛋白水解切割，向单个氨基酸添加各种官能团（例如磷酸化），或通过改变氨基酸残基的化学性质（例如瓜氨酸化），各种PTM会创建或破坏共价键，从而改变蛋白质的结构，定位和功能，在几乎所有的细胞信号通路和网络中发挥重要作用，并确定细胞动力学和可塑性。尽管已发现350多种类型的PTM，但由于缺乏足够的分析数据，因此只有少数PTM得到了很好的表征。PTM底物及其位点的实验鉴定是劳动密集型的，并且通常受到酶促反应的可用性和优化的限制。计算机模拟预测可能是进行初步分析并大大减少需要进一步体内或体外确认的潜在靶标数量的有前途的策略。 预测蛋白质的翻译后修饰（Post-Translational Modifications, PTMs）位点是功能研究和机制解析的重要步骤。以下是常见翻译后修饰类型及其预测方法、工具和数据库的详细总结： 一、常见翻译后修饰类型及预测工具 1. 磷酸化（Phosphorylation） 修饰位点：丝氨酸（S）、苏氨酸（T）、酪氨酸（Y）。 预测工具： NetPhos：基于神经网络的通用磷酸化位点预测(https://services.healthtech.dtu.dk/service.php?NetPhos-3.1)。 GPS：支持激酶特异性预测（如预测某个激酶催化的磷酸化位点）(http://gps.biocuckoo.cn/)。 PhosphoSitePlus：整合已知实验数据的磷酸化位点数据库(https://www.phosphosite.org/)。 实验验证：质谱、抗磷酸化抗体。 2. 泛素化（Ubiquitination） 修饰位点：赖氨酸（K）。 预测工具： UbPred：基于机器学习的泛素化位点预测(http://www.ubpred.org/)。 GPS-Uber：支持泛素化和其他修饰的预测(http://gps.biocuckoo.cn/)。 dbPTM：整合泛素化位点的数据库(https://awi.cuhk.edu.cn/dbPTM/)。 实验验证：泛素化抗体、质谱、突变赖氨酸（K→R）。 3. 乙酰化（Acetylation） 修饰位点：赖氨酸（K）。 预测工具： PAIL：预测蛋白质的乙酰化位点(http://bdmpail.biocuckoo.org/)。 GPS-PAIL：结合乙酰化特异性的预测工具(http://pail.biocuckoo.cn/)。 PLMD：乙酰化数据库(http://plmd.biocuckoo.org/)。 实验验证：抗乙酰化抗体（如抗-Ac-K）、质谱。 4. 甲基化（Methylation） 修饰位点：赖氨酸（K）、精氨酸（R）。 预测工具： MASA：预测精氨酸甲基化位点(http://bioinfo.ncu.edu.cn/MASA.aspx)。 BPB-PPMS：赖氨酸甲基化预测(http://www.biomine.org/BPB-PPMS/)。 MethK：甲基化数据库(https://methk.net/)。 实验验证：质谱、甲基化特异性抗体。 5. SUMO化（SUMOylation） 修饰位点：赖氨酸（K）。 预测工具： SUMOsp：预测SUMO化位点(http://sumosp.biocuckoo.org/)。 GPS-SUMO：结合SUMO化特异性的预测工具(http://sumo.biocuckoo.cn/)）。 SUMOmune：整合实验数据的SUMO化数据库(http://sumosp.biocuckoo.org/online.php)。 实验验证：抗SUMO抗体、质谱。 6. 糖基化（Glycosylation） 类型：N-糖基化（天冬酰胺，N）、O-糖基化（丝氨酸/苏氨酸，S/T）。 预测工具： NetNGlyc：预测N-糖基化位点(https://services.healthtech.dtu.dk/service.php?NetNGlyc-1.0)。 NetOGlyc：预测O-糖基化位点(https://services.healthtech.dtu.dk/service.php?NetOGlyc-4.0)。 GlycoEP：综合糖基化预测工具(http://www.imtech.res.in/raghava/glycoep/)。 实验验证：凝集素印迹（Lectin blot）、质谱。 二、综合预测工具和数据库 1. 多修饰整合工具 GPS：支持磷酸化、泛素化、乙酰化等多种修饰预测(http://gps.biocuckoo.cn/)。 dbPTM：整合所有已知PTM位点的数据库(https://awi.cuhk.edu.cn/dbPTM/)。 PTMcode：分析PTM的功能关联性(http://ptmcode.embl.de/)。 2. 蛋白质序列分析平台 UniProt：提供已知PTM注释(https://www.uniprot.org/)。 PhosphoSitePlus：综合磷酸化和其他修饰的数据库(https://www.phosphosite.org/)。 三，其他数据库 3.1 PhosphoSitePlus PhosphoSitePlus数据库（https://www.phosphosite.org/）是一个由CST和NIH联合开发免费的翻译后修饰预测数据库，整合了大量来自高通量测序预测和科学研究实验验证的结果，为蛋白质翻译后修饰的研究提供了全面的信息和工具。该数据库主要包括磷酸化、甲基化、乙酰化、泛素化等，共收录了59499个蛋白的600798个翻译后修饰位点。通过查询蛋白质可以获得蛋白质基本信息（结构域、亚细胞定位）以及蛋白质发生修饰的类型、修饰位点、抗体、修饰相关疾病，以及激酶底物序列。 图2.1PhosphoSitePlus数据库使用 3.2 qPTM qPTM（quantification of Post-Translational Modifications，http://qptm.omicsbio.info）是中山大学肿瘤防治中心刘泽先教授团队收集并整合PTMs文献的数据库，涉及从600多个已发表研究中收集的四种不同生物体（人、大鼠、小鼠、酵母）中40728个蛋白质在2596种条件下的660 030个非冗余PTM位点，修饰类型包括6种（磷酸化、乙酰化、糖基化、甲基化、SUMO化以及泛素化修饰）。通过搜索特定物种的蛋白，即可获得前人研究的修饰发生的位点以及实验条件和参考文献。 图2.2 qPTM数据库使用 3.3 dbPTM dbPTM（https://awi.cuhk.edu.cn/dbPTM/index.php）是蛋白质翻译后修饰 (PTM) 的综合资源，整合来自40+数据库、70+种修饰类型、已经被实验/文献证实的PTM位点和预测位点共2235664个，其中重点修饰类型包括磷酸化、糖基化和硫修饰。通过搜索蛋白可获得蛋白二级结构、修饰位点信息、上游调节蛋白、位点功能以及疾病相关信息。 图2.3dbPTM数据库使用 3.4 Plant PTM Viewer Plant PTM Viewer（http://www.psb.ugent.be/PlantPTMViewer）是植物蛋白翻译后修饰数据库，包含8种不同植物（拟南芥、水稻、大豆、小立碗藓、番茄、玉米、小麦、莱茵衣藻）大约128920个蛋白334255个PTM位点的33种蛋白质修饰。通过该网站我们可以检索目的蛋白在植物中的修饰情况，此外还可以搜索同源序列中的保守翻译后修饰位点。 图2.4Plant PTM Viewer数据库使用 此处重点介绍 http://biocuckoo.cn 因为有很多PTM翻译后修饰种类都集成到了其中 各种PTM预测工具在左侧： 另外，该团队还开发了很多工具和数据库： 四、预测步骤和注意事项 1. 预测流程 输入蛋白质序列：从UniProt获取目标蛋白的FASTA格式序列。 选择预测工具：根据修饰类型选择工具（如磷酸化用NetPhos，泛素化用UbPred）。 设置参数：调整阈值（如p&gt;0.5为高置信度位点）。 交叉验证：使用多个工具预测同一修饰，取交集位点提高可靠性。 结合实验数据：参考数据库（如PhosphoSitePlus）中的已知位点。 2. 注意事项 假阳性和假阴性：预测工具基于已有数据训练，新位点可能未被覆盖。 物种特异性：部分工具针对特定物种（如人类、小鼠）优化。 功能相关性：预测位点需结合功能实验（如突变后功能丧失）。 四、实验验证方法 质谱（Mass Spectrometry）：直接鉴定修饰位点。 抗体检测：使用修饰特异性抗体（如抗磷酸化抗体）。 定点突变（Site-Directed Mutagenesis）：将预测位点突变（如S→A），观察功能变化。 蛋白质稳定性实验：如环己酰亚胺（CHX）追踪蛋白降解速率。 五、示例：磷酸化位点预测流程 输入序列：从UniProt获取B的FASTA序列（如UniProt ID XXXX）。 使用NetPhos：预测丝氨酸、苏氨酸和酪氨酸的磷酸化位点。 使用PhosphoSitePlus：查询已知的B磷酸化位点（如S10、S20）。 交叉验证：结合GPS预测结果，筛选高置信度位点。 实验验证：通过体外激酶实验和质谱确认A是否磷酸化这些位点。 还有其他的数据库： 参考： 资源分享 | 蛋白质研究常用数据库！ 翻译后修饰位点的预测需要结合生物信息学工具和实验验证。通过多工具交叉验证、参考已知数据库，并设计合理的功能实验，可以高效定位关键修饰位点，解析蛋白质功能调控机制。</p>
</div></details><h2 id="toc-70">36. Strong conflict-free connection of graphs</h2>
<ul>
<li>链接：https://arxiv.org/abs/1901.08240v1</li>
<li>来源：arxiv</li>
<li>摘要：A path $P$ in an edge-colored graph is called \emph{a conflict-free path} if there exists a color used on only one of the edges of $P$. An edge-colored graph $G$ is called \emph{conflict-free connected} if for each pair of distinct vertices of $G$ there is a conflict-free path in $G$ connecting them. The graph $G$ is called \emph{strongly conflict-free connected }if for every pair of vertices $u$ and $v$ of $G$ there exists a conflict-free path of length $d_G(u,v)$ in $G$ connecting them. For a connected graph $G$, the \emph{strong conflict-free connection number} of $G$, denoted by $\mathit{scfc}(G)$, is defined as the smallest number of colors that are required in order to make $G$ strongly conflict-free connected. In this paper, we first show that if $G_t$ is a connected graph with $m$ $(m\geq 2)$ edges and $t$ edge-disjoint triangles, then $\mathit{scfc}(G_t)\leq m-2t$, and the equality holds if and only if $G_t\cong S_{m,t}$. Then we characterize the graphs $G$ with $scfc(G)=k$ for $k\in {1,m-3,m-2,m-1,m}$. In the end, we present a complete characterization for the cubic graphs $G$ with $scfc(G)=2$.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">conflict-free path 是指图中使用单一种颜色的边构成的路径。conflict-free connected 表示图中任意两个顶点之间存在冲突自由路径，即这些路径使用不同的颜色边。进一步地，strongly conflict-free connected 指的是任意两个顶点之间存在长度等于最短路径长度的冲突自由路径，这意味着这些路径不仅使用不同的颜色边，而且在最短路径长度上保持一致。scfc(G) 代表使图 G 成为强冲突自由连接所需的最小颜色数。对于特定的图 G_t，当且仅当 G_t 与 S_{m,t} 同构时，scfc(G_t) ≤ m - 2t 成立。此外，scfc(G) 的值决定了图 G 的特征，对于立方图 G，当 scfc(G) = 2 时，其特征完全确定。因此，scfc(G) 的值不仅影响图的连接性，还决定了图的具体结构特征。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>conflict-free path 使用的是单一种颜色的边。</li>
<li>conflict-free connected 图中任意两个顶点之间存在冲突自由路径。</li>
<li>strongly conflict-free connected 图中任意两个顶点之间存在长度等于最短路径长度的冲突自由路径。</li>
<li>scfc(G) 表示使图 G 成为强冲突自由连接所需的最小颜色数。</li>
<li>scfc(G_t) ≤ m - 2t，当且仅当 G_t ≅ S_{m,t} 时等号成立。</li>
<li>scfc(G) = k 时，G 的特征由 k 的值决定。</li>
<li>对于立方图 G，scfc(G) = 2 的特征完全确定。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-71">正文（抓取，非 AI）</h3>
<p>[1901.08240v1] Strong conflict-free connection of graphs Mathematics &gt; Combinatorics arXiv:1901.08240v1 (math) [Submitted on 24 Jan 2019] Title: Strong conflict-free connection of graphs Authors: Meng Ji , Xueliang Li View a PDF of the paper titled Strong conflict-free connection of graphs, by Meng Ji and 1 other authors View PDF Abstract: A path $P$ in an edge-colored graph is called \emph{a conflict-free path} if there exists a color used on only one of the edges of $P$. An edge-colored graph $G$ is called \emph{conflict-free connected} if for each pair of distinct vertices of $G$ there is a conflict-free path in $G$ connecting them. The graph $G$ is called \emph{strongly conflict-free connected }if for every pair of vertices $u$ and $v$ of $G$ there exists a conflict-free path of length $d_G(u,v)$ in $G$ connecting them. For a connected graph $G$, the \emph{strong conflict-free connection number} of $G$, denoted by $\mathit{scfc}(G)$, is defined as the smallest number of colors that are required in order to make $G$ strongly conflict-free connected. In this paper, we first show that if $G_t$ is a connected graph with $m$ $(m\geq 2)$ edges and $t$ edge-disjoint triangles, then $\mathit{scfc}(G_t)\leq m-2t$, and the equality holds if and only if $G_t\cong S_{m,t}$. Then we characterize the graphs $G$ with $scfc(G)=k$ for $k\in {1,m-3,m-2,m-1,m}$. In the end, we present a complete characterization for the cubic graphs $G$ with $scfc(G)=2$. Comments: 23 pages, 10 figures Subjects: Combinatorics (math.CO) MSC classes: 05C15, 05C40, 05C75 Cite as: arXiv:1901.08240 [math.CO] (or arXiv:1901.08240v1 [math.CO] for this version) https://doi.org/10.48550/arXiv.1901.08240 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Xueliang Li [ view email ] [v1] Thu, 24 Jan 2019 05:50:02 UTC (313 KB) Full-text links: Access Paper: View a PDF of the paper titled Strong conflict-free connection of graphs, by Meng Ji and 1 other authors View PDF TeX Source view license Current browse context: math.CO &lt; prev | next &gt; new | recent | 2019-01 Change to browse by: math References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-72">37. MARS: Margin-Aware Reward-Modeling with Self-Refinement</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.17658v1</li>
<li>来源：arxiv</li>
<li>摘要：Reward modeling is a core component of modern alignment pipelines including RLHF and RLAIF, underpinning policy optimization methods including PPO and TRPO. However, training reliable reward models relies heavily on human-labeled preference data, which is costly and limited, motivating the use of data augmentation. Existing augmentation approaches typically operate at the representation or semantic level and remain agnostic to the reward model's estimation difficulty. In this paper, we propose MARS, an adaptive, margin-aware augmentation and sampling strategy that explicitly targets ambiguous and failure modes of the reward model. Our proposed framework, MARS, concentrates augmentation on low-margin (ambiguous) preference pairs where the reward model is most uncertain, and iteratively refines the training distribution via hard-sample augmentation. We provide theoretical guarantees showing that this strategy increases the average curvature of the loss function hence enhance information and improves conditioning, along with empirical results demonstrating consistent gains over uniform augmentation for robust reward modeling.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">reward模型的训练依赖于昂贵且有限的人工标注偏好数据，这使得模型的训练成本高昂且数据稀缺。现有的数据增强方法通常集中在表示或语义层面，但忽略了reward模型的估计难度。MARS策略则专注于低边际（模糊）偏好对，这些对reward模型的估计最为不确定。理论保证表明，MARS策略通过增加损失函数的平均曲率，增强了信息并改善了条件。此外，MARS通过硬样本增强迭代精炼训练分布，特别关注reward模型的模糊和失败模式，从而在鲁棒reward建模中提供了持续的收益，优于均匀增强。因此，MARS策略不仅提高了模型的准确性，还增强了其在模糊和不确定情况下的鲁棒性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>reward模型的训练依赖于昂贵且有限的人工标注偏好数据。</li>
<li>现有的数据增强方法通常在表示或语义层面进行，但忽略了reward模型的估计难度。</li>
<li>MARS策略集中在低边际（模糊）偏好对上，这些对reward模型最不确定。</li>
<li>理论保证表明，MARS策略增加了损失函数的平均曲率，从而增强信息并改善条件。</li>
<li>MARS通过硬样本增强迭代精炼训练分布。</li>
<li>MARS策略在鲁棒reward建模中提供了持续的收益，优于均匀增强。</li>
<li>MARS特别关注reward模型的模糊和失败模式。</li>
<li>损失函数的平均曲率增加有助于提高信息量和改善条件。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-73">正文（抓取，非 AI）</h3>
<p>[2602.17658v1] MARS: Margin-Aware Reward-Modeling with Self-Refinement Computer Science &gt; Machine Learning arXiv:2602.17658v1 (cs) [Submitted on 19 Feb 2026] Title: MARS: Margin-Aware Reward-Modeling with Self-Refinement Authors: Payel Bhattacharjee , Osvaldo Simeone , Ravi Tandon View a PDF of the paper titled MARS: Margin-Aware Reward-Modeling with Self-Refinement, by Payel Bhattacharjee and 2 other authors View PDF HTML (experimental) Abstract: Reward modeling is a core component of modern alignment pipelines including RLHF and RLAIF, underpinning policy optimization methods including PPO and TRPO. However, training reliable reward models relies heavily on human-labeled preference data, which is costly and limited, motivating the use of data augmentation. Existing augmentation approaches typically operate at the representation or semantic level and remain agnostic to the reward model's estimation difficulty. In this paper, we propose MARS, an adaptive, margin-aware augmentation and sampling strategy that explicitly targets ambiguous and failure modes of the reward model. Our proposed framework, MARS, concentrates augmentation on low-margin (ambiguous) preference pairs where the reward model is most uncertain, and iteratively refines the training distribution via hard-sample augmentation. We provide theoretical guarantees showing that this strategy increases the average curvature of the loss function hence enhance information and improves conditioning, along with empirical results demonstrating consistent gains over uniform augmentation for robust reward modeling. Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI); Information Theory (cs.IT) Cite as: arXiv:2602.17658 [cs.LG] (or arXiv:2602.17658v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.17658 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Payel Bhattacharjee [ view email ] [v1] Thu, 19 Feb 2026 18:59:03 UTC (26,329 KB) Full-text links: Access Paper: View a PDF of the paper titled MARS: Margin-Aware Reward-Modeling with Self-Refinement, by Payel Bhattacharjee and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI cs.IT math math.IT References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-74">38. Composable Model-Free RL for Navigation with Input-Affine Systems</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.12492v1</li>
<li>来源：arxiv</li>
<li>摘要：As autonomous robots move into complex, dynamic real-world environments, they must learn to navigate safely in real time, yet anticipating all possible behaviors is infeasible. We propose a composable, model-free reinforcement learning method that learns a value function and an optimal policy for each individual environment element (e.g., goal or obstacle) and composes them online to achieve goal reaching and collision avoidance. Assuming unknown nonlinear dynamics that evolve in continuous time and are input-affine, we derive a continuous-time Hamilton-Jacobi-Bellman (HJB) equation for the value function and show that the corresponding advantage function is quadratic in the action and optimal policy. Based on this structure, we introduce a model-free actor-critic algorithm that learns policies and value functions for static or moving obstacles using gradient descent. We then compose multiple reach/avoid models via a quadratically constrained quadratic program (QCQP), yielding formal obstacle-avoidance guarantees in terms of value-function level sets, providing a model-free alternative to CLF/CBF-based controllers. Simulations demonstrate improved performance over a PPO baseline ap</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">value function 的学习基于连续时间的Hamilton-Jacobi-Bellman（HJB）方程，而优势函数在动作上是二次的。模型自由的演员-评论家算法使用梯度下降来学习策略和价值函数，这种方法提供了一种模型自由的替代CLF/CBF控制器。输入齐次性假设对于推导优势函数的结构至关重要，而连续时间的HJB方程适用于未知的非线性动力学。此外，假设未知的非线性动力学是输入齐次的，使得通过价值函数等值集给出障碍物避免保证成为可能。障碍物避免通过价值函数等值集的形式化保证实现，而障碍物模型的组合通过二次约束的二次规划来实现。模拟显示了相对于PPO基线的改进性能，因此该方法在实际应用中具有显著的优势。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>value function 的学习基于连续时间的Hamilton-Jacobi-Bellman方程。</li>
<li>优势函数在动作上是二次的。</li>
<li>假设未知的非线性动力学是输入齐次的。</li>
<li>模型自由的演员-评论家算法使用梯度下降来学习策略和价值函数。</li>
<li>障碍物避免保证通过价值函数等值集给出。</li>
<li>该方法提供了一种模型自由的替代CLF/CBF控制器。</li>
<li>模拟显示了相对于PPO基线的改进性能。</li>
<li>输入齐次性假设对于推导优势函数的结构至关重要。</li>
<li>连续时间的HJB方程适用于未知的非线性动力学。</li>
<li>障碍物模型的组合通过二次约束的二次规划实现。</li>
<li>价值函数等值集提供了形式化的障碍物避免保证。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-75">正文（抓取，非 AI）</h3>
<p>[2602.12492v1] Composable Model-Free RL for Navigation with Input-Affine Systems Computer Science &gt; Robotics arXiv:2602.12492v1 (cs) [Submitted on 13 Feb 2026] Title: Composable Model-Free RL for Navigation with Input-Affine Systems Authors: Xinhuan Sang , Abdelrahman Abdelgawad , Roberto Tron View a PDF of the paper titled Composable Model-Free RL for Navigation with Input-Affine Systems, by Xinhuan Sang and 2 other authors View PDF HTML (experimental) Abstract: As autonomous robots move into complex, dynamic real-world environments, they must learn to navigate safely in real time, yet anticipating all possible behaviors is infeasible. We propose a composable, model-free reinforcement learning method that learns a value function and an optimal policy for each individual environment element (e.g., goal or obstacle) and composes them online to achieve goal reaching and collision avoidance. Assuming unknown nonlinear dynamics that evolve in continuous time and are input-affine, we derive a continuous-time Hamilton-Jacobi-Bellman (HJB) equation for the value function and show that the corresponding advantage function is quadratic in the action and optimal policy. Based on this structure, we introduce a model-free actor-critic algorithm that learns policies and value functions for static or moving obstacles using gradient descent. We then compose multiple reach/avoid models via a quadratically constrained quadratic program (QCQP), yielding formal obstacle-avoidance guarantees in terms of value-function level sets, providing a model-free alternative to CLF/CBF-based controllers. Simulations demonstrate improved performance over a PPO baseline applied to a discrete-time approximation. Comments: 17 pages, 8 figures. Submitted to WAFR 2026 (under review) Subjects: Robotics (cs.RO) ; Machine Learning (cs.LG) Cite as: arXiv:2602.12492 [cs.RO] (or arXiv:2602.12492v1 [cs.RO] for this version) https://doi.org/10.48550/arXiv.2602.12492 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Xinhuan Sang [ view email ] [v1] Fri, 13 Feb 2026 00:19:35 UTC (3,979 KB) Full-text links: Access Paper: View a PDF of the paper titled Composable Model-Free RL for Navigation with Input-Affine Systems, by Xinhuan Sang and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.RO &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-76">39. AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection</h2>
<ul>
<li>链接：https://arxiv.org/abs/2511.13880v1</li>
<li>来源：arxiv</li>
<li>摘要：This paper studies the problem of class-incremental learning (CIL), a core setting within continual learning where a model learns a sequence of tasks, each containing a distinct set of classes. Traditional CIL methods, which do not leverage pre-trained models (PTMs), suffer from catastrophic forgetting (CF) due to the need to incrementally learn both feature representations and the classifier. The integration of PTMs into CIL has recently led to efficient approaches that treat the PTM as a fixed feature extractor combined with analytic classifiers, achieving state-of-the-art performance. However, they still face a major limitation: the inability to continually adapt feature representations to best suit the CIL tasks, leading to suboptimal performance. To address this, we propose AnaCP (Analytic Contrastive Projection), a novel method that preserves the efficiency of analytic classifiers while enabling incremental feature adaptation without gradient-based training, thereby eliminating the CF caused by gradient updates. Our experiments show that AnaCP not only outperforms existing baselines but also achieves the accuracy level of joint training, which is regarded as the upper bound o</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">CIL需要同时学习特征表示和分类器，这导致了灾难性遗忘的问题。传统CIL方法由于无法利用预训练模型，因此容易出现灾难性遗忘。为了解决这一问题，预训练模型的集成虽然提高了CIL的效率，但特征表示仍难以适应新任务。AnaCP通过对比投影实现特征表示的逐步适应，从而避免了灾难性遗忘。此外，AnaCP保持了分析分类器的效率，同时允许特征表示的逐步适应，从而提高了CIL的整体性能。实验结果表明，AnaCP优于现有基线，并接近联合训练的性能上限。因此，AnaCP解决了传统CIL方法无法适应特征表示的问题，为CIL领域带来了新的解决方案。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>CIL需要同时学习特征表示和分类器，导致灾难性遗忘。</li>
<li>传统CIL方法无法利用预训练模型，因此容易出现灾难性遗忘。</li>
<li>预训练模型的集成提高了CIL的效率，但特征表示仍难以适应。</li>
<li>AnaCP通过对比投影实现特征表示的逐步适应，避免了灾难性遗忘。</li>
<li>AnaCP保持了分析分类器的效率，同时允许特征表示的逐步适应。</li>
<li>AnaCP的实验结果优于现有基线，并接近联合训练的性能上限。</li>
<li>AnaCP解决了传统CIL方法无法适应特征表示的问题。</li>
<li>联合训练被认为是CIL的性能上限。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-77">正文（抓取，非 AI）</h3>
<p>[2511.13880v1] AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection Computer Science &gt; Machine Learning arXiv:2511.13880v1 (cs) [Submitted on 17 Nov 2025] Title: AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection Authors: Saleh Momeni , Changnan Xiao , Bing Liu View a PDF of the paper titled AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection, by Saleh Momeni and 2 other authors View PDF HTML (experimental) Abstract: This paper studies the problem of class-incremental learning (CIL), a core setting within continual learning where a model learns a sequence of tasks, each containing a distinct set of classes. Traditional CIL methods, which do not leverage pre-trained models (PTMs), suffer from catastrophic forgetting (CF) due to the need to incrementally learn both feature representations and the classifier. The integration of PTMs into CIL has recently led to efficient approaches that treat the PTM as a fixed feature extractor combined with analytic classifiers, achieving state-of-the-art performance. However, they still face a major limitation: the inability to continually adapt feature representations to best suit the CIL tasks, leading to suboptimal performance. To address this, we propose AnaCP (Analytic Contrastive Projection), a novel method that preserves the efficiency of analytic classifiers while enabling incremental feature adaptation without gradient-based training, thereby eliminating the CF caused by gradient updates. Our experiments show that AnaCP not only outperforms existing baselines but also achieves the accuracy level of joint training, which is regarded as the upper bound of CIL. Subjects: Machine Learning (cs.LG) ; Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2511.13880 [cs.LG] (or arXiv:2511.13880v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2511.13880 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Saleh Momeni [ view email ] [v1] Mon, 17 Nov 2025 19:56:15 UTC (651 KB) Full-text links: Access Paper: View a PDF of the paper titled AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection, by Saleh Momeni and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-11 Change to browse by: cs cs.CV References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-78">40. Dynamic Interference Management for TN-NTN Coexistence in the Upper Mid-Band</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.10813v1</li>
<li>来源：arxiv</li>
<li>摘要：The coexistence of terrestrial networks (TN) and non-terrestrial networks (NTN) in the frequency range 3 (FR3) upper mid-band presents considerable interference concerns, as dense TN deployments can severely degrade NTN downlink performance. Existing studies rely on interference-nulling beamforming, precoding, or exclusion zones that require accurate channel state information (CSI) and static coordination, making them unsuitable for dynamic NTN scenarios. To overcome these limitations, we develop an optimization framework that jointly controls TN downlink power, uplink power, and antenna downtilt to protect NTN links while preserving terrestrial performance. The resultant non-convex coupling between TN and NTN parameters is addressed by a Proximal Policy Optimization (PPO)-based reinforcement learning method that develops adaptive power and tilt control strategies. Simulation results demonstrate a reduction up to 8 dB in the median interference-to-noise ratio (INR) while maintaining over 87% TN basestation activity, outperforming conventional baseline methods and validating the feasibility of the proposed strategy for FR3 coexistence.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，密集部署的终端节点（TN）可能会严重降低新型终端节点（NTN）的下行链路性能，这主要是因为密集部署导致的干扰。其次，为了应对这一问题，需要采用干扰消除波束成形、预编码或排除区等技术，但这些技术的有效实施依赖于准确的信道状态信息（CSI）和静态协调。此外，优化框架通过联合控制TN的下行链路功率、上行链路功率以及天线俯仰角来解决这一问题。因此，通过基于策略梯度（PPO）的强化学习方法，可以有效处理TN和NTN参数之间的非凸耦合关系。最终，模拟结果表明，该策略可以将中位干扰噪声比（INR）降低高达8 dB，并保持超过87%的TN基站活动。因此，与传统的基线方法相比，该策略表现出更好的性能。这项工作已被接受在2026年IEEE国际通信大会（IEEE ICC 2026）上发表。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>dense TN deployments can severely degrade NTN downlink performance</li>
<li>interference-nulling beamforming, precoding, or exclusion zones require accurate CSI and static coordination</li>
<li>the optimization framework jointly controls TN downlink power, uplink power, and antenna downtilt</li>
<li>the non-convex coupling between TN and NTN parameters is addressed by PPO-based reinforcement learning</li>
<li>simulation results demonstrate a reduction up to 8 dB in the median INR</li>
<li>the proposed strategy maintains over 87% TN basestation activity</li>
<li>conventional baseline methods are outperformed by the proposed strategy</li>
<li>the work has been accepted for publication in the IEEE ICC 2026 Conference</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-79">正文（抓取，非 AI）</h3>
<p>[2602.10813v1] Dynamic Interference Management for TN-NTN Coexistence in the Upper Mid-Band Computer Science &gt; Information Theory arXiv:2602.10813v1 (cs) [Submitted on 11 Feb 2026] Title: Dynamic Interference Management for TN-NTN Coexistence in the Upper Mid-Band Authors: Pradyumna Kumar Bishoyi , Chia Chia Lee , Navid Keshtiarast , Marina Petrova View a PDF of the paper titled Dynamic Interference Management for TN-NTN Coexistence in the Upper Mid-Band, by Pradyumna Kumar Bishoyi and 3 other authors View PDF HTML (experimental) Abstract: The coexistence of terrestrial networks (TN) and non-terrestrial networks (NTN) in the frequency range 3 (FR3) upper mid-band presents considerable interference concerns, as dense TN deployments can severely degrade NTN downlink performance. Existing studies rely on interference-nulling beamforming, precoding, or exclusion zones that require accurate channel state information (CSI) and static coordination, making them unsuitable for dynamic NTN scenarios. To overcome these limitations, we develop an optimization framework that jointly controls TN downlink power, uplink power, and antenna downtilt to protect NTN links while preserving terrestrial performance. The resultant non-convex coupling between TN and NTN parameters is addressed by a Proximal Policy Optimization (PPO)-based reinforcement learning method that develops adaptive power and tilt control strategies. Simulation results demonstrate a reduction up to 8 dB in the median interference-to-noise ratio (INR) while maintaining over 87% TN basestation activity, outperforming conventional baseline methods and validating the feasibility of the proposed strategy for FR3 coexistence. Comments: This work has been accepted for publication in the IEEE ICC 2026 Conference Subjects: Information Theory (cs.IT) ; Systems and Control (eess.SY) Cite as: arXiv:2602.10813 [cs.IT] (or arXiv:2602.10813v1 [cs.IT] for this version) https://doi.org/10.48550/arXiv.2602.10813 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Navid Keshtiarast [ view email ] [v1] Wed, 11 Feb 2026 12:54:28 UTC (10,798 KB) Full-text links: Access Paper: View a PDF of the paper titled Dynamic Interference Management for TN-NTN Coexistence in the Upper Mid-Band, by Pradyumna Kumar Bishoyi and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.IT &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.SY eess eess.SY math math.IT References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-80">41. Advancing Analytic Class-Incremental Learning through Vision-Language Calibration</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.13670v1</li>
<li>来源：arxiv</li>
<li>摘要：Class-incremental learning (CIL) with pre-trained models (PTMs) faces a critical trade-off between efficient adaptation and long-term stability. While analytic learning enables rapid, recursive closed-form updates, its efficacy is often compromised by accumulated errors and feature incompatibility. In this paper, we first conduct a systematic study to dissect the failure modes of PTM-based analytic CIL, identifying representation rigidity as the primary bottleneck. Motivated by these insights, we propose \textbf{VILA}, a novel dual-branch framework that advances analytic CIL via a two-level vision-language calibration strategy. Specifically, we coherently fuse plastic, task-adapted features with a frozen, universal semantic anchor at the feature level through geometric calibration, and leverage cross-modal priors at the decision level to rectify prediction bias. This confluence maintains analytic-learning's extreme efficiency while overcoming its inherent brittleness. Extensive experiments across eight benchmarks demonstrate that VILA consistently yields superior performance, particularly in fine-grained and long-sequence scenarios. Our framework harmonizes high-fidelity prediction</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">efficient adaptation often comes at the cost of long-term stability, which is a common challenge in many learning systems. In the context of PTM-based analytic CIL, representation rigidity is identified as the main bottleneck, hindering the system's ability to adapt efficiently. To address this issue, VILA (Vision-Language Integrated Learning Architecture) is designed to maintain the efficiency of analytic learning while mitigating its brittleness. VILA achieves this by employing a dual-branch framework for vision-language calibration, which helps in fusing task-adapted features with a universal semantic anchor through geometric calibration. Additionally, VILA leverages cross-modal priors to correct prediction bias at the decision level, ensuring high-fidelity predictions in fine-grained and long-sequence scenarios. This harmonization of high-fidelity prediction with the simplicity of analytic learning makes VILA particularly effective in these specific contexts.</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>efficient adaptation often comes at the cost of long-term stability.</li>
<li>representation rigidity is identified as the main bottleneck for PTM-based analytic CIL.</li>
<li>VILA maintains the efficiency of analytic learning while addressing its brittleness.</li>
<li>VILA uses a dual-branch framework for vision-language calibration.</li>
<li>geometric calibration is used to fuse task-adapted features with a universal semantic anchor.</li>
<li>cross-modal priors are leveraged to correct prediction bias at the decision level.</li>
<li>VILA performs particularly well in fine-grained and long-sequence scenarios.</li>
<li>VILA harmonizes high-fidelity prediction with the simplicity of analytic learning.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-81">正文（抓取，非 AI）</h3>
<p>[2602.13670v1] Advancing Analytic Class-Incremental Learning through Vision-Language Calibration Computer Science &gt; Machine Learning arXiv:2602.13670v1 (cs) [Submitted on 14 Feb 2026] Title: Advancing Analytic Class-Incremental Learning through Vision-Language Calibration Authors: Binyu Zhao , Wei Zhang , Xingrui Yu , Zhaonian Zou , Ivor Tsang View a PDF of the paper titled Advancing Analytic Class-Incremental Learning through Vision-Language Calibration, by Binyu Zhao and 4 other authors View PDF Abstract: Class-incremental learning (CIL) with pre-trained models (PTMs) faces a critical trade-off between efficient adaptation and long-term stability. While analytic learning enables rapid, recursive closed-form updates, its efficacy is often compromised by accumulated errors and feature incompatibility. In this paper, we first conduct a systematic study to dissect the failure modes of PTM-based analytic CIL, identifying representation rigidity as the primary bottleneck. Motivated by these insights, we propose \textbf{VILA}, a novel dual-branch framework that advances analytic CIL via a two-level vision-language calibration strategy. Specifically, we coherently fuse plastic, task-adapted features with a frozen, universal semantic anchor at the feature level through geometric calibration, and leverage cross-modal priors at the decision level to rectify prediction bias. This confluence maintains analytic-learning's extreme efficiency while overcoming its inherent brittleness. Extensive experiments across eight benchmarks demonstrate that VILA consistently yields superior performance, particularly in fine-grained and long-sequence scenarios. Our framework harmonizes high-fidelity prediction with the simplicity of analytic learning. Our code is available at this https URL Comments: 14 pages, 11 figures Subjects: Machine Learning (cs.LG) Cite as: arXiv:2602.13670 [cs.LG] (or arXiv:2602.13670v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.13670 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Binyu Zhao [ view email ] [v1] Sat, 14 Feb 2026 08:32:51 UTC (1,137 KB) Full-text links: Access Paper: View a PDF of the paper titled Advancing Analytic Class-Incremental Learning through Vision-Language Calibration, by Binyu Zhao and 4 other authors View PDF TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-82">42. TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.11767v1</li>
<li>来源：arxiv</li>
<li>摘要：Advances in large language models (LLMs) are driving a shift toward using reinforcement learning (RL) to train agents from iterative, multi-turn interactions across tasks. However, multi-turn RL remains challenging as rewards are often sparse or delayed, and environments can be stochastic. In this regime, naive trajectory sampling can hinder exploitation and induce mode collapse. We propose TSR (Trajectory-Search Rollouts), a training-time approach that repurposes test-time scaling ideas for improved per-turn rollout generation. TSR performs lightweight tree-style search to construct high-quality trajectories by selecting high-scoring actions at each turn using task-specific feedback. This improves rollout quality and stabilizes learning while leaving the underlying optimization objective unchanged, making TSR optimizer-agnostic. We instantiate TSR with best-of-N, beam, and shallow lookahead search, and pair it with PPO and GRPO, achieving up to 15% performance gains and more stable learning on Sokoban, FrozenLake, and WebShop tasks at a one-time increase in training compute. By moving search from inference time to the rollout stage of training, TSR provides a simple and general me</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">naive trajectory sampling can hinder exploitation and induce mode collapse, which limits the performance and stability of learning processes. To address these issues, TSR (Trajectory Sampling Repurposing) repurposes test-time scaling ideas for improved per-turn rollout generation, performing a lightweight tree-style search to construct high-quality trajectories. By moving search from inference time to the rollout stage of training, TSR significantly enhances rollout quality and stabilizes learning without altering the optimization objective. Moreover, TSR is optimizer-agnostic, allowing its use with various optimization methods, and can be instantiated with best-of-N, beam, and shallow lookahead search strategies. Consequently, TSR achieves up to 15% performance gains and more stable learning, providing a simple and general mechanism for stronger multi-turn agent learning. Furthermore, TSR complements existing frameworks and rejection-sampling-style selection methods, making it a versatile tool for improving the learning and performance of multi-turn agents.</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>naive trajectory sampling can hinder exploitation and induce mode collapse</li>
<li>TSR repurposes test-time scaling ideas for improved per-turn rollout generation</li>
<li>TSR performs lightweight tree-style search to construct high-quality trajectories</li>
<li>TSR improves rollout quality and stabilizes learning without changing the optimization objective</li>
<li>TSR is optimizer-agnostic, allowing its use with various optimization methods</li>
<li>TSR can be instantiated with best-of-N, beam, and shallow lookahead search</li>
<li>TSR achieves up to 15% performance gains and more stable learning</li>
<li>TSR moves search from inference time to the rollout stage of training</li>
<li>TSR provides a simple and general mechanism for stronger multi-turn agent learning</li>
<li>TSR is complementary to existing frameworks and rejection-sampling-style selection methods</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-83">正文（抓取，非 AI）</h3>
<p>[2602.11767v1] TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents Computer Science &gt; Artificial Intelligence arXiv:2602.11767v1 (cs) [Submitted on 12 Feb 2026] Title: TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents Authors: Aladin Djuhera , Swanand Ravindra Kadhe , Farhan Ahmed , Holger Boche View a PDF of the paper titled TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents, by Aladin Djuhera and 3 other authors View PDF HTML (experimental) Abstract: Advances in large language models (LLMs) are driving a shift toward using reinforcement learning (RL) to train agents from iterative, multi-turn interactions across tasks. However, multi-turn RL remains challenging as rewards are often sparse or delayed, and environments can be stochastic. In this regime, naive trajectory sampling can hinder exploitation and induce mode collapse. We propose TSR (Trajectory-Search Rollouts), a training-time approach that repurposes test-time scaling ideas for improved per-turn rollout generation. TSR performs lightweight tree-style search to construct high-quality trajectories by selecting high-scoring actions at each turn using task-specific feedback. This improves rollout quality and stabilizes learning while leaving the underlying optimization objective unchanged, making TSR optimizer-agnostic. We instantiate TSR with best-of-N, beam, and shallow lookahead search, and pair it with PPO and GRPO, achieving up to 15% performance gains and more stable learning on Sokoban, FrozenLake, and WebShop tasks at a one-time increase in training compute. By moving search from inference time to the rollout stage of training, TSR provides a simple and general mechanism for stronger multi-turn agent learning, complementary to existing frameworks and rejection-sampling-style selection methods. Subjects: Artificial Intelligence (cs.AI) ; Computation and Language (cs.CL); Machine Learning (cs.LG) Cite as: arXiv:2602.11767 [cs.AI] (or arXiv:2602.11767v1 [cs.AI] for this version) https://doi.org/10.48550/arXiv.2602.11767 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Aladin Djuhera [ view email ] [v1] Thu, 12 Feb 2026 09:49:24 UTC (2,786 KB) Full-text links: Access Paper: View a PDF of the paper titled TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents, by Aladin Djuhera and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.AI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CL cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-84">43. Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.15640v1</li>
<li>来源：arxiv</li>
<li>摘要：Semantic communication promises task-aligned transmission but must reconcile semantic fidelity with stringent latency guarantees in immersive and safety-critical services. This paper introduces a time-constrained human-in-the-loop reinforcement learning (TC-HITL-RL) framework that embeds human feedback, semantic utility, and latency control within a semantic-aware Open radio access network (RAN) architecture. We formulate semantic adaptation driven by human feedback as a constrained Markov decision process (CMDP) whose state captures semantic quality, human preferences, queue slack, and channel dynamics, and solve it via a primal--dual proximal policy optimization algorithm with action shielding and latency-aware reward shaping. The resulting policy preserves PPO-level semantic rewards while tightening the variability of both air-interface and near-real-time RAN intelligent controller processing budgets. Simulations over point-to-multipoint links with heterogeneous deadlines show that TC-HITL-RL consistently meets per-user timing constraints, outperforms baseline schedulers in reward, and stabilizes resource consumption, providing a practical blueprint for latency-aware semantic ad</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">CMDP状态涵盖了语义质量、人类偏好、队列余量和信道动态，这些因素共同构成了决策的基础。为了解决CMDP，PPO算法通过动作屏蔽和延迟感知奖励塑形来调整处理预算，确保了资源的有效利用。TC-HITL-RL框架则进一步嵌入了人类反馈、语义效用和延迟控制，确保每位用户的定时约束得到满足。与基线调度器相比，TC-HITL-RL在奖励上表现更优，不仅稳定了资源消耗，还为延迟感知语义适应提供了实用的蓝图。因此，通过TC-HITL-RL框架，处理预算被调整以紧缩语义奖励的变异性，从而实现了更高效的资源管理和用户满意度。处理预算包括了空中接口和近实时RAN智能控制器，进一步增强了系统的灵活性和响应性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>CMDP状态包括了语义质量、人类偏好、队列余量和信道动态。</li>
<li>TC-HITL-RL框架嵌入了人类反馈、语义效用和延迟控制。</li>
<li>PPO算法通过动作屏蔽和延迟感知奖励塑形来解决CMDP。</li>
<li>TC-HITL-RL确保了每位用户的定时约束。</li>
<li>TC-HITL-RL在奖励上优于基线调度器。</li>
<li>TC-HITL-RL稳定了资源消耗。</li>
<li>TC-HITL-RL为延迟感知语义适应提供了实用蓝图。</li>
<li>CMDP的解决方案通过调整处理预算来紧缩语义奖励的变异性。</li>
<li>处理预算包括了空中接口和近实时RAN智能控制器。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-85">正文（抓取，非 AI）</h3>
<p>[2602.15640v1] Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications Electrical Engineering and Systems Science &gt; Signal Processing arXiv:2602.15640v1 (eess) [Submitted on 17 Feb 2026] Title: Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications Authors: Peizheng Li , Xinyi Lin , Adnan Aijaz View a PDF of the paper titled Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications, by Peizheng Li and 2 other authors View PDF HTML (experimental) Abstract: Semantic communication promises task-aligned transmission but must reconcile semantic fidelity with stringent latency guarantees in immersive and safety-critical services. This paper introduces a time-constrained human-in-the-loop reinforcement learning (TC-HITL-RL) framework that embeds human feedback, semantic utility, and latency control within a semantic-aware Open radio access network (RAN) architecture. We formulate semantic adaptation driven by human feedback as a constrained Markov decision process (CMDP) whose state captures semantic quality, human preferences, queue slack, and channel dynamics, and solve it via a primal--dual proximal policy optimization algorithm with action shielding and latency-aware reward shaping. The resulting policy preserves PPO-level semantic rewards while tightening the variability of both air-interface and near-real-time RAN intelligent controller processing budgets. Simulations over point-to-multipoint links with heterogeneous deadlines show that TC-HITL-RL consistently meets per-user timing constraints, outperforms baseline schedulers in reward, and stabilizes resource consumption, providing a practical blueprint for latency-aware semantic adaptation. Comments: 6 pages, 8 figures. This paper has been accepted for publication in IEEE ICC 2026 Subjects: Signal Processing (eess.SP) ; Machine Learning (cs.LG) Cite as: arXiv:2602.15640 [eess.SP] (or arXiv:2602.15640v1 [eess.SP] for this version) https://doi.org/10.48550/arXiv.2602.15640 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Peizheng Li [ view email ] [v1] Tue, 17 Feb 2026 15:07:41 UTC (926 KB) Full-text links: Access Paper: View a PDF of the paper titled Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications, by Peizheng Li and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SP &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.LG eess References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-86">44. MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.04319v1</li>
<li>来源：arxiv</li>
<li>摘要：The reliable application of deep learning models to software engineering tasks hinges on high-quality training data. Yet, large-scale repositories inevitably introduce noisy or mislabeled examples that degrade both accuracy and robustness. While Noise Label Learning (NLL) has been extensively studied in other fields, there are a few works that investigate NLL in Software Engineering (SE) and Large Language Models (LLMs) for SE tasks. In this work, we propose MANTRA, a Multi-stage Adaptive Noise TReAtment framework that embeds noise diagnosis and mitigation directly into the fine-tuning process of code-Pretrained Language Models (PTM) and code-LLMs. We first investigate the effect of noise at varying levels on convergence and loss trajectories of the models. Then we apply an adaptive dropout strategy guided by per-sample loss dynamics and Gaussian Mixture Model clustering to exclude persistently noisy points while preserving clean data. Applying to code summarization and commit intent classification, our experiments reveal that some LLMs are more sensitive to noise than others. However, with MANTRA, the performance of all models in both tasks is improved. MANTRA enables researchers </li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">MANTRA框架通过适应性丢弃策略有效地处理了噪声，从而提高了不同模型在软件工程任务中的性能。然而，噪声对模型的收敛和损失轨迹有显著影响，这表明MANTRA框架中的噪声处理策略可能并不适用于所有模型。值得注意的是，一些大型语言模型对噪声更为敏感，因此在这些模型上应用MANTRA时可能会遇到更多挑战。尽管如此，MANTRA依然能够显著提升模型的表现。此外，噪声标签学习在软件工程领域研究较少，这表明未来的研究可以进一步探索如何更好地理解和处理噪声，从而进一步优化模型性能。因此，通过MANTRA框架，不仅可以提高模型的性能，还能节省数据清洗和处理的时间，尽管其适用性可能受限于模型的特性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>MANTRA框架中的噪声处理策略可能不适用于所有模型。</li>
<li>MANTRA能够提高不同模型在软件工程任务中的性能。</li>
<li>噪声对模型收敛和损失轨迹有影响。</li>
<li>适应性丢弃策略有助于排除持久性噪声点。</li>
<li>一些大型语言模型对噪声更为敏感。</li>
<li>数据清洗和处理时间可以被节省。</li>
<li>噪声标签学习在软件工程领域研究较少。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-87">正文（抓取，非 AI）</h3>
<p>[2512.04319v1] MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training Computer Science &gt; Software Engineering arXiv:2512.04319v1 (cs) [Submitted on 3 Dec 2025] Title: MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training Authors: Zixiao Zhao , Fatemeh H. Fard , Jie JW Wu View a PDF of the paper titled MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training, by Zixiao Zhao and 1 other authors View PDF HTML (experimental) Abstract: The reliable application of deep learning models to software engineering tasks hinges on high-quality training data. Yet, large-scale repositories inevitably introduce noisy or mislabeled examples that degrade both accuracy and robustness. While Noise Label Learning (NLL) has been extensively studied in other fields, there are a few works that investigate NLL in Software Engineering (SE) and Large Language Models (LLMs) for SE tasks. In this work, we propose MANTRA, a Multi-stage Adaptive Noise TReAtment framework that embeds noise diagnosis and mitigation directly into the fine-tuning process of code-Pretrained Language Models (PTM) and code-LLMs. We first investigate the effect of noise at varying levels on convergence and loss trajectories of the models. Then we apply an adaptive dropout strategy guided by per-sample loss dynamics and Gaussian Mixture Model clustering to exclude persistently noisy points while preserving clean data. Applying to code summarization and commit intent classification, our experiments reveal that some LLMs are more sensitive to noise than others. However, with MANTRA, the performance of all models in both tasks is improved. MANTRA enables researchers and practitioners to reduce the impact of errors introduced by the dataset in training, saves time in data cleaning and processing, while maximizing the effect of fine-tuning. Subjects: Software Engineering (cs.SE) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2512.04319 [cs.SE] (or arXiv:2512.04319v1 [cs.SE] for this version) https://doi.org/10.48550/arXiv.2512.04319 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Zixiao Zhao [ view email ] [v1] Wed, 3 Dec 2025 23:09:55 UTC (2,179 KB) Full-text links: Access Paper: View a PDF of the paper titled MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training, by Zixiao Zhao and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.SE &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-88">45. Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.11076v1</li>
<li>来源：arxiv</li>
<li>摘要：Sixth-generation (6G) radio access networks (RANs) must enforce strict service-level agreements (SLAs) for heterogeneous slices, yet sudden latency spikes remain difficult to diagnose and resolve with conventional deep reinforcement learning (DRL) or explainable RL (XRL). We propose \emph{Attention-Enhanced Multi-Agent Proximal Policy Optimization (AE-MAPPO)}, which integrates six specialized attention mechanisms into multi-agent slice control and surfaces them as zero-cost, faithful explanations. The framework operates across O-RAN timescales with a three-phase strategy: predictive, reactive, and inter-slice optimization.   A URLLC case study shows AE-MAPPO resolves a latency spike in $18$ms, restores latency to $0.98$ms with $99.9999\%$ reliability, and reduces troubleshooting time by $93\%$ while maintaining eMBB and mMTC continuity. These results confirm AE-MAPPO's ability to combine SLA compliance with inherent interpretability, enabling trustworthy and real-time automation for 6G RAN slicing.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，传统深度强化学习（DRL）或可解释的强化学习（XRL）难以诊断和解决突发的延迟峰值。为此，AE-MAPPO框架通过整合六种专门的注意力机制，实现了针对多代理切片控制的高效管理。该框架在O-RAN时间尺度上运行，并采用三阶段策略：预测、反应和跨切片优化。AE-MAPPO能够在18毫秒内解决延迟峰值，将延迟恢复至0.98毫秒，且具有99.9999%的可靠性。通过结合SLA合规性和内在可解释性，AE-MAPPO实现了可信且实时的6G RAN切片自动化。案例研究证实了AE-MAPPO在处理6G RAN切片挑战方面的有效性。研究结果表明，AE-MAPPO在解决延迟峰值方面优于传统方法，其零成本、忠实的解释对于故障排除极为有价值。三阶段策略增强了系统的鲁棒性和适应性。该工作已被接受在IEEE国际通信会议（ICC）上展示，并提供了PDF和HTML格式的论文供阅读。提交历史和相关工具为深入探索提供了额外资源。智能引文功能突显了重要参考和引文，核心推荐器和影响花工具帮助识别关键相关作品及其影响。这些工具为理解研究的更广泛背景提供了全面视角，并帮助研究人员了解相关发展。核心推荐器和影响花工具是理解论文及其在研究社区中影响的重要资源。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>conventional deep reinforcement learning (DRL) or explainable RL (XRL) struggle with diagnosing and resolving sudden latency spikes.</li>
<li>six specialized attention mechanisms are integrated into multi-agent slice control for AE-MAPPO.</li>
<li>the framework operates across O-RAN timescales with a three-phase strategy: predictive, reactive, and inter-slice optimization.</li>
<li>AE-MAPPO resolves a latency spike in 18ms, restoring latency to 0.98ms with 99.9999% reliability.</li>
<li>% reduction in troubleshooting time is achieved while maintaining eMBB and mMTC continuity.</li>
<li>AE-MAPPO combines SLA compliance with inherent interpretability, enabling trustworthy and real-time automation for 6G RAN slicing.</li>
<li>the case study confirms AE-MAPPO's ability to handle 6G RAN slicing challenges effectively.</li>
<li>the results demonstrate AE-MAPPO's superior performance in resolving latency spikes compared to conventional methods.</li>
<li>the framework's predictive phase helps in anticipating potential latency issues.</li>
<li>the reactive phase addresses immediate latency spikes effectively.</li>
<li>the inter-slice optimization phase ensures overall network efficiency and reliability.</li>
<li>the zero-cost, faithful explanations provided by AE-MAPPO are valuable for troubleshooting.</li>
<li>the three-phase strategy enhances the robustness and adaptability of the system.</li>
<li>the work has been accepted for presentation at the IEEE International Conference on Communications (ICC).</li>
<li>the paper is available in PDF and HTML formats for easy access and reading.</li>
<li>the submission history and associated tools provide additional resources for further exploration.</li>
<li>the connected papers and litmaps tools offer insights into related research and publications.</li>
<li>the smart citations feature highlights important references and citations for the paper.</li>
<li>the core recommender provides recommendations based on the paper's content and related works.</li>
<li>the influence flower tool visualizes the impact and connections of the paper within the research community.</li>
<li>the core recommender and influence flower tools help identify key related works and their impact.</li>
<li>the core recommender and influence flower tools are useful for understanding the broader context of the research.</li>
<li>the core recommender and influence flower tools provide a comprehensive view of the paper's significance.</li>
<li>the core recommender and influence flower tools help researchers stay informed about related developments.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-89">正文（抓取，非 AI）</h3>
<p>[2602.11076v1] Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing Electrical Engineering and Systems Science &gt; Systems and Control arXiv:2602.11076v1 (eess) [Submitted on 11 Feb 2026] Title: Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing Authors: Kavan Fatehi , Mostafa Rahmani Ghourtani , Amir Sonee , Poonam Yadav , Alessandra M Russo , Hamed Ahmadi , Radu Calinescu View a PDF of the paper titled Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing, by Kavan Fatehi and 6 other authors View PDF HTML (experimental) Abstract: Sixth-generation (6G) radio access networks (RANs) must enforce strict service-level agreements (SLAs) for heterogeneous slices, yet sudden latency spikes remain difficult to diagnose and resolve with conventional deep reinforcement learning (DRL) or explainable RL (XRL). We propose \emph{Attention-Enhanced Multi-Agent Proximal Policy Optimization (AE-MAPPO)}, which integrates six specialized attention mechanisms into multi-agent slice control and surfaces them as zero-cost, faithful explanations. The framework operates across O-RAN timescales with a three-phase strategy: predictive, reactive, and inter-slice optimization. A URLLC case study shows AE-MAPPO resolves a latency spike in $18$ms, restores latency to $0.98$ms with $99.9999\%$ reliability, and reduces troubleshooting time by $93\%$ while maintaining eMBB and mMTC continuity. These results confirm AE-MAPPO's ability to combine SLA compliance with inherent interpretability, enabling trustworthy and real-time automation for 6G RAN slicing. Comments: This work has been accepted to appear in the IEEE International Conference on Communications (ICC) Subjects: Systems and Control (eess.SY) ; Artificial Intelligence (cs.AI); Signal Processing (eess.SP) Cite as: arXiv:2602.11076 [eess.SY] (or arXiv:2602.11076v1 [eess.SY] for this version) https://doi.org/10.48550/arXiv.2602.11076 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Mostafa Rahmani Ghourtani [ view email ] [v1] Wed, 11 Feb 2026 17:44:03 UTC (1,530 KB) Full-text links: Access Paper: View a PDF of the paper titled Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing, by Kavan Fatehi and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SY &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI cs.SY eess eess.SP References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-90">46. Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes</h2>
<ul>
<li>链接：https://arxiv.org/abs/2601.17530v1</li>
<li>来源：arxiv</li>
<li>摘要：The rapid rise of deepfake technology poses a severe threat to social and political stability by enabling hyper-realistic synthetic media capable of manipulating public perception. However, existing detection methods struggle with two core limitations: (1) modality fragmentation, which leads to poor generalization across diverse and adversarial deepfake modalities; and (2) shallow inter-modal reasoning, resulting in limited detection of fine-grained semantic inconsistencies. To address these, we propose ConLLM (Contrastive Learning with Large Language Models), a hybrid framework for robust multimodal deepfake detection. ConLLM employs a two-stage architecture: stage 1 uses Pre-Trained Models (PTMs) to extract modality-specific embeddings; stage 2 aligns these embeddings via contrastive learning to mitigate modality fragmentation, and refines them using LLM-based reasoning to address shallow inter-modal reasoning by capturing semantic inconsistencies. ConLLM demonstrates strong performance across audio, video, and audio-visual modalities. It reduces audio deepfake EER by up to 50%, improves video accuracy by up to 8%, and achieves approximately 9% accuracy gains in audio-visual task</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">modality fragmentation导致难以在不同模态的深度伪造之间进行泛化，而shallow inter-modal reasoning则限制了对细粒度语义不一致性的检测。尽管PTM-based embeddings在不同模态中提供了9%-10%的一致改进，但现有检测方法难以应对深度伪造的快速崛起带来的威胁。为了解决这些问题，ConLLM通过对比学习和LLM推理，不仅在音频、视频和音频-视觉模态上表现出色，还显著提高了检测准确性。具体而言，EER指标在音频深度伪造检测中降低了50%，视频准确性提高了8%，而音频-视觉任务的准确性提高了约9%。对比学习有助于缓解模态碎片化问题，而LLM推理则用于捕捉语义不一致性，从而有效解决了浅层跨模态推理问题。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>modality fragmentation导致难以在不同模态的深度伪造之间进行泛化。</li>
<li>shallow inter-modal reasoning限制了对细粒度语义不一致性的检测。</li>
<li>PTM-based embeddings在不同模态中提供9%-10%的一致改进。</li>
<li>ConLLM通过对比学习和LLM推理解决了模态碎片化和浅层跨模态推理的问题。</li>
<li>现有检测方法难以应对深度伪造的快速崛起带来的威胁。</li>
<li>ConLLM在音频、视频和音频-视觉模态上表现出色。</li>
<li>EER指标在音频深度伪造检测中降低了50%。</li>
<li>视频准确性提高了8%。</li>
<li>音频-视觉任务的准确性提高了约9%。</li>
<li>对比学习有助于缓解模态碎片化问题。</li>
<li>LLM推理用于捕捉语义不一致性，以解决浅层跨模态推理问题。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-91">正文（抓取，非 AI）</h3>
<p>[2601.17530v1] Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes Computer Science &gt; Computation and Language arXiv:2601.17530v1 (cs) [Submitted on 24 Jan 2026] Title: Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes Authors: Gautam Siddharth Kashyap , Harsh Joshi , Niharika Jain , Ebad Shabbir , Jiechao Gao , Nipun Joshi , Usman Naseem View a PDF of the paper titled Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes, by Gautam Siddharth Kashyap and 6 other authors View PDF HTML (experimental) Abstract: The rapid rise of deepfake technology poses a severe threat to social and political stability by enabling hyper-realistic synthetic media capable of manipulating public perception. However, existing detection methods struggle with two core limitations: (1) modality fragmentation, which leads to poor generalization across diverse and adversarial deepfake modalities; and (2) shallow inter-modal reasoning, resulting in limited detection of fine-grained semantic inconsistencies. To address these, we propose ConLLM (Contrastive Learning with Large Language Models), a hybrid framework for robust multimodal deepfake detection. ConLLM employs a two-stage architecture: stage 1 uses Pre-Trained Models (PTMs) to extract modality-specific embeddings; stage 2 aligns these embeddings via contrastive learning to mitigate modality fragmentation, and refines them using LLM-based reasoning to address shallow inter-modal reasoning by capturing semantic inconsistencies. ConLLM demonstrates strong performance across audio, video, and audio-visual modalities. It reduces audio deepfake EER by up to 50%, improves video accuracy by up to 8%, and achieves approximately 9% accuracy gains in audio-visual tasks. Ablation studies confirm that PTM-based embeddings contribute 9%-10% consistent improvements across modalities. Comments: Accepted at EACL Findings 2026 Subjects: Computation and Language (cs.CL) Cite as: arXiv:2601.17530 [cs.CL] (or arXiv:2601.17530v1 [cs.CL] for this version) https://doi.org/10.48550/arXiv.2601.17530 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Gautam Siddharth Kashyap [ view email ] [v1] Sat, 24 Jan 2026 17:07:51 UTC (888 KB) Full-text links: Access Paper: View a PDF of the paper titled Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes, by Gautam Siddharth Kashyap and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CL &lt; prev | next &gt; new | recent | 2026-01 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-92">47. Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.18386v1</li>
<li>来源：arxiv</li>
<li>摘要：Pure Pursuit (PP) is widely used in autonomous racing for real-time path tracking due to its efficiency and geometric clarity, yet performance is highly sensitive to how key parameters-lookahead distance and steering gain-are chosen. Standard velocity-based schedules adjust these only approximately and often fail to transfer across tracks and speed profiles. We propose a reinforcement-learning (RL) approach that jointly chooses the lookahead Ld and a steering gain g online using Proximal Policy Optimization (PPO). The policy observes compact state features (speed and curvature taps) and outputs (Ld, g) at each control step. Trained in F1TENTH Gym and deployed in a ROS 2 stack, the policy drives PP directly (with light smoothing) and requires no per-map retuning. Across simulation and real-car tests, the proposed RL-PP controller that jointly selects (Ld, g) consistently outperforms fixed-lookahead PP, velocity-scheduled adaptive PP, and an RL lookahead-only variant, and it also exceeds a kinematic MPC raceline tracker under our evaluated settings in lap time, path-tracking accuracy, and steering smoothness, demonstrating that policy-guided parameter tuning can reliably improve clas</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">lookahead距离和steering gain的选择对Pure Pursuit（PP）的性能影响很大，而标准的速度基线调整只能近似地改变这些参数，且难以在不同赛道和速度配置下实现稳定的性能。相比之下，基于强化学习（RL）的方法能够在线联合选择lookahead距离和steering gain，从而显著提升控制性能。提出的RL-PP控制器在模拟和真实车辆测试中均优于固定lookahead的PP，不仅在赛道时间、路径跟踪精度和转向平滑性方面表现出色，还超越了kinematic MPC控制器。此外，RL方法通过政策指导下的参数调整，能够可靠地改善基于经典几何的控制，且不需要针对每个地图重新调整参数。因此，RL方法能够更灵活地适应不同的赛道和速度配置，显著提升Pure Pursuit的性能。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>lookahead距离和 steering gain的选择对Pure Pursuit性能影响很大。</li>
<li>标准的速度基线调整只能近似地改变这些参数，且难以跨不同赛道和速度配置转移。</li>
<li>RL方法能在线联合选择lookahead距离和steering gain，提高控制性能。</li>
<li>提出的RL-PP控制器在模拟和真实车辆测试中均优于固定lookahead的PP。</li>
<li>RL-PP控制器在赛道时间、路径跟踪精度和转向平滑性方面超过kinematic MPC控制器。</li>
<li>policy指导下的参数调整能可靠地改善基于经典几何的控制。</li>
<li>RL方法不需要针对每个地图重新调整参数。</li>
<li>lookahead距离和steering gain的联合选择能显著提升Pure Pursuit的性能。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-93">正文（抓取，非 AI）</h3>
<p>[2602.18386v1] Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO Computer Science &gt; Robotics arXiv:2602.18386v1 (cs) [Submitted on 20 Feb 2026] Title: Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO Authors: Mohamed Elgouhary , Amr S. El-Wakeel View a PDF of the paper titled Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO, by Mohamed Elgouhary and Amr S. El-Wakeel View PDF HTML (experimental) Abstract: Pure Pursuit (PP) is widely used in autonomous racing for real-time path tracking due to its efficiency and geometric clarity, yet performance is highly sensitive to how key parameters-lookahead distance and steering gain-are chosen. Standard velocity-based schedules adjust these only approximately and often fail to transfer across tracks and speed profiles. We propose a reinforcement-learning (RL) approach that jointly chooses the lookahead Ld and a steering gain g online using Proximal Policy Optimization (PPO). The policy observes compact state features (speed and curvature taps) and outputs (Ld, g) at each control step. Trained in F1TENTH Gym and deployed in a ROS 2 stack, the policy drives PP directly (with light smoothing) and requires no per-map retuning. Across simulation and real-car tests, the proposed RL-PP controller that jointly selects (Ld, g) consistently outperforms fixed-lookahead PP, velocity-scheduled adaptive PP, and an RL lookahead-only variant, and it also exceeds a kinematic MPC raceline tracker under our evaluated settings in lap time, path-tracking accuracy, and steering smoothness, demonstrating that policy-guided parameter tuning can reliably improve classical geometry-based control. Subjects: Robotics (cs.RO) ; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY) Cite as: arXiv:2602.18386 [cs.RO] (or arXiv:2602.18386v1 [cs.RO] for this version) https://doi.org/10.48550/arXiv.2602.18386 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Amr El-Wakeel [ view email ] [v1] Fri, 20 Feb 2026 17:48:21 UTC (1,326 KB) Full-text links: Access Paper: View a PDF of the paper titled Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO, by Mohamed Elgouhary and Amr S. El-Wakeel View PDF HTML (experimental) TeX Source view license Current browse context: cs.RO &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI cs.LG cs.SY eess eess.SY References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-94">48. C3Box: A CLIP-based Class-Incremental Learning Toolbox</h2>
<ul>
<li>链接：https://arxiv.org/abs/2601.20852v1</li>
<li>来源：arxiv</li>
<li>摘要：Traditional machine learning systems are typically designed for static data distributions, which suffer from catastrophic forgetting when learning from evolving data streams. Class-Incremental Learning (CIL) addresses this challenge by enabling learning systems to continuously learn new classes while preserving prior knowledge. With the rise of pre-trained models (PTMs) such as CLIP, leveraging their strong generalization and semantic alignment capabilities has become a promising direction in CIL. However, existing CLIP-based CIL methods are often scattered across disparate codebases, rely on inconsistent configurations, hindering fair comparisons, reproducibility, and practical adoption. Therefore, we propose C3Box (CLIP-based Class-inCremental learning toolBOX), a modular and comprehensive Python toolbox. C3Box integrates representative traditional CIL methods, ViT-based CIL methods, and state-of-the-art CLIP-based CIL methods into a unified CLIP-based framework. By inheriting the streamlined design of PyCIL, C3Box provides a JSON-based configuration and standardized execution pipeline. This design enables reproducible experimentation with low engineering overhead and makes C3Box</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">CIL方法通常分散在不同的代码库中，且传统上设计用于静态数据分布，这导致了现有实现往往缺乏统一性。配置不一致会妨碍公平比较和可重复性，尤其是在持续学习的研究中。为了解决这些问题，C3Box提供了一个模块化和全面的Python工具箱，旨在支持主要操作系统，并依赖于广泛使用的开源库。C3Box继承了PyCIL的简洁设计，旨在使实验可重复且工程成本低，从而成为一个可靠的持续学习研究基准平台。C3Box通过提供一个JSON配置和标准化执行管道，确保了配置的一致性，代码可在GitHub上获得，进一步增强了其可靠性和可访问性。因此，C3Box不仅解决了CIL方法的现有问题，还提供了一个统一的、易于使用的平台，以促进持续学习研究的公平性和可重复性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>CIL方法通常分散在不同的代码库中。</li>
<li>配置不一致会妨碍公平比较和可重复性。</li>
<li>C3Box提供了一个JSON配置和标准化执行管道。</li>
<li>C3Box旨在支持主要操作系统。</li>
<li>C3Box依赖于广泛使用的开源库。</li>
<li>CIL传统上设计用于静态数据分布。</li>
<li>CIL方法的现有实现往往缺乏统一性。</li>
<li>C3Box是一个模块化和全面的Python工具箱。</li>
<li>C3Box继承了PyCIL的简洁设计。</li>
<li>CIL旨在使实验可重复且工程成本低。</li>
<li>C3Box是一个可靠的持续学习研究基准平台。</li>
<li>CIL方法通常依赖于不一致的配置。</li>
<li>C3Box代码可在GitHub上获得。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-95">正文（抓取，非 AI）</h3>
<p>[2601.20852v1] C3Box: A CLIP-based Class-Incremental Learning Toolbox Computer Science &gt; Machine Learning arXiv:2601.20852v1 (cs) [Submitted on 28 Jan 2026] Title: C3Box: A CLIP-based Class-Incremental Learning Toolbox Authors: Hao Sun , Da-Wei Zhou View a PDF of the paper titled C3Box: A CLIP-based Class-Incremental Learning Toolbox, by Hao Sun and 1 other authors View PDF HTML (experimental) Abstract: Traditional machine learning systems are typically designed for static data distributions, which suffer from catastrophic forgetting when learning from evolving data streams. Class-Incremental Learning (CIL) addresses this challenge by enabling learning systems to continuously learn new classes while preserving prior knowledge. With the rise of pre-trained models (PTMs) such as CLIP, leveraging their strong generalization and semantic alignment capabilities has become a promising direction in CIL. However, existing CLIP-based CIL methods are often scattered across disparate codebases, rely on inconsistent configurations, hindering fair comparisons, reproducibility, and practical adoption. Therefore, we propose C3Box (CLIP-based Class-inCremental learning toolBOX), a modular and comprehensive Python toolbox. C3Box integrates representative traditional CIL methods, ViT-based CIL methods, and state-of-the-art CLIP-based CIL methods into a unified CLIP-based framework. By inheriting the streamlined design of PyCIL, C3Box provides a JSON-based configuration and standardized execution pipeline. This design enables reproducible experimentation with low engineering overhead and makes C3Box a reliable benchmark platform for continual learning research. Designed to be user-friendly, C3Box relies only on widely used open-source libraries and supports major operating systems. The code is available at this https URL . Comments: The code is available at this https URL Subjects: Machine Learning (cs.LG) ; Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2601.20852 [cs.LG] (or arXiv:2601.20852v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2601.20852 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Hao Sun [ view email ] [v1] Wed, 28 Jan 2026 18:52:36 UTC (343 KB) Full-text links: Access Paper: View a PDF of the paper titled C3Box: A CLIP-based Class-Incremental Learning Toolbox, by Hao Sun and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-01 Change to browse by: cs cs.CV References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-96">49. PACE: Pretrained Audio Continual Learning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.03355v1</li>
<li>来源：arxiv</li>
<li>摘要：Audio is a fundamental modality for analyzing speech, music, and environmental sounds. Although pretrained audio models have significantly advanced audio understanding, they remain fragile in real-world settings where data distributions shift over time. In this work, we present the first systematic benchmark for audio continual learning (CL) with pretrained models (PTMs), together with a comprehensive analysis of its unique challenges. Unlike in vision, where parameter-efficient fine-tuning (PEFT) has proven effective for CL, directly transferring such strategies to audio leads to poor performance. This stems from a fundamental property of audio backbones: they focus on low-level spectral details rather than structured semantics, causing severe upstream-downstream misalignment. Through extensive empirical study, we identify analytic classifiers with first-session adaptation (FSA) as a promising direction, but also reveal two major limitations: representation saturation in coarse-grained scenarios and representation drift in fine-grained scenarios. To address these challenges, we propose PACE, a novel method that enhances FSA via a regularized analytic classifier and enables multi-s</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">pretrained audio models tend to focus on low-level spectral details rather than structured semantics, which poses challenges for fine-tuning strategies from vision that are parameter-efficient. Direct parameter-efficient fine-tuning methods do not work well for audio, primarily due to representation saturation and drift, which are significant limitations for both coarse-grained and fine-grained scenarios. To address these issues, PACE enhances first-session adaptation through a regularized analytic classifier, which shows promise but still has limitations. Additionally, PACE employs adaptive subspace-orthogonal parameter-efficient fine-tuning for multi-session adaptation, and spectrogram-based boundary-aware perturbations help mitigate representation overlap. Experimental results demonstrate that PACE outperforms state-of-the-art baselines in audio continual learning, highlighting its effectiveness in overcoming the aforementioned challenges.</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>pretrained audio models focus on low-level spectral details rather than structured semantics.</li>
<li>direct parameter-efficient fine-tuning strategies from vision do not work well for audio.</li>
<li>representation saturation and drift are major limitations for coarse-grained and fine-grained scenarios.</li>
<li>analytic classifiers with first-session adaptation show promise but have limitations.</li>
<li>PACE enhances FSA through a regularized analytic classifier.</li>
<li>PACE uses adaptive subspace-orthogonal parameter-efficient fine-tuning for multi-session adaptation.</li>
<li>spectrogram-based boundary-aware perturbations help mitigate representation overlap.</li>
<li>experiments demonstrate PACE outperforms state-of-the-art baselines in audio continual learning.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-97">正文（抓取，非 AI）</h3>
<p>[2602.03355v1] PACE: Pretrained Audio Continual Learning Computer Science &gt; Sound arXiv:2602.03355v1 (cs) [Submitted on 3 Feb 2026] Title: PACE: Pretrained Audio Continual Learning Authors: Chang Li , Kanglei Zhou , Liyuan Wang View a PDF of the paper titled PACE: Pretrained Audio Continual Learning, by Chang Li and 2 other authors View PDF HTML (experimental) Abstract: Audio is a fundamental modality for analyzing speech, music, and environmental sounds. Although pretrained audio models have significantly advanced audio understanding, they remain fragile in real-world settings where data distributions shift over time. In this work, we present the first systematic benchmark for audio continual learning (CL) with pretrained models (PTMs), together with a comprehensive analysis of its unique challenges. Unlike in vision, where parameter-efficient fine-tuning (PEFT) has proven effective for CL, directly transferring such strategies to audio leads to poor performance. This stems from a fundamental property of audio backbones: they focus on low-level spectral details rather than structured semantics, causing severe upstream-downstream misalignment. Through extensive empirical study, we identify analytic classifiers with first-session adaptation (FSA) as a promising direction, but also reveal two major limitations: representation saturation in coarse-grained scenarios and representation drift in fine-grained scenarios. To address these challenges, we propose PACE, a novel method that enhances FSA via a regularized analytic classifier and enables multi-session adaptation through adaptive subspace-orthogonal PEFT for improved semantic alignment. In addition, we introduce spectrogram-based boundary-aware perturbations to mitigate representation overlap and improve stability. Experiments on six diverse audio CL benchmarks demonstrate that PACE substantially outperforms state-of-the-art baselines, marking an important step toward robust and scalable audio continual learning with PTMs. Comments: Accepted at ICLR 2026 Subjects: Sound (cs.SD) ; Machine Learning (cs.LG) Cite as: arXiv:2602.03355 [cs.SD] (or arXiv:2602.03355v1 [cs.SD] for this version) https://doi.org/10.48550/arXiv.2602.03355 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Chang Li [ view email ] [v1] Tue, 3 Feb 2026 10:28:35 UTC (4,887 KB) Full-text links: Access Paper: View a PDF of the paper titled PACE: Pretrained Audio Continual Learning, by Chang Li and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.SD &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-98">50. Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.14322v1</li>
<li>来源：arxiv</li>
<li>摘要：We investigate how formal temporal logic specifications can enhance the safety and robustness of reinforcement learning (RL) control in aerospace applications. Using the open source AeroBench F-16 simulation benchmark, we train a Proximal Policy Optimization (PPO) agent to regulate engine throttle and track commanded airspeed. The control objective is encoded as a Signal Temporal Logic (STL) requirement to maintain airspeed within a prescribed band during the final seconds of each maneuver. To enforce this specification at run time, we introduce a conformal STL shield that filters the RL agent's actions using online conformal prediction. We compare three settings: (i) PPO baseline, (ii) PPO with a classical rule-based STL shield, and (iii) PPO with the proposed conformal shield, under both nominal conditions and a severe stress scenario involving aerodynamic model mismatch, actuator rate limits, measurement noise, and mid-episode setpoint jumps. Experiments show that the conformal shield preserves STL satisfaction while maintaining near baseline performance and providing stronger robustness guarantees than the classical shield. These results demonstrate that combining formal specif</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，proposed conformal STL shield结合了形式化规格监控和数据驱动的RL控制，利用在线conformal预测来过滤RL代理的动作，从而在运行时强制执行STL规范。STL要求编码为空速在每个机动的最后几秒内保持在指定范围内，这确保了空速在指定范围内。其次，conformal shield在名义条件下保持了接近基线的性能，并在严重压力场景下提供了更强的鲁棒性保证。相比之下，经典shield使用基于规则的STL屏蔽，而PPO基线没有额外的STL屏蔽。因此，conformal shield在严重压力场景下保持了STL规范的满足，并在名义条件下保持了接近基线的性能，同时在保持近基线性能的同时，比经典shield提供了更强的鲁棒性保证。实验在AeroBench F-16仿真基准上进行，证明了conformal shield在严重压力场景下提供了更强的鲁棒性保证。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>conformal STL shield利用在线 conformal预测来过滤RL代理的动作。</li>
<li>conformal shield在保持近基线性能的同时，比经典shield提供了更强的鲁棒性保证。</li>
<li>conformal shield在名义条件下和严重压力场景下都进行了测试。</li>
<li>经典shield使用基于规则的STL屏蔽。</li>
<li>PPO基线没有额外的STL屏蔽。</li>
<li>STL要求编码为空速在每个机动的最后几秒内保持在指定范围内。</li>
<li>实验在AeroBench F-16仿真基准上进行。</li>
<li>proposed conformal shield结合了形式化规格监控和数据驱动的RL控制。</li>
<li>conformal prediction在线过滤RL代理的动作。</li>
<li>STL用于编码控制目标。</li>
<li>PPO训练了一个代理来调节发动机油门和跟踪指令空速。</li>
<li>conformal STL shield在运行时强制执行STL规范。</li>
<li>STL规范用于确保空速在指定范围内。</li>
<li>PPO与经典STL屏蔽进行了比较。</li>
<li>STL规范在每个机动的最后几秒内保持空速在指定范围内。</li>
<li>conformal shield在严重压力场景下提供了更强的鲁棒性。</li>
<li>STL规范用于确保空速在指定范围内。</li>
<li>conformal shield在名义条件下保持了接近基线的性能。</li>
<li>STL规范用于确保空速在指定范围内。</li>
<li>conformal shield在严重压力场景下保持了STL规范的满足。</li>
<li>STL规范用于确保空速在指定范围内。</li>
<li>conformal shield在严重压力场景下提供了更强的鲁棒性保证。</li>
<li>STL规范用于确保空速在指定范围内。</li>
<li>conformal shield在严重压力场景下保持了接近基线的性能。</li>
<li>STL规范用于确保空速在指定范围内。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-99">正文（抓取，非 AI）</h3>
<p>[2602.14322v1] Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study Computer Science &gt; Machine Learning arXiv:2602.14322v1 (cs) [Submitted on 15 Feb 2026] Title: Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study Authors: Hani Beirami , M M Manjurul Islam View a PDF of the paper titled Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study, by Hani Beirami and 1 other authors View PDF HTML (experimental) Abstract: We investigate how formal temporal logic specifications can enhance the safety and robustness of reinforcement learning (RL) control in aerospace applications. Using the open source AeroBench F-16 simulation benchmark, we train a Proximal Policy Optimization (PPO) agent to regulate engine throttle and track commanded airspeed. The control objective is encoded as a Signal Temporal Logic (STL) requirement to maintain airspeed within a prescribed band during the final seconds of each maneuver. To enforce this specification at run time, we introduce a conformal STL shield that filters the RL agent's actions using online conformal prediction. We compare three settings: (i) PPO baseline, (ii) PPO with a classical rule-based STL shield, and (iii) PPO with the proposed conformal shield, under both nominal conditions and a severe stress scenario involving aerodynamic model mismatch, actuator rate limits, measurement noise, and mid-episode setpoint jumps. Experiments show that the conformal shield preserves STL satisfaction while maintaining near baseline performance and providing stronger robustness guarantees than the classical shield. These results demonstrate that combining formal specification monitoring with data driven RL control can substantially improve the reliability of autonomous flight control in challenging environments. Comments: 6 pages, 2 figures Subjects: Machine Learning (cs.LG) ; Logic in Computer Science (cs.LO) Cite as: arXiv:2602.14322 [cs.LG] (or arXiv:2602.14322v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.14322 Focus to learn more arXiv-issued DOI via DataCite Submission history From: M M Manjurul Islam [ view email ] [v1] Sun, 15 Feb 2026 22:10:11 UTC (141 KB) Full-text links: Access Paper: View a PDF of the paper titled Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study, by Hani Beirami and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.LO References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-100">51. Scaling Continual Learning with Bi-Level Routing Mixture-of-Experts</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.03473v1</li>
<li>来源：arxiv</li>
<li>摘要：Continual learning, especially class-incremental learning (CIL), on the basis of a pre-trained model (PTM) has garnered substantial research interest in recent years. However, how to effectively learn both discriminative and comprehensive feature representations while maintaining stability and plasticity over very long task sequences remains an open problem. We propose CaRE, a scalable {C}ontinual Le{a}rner with efficient Bi-Level {R}outing Mixture-of-{E}xperts (BR-MoE). The core idea of BR-MoE is a bi-level routing mechanism: a router selection stage that dynamically activates relevant task-specific routers, followed by an expert routing phase that dynamically activates and aggregates experts, aiming to inject discriminative and comprehensive representations into every intermediate network layer. On the other hand, we introduce a challenging evaluation protocol for comprehensively assessing CIL methods across very long task sequences spanning hundreds of tasks. Extensive experiments show that CaRE demonstrates leading performance across a variety of datasets and task settings, including commonly used CIL datasets with classical CIL settings (e.g., 5-20 tasks). To the best of our k</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-101">正文（抓取，非 AI）</h3>
<p>[2602.03473v1] Scaling Continual Learning with Bi-Level Routing Mixture-of-Experts Computer Science &gt; Machine Learning arXiv:2602.03473v1 (cs) [Submitted on 3 Feb 2026] Title: Scaling Continual Learning with Bi-Level Routing Mixture-of-Experts Authors: Meng Lou , Yunxiang Fu , Yizhou Yu View a PDF of the paper titled Scaling Continual Learning with Bi-Level Routing Mixture-of-Experts, by Meng Lou and 2 other authors View PDF HTML (experimental) Abstract: Continual learning, especially class-incremental learning (CIL), on the basis of a pre-trained model (PTM) has garnered substantial research interest in recent years. However, how to effectively learn both discriminative and comprehensive feature representations while maintaining stability and plasticity over very long task sequences remains an open problem. We propose CaRE, a scalable {C}ontinual Le{a}rner with efficient Bi-Level {R}outing Mixture-of-{E}xperts (BR-MoE). The core idea of BR-MoE is a bi-level routing mechanism: a router selection stage that dynamically activates relevant task-specific routers, followed by an expert routing phase that dynamically activates and aggregates experts, aiming to inject discriminative and comprehensive representations into every intermediate network layer. On the other hand, we introduce a challenging evaluation protocol for comprehensively assessing CIL methods across very long task sequences spanning hundreds of tasks. Extensive experiments show that CaRE demonstrates leading performance across a variety of datasets and task settings, including commonly used CIL datasets with classical CIL settings (e.g., 5-20 tasks). To the best of our knowledge, CaRE is the first continual learner that scales to very long task sequences (ranging from 100 to over 300 non-overlapping tasks), while outperforming all baselines by a large margin on such task sequences. Code will be publicly released at this https URL . Subjects: Machine Learning (cs.LG) ; Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.03473 [cs.LG] (or arXiv:2602.03473v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.03473 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Meng Lou [ view email ] [v1] Tue, 3 Feb 2026 12:45:10 UTC (3,494 KB) Full-text links: Access Paper: View a PDF of the paper titled Scaling Continual Learning with Bi-Level Routing Mixture-of-Experts, by Meng Lou and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CV References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-102">52. FedZMG: Efficient Client-Side Optimization in Federated Learning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.18384v1</li>
<li>来源：arxiv</li>
<li>摘要：Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the "intensity" or "bias" shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CI</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-103">正文（抓取，非 AI）</h3>
<p>[2602.18384v1] FedZMG: Efficient Client-Side Optimization in Federated Learning Computer Science &gt; Machine Learning arXiv:2602.18384v1 (cs) [Submitted on 20 Feb 2026] Title: FedZMG: Efficient Client-Side Optimization in Federated Learning Authors: Fotios Zantalis , Evangelos Zervas , Grigorios Koulouras View a PDF of the paper titled FedZMG: Efficient Client-Side Optimization in Federated Learning, by Fotios Zantalis and 2 other authors View PDF HTML (experimental) Abstract: Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the "intensity" or "bias" shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CIFAR100, and Shakespeare datasets demonstrate that FedZMG achieves better convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, particularly in highly non-IID settings. Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.18384 [cs.LG] (or arXiv:2602.18384v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.18384 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Grigorios Koulouras Koulouras [ view email ] [v1] Fri, 20 Feb 2026 17:45:28 UTC (3,896 KB) Full-text links: Access Paper: View a PDF of the paper titled FedZMG: Efficient Client-Side Optimization in Federated Learning, by Fotios Zantalis and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-104">53. Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.18377v1</li>
<li>来源：arxiv</li>
<li>摘要：Quantum reservoir computers (QRCs) have emerged as a promising approach to quantum machine learning, since they utilize the natural dynamics of quantum systems for data processing and are simple to train. Here, we consider n-qubit quantum extreme learning machines (QELMs) with continuous-time reservoir dynamics. QELMs are memoryless QRCs capable of various ML tasks, including image classification and time series forecasting. We apply the Pauli transfer matrix (PTM) formalism to theoretically analyze the influence of encoding, reservoir dynamics, and measurement operations, including temporal multiplexing, on the QELM performance. This formalism makes explicit that the encoding determines the complete set of (nonlinear) features available to the QELM, while the quantum channels linearly transform these features before they are probed by the chosen measurement operators. Optimizing a QELM can therefore be cast as a decoding problem in which one shapes the channel-induced transformations such that task-relevant features become available to the regressor. The PTM formalism allows one to identify the classical representation of a QELM and thereby guide its design towards a given trainin</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-105">正文（抓取，非 AI）</h3>
<p>[2602.18377v1] Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach Quantum Physics arXiv:2602.18377v1 (quant-ph) [Submitted on 20 Feb 2026] Title: Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach Authors: Markus Gross , Hans-Martin Rieser View a PDF of the paper titled Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach, by Markus Gross and 1 other authors View PDF HTML (experimental) Abstract: Quantum reservoir computers (QRCs) have emerged as a promising approach to quantum machine learning, since they utilize the natural dynamics of quantum systems for data processing and are simple to train. Here, we consider n-qubit quantum extreme learning machines (QELMs) with continuous-time reservoir dynamics. QELMs are memoryless QRCs capable of various ML tasks, including image classification and time series forecasting. We apply the Pauli transfer matrix (PTM) formalism to theoretically analyze the influence of encoding, reservoir dynamics, and measurement operations, including temporal multiplexing, on the QELM performance. This formalism makes explicit that the encoding determines the complete set of (nonlinear) features available to the QELM, while the quantum channels linearly transform these features before they are probed by the chosen measurement operators. Optimizing a QELM can therefore be cast as a decoding problem in which one shapes the channel-induced transformations such that task-relevant features become available to the regressor. The PTM formalism allows one to identify the classical representation of a QELM and thereby guide its design towards a given training objective. As a specific application, we focus on learning nonlinear dynamical systems and show that a QELM trained on such trajectories learns a surrogate-approximation to the underlying flow map. Comments: 34 pages, 12 figures Subjects: Quantum Physics (quant-ph) ; Machine Learning (cs.LG) Cite as: arXiv:2602.18377 [quant-ph] (or arXiv:2602.18377v1 [quant-ph] for this version) https://doi.org/10.48550/arXiv.2602.18377 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Markus Gross [ view email ] [v1] Fri, 20 Feb 2026 17:33:27 UTC (1,524 KB) Full-text links: Access Paper: View a PDF of the paper titled Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach, by Markus Gross and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: quant-ph &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.LG References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-106">54. ExO-PPO: an Extended Off-policy Proximal Policy Optimization Algorithm</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.09726v1</li>
<li>来源：arxiv</li>
<li>摘要：Deep reinforcement learning has been able to solve various tasks successfully, however, due to the construction of policy gradient and training dynamics, tuning deep reinforcement learning models remains challenging. As one of the most successful deep reinforcement-learning algorithm, the Proximal Policy Optimization algorithm (PPO) clips the policy gradient within a conservative on-policy updates, which ensures reliable and stable policy improvement. However, this training pattern may sacrifice sample efficiency. On the other hand, off-policy methods make more adequate use of data through sample reuse, though at the cost of increased the estimation variance and bias. To leverage the advantages of both, in this paper, we propose a new PPO variant based on the stability guarantee from conservative on-policy iteration with a more efficient off-policy data utilization. Specifically, we first derive an extended off-policy improvement from an expectation form of generalized policy improvement lower bound. Then, we extend the clipping mechanism with segmented exponential functions for a suitable surrogate objective function. Third, the trajectories generated by the past $M$ policies are </li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-107">正文（抓取，非 AI）</h3>
<p>[2602.09726v1] ExO-PPO: an Extended Off-policy Proximal Policy Optimization Algorithm Computer Science &gt; Machine Learning arXiv:2602.09726v1 (cs) [Submitted on 10 Feb 2026] Title: ExO-PPO: an Extended Off-policy Proximal Policy Optimization Algorithm Authors: Hanyong Wang , Menglong Yang View a PDF of the paper titled ExO-PPO: an Extended Off-policy Proximal Policy Optimization Algorithm, by Hanyong Wang and 1 other authors View PDF HTML (experimental) Abstract: Deep reinforcement learning has been able to solve various tasks successfully, however, due to the construction of policy gradient and training dynamics, tuning deep reinforcement learning models remains challenging. As one of the most successful deep reinforcement-learning algorithm, the Proximal Policy Optimization algorithm (PPO) clips the policy gradient within a conservative on-policy updates, which ensures reliable and stable policy improvement. However, this training pattern may sacrifice sample efficiency. On the other hand, off-policy methods make more adequate use of data through sample reuse, though at the cost of increased the estimation variance and bias. To leverage the advantages of both, in this paper, we propose a new PPO variant based on the stability guarantee from conservative on-policy iteration with a more efficient off-policy data utilization. Specifically, we first derive an extended off-policy improvement from an expectation form of generalized policy improvement lower bound. Then, we extend the clipping mechanism with segmented exponential functions for a suitable surrogate objective function. Third, the trajectories generated by the past $M$ policies are organized in the replay buffer for off-policy training. We refer to this method as Extended Off-policy Proximal Policy Optimization (ExO-PPO). Compared with PPO and some other state-of-the-art variants, we demonstrate an improved performance of ExO-PPO with balanced sample efficiency and stability on varied tasks in the empirical experiments. Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.09726 [cs.LG] (or arXiv:2602.09726v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.09726 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Hanyong Wang [ view email ] [v1] Tue, 10 Feb 2026 12:29:57 UTC (41,072 KB) Full-text links: Access Paper: View a PDF of the paper titled ExO-PPO: an Extended Off-policy Proximal Policy Optimization Algorithm, by Hanyong Wang and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-108">55. 微软更新Win11任务栏电池图标 支持彩色提示与百分比显示 ...</h2>
<ul>
<li>链接：https://news.zol.com.cn/1079/10794421.html</li>
<li>来源：bing</li>
<li>摘要：2025年11月10日，有技术博客发布信息显示，微软在Windows 11 Build 26x00.7019预览版本的更新中，对任务栏的电池图标进行了重新设计。此次调整旨在优化 ...</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-109">正文（抓取，非 AI）</h3>
<p>微软更新Win11任务栏电池图标 支持彩色提示与百分比显示_Microsoft Windows 11_业界资讯-中关村在线 网站功能 查报价 新品 排行榜 经销商 专题 评测 行情 新闻 模拟攒机 图赏 论坛 问答 试用 直播 视频 图说 软件下载 产品频道 更多 &gt;&gt; 手机 笔记本 平板电脑 台式机 数码相机 数码配件 硬件DIY 外设 企业 办公 家电 汽车 推荐热词 CES MWC AWE 苹果发布会 CES亚洲 台北电脑展 Chinajoy IFA 热点： ZOL首页 &gt; 新闻中心 &gt; 业界资讯 &gt; 正文 Microsoft Windows 11 产品综述 图片 参数 报价 点评 论坛帖子 评测 微软更新Win11任务栏电池图标 支持彩色提示与百分比显示 2025-11-10 07:40:27 [ 中关村在线 原创 ] 作者：牛奶秋刀鱼 2025年11月10日，有技术博客发布信息显示，微软在Windows 11 Build 26x00.7019预览版本的更新中，对任务栏的电池图标进行了重新设计。此次调整旨在优化用户查看设备电量状态的效率与直观性，引入了彩色状态提示，并新增了备受期待的电量百分比直接显示功能。 更新后的电池图标不再保持单一的白色静态样式，而是根据设备状态呈现不同颜色和图形反馈。当设备连接电源并处于充电状态时，图标将变为绿色，并叠加闪电符号，直观反映充电行为。若设备未接通电源且启用了节能模式，图标则会显示为橙色，取代此前辨识度较低的叶子图案，提升视觉传达效果。 在电量低于6%的关键阈值时，图标将切换为醒目的红色，提醒用户尽快充电，避免设备因电量耗尽 自动关机 。这一颜色机制配合动态图形，使用户无需点击即可快速掌握当前电力状况。 在智能充电功能方面，本次更新也进行了视觉逻辑优化。过去该功能在充电至80%时会显示一个带有心形的闪电图标，而新设计改为在充电过程中保持绿色图标，当达到80%后自动变更为插头符号。此时若需继续充至100%，用户必须手动点击图标确认，从而实现对充电过程的更明确控制。 为适应新增的百分比数字和更丰富的视觉元素，电池图标的任务栏占用宽度已适当加长。设计团队表示，这一调整不仅为图标内部的叠加符号提供了充足空间，还能确保关键信息居中呈现，提升整体可读性。更大的显示区域也使得不同电量层级之间的差异更加清晰，结合红、黄、绿三色状态提示，用户只需 glance 一眼即可准确判断剩余电量水平。 值得注意的是，据相关开发记录显示，该功能从立项到最终实现历时约一年半。目前用户可通过系统设置中的“电源与电池”选项，找到新增的“显示电池百分比”开关并启用该功能。开启后，具体的电量数值将直接嵌入任务栏电池图标内，便于实时查看。 本文属于原创文章，如若转载，请注明来源： 微软更新Win11任务栏电池图标 支持彩色提示与百分比显示 https://news.zol.com.cn/1079/10794421.html 纠错与问题建议 标签： 操作系统 https://news.zol.com.cn/1079/10794421.html news.zol.com.cn true 中关村在线 https://news.zol.com.cn/1079/10794421.html report 1455 2025年11月10日，有技术博客发布信息显示，微软在Windows 11 Build 26x00.7019预览版本的更新中，对任务栏的电池图标进行了重新设计。此次调整旨在优化用户查看设备电量状态的效率与直观性，引入了彩色状态提示，并新增了备受期待的电量百分比直接显示功能。更新后的电池... 1 2 下一页 提示：支持键盘“← →”键翻页 阅读全文 本文导航 第1页：Win11任务栏电池图标焕新 第2页：Microsoft Windows 11详细参数 猜你喜欢 最新 精选 相关 手机版阅读 即时更新 点击加载更多内容 Windows画图迎史诗级更新：终于能自由旋转了 评论 ( 4 ) Windows记事本迎史诗级更新：终于能支持图片了 评论 ( 7 ) 联想因AI驱动DRAM短缺，3月起上调部分PC价格 评论 ( 7 ) 夜王票房破3500万，谭旻萱减重逆袭成篮球女神与夜总会颜值标杆 评论 ( 6 ) 国产DDR5内存价格与国际接轨，消费级低价预期落空 评论 ( 6 ) 苹果2026年3月上海新品体验活动：五款新机密集发布，含入门MacBook等 评论 ( 5 ) 镖人：风起大漠破影史武侠票房纪录，春节档口碑票房双冠王 评论 ( 4 ) 2026春节档创9天最长纪录，总票房破51亿，镖人口碑居首 评论 ( 5 ) 飞驰人生3票房破24亿登顶春节档，口碑下滑引热议与类型期待分化 评论 ( 7 ) 流浪地球3官宣2027年春节上映，郭帆发公益短片倡导文明观影 评论 ( 7 ) 雷军春节雪场六日行：滑雪收官返京，速度感映照互联网进取精神 评论 ( 0 ) 联想因内存短缺将于2026年3月起上调商用PC及服务器价格 评论 ( 0 ) 索尼官宣毒液全新动画电影，扎克·利波夫斯基与亚当·B·斯坦联合执导 评论 ( 0 ) RTX 5090 Ti要来了？功耗超700W性能提升10% 评论 ( 0 ) 平替Mac mini！国产芯片mini主机也能跑OpenClaw 评论 ( 0 ) 自助结账机索要小费引质疑：无人服务何来小费合理性？ 评论 ( 0 ) 马斯克称将缴税超5000亿美元，专家预估或达5万亿美元 评论 ( 0 ) Windows XP经典壁纸Bliss拍摄地三十年后罕见复现 评论 ( 0 ) 流浪地球3官宣定档2027年大年初一，郭帆携主演发布新春贴片引爆热搜 评论 ( 0 ) 哈姆奈特横扫爱尔兰影视学院奖，吉尼斯家族携杰克·格里森强势回归 评论 ( 0 ) Windows 11 25H2更新：通知中心优化与多屏任务栏改进 评论 ( 7 ) 微软强制推送Windows 11 25H2更新 评论 ( 8 ) 一加15配置曝光：7000mAh电池、16GB内存、120Hz高刷屏 评论 ( 28 ) 东风华为联手打造奕境首款SUV曝光，2026年亮相 评论 ( 7 ) 微信新功能上线：通知栏可显示好友头像 评论 ( 6 ) 华为全新 MatePad Mini 小平板发布：多版本可选，起售价 3299 元 评论 ( 7 ) 小米YU7 Max紫水晶版亮相广州车展 评论 ( 6 ) 姚安娜代言阿维塔畅谈与华为合作愿景 评论 ( 6 ) iPhone 17 Pro Max量产机曝光：对称设计、新材质与天线布局引领升级 评论 ( 9 ) AMD Zen6锐龙将沿用AM5接口，BIOS容量成升级关键 评论 ( 0 ) 电影731发布人物海报，揭露侵华日军罪行 评论 ( 7 ) 沈腾流浪地球3杀青在即，郭帆晒蛋糕官宣进度 评论 ( 9 ) 我国半导体光刻设备发展现状与国际差距分析 评论 ( 6 ) 75岁半导体专家涉泄密被查，资产冻结境外潜逃引关注 评论 ( 2 ) 马年纪念钞兑换启动，市民喜获88888888稀有号码 评论 ( 5 ) 国产动作片捕风追影票房破8亿，豆瓣评分8.2创十年新高 评论 ( 18 ) Windows 10退役助推全球CPU出货增长 评论 ( 6 ) Xeno将Win7精简至69MB引发热议 评论 ( 9 ) Windows画图迎史诗级更新：终于能自由旋转了 评论 ( 4 ) Windows记事本迎史诗级更新：终于能支持图片了 评论 ( 7 ) 保养手机电池的四大技巧 多用几年不吃亏 评论 ( 2 ) 南北真一箱油即可？2026年新技术展望 评论 ( 6 ) 不是5G还比5G强 华为的5A到底是个啥 评论 ( 28 ) 数码选购：春节想买个音箱，先把这3个问题想清楚 评论 ( 8 ) Windows 11 26H1要来了 但大家可能用不着 评论 ( 6 ) 比亚迪海豹08、全新纯电奔驰C级，2026重点纯电轿车展望 评论 ( 4 ) 64GB内存价格将飙升到7000元？一季度预测涨价90% 评论 ( 45 ) 开放式耳机怎么选？记住这4条，基本不踩坑 评论 ( 5 ) 用了10年手机，竟然不知道手机上有这么多健康功能 评论 ( 10 ) 预测：2026年第一季度最值得期待的Ultra新机前瞻 评论 ( 13 ) RTX 3080 Ti 20GB性能曝光 评论 ( 13 ) 4G、5G、6G差别在哪里？远不只是网速升级 评论 ( 9 ) 家庭版/专业版/教育版/企业版？Windows版本应该怎么选 评论 ( 3 ) 假期孩子不无聊春节适合陪孩子看的五部大片推荐 评论 ( 16 ) 为啥今年支持卫星通讯的手机越来越少？你用过吗？ 评论 ( 12 ) 苹果新款MacBook Pro曝光：首发M5 Pro/Max芯片，库存紧张预示发布临近 评论 ( 8 ) 2026年四款轻薄旗舰手机盘点：告别“半斤机” 评论 ( 70 ) 这台迷你主机居然搭载RTX5060 售价很惊人 评论 ( 13 ) 2026年值得购买的充电宝排行榜，选对能用好几年 评论 ( 5 ) 雷神推出新款迷你主机 居然标配大内存 评论 ( 10 ) 中关村在线首页 新闻中心首页 热门搜索 苹果发布会 AWE 台北电脑展 mwc 热词： 智能穿戴 汽车科技 三菱空调 24小时热文 本周热评 XP经典壁纸Bliss原址再现：网友偶遇三十年一遇的翡翠山丘 DDR5内存价格触顶回落，32GB/64GB套装显著下调但仍未回归常态 飞驰人生3春节上映首日破4亿，口碑两极：专业赛车升级VS节奏重复争议 DDR5内存价格达峰回落，32GB/64GB套装显著松动，装机用户观望情绪升温 2026不卡顿安卓手机推荐：从旗舰到中端，这5款用2年依旧流畅 京东与vivo签署战略合作协议：深耕用户价值 三年全渠道销售目标破千亿 全球首届机器人春晚惊艳亮相！京东“机器人”搜索量同比增超400% 2026年耳夹式耳机推荐，当贝/华为/JBL/塞那/韶音等哪个值得选 推荐问答 提问 论坛精选 最热回答 摄影 手机 硬件 笔电 平板 那年 那个秋 小公主和小鸭子 初夏时光 城市迷离 荣耀X10拍照真实体验 担心孩子迷恋网络？ vivo S1 Pro仲夏梦图说 AI手机瞬间让你变成外国人 华硕TUF B460M PRO重炮手体验 送腕表等好礼！9月17日ZOL&amp;斗鱼30系显卡首发直播 #CPU热血Battle不服来战# ITX机箱装机SHOW 华硕天选游戏笔记本 宅在家里玩VR游戏 随身携带的素材库 体验SDA-2 DAC船解码耳放一体机 有限空间里的声音美学 最近还爱上了便携吸尘器 巫便携式CD机带你回到校园时代 这个设计果然有胆识 骁龙7制程工艺 MacBook还是高配Win本？ MacBook真有必要买吗？ 搭载骁龙660的小米千元机 致敬小米3？小米11 Pro真机曝光：硬朗外观、150倍变焦+骁龙875! CAD施工图的详细解释 粗糙表面为何更显红色？ 童年那些尴尬糗事 计算机类专业有哪些？ 高通778g和870哪个更好 word文档空白页靠左了 怎么居中 狄仁杰古装武侠票房前景如何 更多 经销商 关闭 提示 0 下载ZOL APP 秒看最新热品 内容纠错</p>
</div></details><h2 id="toc-110">56. Conflict-free connections: algorithm and complexity</h2>
<ul>
<li>链接：https://arxiv.org/abs/1805.08072v3</li>
<li>来源：arxiv</li>
<li>摘要：A path in an(a) edge(vertex)-colored graph is called \emph{a conflict-free path} if there exists a color used on only one of its edges(vertices). An(A) edge(vertex)-colored graph is called \emph{conflict-free (vertex-)connected} if there is a conflict-free path between each pair of distinct vertices. We call the graph $G$ \emph{strongly conflict-free connected }if there exists a conflict-free path of length $d_G(u,v)$ for every two vertices $u,v\in V(G)$. And the \emph{strong conflict-free connection number} of a connected graph $G$, denoted by $scfc(G)$, is defined as the smallest number of colors that are required to make $G$ strongly conflict-free connected. In this paper, we first investigate the question: Given a connected graph $G$ and a coloring $c: E(or\ V)\rightarrow {1,2,\cdots,k} \ (k\geq 1)$ of the graph, determine whether or not $G$ is, respectively, conflict-free connected, vertex-conflict-free connected, strongly conflict-free connected under coloring $c$. We solve this question by providing polynomial-time algorithms. We then show that it is NP-complete to decide whether there is a k-edge-coloring $(k\geq 2)$ of $G$ such that all pairs $(u,v)\in P \ (P\subset V\ti</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-111">正文（抓取，非 AI）</h3>
<p>[1805.08072v3] Conflict-free connections: algorithm and complexity Mathematics &gt; Combinatorics arXiv:1805.08072v3 (math) [Submitted on 18 May 2018 ( v1 ), last revised 19 Sep 2018 (this version, v3)] Title: Conflict-free connections: algorithm and complexity Authors: Meng Ji , Xueliang Li , Xiaoyu Zhu View a PDF of the paper titled Conflict-free connections: algorithm and complexity, by Meng Ji and 2 other authors View PDF Abstract: A path in an(a) edge(vertex)-colored graph is called \emph{a conflict-free path} if there exists a color used on only one of its edges(vertices). An(A) edge(vertex)-colored graph is called \emph{conflict-free (vertex-)connected} if there is a conflict-free path between each pair of distinct vertices. We call the graph $G$ \emph{strongly conflict-free connected }if there exists a conflict-free path of length $d_G(u,v)$ for every two vertices $u,v\in V(G)$. And the \emph{strong conflict-free connection number} of a connected graph $G$, denoted by $scfc(G)$, is defined as the smallest number of colors that are required to make $G$ strongly conflict-free connected. In this paper, we first investigate the question: Given a connected graph $G$ and a coloring $c: E(or\ V)\rightarrow {1,2,\cdots,k} \ (k\geq 1)$ of the graph, determine whether or not $G$ is, respectively, conflict-free connected, vertex-conflict-free connected, strongly conflict-free connected under coloring $c$. We solve this question by providing polynomial-time algorithms. We then show that it is NP-complete to decide whether there is a k-edge-coloring $(k\geq 2)$ of $G$ such that all pairs $(u,v)\in P \ (P\subset V\times V)$ are strongly conflict-free connected. Finally, we prove that the problem of deciding whether $scfc(G)\leq k$ $(k\geq 2)$ for a given graph $G$ is NP-complete. Comments: 17 pages. The main change is in Subsection 3.2, Theorem 3.4, where we add the result and proof of the NP-completeness for the case $k=2$, which was not done in the old version Subjects: Combinatorics (math.CO) ; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM) MSC classes: 05C15, 05C40, 68Q17, 68Q25, 68R10 Cite as: arXiv:1805.08072 [math.CO] (or arXiv:1805.08072v3 [math.CO] for this version) https://doi.org/10.48550/arXiv.1805.08072 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Xueliang Li [ view email ] [v1] Fri, 18 May 2018 07:40:12 UTC (12 KB) [v2] Sat, 7 Jul 2018 06:37:55 UTC (12 KB) [v3] Wed, 19 Sep 2018 08:44:53 UTC (13 KB) Full-text links: Access Paper: View a PDF of the paper titled Conflict-free connections: algorithm and complexity, by Meng Ji and 2 other authors View PDF TeX Source view license Current browse context: math.CO &lt; prev | next &gt; new | recent | 2018-05 Change to browse by: cs cs.CC cs.DM math References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-112">57. Statistical Confidence in Functional Correctness: An Approach for AI Product Functional Correctness Evaluation</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.18357v1</li>
<li>来源：arxiv</li>
<li>摘要：The quality assessment of Artificial Intelligence (AI) systems is a fundamental challenge due to their inherently probabilistic nature. Standards such as ISO/IEC 25059 provide a quality model, but they lack practical and statistically robust methods for assessing functional correctness. This paper proposes and evaluates the Statistical Confidence in Functional Correctness (SCFC) approach, which seeks to fill this gap by connecting business requirements to a measure of statistical confidence that considers both the model's average performance and its variability. The approach consists of four steps: defining quantitative specification limits, performing stratified and probabilistic sampling, applying bootstrapping to estimate a confidence interval for the performance metric, and calculating a capability index as a final indicator. The approach was evaluated through a case study on two real-world AI systems in industry involving interviews with AI experts. Valuable insights were collected from the experts regarding the utility, ease of use, and intention to adopt the methodology in practical scenarios. We conclude that the proposed approach is a feasible and valuable way to operation</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-113">正文（抓取，非 AI）</h3>
<p>[2602.18357v1] Statistical Confidence in Functional Correctness: An Approach for AI Product Functional Correctness Evaluation Computer Science &gt; Software Engineering arXiv:2602.18357v1 (cs) [Submitted on 20 Feb 2026] Title: Statistical Confidence in Functional Correctness: An Approach for AI Product Functional Correctness Evaluation Authors: Wallace Albertini , Marina Condé Araújo , Júlia Condé Araújo , Antonio Pedro Santos Alves , Marcos Kalinowski View a PDF of the paper titled Statistical Confidence in Functional Correctness: An Approach for AI Product Functional Correctness Evaluation, by Wallace Albertini and 4 other authors View PDF HTML (experimental) Abstract: The quality assessment of Artificial Intelligence (AI) systems is a fundamental challenge due to their inherently probabilistic nature. Standards such as ISO/IEC 25059 provide a quality model, but they lack practical and statistically robust methods for assessing functional correctness. This paper proposes and evaluates the Statistical Confidence in Functional Correctness (SCFC) approach, which seeks to fill this gap by connecting business requirements to a measure of statistical confidence that considers both the model's average performance and its variability. The approach consists of four steps: defining quantitative specification limits, performing stratified and probabilistic sampling, applying bootstrapping to estimate a confidence interval for the performance metric, and calculating a capability index as a final indicator. The approach was evaluated through a case study on two real-world AI systems in industry involving interviews with AI experts. Valuable insights were collected from the experts regarding the utility, ease of use, and intention to adopt the methodology in practical scenarios. We conclude that the proposed approach is a feasible and valuable way to operationalize the assessment of functional correctness, moving the evaluation from a point estimate to a statement of statistical confidence. Comments: Author version of the paper accepted for publication at CAIN 2026 Subjects: Software Engineering (cs.SE) Cite as: arXiv:2602.18357 [cs.SE] (or arXiv:2602.18357v1 [cs.SE] for this version) https://doi.org/10.48550/arXiv.2602.18357 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Marcos Kalinowski [ view email ] [v1] Fri, 20 Feb 2026 17:06:38 UTC (289 KB) Full-text links: Access Paper: View a PDF of the paper titled Statistical Confidence in Functional Correctness: An Approach for AI Product Functional Correctness Evaluation, by Wallace Albertini and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.SE &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-114">58. MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.07940v2</li>
<li>来源：arxiv</li>
<li>摘要：To cope with uncertain changes of the external world, intelligent systems must continually learn from complex, evolving environments and respond in real time. This ability, collectively known as general continual learning (GCL), encapsulates practical challenges such as online datastreams and blurry task boundaries. Although leveraging pretrained models (PTMs) has greatly advanced conventional continual learning (CL), these methods remain limited in reconciling the diverse and temporally mixed information along a single pass, resulting in sub-optimal GCL performance. Inspired by meta-plasticity and reconstructive memory in neuroscience, we introduce here an innovative approach named Meta Post-Refinement (MePo) for PTMs-based GCL. This approach constructs pseudo task sequences from pretraining data and develops a bi-level meta-learning paradigm to refine the pretrained backbone, which serves as a prolonged pretraining phase but greatly facilitates rapid adaptation of representation learning to downstream GCL tasks. MePo further initializes a meta covariance matrix as the reference geometry of pretrained representation space, enabling GCL to exploit second-order statistics for robust</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-115">正文（抓取，非 AI）</h3>
<p>[2602.07940v2] MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learning Computer Science &gt; Artificial Intelligence arXiv:2602.07940v2 (cs) [Submitted on 8 Feb 2026 ( v1 ), last revised 11 Feb 2026 (this version, v2)] Title: MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learning Authors: Guanglong Sun , Hongwei Yan , Liyuan Wang , Zhiqi Kang , Shuang Cui , Hang Su , Jun Zhu , Yi Zhong View a PDF of the paper titled MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learning, by Guanglong Sun and 7 other authors View PDF HTML (experimental) Abstract: To cope with uncertain changes of the external world, intelligent systems must continually learn from complex, evolving environments and respond in real time. This ability, collectively known as general continual learning (GCL), encapsulates practical challenges such as online datastreams and blurry task boundaries. Although leveraging pretrained models (PTMs) has greatly advanced conventional continual learning (CL), these methods remain limited in reconciling the diverse and temporally mixed information along a single pass, resulting in sub-optimal GCL performance. Inspired by meta-plasticity and reconstructive memory in neuroscience, we introduce here an innovative approach named Meta Post-Refinement (MePo) for PTMs-based GCL. This approach constructs pseudo task sequences from pretraining data and develops a bi-level meta-learning paradigm to refine the pretrained backbone, which serves as a prolonged pretraining phase but greatly facilitates rapid adaptation of representation learning to downstream GCL tasks. MePo further initializes a meta covariance matrix as the reference geometry of pretrained representation space, enabling GCL to exploit second-order statistics for robust output alignment. MePo serves as a plug-in strategy that achieves significant performance gains across a variety of GCL benchmarks and pretrained checkpoints in a rehearsal-free manner (e.g., 15.10\%, 13.36\%, and 12.56\% on CIFAR-100, ImageNet-R, and CUB-200 under Sup-21/1K). Our source code is available at \href{ this https URL }{MePo} Subjects: Artificial Intelligence (cs.AI) Cite as: arXiv:2602.07940 [cs.AI] (or arXiv:2602.07940v2 [cs.AI] for this version) https://doi.org/10.48550/arXiv.2602.07940 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Guanglong Sun [ view email ] [v1] Sun, 8 Feb 2026 12:15:35 UTC (849 KB) [v2] Wed, 11 Feb 2026 09:48:31 UTC (724 KB) Full-text links: Access Paper: View a PDF of the paper titled MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learning, by Guanglong Sun and 7 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.AI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-116">59. SCOPE: A Training-Free Online 3D Deployment for UAV-BSs with Theoretical Analysis and Comparative Study</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.09971v1</li>
<li>来源：arxiv</li>
<li>摘要：Unmanned Aerial Vehicle (UAV)-mounted Base Stations (UAV-BSs) offer a flexible solution for serving ground users in temporary hotspot scenarios. However, efficiently deploying UAV-BSs to satisfy heterogeneous user distributions remains a challenging optimization problem. While recent data-driven approaches, particularly Deep Reinforcement Learning (DRL), have shown promise in dynamic environments, they often suffer from prohibitive training overhead, poor generalization to topology changes, and high computational complexity. To address these limitations, this paper proposes Satisfaction-driven Coverage Optimization via Perimeter Extraction (SCOPE), a training-free and online 3D deployment framework. Unlike heuristic baselines that rely on fixed-altitude assumptions, SCOPE integrates a perimeter extraction mechanism with the Smallest Enclosing Circle (SEC) algorithm to dynamically optimize 3D UAV positions. Theoretically, we provide a rigorous convergence proof of the proposed algorithm and derive its polynomial time complexity of $O(N^2 \log N)$. Experimentally, we conduct a comprehensive comparative study against state-of-the-art DRL baselines (e.g., PPO). Simulation results demon</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-117">正文（抓取，非 AI）</h3>
<p>[2602.09971v1] SCOPE: A Training-Free Online 3D Deployment for UAV-BSs with Theoretical Analysis and Comparative Study Computer Science &gt; Networking and Internet Architecture arXiv:2602.09971v1 (cs) [Submitted on 10 Feb 2026] Title: SCOPE: A Training-Free Online 3D Deployment for UAV-BSs with Theoretical Analysis and Comparative Study Authors: Chuan-Chi Lai View a PDF of the paper titled SCOPE: A Training-Free Online 3D Deployment for UAV-BSs with Theoretical Analysis and Comparative Study, by Chuan-Chi Lai View PDF HTML (experimental) Abstract: Unmanned Aerial Vehicle (UAV)-mounted Base Stations (UAV-BSs) offer a flexible solution for serving ground users in temporary hotspot scenarios. However, efficiently deploying UAV-BSs to satisfy heterogeneous user distributions remains a challenging optimization problem. While recent data-driven approaches, particularly Deep Reinforcement Learning (DRL), have shown promise in dynamic environments, they often suffer from prohibitive training overhead, poor generalization to topology changes, and high computational complexity. To address these limitations, this paper proposes Satisfaction-driven Coverage Optimization via Perimeter Extraction (SCOPE), a training-free and online 3D deployment framework. Unlike heuristic baselines that rely on fixed-altitude assumptions, SCOPE integrates a perimeter extraction mechanism with the Smallest Enclosing Circle (SEC) algorithm to dynamically optimize 3D UAV positions. Theoretically, we provide a rigorous convergence proof of the proposed algorithm and derive its polynomial time complexity of $O(N^2 \log N)$. Experimentally, we conduct a comprehensive comparative study against state-of-the-art DRL baselines (e.g., PPO). Simulation results demonstrate that SCOPE achieves comparable user satisfaction to DRL methods but significantly lower computational latency (milliseconds vs. hours of training) and superior energy efficiency, making it an ideal solution for real-time, on-demand emergency deployment. Comments: 11 pages, 5 figures, Full research paper providing a training-free determinisitc 3D UAV deployment algorithm, SCOPE. Submitted to IEEE Journal for possible publication Subjects: Networking and Internet Architecture (cs.NI) Cite as: arXiv:2602.09971 [cs.NI] (or arXiv:2602.09971v1 [cs.NI] for this version) https://doi.org/10.48550/arXiv.2602.09971 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Chuan-Chi Lai [ view email ] [v1] Tue, 10 Feb 2026 16:59:20 UTC (2,693 KB) Full-text links: Access Paper: View a PDF of the paper titled SCOPE: A Training-Free Online 3D Deployment for UAV-BSs with Theoretical Analysis and Comparative Study, by Chuan-Chi Lai View PDF HTML (experimental) TeX Source view license Current browse context: cs.NI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-118">60. Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.20245v1</li>
<li>来源：arxiv</li>
<li>摘要：The memory of contemporary Large Language Models is bound by a physical paradox: as they learn, they fill up. The linear accumulation (O(N)) of Key-Value states treats context as a warehouse of static artifacts, eventually forcing a destructive choice between amnesia and latency. We challenge this discrete orthodoxy, proposing that long-term memory is not the storage of items, but the persistence of a trajectory. We introduce Phonetic Trajectory Memory (PTM), a neuro-symbolic architecture that encodes language not as a sequence of tensors, but as a continuous path on an ergodic manifold governed by irrational rotation matrices. By decoupling the navigation (an invariant O(1) geometric signal) from the reconstruction (a probabilistic generative act), PTM achieves a compression magnitude of greater than 3,000x relative to dense caches. We demonstrate that retrieval becomes a process of resonance: the phonetic trace stabilizes the model against hallucination via "Signal Consensus" mechanism, securing up to approximately 92% factual accuracy. While this aggressive abstraction alters generative texture, it unlocks immediate access latency (approximately 34ms) independent of depth. Our r</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-119">正文（抓取，非 AI）</h3>
<p>[2512.20245v1] Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds Computer Science &gt; Neural and Evolutionary Computing arXiv:2512.20245v1 (cs) [Submitted on 23 Dec 2025] Title: Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds Authors: Tarik Houichime , Abdelghani Souhar , Younes El Amrani View a PDF of the paper titled Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds, by Tarik Houichime and 2 other authors View PDF HTML (experimental) Abstract: The memory of contemporary Large Language Models is bound by a physical paradox: as they learn, they fill up. The linear accumulation (O(N)) of Key-Value states treats context as a warehouse of static artifacts, eventually forcing a destructive choice between amnesia and latency. We challenge this discrete orthodoxy, proposing that long-term memory is not the storage of items, but the persistence of a trajectory. We introduce Phonetic Trajectory Memory (PTM), a neuro-symbolic architecture that encodes language not as a sequence of tensors, but as a continuous path on an ergodic manifold governed by irrational rotation matrices. By decoupling the navigation (an invariant O(1) geometric signal) from the reconstruction (a probabilistic generative act), PTM achieves a compression magnitude of greater than 3,000x relative to dense caches. We demonstrate that retrieval becomes a process of resonance: the phonetic trace stabilizes the model against hallucination via "Signal Consensus" mechanism, securing up to approximately 92% factual accuracy. While this aggressive abstraction alters generative texture, it unlocks immediate access latency (approximately 34ms) independent of depth. Our results suggest that infinite context does not require infinite silicon; it requires treating memory not as data to be stored, but as a reconstructive process acting on a conserved, undying physical signal. Subjects: Neural and Evolutionary Computing (cs.NE) ; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Symbolic Computation (cs.SC); Software Engineering (cs.SE) Cite as: arXiv:2512.20245 [cs.NE] (or arXiv:2512.20245v1 [cs.NE] for this version) https://doi.org/10.48550/arXiv.2512.20245 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Tarik Houichime [ view email ] [v1] Tue, 23 Dec 2025 10:55:32 UTC (8,534 KB) Full-text links: Access Paper: View a PDF of the paper titled Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds, by Tarik Houichime and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.NE &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs cs.AI cs.IR cs.SC cs.SE References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-120">61. Revisiting Weight Regularization for Low-Rank Continual Learning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.17559v1</li>
<li>来源：arxiv</li>
<li>摘要：Continual Learning (CL) with large-scale pre-trained models (PTMs) has recently gained wide attention, shifting the focus from training from scratch to continually adapting PTMs. This has given rise to a promising paradigm: parameter-efficient continual learning (PECL), where task interference is typically mitigated by assigning a task-specific module during training, such as low-rank adapters. However, weight regularization techniques, such as Elastic Weight Consolidation (EWC)-a key strategy in CL-remain underexplored in this new paradigm. In this paper, we revisit weight regularization in low-rank CL as a new perspective for mitigating task interference in PECL. Unlike existing low-rank CL methods, we mitigate task interference by regularizing a shared low-rank update through EWC, thereby keeping the storage requirement and inference costs constant regardless of the number of tasks. Our proposed method EWC-LoRA leverages a low-rank representation to estimate parameter importance over the full-dimensional space. This design offers a practical, computational- and memory-efficient solution for CL with PTMs, and provides insights that may inform the broader application of regulariza</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-121">正文（抓取，非 AI）</h3>
<p>[2602.17559v1] Revisiting Weight Regularization for Low-Rank Continual Learning Computer Science &gt; Machine Learning arXiv:2602.17559v1 (cs) [Submitted on 19 Feb 2026] Title: Revisiting Weight Regularization for Low-Rank Continual Learning Authors: Yaoyue Zheng , Yin Zhang , Joost van de Weijer , Gido M van de Ven , Shaoyi Du , Xuetao Zhang , Zhiqiang Tian View a PDF of the paper titled Revisiting Weight Regularization for Low-Rank Continual Learning, by Yaoyue Zheng and 6 other authors View PDF HTML (experimental) Abstract: Continual Learning (CL) with large-scale pre-trained models (PTMs) has recently gained wide attention, shifting the focus from training from scratch to continually adapting PTMs. This has given rise to a promising paradigm: parameter-efficient continual learning (PECL), where task interference is typically mitigated by assigning a task-specific module during training, such as low-rank adapters. However, weight regularization techniques, such as Elastic Weight Consolidation (EWC)-a key strategy in CL-remain underexplored in this new paradigm. In this paper, we revisit weight regularization in low-rank CL as a new perspective for mitigating task interference in PECL. Unlike existing low-rank CL methods, we mitigate task interference by regularizing a shared low-rank update through EWC, thereby keeping the storage requirement and inference costs constant regardless of the number of tasks. Our proposed method EWC-LoRA leverages a low-rank representation to estimate parameter importance over the full-dimensional space. This design offers a practical, computational- and memory-efficient solution for CL with PTMs, and provides insights that may inform the broader application of regularization techniques within PECL. Extensive experiments on various benchmarks demonstrate the effectiveness of EWC-LoRA, achieving a stability-plasticity trade-off superior to existing low-rank CL approaches. These results indicate that, even under low-rank parameterizations, weight regularization remains an effective mechanism for mitigating task interference. Code is available at: this https URL . Comments: Accepted by ICLR 2026 Subjects: Machine Learning (cs.LG) Cite as: arXiv:2602.17559 [cs.LG] (or arXiv:2602.17559v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.17559 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Yaoyue Zheng [ view email ] [v1] Thu, 19 Feb 2026 17:13:00 UTC (1,279 KB) Full-text links: Access Paper: View a PDF of the paper titled Revisiting Weight Regularization for Low-Rank Continual Learning, by Yaoyue Zheng and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-122">62. Stacked Cross-modal Feature Consolidation Attention Networks for Image Captioning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2302.04676v1</li>
<li>来源：arxiv</li>
<li>摘要：Recently, the attention-enriched encoder-decoder framework has aroused great interest in image captioning due to its overwhelming progress. Many visual attention models directly leverage meaningful regions to generate image descriptions. However, seeking a direct transition from visual space to text is not enough to generate fine-grained captions. This paper exploits a feature-compounding approach to bring together high-level semantic concepts and visual information regarding the contextual environment fully end-to-end. Thus, we propose a stacked cross-modal feature consolidation (SCFC) attention network for image captioning in which we simultaneously consolidate cross-modal features through a novel compounding function in a multi-step reasoning fashion. Besides, we jointly employ spatial information and context-aware attributes (CAA) as the principal components in our proposed compounding function, where our CAA provides a concise context-sensitive semantic representation. To make better use of consolidated features potential, we further propose an SCFC-LSTM as the caption generator, which can leverage discriminative semantic information through the caption generation process. The</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-123">正文（抓取，非 AI）</h3>
<p>[2302.04676v1] Stacked Cross-modal Feature Consolidation Attention Networks for Image Captioning Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2302.04676v1 (cs) [Submitted on 8 Feb 2023] Title: Stacked Cross-modal Feature Consolidation Attention Networks for Image Captioning Authors: Mozhgan Pourkeshavarz , Shahabedin Nabavi , Mohsen Ebrahimi Moghaddam , Mehrnoush Shamsfard View a PDF of the paper titled Stacked Cross-modal Feature Consolidation Attention Networks for Image Captioning, by Mozhgan Pourkeshavarz and 3 other authors View PDF Abstract: Recently, the attention-enriched encoder-decoder framework has aroused great interest in image captioning due to its overwhelming progress. Many visual attention models directly leverage meaningful regions to generate image descriptions. However, seeking a direct transition from visual space to text is not enough to generate fine-grained captions. This paper exploits a feature-compounding approach to bring together high-level semantic concepts and visual information regarding the contextual environment fully end-to-end. Thus, we propose a stacked cross-modal feature consolidation (SCFC) attention network for image captioning in which we simultaneously consolidate cross-modal features through a novel compounding function in a multi-step reasoning fashion. Besides, we jointly employ spatial information and context-aware attributes (CAA) as the principal components in our proposed compounding function, where our CAA provides a concise context-sensitive semantic representation. To make better use of consolidated features potential, we further propose an SCFC-LSTM as the caption generator, which can leverage discriminative semantic information through the caption generation process. The experimental results indicate that our proposed SCFC can outperform various state-of-the-art image captioning benchmarks in terms of popular metrics on the MSCOCO and Flickr30K datasets. Subjects: Computer Vision and Pattern Recognition (cs.CV) ; Image and Video Processing (eess.IV) Cite as: arXiv:2302.04676 [cs.CV] (or arXiv:2302.04676v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2302.04676 Focus to learn more arXiv-issued DOI via DataCite Journal reference: Multimedia Tools and Applications, Volume 83, pages 12209-12233, 2024 Related DOI : https://doi.org/10.1007/s11042-023-15869-x Focus to learn more DOI(s) linking to related resources Submission history From: Shahabedin Nabavi [ view email ] [v1] Wed, 8 Feb 2023 09:15:09 UTC (3,589 KB) Full-text links: Access Paper: View a PDF of the paper titled Stacked Cross-modal Feature Consolidation Attention Networks for Image Captioning, by Mozhgan Pourkeshavarz and 3 other authors View PDF TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2023-02 Change to browse by: cs eess eess.IV References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-124">63. 什么是智能体（AI Bot）？</h2>
<ul>
<li>链接：https://www.zhihu.com/tardis/bd/ans/1915722015987472237</li>
<li>来源：bing</li>
<li>摘要：2025年8月13日 · （图2 智能体运行引擎的架构图，简化版） 智能体引擎的主要职责体现在以下几个方面： * 任务编排与执行控制：将复杂任务分解为职责相对单一的、可执行的任务序列，并管理任务间的依 …</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-125">正文（抓取，非 AI）</h3>
<p>相比于传统软件，AI智能体是一个新兴事物，技术架构和解决方案仍处在高速迭代中。所以，本文章将重点放在理清AI智能体相关的技术脉络，而非具体技术实现。更多相关知识还需要读者通过第三方搜索等方式，保持与时俱进。 一、架构总览 在技术实现的视角看，智能体分为三层：交互层、智能决策层和系统连接层，如图1所示，由智能体执行引擎统一完成编排与调度。 （图1 智能体标准参考架构） 交互层和系统连接层的开发技术与传统的软件开发一致，这里不再赘述。接下来，我们将关注的重点放在智能决策层的核心技术。 二、智能决策层，拆解智能体的核心技术 一个工程可落地的 AI 智能体智能决策层，并非仅仅是将一个大语言模型封装成接口那么简单。它的背后是一整套针对理解、推理、执行、感知和集成等多个维度的技术体系，包含以下3个核心技术： * 智能体运行引擎 * 外部知识引入 * 外部能力引入 2.1 智能体运行引擎 智能体运行引擎是AI智能体的核心骨架，可类比于编码开发中的后端框架，如SpringBoot。它负责协调各个功能模块，编排并执行流程，并确保系统的可靠性与可扩展性。一个成熟的智能体引擎不仅仅是简单的调度器，更是一个复杂的状态管理与决策系统，如图2所示。 （图2 智能体运行引擎的架构图，简化版） 智能体引擎的主要职责体现在以下几个方面： * 任务编排与执行控制：将复杂任务分解为职责相对单一的、可执行的任务序列，并管理任务间的依赖关系与执行顺序 * 状态管理与上下文保持：维护人与智能体的对话历史，确保多轮交互的连贯性 * 资源调度与负载均衡：智能体本身是一个独立运行的数字化系统，需要确保系统的稳定性 * 错误处理与自我修复：提供日志机制，检测执行异常并实施故障恢复策略，提高系统健壮性 为了提升智能体的开发效率，大部分智能体引擎会提供可视化的任务编排能力。任务编排工作可以看成是手工构建一个由多个节点构成的工作流，如图3所示，每一个节点对应了拆解后的一项任务。下图中的“Customer Insight Agent”节点就是调用“OpenAI Chat Model”（兼容OpenAI SDK的大模型）的任务。 （图3 智能体工作流的示例） 作为最核心的能力，智能体引擎调用大语言模式的最核心功能，是为大模型传入提示词，接收大模型的响应。就像我们在Deepseek的网站上询问AI大模型一样，如图4所示。AI智能体的全部功能都需要依托于这个机制来实现。依然是为了提升效率，智能体引擎还会提供更多的扩展机制，实现外部知识引入和外部能力引入。 （图4 大语言模型的提示词与响应） 2.2 外部知识引入 提示：实现层面，外部知识的提供方（如知识库）通常位于AI智能体之外，智能体引擎仅需调用其接口即可完成引入工作。 尽管大语言模型（LLM）在多种任务中展现出强大的通用能力，但它们的知识主要来自预训练阶段的语料，一旦训练完成，模型的知识便固定了下来。这种静态知识局限，使得 LLM 在以下几类任务中难以胜任： 涉及组织内部、领域专有的知识内容： 例如一家制造企业的设备操作规程、质量检验标准，或一家银行的风险评估规则和内部授信流程，这些内容不可能出现在公开训练语料中 涉及时效性强、经常更新的业务信息： 比如电商平台的每日促销活动、物流系统的实时运单状态、企业最新的销售数据。这类信息更新频繁，需动态接入，模型本体很难预先掌握。 需要可验证、可追溯的答案来源： 如医疗场景下对某药品用法的回答，需要明确引用权威指南；或政务场景下对政策解释的结果，需标明对应的政策原文出处。这些任务要求 AI 智能体不仅回答得对，还要回答得有依据。 而在真实的企业环境中，上述应用场景恰好是无法避免，甚至需要重点攻克的，如产品说明答疑、制度解读、政策判断、流程执行、知识总结等。所以，智能体引擎必须提供外部知识（这里的外部指的是大语言模型之外的知识，对于企业来说，大部分都属于“内部”知识）的获取和绑定机制，将动态的知识一并提交给大模型。 2.2.1 知识获取 外部知识的种类千差万别，存储在不同的系统中，智能体引擎需要提供差异化的获取方式。典型的知识来源于接入方式如下： 传统知识库： 在OA等传统软件系统的知识库模块中，存储了大量的非结构化知识，如规章制度、标准操作流程等。这种知识库通常基于全文检索机制建立，并提供有查询接口。智能体引擎需要先将用户输入的意图拆解成关键词，然后才能调用知识库的接口获取相关的知识。 支持语义检索的矢量型知识库： 生成式人工智能技术普及后，传统知识库的“升级版”，矢量型知识库诞生了。矢量型知识库在传统知识库的基础上，提供了语义检索的能力。智能体引擎将知识获取和引入的过程合二为一，可以自动将用户输入的意图发送给知识库，然后将知识和意图一起发给大模型，一次性最终结果。调用方式更简单，效果也更好。 元数据库/元数据仓库： 除了上述的两种非结构化知识外，完成数据治理的企业中通常也会存在一些结构化的知识，以元数据的形式保存在数据库或数据仓库中，比如术语表、指标表等。智能体引擎需要像操作传统知识库一样，先拆解关键词，再查询这些数据库、数据仓库来获取相关知识。由于经过了数据治理，这部分知识的质量更好，可优先采用。 业务数据： 另一种结构化的知识是业务数据，如销售目标、销售额等，智能体引擎获取这部分知识的方式与元数据类似，不再赘述。 2.2.2 知识绑定 智能体引擎获取到的知识，主要用于拼接提示词，让发送给AI大模型的内容中既有用户输入的意图，也包含与之相关的知识。AI大模型就会优先将这部分知识纳入推导和判断中，从而提升回答的准确率，最终达到提升智能体能力的目标。这个过程被称为“知识绑定”或“知识引入”。 对于C端场景和少量简单的企业应用场景来说，知识的来源比较单一，以矢量型知识库为主。智能体引擎提供的检索增强生成（Retrieval-Augmented Generation，RAG）模式就可以完成知识的获取和引用。具体而言，RAG有经典RAG和增强RAG两种模式，差异集中体现在智能体引擎中编排的复杂度，如图5所示。 （图5 RAG的两种典型实现模式） 但是，大部分企业应用场景中涉及到的知识来源多样性强，而且大多以元数据库、第三方服务和业务数据库为主，RAG模式无法满足此类场景的要求。于是，我们需要在智能体引擎的任务编排机制中人工完成知识绑定。具体操作是，我们可以先设置一些获取知识的节点，将数据库、第三方WebAPI返回的数据存储到参数中；在调用大语言模型的节点中，使用这些参数拼接出完整的提示词，如图6所示。 （图6 将外部知识融入提示词） 特别需要注意，外部知识引入的成效主要取决于知识本身的质量。除了覆盖面之外，知识的结构化程度越高、冲突越少，对智能体的能力提升越大，反之则越小。从部分实践案例上，未经治理的、广泛存在矛盾的知识库反而会放大AI幻觉，降低智能体的处理能力。所以，我们强烈建议企业在引入外部知识前做好知识相关的数据治理工作，治理好一个知识来源，再接入这个知识来源。 2.3 外部能力引入 这项能力是AI智能体最核心的能力。 现代AI智能体不仅要“会说”，更要“能做”。这就要求AI智能体可以将大模型以外的能力引入进来，具体而言就是要具备调用外部工具的能力（这里的外部指的也是大模型的外部，对于企业来说，这些工具大多也是部署在企业内部的）。 2.3.1 函数调用，强化大模型自身的处理能力 函数调用机制，是目前大语言模型原生支持最好的方式之一（如 OpenAI GPT 的 function calling、Anthropic 的 tool use）。 该技术的核心在于通过对工具（函数）进行结构化描述，引导模型输出所需参数，并由智能体引擎协调其他功能完成实际调用，如图7所示。 步骤如下： 开发者首先需要在智能体中定义能够提供给AI、供AI操作的“工具” 在智能体编排的“调用大模型”环节，将用户提供的提示词和上下文连同上一个步骤中工具的定义（含工具描述、参数描述等），一并交给AI服务器，等待AI服务器的响应 在智能体编排中，处理AI返回的函数调用指令和参数，执行该函数。如果函数是“中间节点”，则需要将函数返回结果和之前的所有提示词进行合并，调用大模型，否则就可以视为结束，将处理后的结果作为智能体的返回结果。在图7中，get_weather函数就是中间节点，调用该节点后还需要再一轮调用才能完成大模型调用工作。 （图7 函数调用的原理示意） 函数调用机制的优势在于开发简单、易于理解和维护、与模型原生集成好，但也有不足之处，如与调用大模型环节紧密绑定，复用性欠佳等。 2.3.2 MCP，大幅提升函数的复用性 为了提升函数调用环节的可复用性，智能体引擎首先尝试的是将软件开发中私有方法的理念引入到智能体函数调用，将具体的处理逻辑抽象为“私有方法”，在调用各种AI大模型时简单封装一下就可以作为Function Calling。但这也仅仅是解决了同一个智能体或同一个大模型引擎内的复用。 为了进一步扩大复用范围，达到像npm开源社区那种程度，行业需要建立一个被广泛接受的函数封装协议和门户。于是，MCP（Model Context Protocol）进入了我们视野。MCP由Claude大模型的公司提出的开源协议，希望智能体开发者就像使用电脑上的USB接口一样，将所有符合MCP协议的函数直接引入到AI大模型中，如图8所示，实现最大程度的复用，建立全新的智能体函数库，打造AI智能体的开源生态。 （图8 以电脑硬件接口为类比的MCP架构示意图） MCP协议诞生于2024年底。该领域处在高速发展与变革中，能力和功能尚未定型，在企业应用场景下的价值也存在争议。但这并不影响数以千计、面向C端场景的MCP服务器不断涌现，从文件处理、在线搜索到地图路径规划、社交媒体分享，以图9所示的全球最大MCP源MCP.so为例，兼容MCP协议的软件在2025年4月就达到了7000余个。 （图9 MCP.so上的MCP服务器与客户端） 2.3.3 动态能力选择器 随着智能体应用场景的扩充，智能体引擎中注册的函数或MCP服务器数量也会迎来大幅增长，如果将其全部提交给大模型，不但会导致提示词数量超长，还会影响大模型的执行效果。该如何为不同的大模型调用场景选择合适的外部能力清单成为了关键问题。 能力选择器就是为了解决这一问题而生的。能力选择器是智能体架构中用于 “决策调度” 的核心组件，负责根据意图、上下文以及策略规则，从能力库中动态选择最佳的函数/MCP组合来完成任务。能力选择器的定位可以简单理解为连接“语言理解”和“任务执行”的中枢模块。 能力选择器的主要职责如下： 上下文感知与能力筛选：通过上下文（如当前业务页面、用户身份、可访问资源、数据范围等），能力选择器可根据预设规则或截止大语言模型筛选出适用的函数 回退与兜底机制：当匹配失败或插件调用异常时，能力选择器负责执行回退策略，如 调用兜底能力（默认回复、固定动作）、请求用户补充信息、引导用户手动执行等 在能力选择器的调度下，智能体引擎与外部能力协同配合，构成了AI智能体的“感知—判断—执行”链路，最终支撑起复杂企业环境下灵活、稳健的业务执行能力。 三、案例解析，看智能体各组件的协同方式 现实业务中，AI智能体通常需要智能体引擎、大语言模型（LLM）、外部能力系统（如MCP）、外部知识系统（如KAS）和用户交互层（UX）等多个组件协同工作。接下来，我们以OA系统的AI查询场景为例，展现一个基于MCP技术构建的Agent范式智能体中，多组件的协作流程。 如需扩充该智能体的能力，我们仅需要同步修改MCP1（获取审批中心能力清单）的数据、MCP3（生成工作流对话框渲染指令）和UX的逻辑即可。 扩展链接： 低代码 + AI 在 Excel 中加入 AI 对话式AI分析</p>
</div></details><h2 id="toc-126">64. A probabilistic foundation model for crystal structure denoising, phase classification, and order parameters</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.11077v2</li>
<li>来源：arxiv</li>
<li>摘要：Atomistic simulations generate large volumes of noisy structural data, but extracting phase labels, order parameters (OPs), and defect information in a way that is universal, robust, and interpretable remains challenging. Existing tools such as PTM and CNA are restricted to a small set of hand-crafted lattices (e.g.\ FCC/BCC/HCP), degrade under strong thermal disorder or defects, and produce hard, template-based labels without per-atom probability or confidence scores. Here we introduce a log-probability foundation model that unifies denoising, phase classification, and OP extraction within a single probabilistic framework. We reuse the MACE-MP foundation interatomic potential on crystal structures mapped to AFLOW prototypes, training it to predict per-atom, per-phase logits $l$ and to aggregate them into a global log-density $\log \hat{P}<em ac="">θ(\boldsymbol{r})$ whose gradient defines a conservative score field. Denoising corresponds to gradient ascent on this learned log-density, phase labels follow from $\arg\max_c l</em>$, and the $l$ values act as continuous, defect-sensitive and interpretable OPs quantifying the Euclidean distance to ideal phases. We demonstrate universality acros</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-127">正文（抓取，非 AI）</h3>
<p>[2512.11077v2] A probabilistic foundation model for crystal structure denoising, phase classification, and order parameters Condensed Matter &gt; Materials Science arXiv:2512.11077v2 (cond-mat) [Submitted on 11 Dec 2025 ( v1 ), last revised 21 Dec 2025 (this version, v2)] Title: A probabilistic foundation model for crystal structure denoising, phase classification, and order parameters Authors: Hyuna Kwon , Babak Sadigh , Sebastien Hamel , Vincenzo Lordi , John Klepeis , Fei Zhou View a PDF of the paper titled A probabilistic foundation model for crystal structure denoising, phase classification, and order parameters, by Hyuna Kwon and 5 other authors View PDF HTML (experimental) Abstract: Atomistic simulations generate large volumes of noisy structural data, but extracting phase labels, order parameters (OPs), and defect information in a way that is universal, robust, and interpretable remains challenging. Existing tools such as PTM and CNA are restricted to a small set of hand-crafted lattices (e.g.\ FCC/BCC/HCP), degrade under strong thermal disorder or defects, and produce hard, template-based labels without per-atom probability or confidence scores. Here we introduce a log-probability foundation model that unifies denoising, phase classification, and OP extraction within a single probabilistic framework. We reuse the MACE-MP foundation interatomic potential on crystal structures mapped to AFLOW prototypes, training it to predict per-atom, per-phase logits $l$ and to aggregate them into a global log-density $\log \hat{P}<em ac="">\theta(\boldsymbol{r})$ whose gradient defines a conservative score field. Denoising corresponds to gradient ascent on this learned log-density, phase labels follow from $\arg\max_c l</em>$, and the $l$ values act as continuous, defect-sensitive and interpretable OPs quantifying the Euclidean distance to ideal phases. We demonstrate universality across hundreds of prototypes, robustness under strong thermal and defect-induced disorder, and accurate treatment of complex systems such as ice polymorphs, ice--water interfaces, and shock-compressed Ti. Subjects: Materials Science (cond-mat.mtrl-sci) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2512.11077 [cond-mat.mtrl-sci] (or arXiv:2512.11077v2 [cond-mat.mtrl-sci] for this version) https://doi.org/10.48550/arXiv.2512.11077 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Hyuna Kwon [ view email ] [v1] Thu, 11 Dec 2025 19:46:56 UTC (15,116 KB) [v2] Sun, 21 Dec 2025 02:16:45 UTC (20,134 KB) Full-text links: Access Paper: View a PDF of the paper titled A probabilistic foundation model for crystal structure denoising, phase classification, and order parameters, by Hyuna Kwon and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cond-mat.mtrl-sci &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cond-mat cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-128">65. Self-Evolving Multi-Agent Network for Industrial IoT Predictive Maintenance</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.16738v1</li>
<li>来源：arxiv</li>
<li>摘要：Industrial IoT predictive maintenance requires systems capable of real-time anomaly detection without sacrificing interpretability or demanding excessive computational resources. Traditional approaches rely on static, offline-trained models that cannot adapt to evolving operational conditions, while LLM-based monolithic systems demand prohibitive memory and latency, rendering them impractical for on-site edge deployment. We introduce SEMAS, a self-evolving hierarchical multi-agent system that distributes specialized agents across Edge, Fog, and Cloud computational tiers. Edge agents perform lightweight feature extraction and pre-filtering; Fog agents execute diversified ensemble detection with dynamic consensus voting; and Cloud agents continuously optimize system policies via Proximal Policy Optimization (PPO) while maintaining asynchronous, non-blocking inference. The framework incorporates LLM-based response generation for explainability and federated knowledge aggregation for adaptive policy distribution. This architecture enables resource-aware specialization without sacrificing real-time performance or model interpretability. Empirical evaluation on two industrial benchmarks </li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-129">正文（抓取，非 AI）</h3>
<p>[2602.16738v1] Self-Evolving Multi-Agent Network for Industrial IoT Predictive Maintenance Computer Science &gt; Multiagent Systems arXiv:2602.16738v1 (cs) [Submitted on 17 Feb 2026] Title: Self-Evolving Multi-Agent Network for Industrial IoT Predictive Maintenance Authors: Rebin Saleh , Khanh Pham Dinh , Balázs Villányi , Truong-Son Hy View a PDF of the paper titled Self-Evolving Multi-Agent Network for Industrial IoT Predictive Maintenance, by Rebin Saleh and 3 other authors View PDF HTML (experimental) Abstract: Industrial IoT predictive maintenance requires systems capable of real-time anomaly detection without sacrificing interpretability or demanding excessive computational resources. Traditional approaches rely on static, offline-trained models that cannot adapt to evolving operational conditions, while LLM-based monolithic systems demand prohibitive memory and latency, rendering them impractical for on-site edge deployment. We introduce SEMAS, a self-evolving hierarchical multi-agent system that distributes specialized agents across Edge, Fog, and Cloud computational tiers. Edge agents perform lightweight feature extraction and pre-filtering; Fog agents execute diversified ensemble detection with dynamic consensus voting; and Cloud agents continuously optimize system policies via Proximal Policy Optimization (PPO) while maintaining asynchronous, non-blocking inference. The framework incorporates LLM-based response generation for explainability and federated knowledge aggregation for adaptive policy distribution. This architecture enables resource-aware specialization without sacrificing real-time performance or model interpretability. Empirical evaluation on two industrial benchmarks (Boiler Emulator and Wind Turbine) demonstrates that SEMAS achieves superior anomaly detection performance with exceptional stability under adaptation, sustains prediction accuracy across evolving operational contexts, and delivers substantial latency improvements enabling genuine real-time deployment. Ablation studies confirm that PPO-driven policy evolution, consensus voting, and federated aggregation each contribute materially to system effectiveness. These findings indicate that resource-aware, self-evolving 1multi-agent coordination is essential for production-ready industrial IoT predictive maintenance under strict latency and explainability constraints. Subjects: Multiagent Systems (cs.MA) ; Machine Learning (cs.LG) Cite as: arXiv:2602.16738 [cs.MA] (or arXiv:2602.16738v1 [cs.MA] for this version) https://doi.org/10.48550/arXiv.2602.16738 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Truong-Son Hy [ view email ] [v1] Tue, 17 Feb 2026 22:45:43 UTC (4,161 KB) Full-text links: Access Paper: View a PDF of the paper titled Self-Evolving Multi-Agent Network for Industrial IoT Predictive Maintenance, by Rebin Saleh and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.MA &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-130">66. Compact LLM Deployment and World Model Assisted Offloading in Mobile Edge Computing</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.13628v1</li>
<li>来源：arxiv</li>
<li>摘要：This paper investigates compact large language model (LLM) deployment and world-model-assisted inference offloading in mobile edge computing (MEC) networks. We first propose an edge compact LLM deployment (ECLD) framework that jointly applies structured pruning, low-bit quantization, and knowledge distillation to construct edge-deployable LLM variants, and we evaluate these models using four complementary metrics: accessibility, energy consumption, hallucination rate, and generalization accuracy. Building on the resulting compact models, we formulate an MEC offloading optimization problem that minimizes the long-term average inference latency subject to per-device energy budgets and LLM-specific quality-of-service constraints on effective accuracy and hallucination. To solve this problem under unknown and time-varying network dynamics, we develop a world model-proximal policy optimization (PPO) algorithm, which augments an on-policy PPO algorithm with a learned recurrent world model that provides improved value targets and short imagination rollouts. Extensive experiments on Llama-3.1-8B, Qwen3-8B, and Mistral-12B show that ECLD compresses base models by about 70-80% in storage (i.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-131">正文（抓取，非 AI）</h3>
<p>[2602.13628v1] Compact LLM Deployment and World Model Assisted Offloading in Mobile Edge Computing Computer Science &gt; Networking and Internet Architecture arXiv:2602.13628v1 (cs) [Submitted on 14 Feb 2026] Title: Compact LLM Deployment and World Model Assisted Offloading in Mobile Edge Computing Authors: Ruichen Zhang , Xiaofeng Luo , Jiayi He , Dusit Niyato , Jiawen Kang , Zehui Xiong , Yonghui Li View a PDF of the paper titled Compact LLM Deployment and World Model Assisted Offloading in Mobile Edge Computing, by Ruichen Zhang and 6 other authors View PDF HTML (experimental) Abstract: This paper investigates compact large language model (LLM) deployment and world-model-assisted inference offloading in mobile edge computing (MEC) networks. We first propose an edge compact LLM deployment (ECLD) framework that jointly applies structured pruning, low-bit quantization, and knowledge distillation to construct edge-deployable LLM variants, and we evaluate these models using four complementary metrics: accessibility, energy consumption, hallucination rate, and generalization accuracy. Building on the resulting compact models, we formulate an MEC offloading optimization problem that minimizes the long-term average inference latency subject to per-device energy budgets and LLM-specific quality-of-service constraints on effective accuracy and hallucination. To solve this problem under unknown and time-varying network dynamics, we develop a world model-proximal policy optimization (PPO) algorithm, which augments an on-policy PPO algorithm with a learned recurrent world model that provides improved value targets and short imagination rollouts. Extensive experiments on Llama-3.1-8B, Qwen3-8B, and Mistral-12B show that ECLD compresses base models by about 70-80% in storage (i.e., from 15.3 GB to 3.3 GB for Llama-3.1-8B) and reduces per-query energy consumption by up to 50%, while largely preserving accuracy and often lowering hallucination compared with quantization-only or pruning-only baselines. Moreover, they also show that world model-PPO speeds up convergence by about 50%, improves the final reward by 15.8% over vanilla PPO, and reduces average inference latency by 12-30% across different user populations, while satisfying the accuracy and hallucination constraints and approaching the generation quality of always-offloading with much of the efficiency of local execution. Comments: 16 pages, 10 figures Subjects: Networking and Internet Architecture (cs.NI) Cite as: arXiv:2602.13628 [cs.NI] (or arXiv:2602.13628v1 [cs.NI] for this version) https://doi.org/10.48550/arXiv.2602.13628 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Ruichen Zhang [ view email ] [v1] Sat, 14 Feb 2026 06:37:29 UTC (3,150 KB) Full-text links: Access Paper: View a PDF of the paper titled Compact LLM Deployment and World Model Assisted Offloading in Mobile Edge Computing, by Ruichen Zhang and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.NI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-132">67. Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.16523v1</li>
<li>来源：arxiv</li>
<li>摘要：We extend directed quantum circuit synthesis (DQCS) with reinforcement learning from purely discrete gate selection to parameterized quantum state preparation with continuous single-qubit rotations (R_x), (R_y), and (R_z). We compare two training regimes: a one-stage agent that jointly selects the gate type, the affected qubit(s), and the rotation angle; and a two-stage variant that first proposes a discrete circuit and subsequently optimizes the rotation angles with Adam using parameter-shift gradients. Using Gymnasium and PennyLane, we evaluate Proximal Policy Optimization (PPO) and Advantage Actor--Critic (A2C) on systems comprising two to ten qubits and on targets of increasing complexity with (λ) ranging from one to five. Whereas A2C does not learn effective policies in this setting, PPO succeeds under stable hyperparameters (one-stage: learning rate approximately (5\times10^{-4}) with a self-fidelity-error threshold of 0.01; two-stage: learning rate approximately (10^{-4})). Both approaches reliably reconstruct computational basis states (between 83\% and 99\% success) and Bell states (between 61\% and 77\% success). However, scalability saturates for (λ) of app</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-133">正文（抓取，非 AI）</h3>
<p>[2602.16523v1] Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study Computer Science &gt; Machine Learning arXiv:2602.16523v1 (cs) [Submitted on 18 Feb 2026] Title: Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study Authors: Gerhard Stenzel , Isabella Debelic , Michael Kölle , Tobias Rohe , Leo Sünkel , Julian Hager , Claudia Linnhoff-Popien View a PDF of the paper titled Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study, by Gerhard Stenzel and Isabella Debelic and Michael K\"olle and Tobias Rohe and Leo S\"unkel and Julian Hager and Claudia Linnhoff-Popien View PDF HTML (experimental) Abstract: We extend directed quantum circuit synthesis (DQCS) with reinforcement learning from purely discrete gate selection to parameterized quantum state preparation with continuous single-qubit rotations (R_x), (R_y), and (R_z). We compare two training regimes: a one-stage agent that jointly selects the gate type, the affected qubit(s), and the rotation angle; and a two-stage variant that first proposes a discrete circuit and subsequently optimizes the rotation angles with Adam using parameter-shift gradients. Using Gymnasium and PennyLane, we evaluate Proximal Policy Optimization (PPO) and Advantage Actor--Critic (A2C) on systems comprising two to ten qubits and on targets of increasing complexity with (\lambda) ranging from one to five. Whereas A2C does not learn effective policies in this setting, PPO succeeds under stable hyperparameters (one-stage: learning rate approximately (5\times10^{-4}) with a self-fidelity-error threshold of 0.01; two-stage: learning rate approximately (10^{-4})). Both approaches reliably reconstruct computational basis states (between 83\% and 99\% success) and Bell states (between 61\% and 77\% success). However, scalability saturates for (\lambda) of approximately three to four and does not extend to ten-qubit targets even at (\lambda=2). The two-stage method offers only marginal accuracy gains while requiring around three times the runtime. For practicality under a fixed compute budget, we therefore recommend the one-stage PPO policy, provide explicit synthesized circuits, and contrast with a classical variational baseline to outline avenues for improved scalability. Comments: Extended version of a short paper to be published at ICAART 2026 Subjects: Machine Learning (cs.LG) ; Quantum Physics (quant-ph) Cite as: arXiv:2602.16523 [cs.LG] (or arXiv:2602.16523v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.16523 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Gerhard Stenzel [ view email ] [v1] Wed, 18 Feb 2026 15:10:43 UTC (170 KB) Full-text links: Access Paper: View a PDF of the paper titled Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study, by Gerhard Stenzel and Isabella Debelic and Michael K\"olle and Tobias Rohe and Leo S\"unkel and Julian Hager and Claudia Linnhoff-Popien View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs quant-ph References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-134">68. Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.16062v1</li>
<li>来源：arxiv</li>
<li>摘要：This paper proposes implicit cooperation, a framework enabling decentralized agents to approximate optimal coordination in local energy markets without explicit peer-to-peer communication. We formulate the problem as a decentralized partially observable Markov decision problem that is solved through a multi-agent reinforcement learning task in which agents use stigmergic signals (key performance indicators at the system level) to infer and react to global states. Through a 3x3 factorial design on an IEEE 34-node topology, we evaluated three training paradigms (CTCE, CTDE, DTDE) and three algorithms (PPO, APPO, SAC). Results identify APPO-DTDE as the optimal configuration, achieving a coordination score of 91.7% relative to the theoretical centralized benchmark (CTCE). However, a critical trade-off emerges between efficiency and stability: while the centralized benchmark maximizes allocative efficiency with a peer-to-peer trade ratio of 0.6, the fully decentralized approach (DTDE) demonstrates superior physical stability. Specifically, DTDE reduces the variance of grid balance by 31% compared to hybrid architectures, establishing a highly predictable, import-biased load profile that</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-135">正文（抓取，非 AI）</h3>
<p>[2602.16062v1] Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets Electrical Engineering and Systems Science &gt; Systems and Control arXiv:2602.16062v1 (eess) [Submitted on 17 Feb 2026] Title: Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets Authors: Nelson Salazar-Pena , Alejandra Tabares , Andres Gonzalez-Mancera View a PDF of the paper titled Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets, by Nelson Salazar-Pena and 2 other authors View PDF HTML (experimental) Abstract: This paper proposes implicit cooperation, a framework enabling decentralized agents to approximate optimal coordination in local energy markets without explicit peer-to-peer communication. We formulate the problem as a decentralized partially observable Markov decision problem that is solved through a multi-agent reinforcement learning task in which agents use stigmergic signals (key performance indicators at the system level) to infer and react to global states. Through a 3x3 factorial design on an IEEE 34-node topology, we evaluated three training paradigms (CTCE, CTDE, DTDE) and three algorithms (PPO, APPO, SAC). Results identify APPO-DTDE as the optimal configuration, achieving a coordination score of 91.7% relative to the theoretical centralized benchmark (CTCE). However, a critical trade-off emerges between efficiency and stability: while the centralized benchmark maximizes allocative efficiency with a peer-to-peer trade ratio of 0.6, the fully decentralized approach (DTDE) demonstrates superior physical stability. Specifically, DTDE reduces the variance of grid balance by 31% compared to hybrid architectures, establishing a highly predictable, import-biased load profile that simplifies grid regulation. Furthermore, topological analysis reveals emergent spatial clustering, where decentralized agents self-organize into stable trading communities to minimize congestion penalties. While SAC excelled in hybrid settings, it failed in decentralized environments due to entropy-driven instability. This research proves that stigmergic signaling provides sufficient context for complex grid coordination, offering a robust, privacy-preserving alternative to expensive centralized communication infrastructure. Comments: 42 pages, 7 figures, 10 tables Subjects: Systems and Control (eess.SY) ; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Applications (stat.AP) Cite as: arXiv:2602.16062 [eess.SY] (or arXiv:2602.16062v1 [eess.SY] for this version) https://doi.org/10.48550/arXiv.2602.16062 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Nelson Salazar-Peña [ view email ] [v1] Tue, 17 Feb 2026 22:22:32 UTC (506 KB) Full-text links: Access Paper: View a PDF of the paper titled Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets, by Nelson Salazar-Pena and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SY &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CE cs.LG cs.MA cs.SY eess stat stat.AP References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-136">69. 内外兼修 尼康Z f详细评测_器材_色影无忌</h2>
<ul>
<li>链接：https://info.xitek.com/allpage/reviews/202310/19-365388.html</li>
<li>来源：bing</li>
<li>摘要：2023年10月19日 · 尼康早在2013年发布过一款复古造型的全幅数码单反Df。进入无反时代后，复古风并未消散，尼康在2021年6月推出了一款复古机身设计的APS-C画幅无反相机Zfc。自Zfc上市以来，期 …</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-137">正文（抓取，非 AI）</h3>
<p>内外兼修 尼康Z f详细评测_器材_色影无忌 器材 影像 行色 她影像 摄影论坛 二手论坛 图片论坛 新锐摄影奖 无忌游 无忌客户端 多色·dosnap 无忌学院 分享 登录 | 注册 注销 动态 烧机 观点 评测 图赏 器材库 专题 推荐 论坛 首页 器材频道 评测 &gt; 内外兼修 尼康Z f详细评测 内外兼修 尼康Z f详细评测 色影无忌 梁爽 梁爽 2023-10-19 尼康早在2013年发布过一款复古造型的全幅数码单反D f。进入无反时代后，复古风并未消散，尼康在2021年6月推出了一款复古机身设计的APS-C画幅无反相机Z fc。自Z fc上市以来，期待推出全画幅复古造型相机的呼声不断，为了应对这一需求，尼康在今年9月正式发布全画幅复古设计无反相机Z f。 Z f是Z fc之后Z系列第二款经典胶片相机造型的产品。与D f、Z fc不同，尼康宣称Z f是一款平衡了经典尼康胶片相机的传统设计与创新的高级性能的数码相机。简单来讲，Z f是一款内外兼修而非单靠“颜值”的相机，它在性能上继承了EXPEED 7影像处理器和高端机型的先进功能。那么同为约2450万有效像素的相机，Z f在性能上与Z 6Ⅱ相比有什么提升？下面我们先看看两款相机的纸面参数对比： 规格对比（点击查看大图） 从规格对比来看，虽然Z f可能与Z 6Ⅱ 采用相同的背照式CMOS，但搭载了与Z 8、Z 9相同的EXPEED 7影像处理器，这使得Z f在性能上得到一系列提升，其中对焦性能最为突出，还具备更好的跟踪性能，支持3D跟踪、提供9种类型的对象侦测、AF侦测下限扩展至-10EV等。此外，尼康改进了基于AI图像分析的检测算法，Z f的相机内防抖效果可实现Z系列中最高的相当于约8档快门速度的提升。功能上，Z f还引入了对焦点VR减震、像素变化拍摄等“独占”新功能。 整体外观 Z fc与Z f正面对比 Z f的外观设计与Z fc相似，都是传承自FM2。除了 FM2 外形设计，尼康还延用了20世纪七、八十年代相机上使用的尼康徽标，突出了造型的经典。与Z fc相比，Z f机身尺寸大了一圈（约144 x 103 x 49 mm VS 约134.5 x 93.5 x 43.5mm），重量也有了明显增加（约710g VS约445g）。也就是说Z f重量与有宽大手柄的Z 6Ⅱ/Z 7Ⅱ相近。握持手感上，虽然Z f正面比Z fc多了一个凸起的小握柄，但机身本身较重，小握柄帮助并不大，在意这点的用户需要购买第三方手柄。 之所以增重，是因为Z fc发售后很多用户反馈机身存在塑料感明显、轻飘、没有质感的问题。为此Z f着重呈现高品质感，机身前盖和顶盖采用镁合金。快门速度/曝光补偿/ISO感光度拨盘、快门释放按钮和电源开关均追求操作感，选择黄铜切割加工制成。每个拨盘的转动声和手感也都经过反复测试和调整。 Z fc与Z f背面对比 与Z fc相比，Z f改进了压花人造革的质感和外观，扩大了人造革覆盖区域，比如翻转屏背面也得到覆盖，这让Z f在选择其他配色时此处颜色也能随之改变。总而言之，Z f在细节方面比Z fc做的要好很多。 同尼康Z fc一样，除了基本黑色机身外，还提供6种颜色可选，相机的压花人造革部分（覆盖手柄和可翻转显示屏背面的区域）提供3种标准颜色（靛青蓝、茶褐棕、赤枣红）和3种自然色彩（落日橘、青苔绿、岩石灰），采用各自匹配的表面纹理。 细节设计 前文谈到Z f在设计上与Z fc类似，下面重点谈谈两者按键拨盘方面的差异。相机左肩的ISO感光度拨盘上，尼康取消了H1、H2扩展感光度档位，改为“C”档，其功能与Z fc曝光补偿拨盘的C档类似，感光度拨盘转到C档，可以在菜单/i菜单设定某ISO值（可触控操作）。如果要开启自动ISO感光度，还是需要进入菜单，笔者希望未来可以自定义C档为自动ISO感光度。Z f机内设置为自动ISO后，与D f、Z fc一样，转动感光度拨盘是调节自动感光度下限。需要注意的是，这款相机拍照模式下扩展感光度是以ISO64000为基础增加，并非常见的ISO51200，最高Hi1.7相当于ISO204800。 ISO感光度拨盘下层是曝光模式拨盘，可在M、A、S、P、AUTO之间自由切换。Z f借助深度学习，AUTO全自动曝光模式变得更加智能，可以识别各种情况，并根据拍摄对象类型和拍摄状况，适当控制光圈、ISO感光度和快门速度。比如半身人像增大光圈虚化背景、多人合影缩小光圈呈现背景。 Z f右肩布局与Z fc一致，有快门速度拨盘、照片/视频切换拨杆、快门按钮、电源开关、视频录制按钮、曝光补偿拨盘。与Z fc的快门设计不同，Z f的快门有螺纹插孔，然而该孔仅能安装装饰快门按钮，并不能使用机械快门线。 Z f在照片/视频切换上增加了B&amp;W黑白照片模式，用户可以转到该档开启黑白摄影，相机提供单色、平面单色、深色调单色三种黑白。 接口方面，Z f与Z fc略有不同，除了D型HDMI端口、C型USB端口、外置麦克风插孔，Z f新增了3.5mm耳机插孔可用于监听。 存储方面，Z f与Z fc不同，Z f提供SD卡（（兼容UHS-II））和microSD卡（兼容UHS-I双存储卡插槽。我们可以看到SD卡槽和电池仓之间空间很小，之所以增加1个microSD卡插槽，尼康希望在不增加相机尺寸的情况下，为拍摄提供额外的安全保障。这样，可以使用第2张卡作为长时间拍摄时的额外存储容量，或作为图像数据的实时备份使用。 续航方面，Z f与Z fc不同，而是与Z 6Ⅱ/Z 7Ⅱ/Z 8一样采用EN-EL15c锂离子充电电池，这款电池在Z系列中广泛应用。Z f与Z 6Ⅱ等Z系列相机一样，USB支持供电，关机时可为电池充电，开机时则为相机供电。 菜单功能 菜单界面和功能设置上继承了Z 8、Z fc诸多亮点，下面重点谈谈几个新功能： 1.三种单色模式 前文谈到平Z f提供单色（MC）、平面单色（FM）、深色调单色（DM）三种黑白模式，其中后两者是新增的。 单色（MC） 平面单色（FM） 深色调单色（DM） 从实拍来看MC单色是以往尼康相机都具备黑白模式，平面单色（FM） 就像彩色“平面”模式的黑白版，低对比度画面，可以最大程度保留画面的动态范围，暗部和高光有更多细节；深色调单色（DM）与平面单色（FM）相反，可以理解为高反差黑白，画面对比度很大。 2.对焦点VR减震 Z f全球首次引入对焦点VR减震，传统的减震主要是为了减少图像中心区域的模糊，而对焦点VR减震可以减轻所选对焦点周围的模糊，无论焦点位于画面中的哪个位置。这样用户可以自由地按照设想的方式构图。 此外，Z f改进了基于AI图像分析的检测算法，机内减震效果可以实现Z系列中最高的相当于约8档的快门速度的提升。为此笔者用Z f搭配尼克尔Z 85mm f/1.8 S 镜头，用中央区域靠边焦点拍摄包装文字查看防抖效果： 1/20s与1/10s（点击查看大图） 1/5s与1/2.5s（点击查看大图） 从实拍来看，对焦点VR减震有点像“点测联动”，中央区域靠边焦点拍摄包装盒的文字，即使1/5s也可以大概率拍摄清晰，而将快门降至1/2.5s则有较小概率可以拍到清晰画面。我们可以看到防抖确实起到明显作用，然而要想实现约8档防抖效果，可能需要搭配相应的镜头（比如Z 24-120mm f/4 S）。 3.像素变化拍摄 尼康Z f新增像素变化拍摄功能，用户能以更高的分辨率和还原度进行拍摄，同时减少摩尔纹、假色和噪点。通过在4、8、16或32张图像之间移动影像传感器的位置，Z f可以获得更准确的色彩信息。增加拍摄张数可增强效果，16张或32张可创建约9,600万像素的高分辨率图像。需要注意的是该模式只能拍摄RAW文件，机内不能合成，需要可以使用“尼康工坊”软件（1.5以上版本）来合并拍摄的RAW图像，最终可生成NEFX文件（尼康工坊和ACR 16.0支持编辑）。 像素变化拍摄原理 1张直出 VS 8张合成（均为2400万像素）（点击查看大图） 8张合成 VS 4张合成（均为2400万像素）（点击查看大图） 8张合成（2400万像素 200%） VS 16张合成（均为9600万像素）（点击查看大图） 32张合成 VS 16张合成（均为9600万像素）（点击查看大图） 从实拍来看，单张与8张合成对比，虽然像素还是2400万，但可以看到锐度有一点提升，同时色彩有一定差异，多张合成可以获得更多色彩信息；4张和8张合成图像均为2400万像素，官方称8张相对4张主要是减少噪点，光线充足的环境拍摄，笔者觉得两者画面基本没有差异；16张和32张均可合成9600万像素的高分辨率图像，32张和16张之间的差异主要是32张可以减少画面噪点，如果在光线充足的环境下两者画质基本没有差异。实际上要想提高画面尺寸（像素），8张到16张变化最为明显，8张200%下出现锯齿、细节损失，与16张（100%）存在差距，而8张相对4张、32张相对16张在清晰度上提升并不大，但更多张采样堆栈可以降低摩尔纹、伪色等干扰。未来希望能将该功能引入到高像素机型上（Z9/Z8/Z7系列），机内可以合成JPG/HEIF，实际拍摄应用将更方便。 4.手动对焦支持对象侦测功能 手动对焦时可以侦测到眼部 尼康考虑到Z f搭配手动对焦镜头拍摄的场景较多。由于搭载EXPEED 7影像处理器和运用了深度学习技术，Z f能够在手动对焦中使用眼睛或脸部侦测等对象检测功能。用户还可以利用此功能放大屏幕上的眼睛区域来帮助调整对焦点。通常这个过程会很耗时，对于采用电子接点的手动对焦镜头，还可以使用对焦辅助装置，以进一步方便对焦。 RAW高感画质测试 Z f与Z 6Ⅱ搭载相同的约2450万背照式CMOS传感器，但由于Z f搭载了EXPEED 7影像处理器，可提供从ISO100- 64000的标准感光度范围（Z 6Ⅱ为ISO 51200），向上可扩展至Hi 1.7 (相当于ISO204800)。为了检验这款相机的高感表现和降噪算法，我们用Z f、Z 6Ⅱ与Z 85mm f/1.8 S搭配进行拍摄，设置为RAW+JPG、矩阵测光、3400K白平衡、焦距85mm、光圈f/8.0。Adobe Camera Raw 16将RAW关闭降噪转JPG比较。下面我们先看两款相机RAW对比（本次评测Z f为固件1.0 SAMPLE工程样机，测试结果仅供参考）： 左：Z 6Ⅱ 右：Z f ISO100（点击查看大图） ISO200（点击查看大图） ISO400（点击查看大图） ISO800（点击查看大图） ISO1600（点击查看大图） ISO3200（点击查看大图） ISO6400（点击查看大图） ISO12800（点击查看大图） ISO25600（点击查看大图） ISO51200（点击查看大图） 从测试结果来看，同曝光设置下Z f画面要比Z 6Ⅱ暗一点，两者噪点表现大体相当。ISO400以下Z f的RAW画面比较干净，没有明显噪点；上升至ISO800时Z f的RAW开始出现非常轻微的噪点（参看蓝色接口）；ISO上升至1600时，Z f的RAW画面噪点开始增多，有少量彩色噪点；ISO3200-ISO6400时，画面上彩色噪点进一步明显；ISO12800时，Z f的RAW画面有明显彩色噪点，暗部并未出现变色；ISO25600-51200上Z f彩色噪点非常严重，至于更高ISO的扩展感光度笔者认为实用价值不高。 JPEG高感画质测试 为了验证Z f的EXPEED 7影像处理器降噪算法，笔者对比了两款相机直出JPEG（标准降噪）各级ISO画质表现： 左：Z 6Ⅱ 右：Z f ISO100（点击查看大图） ISO200（点击查看大图） ISO400（点击查看大图） ISO800（点击查看大图） ISO1600（点击查看大图） ISO3200（点击查看大图） ISO6400（点击查看大图） ISO12800（点击查看大图） ISO25600（点击查看大图） ISO51200（点击查看大图） 从实拍来看，两者在降噪表现上并没有明显差异，ISO6400开始介入明显降噪涂抹，蓝色接口上的灰尘、毛丝已经“消失不见”，ISO25600降噪进一步加强，黑色元器件上的文字变得模糊，上升至ISO51200,黑色元器件的文字已经被彻底涂抹。 低感宽容度测试 至于宽容度，此前测试的Z 6Ⅱ有较好的表现，像素相当的Z f又会有怎么样的表现呢？本次测试笔者采用“暴力还原”的测试方法，相机使用ISO100、F8光圈，在正常曝光基础上分别进行+3、+2、+1、-1、-2、-3，-4，-5曝光补偿，如此得到过曝、欠曝严重的RAW照片，放到解RAW软件中，将曝光向相反的程度进行还原（关闭降噪）。本文采用Adobe Camera Raw 16关闭降噪解文件。（本次测试为工程样机仅供参考） 左：Z 6Ⅱ 右：Z f +1过曝拉回（点击查看大图） +2过曝拉回（点击查看大图） +3过曝拉回（点击查看大图） 从“暴力”测试来看，+1、+2过曝情况下，Z f可以拉回绝大多数细节。+3过曝下，我们可以看到Z f同等曝光画面比Z 6Ⅱ更暗一点这时更有优势，过曝情况下能拉回更多高光细节。 -1欠曝拉回（点击查看大图） -2欠曝拉回（点击查看大图） -3欠曝拉回（点击查看大图） -4欠曝拉回（点击查看大图） -5欠曝拉回（点击查看大图） 再看欠曝还原，-1、-2档Z f基本能做到完好的还原；-3EV画面开始粗糙，出现轻微噪点（参看蓝色接口部分）；将欠曝拉低到-4档时，蓝色接口部分出现彩色噪点；-5档时，蓝色接口部分彩色噪点更加明显。 追焦测试 Z f与Z 9、Z 8搭载相同的EXPEED 7影像处理器，在连拍和对焦上得到明显提升。 连拍方面，Z f像Z 8/Z 9一样，在H<em>（高速连拍 延长）之上增加C30模式（高速画面捕捉+），Z f凭借EXPEED 7影像处理器的高处理能力，实现高达约30张/秒连拍速度。然而C30模式文件格式固定为JPEG [标准]。而H</em>下不限制拍摄文件格式，提供约14张/秒的高速连拍，单就连拍速度与Z 6Ⅱ相当。值得注意的是Z 6Ⅱ的14张/秒，仅限单点AF，而Z f的AF区域模式不受限制。 对焦方面，Z f相比Z 6Ⅱ自动区域AF覆盖范围更广、更准确，可覆盖画面垂直方向约89%、水平方向约96%的区域，Z 6Ⅱ是垂直和水平方向均为约80%；自动区域AF的AF点从Z 6Ⅱ的81个提升至299个；拍照模式下自定义宽区从20种提升至77种，视频下则从12种提高到66种。除此之外，Z f低光照AF下限可达-10EV，相比之下Z 6Ⅱ不开启低光照AF是-7.5EV，开启后为-9.5EV。 与Ｚ８相同有单独的“飞机”识别 当然Z f的深度学习技术支持更好自动对焦对象侦测，新处理器实现快速的数据处理，提高各种场景下的跟踪性能。Z f能识别并自动检测和跟踪9种主体类型，包括人（眼睛、脸部、头部、上半身）、狗、猫、鸟、汽车、摩托车、自行车、火车和飞机，无需更改设置。相比之下，Z 6Ⅱ仅支持人、动物（狗/猫）。 下面笔者实测自动区域AF和3D跟踪模式下对人物的追踪效果： Z f人物追焦测试视频 从实测来看，自动区域AF下可以很好追踪运动中的人物，当人物走出取景范围后，较大面积焦点会在人物出框附近，当人物再次进入画面时，能够较为顺利捕捉到人物并进行追踪；3D跟踪与自动区域AF不同，该模式有起始焦点，半按后起始点跟踪人物，并进一步侦测识别头部、脸部或者眼部，当人物出框时，起始点会对到远处背景，当人物再次进入画面时，起始点由于覆盖面积比较小，并不能及时跟上人物，到画面中央区域才能“锁定”。两种模式在取景器画面内的追踪效果基本一致，如果会有人物出入画面的情况，自动区域AF的表现会更好一些。综上所述，Z f是明显好于Z 6Ⅱ、Z 7Ⅱ等老机型。 4K超清视频功能 Z f的视频规格与Z 6Ⅱ类似，支持全画幅6K图像数据超采样的4K 30p/25p/24p和DX裁切模式下4K 60p视频录制。区别在于，Z f支持内录N-Log和10位H.265。 4K 30p画面视角 4K 60p画面视角 4K 30p与4K 60p 100%画面对比（点击查看大图） 从实拍来看4K 60p的画面视角明显要窄很多，一些用户可以利用这一特点“赚长焦”。画质方面，4K 30p/25p/24p 均是超采样的，清晰锐利，没有差异。4K 60p虽然能够放大画面，但由于并非超采样，建筑的格栅部分出现了摩尔纹。 此外，尼康方面称Z f支持长时间视频录制，相机可以持续录制长达约125的分钟的4K超高清视频（H.265 8位(MOV)，[自动温度切断]：[高]）。考虑到本次测试使用的是工程机，夏天高温情况下，长时间视频录制还是会受到影响。 实拍样张 评测总结 Z f中 F的含义与D f相同，取自“融合（Fusion）”，代表精密仪器感和高画质的 "融合"。通过前文的评测，我们可以看到Z f与Df、Z fc不同，在复古设计的同时尼康意识到相机性能也很重要，在设计和性能上比起“前辈”更加平衡。抛开Z f的“颜值”不谈，单就性能上未来Z 6 Ⅲ如果不搭载新CMOS，升级幅度恐怕就是Z f的水平。 Z f目前最大的问题有三点，第一是机身较为厚重，小手柄握持手感不佳，需要另购第三方外接手柄；第二是机身存在发热，当然并不影响正常拍照；第三是Z镜头群中并没有多少造型搭配的镜头。如果能接受以上三点，且非常喜欢复古造型，还是可以考虑入手的。Z f定价13799元与当年Z 6Ⅱ发售相当，目前比在售的Z 6Ⅱ价格贵不到3000元，考虑到颜值和性能的双升级，以及EXPEED 7新处理器的未来固件升级潜力，Z f在Z系列产品线中还是有一定性价比的。未来希望尼康能把“Z f”做成Z数字系列之外一条复古产品线，胶片时代经典的旁轴相机（比如Nikon SP、Nikon S2）也可以作为无反相机外观设计的灵感。 优点： 1.拥有源自FM2的经典单反造型 2.搭载EXPEED 7处理器，处理器能力更强 3.支持3D跟踪和可侦测9种拍摄对象 4.AF侦测下限扩展至-10EV 5.侧开翻转屏，方便用户自拍 6.支持像素变化拍摄 7.支持对焦点VR减震，防抖可达8档效果 8.手动对焦支持对象侦测 9.具备独立B&amp;W黑白模式 缺点： 1.机身较重 握持手感不佳 2.机身背面没有摇杆 3.卡口旁Fn按钮容易误触 （默认设置白平衡） 4.机身容易发热 5.Z卡口复古造型镜头少 分页阅读 尼康(4730) 全画幅(1859) ZF(37) 复古(183) 无反相机(183) 分享 99 赞 朕知道了～ 99 呵呵 玩打地鼠呢？ 大家都在看 大家都在聊 No.76 期 无忌花园 花开朋友来 &amp; 欢聚一堂抒情怀(续)(续)(续)(续)(续)(续)(续) 3751 808 我要回复 草田集---我的日常记录（16）（祝各位影友新年快乐！身体健康！） 1336 526 我要回复 ★在无忌的日子里★（四） 1722 241 我要回复 --【随意影像】一直走一直拍 538 19 我要回复 手机的拍照功能真的不错了 446 10 我要回复 有喜欢拍火车站的吗 435 8 我要回复 2026年第1-6周中国运动相机（含全景、可穿戴系列）线上零售市场品牌销量排行榜 2026.02.14 大疆公布2026春节服务计划：线下快换升级，线上客服延时至24点 2026.02.14 思锐将亮相2026日本CP+摄影器材展 2026.02.14 影石营收近百亿创新高，核心新品Luna上半年上市 2026.02.14 体验报告｜适马ART 50mm F1.2 DG DN：实至名归的人像镜皇 2026.02.14 体验报告｜适马ART 35mm F1.2 DG II：漫展人像“速通”神器 2026.02.13 猜你喜欢 品牌 新锐摄影奖 她影像 无忌游 多色·dosnap 关于我们 色影无忌 法律顾问 网站声明 加入无忌 联系我们 网站地图 友情链接 关注我们 300K+ 400K+ 互联网违法和不良信息在线举报← 网站举报电话：0771-2094586 ｜ 网站举报邮箱：webmaster@xitek.com 版权所有 2000-2026 色影无忌 ｜ 桂公网安备 45010302000233号 网站备案/许可证号 桂B2-20040025-1 互联网站备案通告</p>
</div></details><h2 id="toc-138">70. 大模型优化利器：RLHF之PPO、DPO</h2>
<ul>
<li>链接：https://www.zhihu.com/tardis/bd/art/717010380</li>
<li>来源：bing</li>
<li>摘要：2025年9月26日 · 其中， 表示需要优化的目标函数。 为了保证分布 和 不要相差太多，PPO 使用KL 散度来约束 和 ，使之更加相似，表示如下： 公式（23）就是 PPO 最终的优化目标。 DPO …</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-139">正文（抓取，非 AI）</h3>
<p>打个小广告 ☻，知乎专栏 《大模型前沿应用》 的内容已经收录在新书 《揭秘大模型：从原理到实战》 中。感兴趣的朋友可以购买，多谢支持！♥♥ 与有 SFT 相比，强化学习能够给大语言模型带什么哪些好处呢？ 针对这个问题，2023 年 4 月 OpenAI 联合创始人 John Schulman 在 Berkeley EECS 会议上所做的报告《Reinforcement Learning from Human Feedback: Progress and Challenges》，分享了 OpenAI 在 RLHF 的进展，分析了监督学习和强化学习各自存在的挑战。 强化学习在大语言模型上的重要作用可以概括为以下几个方面： 强化学习比 SFT 更可以考虑整体影响 ：SFT 针对单个 token 进行反馈，其目标是要求模型针对给定的输入给出的确切答案。而强化学习是针对整个输出文本进行反馈，并不针对特定的 token。这种反馈粒度的不同，使得强化学习更适合大语言模型，既可以兼顾表达多样性，还可以增强对微小变化的敏感性。自然语言十分灵活，可以用多种不同的方式表达相同的语义。而有监督学习很难支持上述学习方式。 强化学习更容易解决幻觉问题 ：用户在大语言模型时主要有三类输入：（a）文本型：用户输入相关文本和问题，让模型基于所提供的文本生成答案；（b）求知型：用户仅提出问题，模型根据内在知识提供真实回答；（c）创造型（Creative）：用户为提供问题或说明，让模型进行创造性输出。SFT 非常容易使得求知型 query 产生幻觉。在模型并不包含或者知道答案的情况下，SFT 仍然会促使模型给出答案。而使用强化学习方法，则可以通过定制奖励函数，将正确答案赋予非常高的分数，放弃回答的答案赋予中低分数，不正确的答案赋予非常高的负分，使得模型学会依赖内部知识选择放弃回答，从而在一定程度上缓解模型幻觉问题。 强化学习可以更好的解决多轮对话奖励累积问题 ：多轮对话能力是大语言模型重要的基础能力之一，多轮对话是否达成最终目标，需要考虑多次交互过程的整体情况，因此很难使用 SFT 方法构建。而使用强化学习方法，可以通过构建奖励函数，将当前输出考虑整个对话的背景和连贯性。 正是因为强化学习具有这些优点，它在大模型方面被广泛应用。本文我们就来介绍一下这一强有力的技术。 RLHF 强化学习（Reinforcement Learning，RL）研究的问题是智能体（Agent）与环境（Environment） 交互的问题，其目标是使智能体在复杂且不确定的环境中最大化奖励（Reward）。强化学习基本框架如图 1 所示，主要由两部分组成：智能体和环境。在强化学习过程中，智能体与环境不断交互。 图 1 强化学习基本框架 智能体在环境中获取某个状态后，会根据该状态输出一个动作（Action），也称为决策（Decision）。 动作会在环境中执行，环境会根据智能体采取的动作，给出下一个状态以及当前动作所带来的奖励。智能体的目标就是尽可能多地从环境中获取奖励。 以图 1 为例，智能体与环境的交互过程如下： 在 时刻，环境的状态为 ，到达这一状态所获得的奖励为 智能体观测到 与 ，采取相应动作 智能体采取 后，环境状态变为 ，得到相应的奖励 智能体在这个过程中不断学习，它的最终目标是： 找到一个策略，这个策略根据当前观测到的环境状态和奖励反馈，来选择最佳的动作。 在给定的环境中，有效动作的集合经常被称为动作空间（Action Space），使用 进行表示。 策略是智能体的动作模型，决定了智能体的动作。策略也可以用函数进行表示，该函数将输入的状态变成动作。策略可分为两种：随机性策略和确定性策。 随机性策略 （Stochastic Policy）用 函数表示，即 ，输入一个状态 ，输出一个概率，表示智能体所有动作的概率。利用这个概率分布进行采样，就可以得到智能体将采取的动作。 确定性策略 （Deterministic Policy）是智能体直接采取最有可能的动作，即 。 价值函数 的值是对未来奖励的预测，可以用它来评估状态的好坏。价值函数可以只根据当前的状态 决定，使用 表示。也可以根据当前状态 以及动作 表示，使用 表示。 和 的具体定义如下： 其中， 为折扣因子（Discount Factor），针对短期奖励和远期奖励进行折中；期望 的下标为 函数，其值反映在使用策略 时所能获得的奖励值。 RLHF 主要分为 奖励模型训练 和 近端策略优化 两个步骤。奖励模型通过由人类反馈标注的偏好数据来学习人类的偏好，判断模型回复的有用性以及保证内容的无害性。奖励模型模拟了人类的偏好信息，能够不断地为模型的训练提供奖励信号。在获得奖励模型后，需要借助强化学习对语言模型继续进行微调。OpenAI 在大多数任务中使用的强化学习算法都是近端策略优化算法（Proximal Policy Optimization, PPO）。近端策略优化可以根据奖励模型获得的反馈优化模型，通过不断的迭代，让模型探索和发现更符合人类偏好的回复策略。PPO 的流程如图 2 所示。 图 2 PPO 算法实施流程 PPO 涉及到四个模型： （1） 策略模型 （Policy Model），生成模型回复。 （2） 奖励模型 （Reward Model），输出奖励分数来评估回复质量的好坏。 （3） 评论模型 （Critic Model），来预测回复的好坏，可以在训练过程中实时调整模型，选择对未来累积收益最大的行为。 （4） 参考模型 （Reference Model）提供了一个 SFT 模型的备份，帮助模型不会出现过于极端的变化。 PPO 的实施流程如下： (1) 环境采样：Policy Model 基于给定输入生成一系列的回复，Reward Model 则对这些回复进行打分获得奖励。 (2) 优势估计：利用 Critic Model，预测生成回复的 未来累积奖励 ，并借助广义优势估计（Generalized Advantage Estimation，GAE）算法来估计优势函数，能够有助于更准确地评估每次行动的好处。 (3) 优化调整：使用优势函数来优化和调整 Policy Model，同时利用 Reference Model 确保更新的策略不会有太大的变化，从而维持模型的稳定性。 下图详细展示了 PPO 的整个流程： 图3：PPO 训练流程 奖励模型（Reward Model） 基于人类反馈训练的 Reward Model 可以很好的评估人类的偏好。从理论上来说，可以通过强化学习使用人类标注的反馈数据直接对模型进行微调。然而，受限于工作量和时间的限制，针对每次优化迭代，人类很难提供足够的反馈。更为有效的方法是构建 Reward Model，模拟人类的评估过程。Reward Model 在强化学习中起着至关重要的作用，它决定了智能体如何从与环境的交互中学习并优化策略，以实现预定的任务目标。 Reward Model 的输入是包含 chosen 和 rejected 的 pair 对，如下图所示。 图4：Reward Model 输入 Reward Model 通常也采用基于 Transformer 架构的预训练语言模型。在 Reward Model 中，移除最后一个非嵌入层，并在最终的 Transformer 层上叠加了一个额外的线性层。无论输入的是何种文本，Reward Model 都能为文本序列中的最后一个 token 分配一个标量奖励值，样本质量越高，奖励值越大。 Reward Model 的损失定义如下： 其中 是 sigmoid 函数， 代表参数为 的奖励模型的值， 表示针对输入提示 和输出 所预测出的单一标量奖励值。 PPO 近端策略优化（ Proximal Policy Optimization, PPO ）是对强化学习中策略梯度方法的改进，可以解决传统的策略梯度方法中存在的高方差、低数据效率、易发散等问题，从而提高了强化学习算法的可靠性和适用性。PPO 在各种基准任务中取得了非常好的性能，并且在机器人控制、自动驾驶、游戏玩家等领域中都有广泛的应用。OpenAI 在多个使用强化学习任务中都采用该方法，并将该方法成功应用于微调语言模型使之遵循人类指令和符合人类偏好。 策略梯度 策略梯度方法有三个基本组成部分：演员（Actor）、环境和奖励函数，如下图所示，Actor 可以采取各种可能的动作与环境交互，在交互的过程中环境会依据当前环境状态和 Actor 的动作给出相应的奖励（Reward），并修改自身状态。Actor 的目的就在于调整策略（Policy），即根据环境信息决定采取什么动作以最大化奖励。 图 5 Actor 与环境交互过程 上述过程可以形式化的表示为：设环境的状态为 ，Actor 的策略函数 是从环境状态 到动作 的映射，其中 是策略函数 的参数；奖励函数 为从环境状态和 Actor 动作到奖励值的映射。一次完整的交互过程如图 5 所示。 图 6 Actor 与环境交互过程 环境初始状态为 ，Actor 依据初始状态 采取动作 ，奖励函数依据 给出奖励 ，环境接受动作 的影响修改自身状态为 ，如此不断重复这一过程直到交互结束。在这一交互过程中，定义环境状态 和 Actor 动作 组成的序列为轨迹（Trajectory） : 给定策略函数参数 ，可以计算某条轨迹发生的概率 为： 其中， 是初始状态 发生的概率， 为给定状态 策略函数采取动作 的概率， 为给定当前状态 和动作 ，环境转移到状态 的概率。 给定轨迹 ，累计奖励为 。累计奖励称为 回报 （Return）。希望 Actor 在交互过程中回报总是尽可能多，但是回报并非是一个标量值，因为 Actor 采取哪一个动作 以及环境转移到哪一个状态 均以概率形式发生，因此轨迹 和对应回报 均为随机变量，只能计算回报的期望： 其中 表示使用参数为 的策略与环境交互的期望回报，轨迹 服从 的概率分布。 给定一条轨迹，回报总是固定的，因此只能调整策略函数参数 使得高回报的轨迹发生概率尽可能大，而低回报的轨迹发生概率尽可能小。为了优化参数 ，可以使用梯度上升方法，优化 使得期望回报 尽可能大： 观察上式可以注意到，只有 与 有关。考虑到 如公式 5 所示是多个概率值的连乘，难以进行梯度优化，因此将 转化为 的形式使之易于计算。 根据 ，带入公式 7 可得： 在上式基础上，将公式 5 带入 ，可以继续推导得到： 这里是对策略函数参数 求梯度，而 和 由环境决定，与策略函数参数 无关，因此这两项的梯度为 0。将上式带入公式 8 可得： 由于期望无法直接计算，因此在实践中，通常是从概率分布 中采样 条轨迹近似计算期望： 可以使用学习率为 的梯度上升方法优化策略参数 ，使之能够获得更高的回报： 为了解决训练过程中的不稳定问题，通常会在回报 上减去一个基线（baseline） ，使得这一项的期望为 0，这样在实际更新的时候概率值更新会有正有负，最终概率更新幅度之和大致为 0。从而避免因为某些动作没有被采样而动作概率下降的问题。回报的梯度如下所示： 其中 ，即回报的期望。这一项在实践中常用的计算方法是，在训练过程中记录历史 的均值用以估计回报的期望。 公式 (13) 中仍然存在另外一个问题值得考虑， 的权重始终为 ，这意味着在一条轨迹中所有的动作都具有同样的价值。然而从直觉上来看，一条轨迹中一般不会所有的动作都是好的，而是有些动作好，而另外一些动作差，然而这些动作目前却会以相同的方式更新概率，这也会造成训练的不稳定。因此有必要为每个动作赋予其所应得的奖励。考虑到交互过程中 Actor 采取某一动作只会对之后的状态产生影响，而不会对之前的有影响。因此，不必令每个动作的权重都为全部奖励之和 ，而只需要累计在当前动作之后的奖励之和 。 另一个直觉是，当前动作会对时间较近的状态影响大，时间较远的影响小。因此，在计算累计奖励的时候，对于未来较遥远的奖励应该予以折扣，即 。引入新的奖励之后，公式（13）中回报的梯度表示为： 公式（14）中的 反应了给定状态 下采取动作 的收益，该收益称为 动作价值 （Action Value），并用 表示。而 则是动作价值的期望。由于动作价值的期望与具体动作无关，因此这个期望也称为 状态价值 （State Value），并用 来表示。 即： 将状态-动作 的梯度权重抽象为 。给定状态 下， 衡量了具体动作 的价值，而 则表示 Actor 采取各种可能动作的期望价值。因此 可以理解为采取特定动作 相比较于随机一个动作的 优势 （Advantage）。 优势 越大，说明采取动作 要比其他可能动作更好，使用 来表示 优势函数 。 根据前面公式（10）和公式（12），策略梯度的基本形式如下： 实际计算时，需要从环境中采样很多轨迹 ，然后按照上述策略梯度公式对策略函数参数 进行更新。但是由于 是从概率分布 中采样得到，一旦策略函数参数 更新，那么概率分布 就会发生变化，因而之前采样过的轨迹便不能再次利用。所以策略梯度方法需要在不断地与环境交互中学习而不能利用历史数据。因而这种方法的训练效率低下。 策略梯度方法中，负责与环境交互的 Actor 与负责学习的 Actor 相同，这种训练方法被称为 On-Policy 训练方法。相反， Off-Policy 训练方法则将这两个 Actor 分离，固定一个 Actor 与环境交互而不更新它，而将交互得到的轨迹交由另外一个负责学习的 Actor 训练。Off-Policy 的优势是可以重复利用历史数据，从而提升训练效率。近端策略优化（Proximal Policy Optimization，PPO） 就是 Off-Policy。 假设负责学习的智能体策略为 ，负责采样的智能体策略为 。按照公式（16）计算 ，但由于 Off-Policy，不能从 中采样得到 ，只能从 中采样，因此可以对公式（16）进行修正： 回到前面讲的策略梯度的具体定义，如公式（14），并结合优势函数 ，可以将公式（14）策略梯度的计算改为如下形式： 结合公式（18），将其改写为如下形式： 此时优势函数从 变成 ，采样策略也从 变成 。 由于： 假设状态只与环境有关，与具体策略无关，那么 ，那么公式（20）可以改写为： 从上述式子的梯度形式反推原来的目标函数，可以得到如下公式： 其中， 表示需要优化的目标函数。 为了保证分布 和 不要相差太多，PPO 使用KL 散度来约束 和 ，使之更加相似，表示如下： 公式（23）就是 PPO 最终的优化目标。 DPO 前面我们详细介绍了 RLHF 的原理，整个过程略显复杂。首先需要训练好 Reward Model，然后在 PPO 阶段需要加载 4 个模型：Actor Model 、Reward Mode、Critic Model 和 Reference Model。对计算资源要求极高，而且训练时间长，对于一般人来说很难玩得起。 好在 2023 年 5 月，斯坦福大学提出了 PPO 的简化版： DPO（Direct Preference Optimization） 。只需要加载 2 个模型，而且不需要在线采样数据，极大地节省了训练开销。下图的右边是 DPO 的训练流程： 图 7：PPO 和 DPO 的区别 下面就简单介绍下 DPO 是如何简化 PPO 的。 首先回顾一下前面讲的 RLHF 是怎么训练的： 第一步是训练 Reward Model 。训练数据是同一个 prompt 的 2 个回答，让人或 GPT-4o 标注哪个回答更好，Reward Model 会去优化如下目标： 其中 就是 Reward Model 用来给回答打分。 是训练数据集， 是 prompt， 和 分别是好的回答和不好的回答。也就是说，要尽可能让好的回答的得分比不好的回答高，拉大他们之间的差别。 第二步是用 RL 算法来提升模型的得分 。优化的目标是： 其中 是我们需要训练的 LLM， 是 Reference Model。这个优化目标的是希望 LLM 输出的回答的评分能尽可能高，同时 不要偏离 太多。 DPO 的作者们意识到，后面的这个式子是有显式解的。因为： 如果我们归一化一下分母，即取 ，也就可以构造出一个新的概率分布： 那么上式变成了： 由于 KL 散度在 2 个分布相等时取最小值，我们得到了这样的结论：RLHF 训练希望得到的最优的概率分布就是 。 另一个角度来说，由 的公式，我们相当于是得到了 和 的关系，那么是否我们可以把训练 转化成直接去训练 呢？ 简单转换一下 的定义式，可以得到： 带入公式（25），也就有了： 同样的，我们可以直接用这个优化目标去求 ： 最终，我们可以得出 DPO 的 loss 如下所示： 这就是 DPO 的 loss。DPO 通过以上的公式转换把 RLHF 巧妙地转化为了 SFT，在训练的时候不再需要同时跑 4 个模型（Actor Model 、Reward Mode、Critic Model 和 Reference Model），而是只用跑 Actor 和 Reference 2 个模型。 DPO 变种 DPO 出来之后，由于其简单易用的特点，迅速成为大模型训练的标配，随后也出现了各种变种，比如 SimPO、Step-DPO、MCTS-DPO、SPO、Iterative-DPO。下面就以 Iterative-DPO 为例，介绍一下做了哪些改动。 Iterative-DPO Iterative Reasoning Preference Optimization 是 2024 年 Meta 提出的 DPO 改进版。 思路很简单，下面介绍下具体流程： 首先训练一个 Reward Model。 然后将训练数据分成 m 等份（比如 3 等份），取第一份数据，用 LLM 对每个 prompt 采样出 k 个答案，使用 Reward Model 对 k 个回答进行打分，选出得分最高的和最低的，构建成 pair 对。使用第一份 pair 对数据训练一轮 DPO，更新 LLM。 再取第二份数据，用 更新后的 LLM 对第二份数据的每个 prompt 采样出 k 个答案，使用 Reward Model 对 k 个回答进行打分，选出得分最高的和最低的，构建成 pair 对。使用 第二份 pair 对数据在更新后的 LLM 上训练一轮 DPO。 重复以上过程，直到 m 份数据全部训练完成。 下图是 Iterative-DPO 的具体流程： 图 7：Iterative-DPO 流程 由于 Iterative DPO 在每轮训练完成后，都会基于最新模型重新采样数据，构建 pair 对，因此 Iterative DPO 是介于 Online-Policy 和 Offline-Policy 之间。 下图是 Iterative DPO 的两阶段流程： 图 8： Iterative DPO 两阶段流程 总结 现今，强化学习已成为大型模型的标配技术，特别是随着 OpenAI O1 的发布，该技术作为其核心方法，掌握并熟练运用强化学习已成为不可或缺的技能。本文简要概述了 RLHF 的基础知识，并初步介绍了 PPO 和 DPO，待日后有机会，将进一步深入学习 PPO 的其他变体。 参考 DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales Secrets of RLHF in Large Language Models Part I: PPO Direct Preference Optimization: Your Language Model is Secretly a Reward Model Proximal Policy Optimization Algorithms 朱小霖：DPO 是如何简化 RLHF 的 infgrad：DPO: Direct Preference Optimization 论文解读及代码实践 RLHF Workflow: From Reward Modeling to Online RLHF 书籍：《大规模语言模型——从原理到实践》</p>
</div></details><h2 id="toc-140">71. 知乎盐选 | 7.2 谐振法测量元件参数</h2>
<ul>
<li>链接：https://www.zhihu.com/market/pub/120224308/manuscript/1414316577005629441</li>
<li>来源：bing</li>
<li>摘要：7.2 谐振法测量元件参数 谐振测试法是根据谐振回路的谐振特性建立起来的测量元件参数的方法，其基本电路如图 7-13 所示。它是由 LC 谐振回路、高频振荡电路和谐振指示电路 3 部分组成。振荡电路提 …</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-141">正文（抓取，非 AI）</h3>
<p>知乎盐选 | 7.2 谐振法测量元件参数 注册或登录 7.2 谐振法测量元件参数 7.2 谐振法测量元件参数 谐振测试法是根据谐振回路的谐振特性建立起来的测量元件参数的方法，其基本电路如图 7-13 所示。它是由 LC 谐振回路、高频振荡电路和谐振指示电路 3 部分组成。振荡电路提供高频信号，它与谐振回路之间的耦合程度应足够弱，使反映到谐振回路中的阻抗小到可以忽略不计。谐振指示器用来判别回路是否处于谐振状态，它可以用并联在回路两端的电压表或串联在回路中的电流表担任。同样要求谐振指示器的内阻对回路的影响小到可以忽略不计。 加载中... 图 7-13 谐振法的基本电路 7.2.1 电容量的测量 谐振法测电容量有直接法和替代法两种。 1．直接法 用直接法测试电容量的电路与图 7-13 所示的电路基本相同。选用一适当的标准电感 L 与被测电容 C x 组成谐振电路，调节高频振荡电路的频率，当电压表的读数达最大时，谐振回路达到串联谐振状态。这时振荡电路输出信号的频率 f 将等于测量回路的固有频率 f 0 ，即 加载中... 由此可求得电容 C x 值为 加载中... 式中，电容的单位是 F；频率的单位是 Hz；电感的单位是 H。若上述各量的单位分别用 pF、MHz、μH，则 C x 式可写为 加载中... 由于谐振频率 f 0 可由振荡电路的刻度盘读得，电感线圈的电感量是已知的，即可由式（7-19）计算被测电容量 C x 。 由直接法测得的电容量是有误差的，因为它的测试结果中包括了线圈的分布电容和引线电容，为了消除这些误差，宜改用替代法。 2．替代法 用替代法测试电容量有并联替代法和串联替代法两种。串联替代法和并联替代法采用替代原理，进行两次测试。被测元件接入前使电路谐振，被测元件接入已调谐好的电路后会使电路失谐，然后重新调整电路中的标准元件，以补偿（替代）被测元件造成的失谐。测量结果需计算后方能得到，这是一种间接测量的方法。 1）并联替代法 用并联替代法测试电容量的电路如图 7-14 所示。进行测试时，首先将标准可变电容器放在电容量很大的刻度位置 C S1 上，调节振荡电路的频率使串联谐振回路谐振。然后将被测电容器接在 C x 接线柱上，与标准可变电容器并联，振荡电路保持原来的频率不变，减小标准可变电容器的电容量到 C S2 ，使串联谐振回路恢复谐振。在这种情况下，有： 加载中... 图 7-14 并联替代法测量电容量 加载中... 即可求得被测电容 C x 的值为 加载中... 显然，并联替代法只能测电容量小于标准可变电容器变化范围内的电容器。由于通常标准可变电容器的电容量变化范围有限，例如，一个能从 500pF 变化到 40pF 的电容器的电容量变化范围为 0～460pF。按照上述测试方法，只能测试电容量小于 460pF 的电容。当被测电容量大于标准可变电容器的电容量变化范围时，则可根据被测电容量的估算数值选择一个适当容量的电容器作为辅助元件，再用上述方法进行测试。选择辅助电容器时，必须使已知辅助电容器的电容量与标准可变电容器的变化范围之和大于被测电容器的电容量。例如，用电容量变化范围为 460pF 的标准可变电容器来测被测电容量约为 680pF 的电容时，必须选择一个电容量大于 220pF 的已知电容作为辅助元件。 测试时，首先把已知电容接在 C x 接线柱上，标准可变电容器放在电容量所在的刻度位置 C S1 上，调节振荡电路的频率使串联谐振回路谐振。然后拆去 C x 接线柱上的已知电容，接上被测电容。振荡电路保持原来的频率不变。减小标准可变电容器的电容量到 C S2 ，使串联谐振回路恢复谐振。在这种情况下有 加载中... 即可求得被测电容 C x 的值为 加载中... 2）串联替代法 被测电容量大于标准可变电容器容量变化范围的另一种方法是串联替代法。使用串联替代法测电容的电路如图 7-15 所示。进行测试时，首先将标准可变电容放在电容量甚小的刻度位置 C S1 上，调节振荡电路的频率使串联谐振回路谐振。然后将被测电容串联在谐振回路中，振荡电路保持原来的频率不变，增加标准可变电容量到 C S2 ，使串联谐振回路恢复谐振。在这种情况下，有 加载中... 图 7-15 串联替代法测量电容量的电路 加载中... 即可测得被测电容 C x 的值为 加载中... 7.2.2 电感量的测量 1．直接法 在图 7-13 中若选用已知标准电容 C S 和被测电感 L x 组成谐振回路，按测试电容的同样方法，调节振荡电路的输出频率，使谐振回路达到谐振状态，由式 加载中... 可得被测电感 L x 的值为 加载中... 式中，电容的单位是 F，频率的单位是 Hz，电感的单位是 H。若上述各量的单位分别用 pF、MHz、μH，则式（7-26）可写为 加载中... 。式中 f 0 可由振荡电路的刻度盘读得， C S 可由标准可变电容器的刻度盘读得，由式（7-26）即可计算出被测电感量 L x 。 实际上按谐振法设置的测试仪器，测电感时为了能直接读数，通常是在某些指定的频率点上进行测试。由式 加载中... 可知，当 f 0 为定值时， L x 与 C S 成反比例关系，所以，在标准可变电容器 C S 的刻度盘上附加直读电感的刻度，就可以直接读出被测电感 L x 值，而无须计算。 用直接法测得的电感量是有误差的，因为实际上，公式 加载中... 中的电容值还包括线圈的分布电容和引线电容，而标准可变电容的刻度中不包括这两项电容值，测试结果为正误差，即测试值大于实际值。若要消除误差，应采用替代法。 2．替代法 与测电容一样，也有并联替代法和串联替代法两种。测小电感时用如图 7-16（a）所示的串联替代法，测大电感时用如图 7-16（b）所示的并联替代法。由于具体的测试方法与测电容的替代法相仿，不再赘述。 加载中... 图 7-16 用替代法测量电感量 （a）用串联替代法测量电容量；（b）用并联替代法测量电容量 7.2.3 品质因数（Q 值）的测量 利用谐振法测回路的品质因数（ Q 值），可采用电容变化法或频率变化法，两种测试方法均采用如图 7-13 所示的电路。 电容变化法是变化调谐回路中的电容量，使回路发生一定程度的失谐，从而求得回路的品质因数。根据回路谐振时可变电容器 C S 的读数 C S0 和回路两次失谐（谐振指示器指示下降到 70.7%）时可变电容器 C S 的读数为 C 1 、 C 2 ，即可按下式计算品质因数为 加载中... 频率变化法是改变高频振荡电路的振荡频率，使回路发生一定程度的失谐，从而求得回路的品质因数。根据回路谐振时振荡电路的频率数 f 0 和回路两次失谐（谐振指示器的指示下降到 70.7%）时振荡电路的频率读数 f 1 和 f 2 ，可计算品质因数为 加载中... 用电容变化法和频率变化法测回路的品质因数 Q 值，须经过几步操作和计算。 7.2.4 Q 表及其使用 1． Q 表的组成 根据谐振原理制成的一种能直接读出线圈 Q 值的测试仪器称为 Q 表。它是测高频电路元件参数的重要仪器。 Q 表除测线圈 Q 值这一基本用途以外，因为其中包含有谐振测试法所需用的各种设备，所以还可以用来进行其他项目的谐振法测试。如图 7-17 所示为 WY2853 型 Q 表。该表是测试频率为 0.7～100MHz 的高频阻抗测试仪器。特别适合对微电感的电感器和其他元件、部件的分布参数的高频特性测试。 加载中... 图 7-17 WY2853 型 Q 表 Q 表的基本原理如图 7-18 所示，被测线圈（视在参量为 L x 与 R x ）与 Q 表内部的一只标准可变电容器 C S 组成一个串联谐振回路；在标准可变电容器的两端跨接一只标准可变电容器 C S 组成一个串联谐振回路；并在标准可变电容器的两端跨接一只输入阻抗很高的电子电压表，作为谐振指示器；加在标准电阻 R 1 及 R 2 上的高频电压，由一个作为监视器的电子电压表测试，用以监视引入串联谐振回路的高频电压 U 1 的大小。 加载中... 图 7-18 Q 表的基本电路 调节可变高频振荡电路的频率或标准可变电容器的电容，使串联谐振回路谐振，此时并联在标准可变电容器上的电子电压表的指示最大。按照谐振回路的原理，最大电压 U 2 和输入回路的电压 U 1 之间关系 U 2 = QU 1 ，可得 最低 0.3 元/天开通会员，查看完整内容 {"name":"manuscript","status":200,"titleHTML":{},"metaHTML":{},"styleHTML":{},"forbiddenModeScript":"\u003cscript defer nonce=\"mnDpikxWcabNFrJm_E1T1\"&gt;\n function _0x1edf(_0x2e6a39,_0x4bcd1a){var _0x542b52=_0x542b();return _0x1edf=function(_0x1edf61,_0x4e7566){_0x1edf61=_0x1edf61-0xab;var _0x1f6a36=_0x542b52[_0x1edf61];return _0x1f6a36;},_0x1edf(_0x2e6a39,_0x4bcd1a);}var _0x15339f=_0x1edf;function _0x542b(){var _0x15876f=['6866916DkSIJe','10221820JlaQxF','%E5%BD%93%E5%89%8D%E9%A1%B5%E9%9D%A2%E5%86%85%E5%AE%B9%E4%B8%BA%E7%89%88%E6%9D%83%E4%BF%9D%E6%8A%A4%E5%86%85%E5%AE%B9%EF%BC%8C%E6%82%A8%E7%9A%84%E8%A1%8C%E4%B8%BA%E6%B6%89%E5%AB%8C%E8%BF%9D%E5%8F%8D%E7%9F%A5%E4%B9%8E%E5%8D%8F%E8%AE%AE%EF%BC%8C%E7%9B%B8%E5%85%B3%E8%B4%A6%E5%8F%B7%E6%9C%89%E8%A2%AB%E5%B0%81%E7%A6%81%E9%A3%8E%E9%99%A9','2632856THltSE','parentElement','removeChild','zhihu.com','\u003c/div&gt;','4664067qJFmtW','getElementById','4gHRMrs','createElement','40KPWcfH','852012idpNLJ','1McIQrn','2179458vftjUb','\u003cdiv style=\"margin: 130px auto;font-size: 30px;line-height: 55px;color: red;text-align: center;\"&gt;','3158485IogzJo','22Wdfejx','innerHTML'];_0x542b=function(){return _0x15876f;};return _0x542b();}(function(_0x57c3fc,_0x4b4fbe){var _0x48884a=_0x1edf,_0x2c6eec=_0x57c3fc();while(!![]){try{var _0x11dec1=parseInt(_0x48884a(0xb4))/0x1<em>(-parseInt(_0x48884a(0xbd))/0x2)+parseInt(_0x48884a(0xae))/0x3+-parseInt(_0x48884a(0xb0))/0x4</em>(-parseInt(_0x48884a(0xb7))/0x5)+parseInt(_0x48884a(0xb3))/0x6+-parseInt(_0x48884a(0xba))/0x7+parseInt(_0x48884a(0xb2))/0x8<em>(-parseInt(_0x48884a(0xb5))/0x9)+parseInt(_0x48884a(0xbb))/0xa</em>(parseInt(_0x48884a(0xb8))/0xb);if(_0x11dec1===_0x4b4fbe)break;else _0x2c6eec<a href="_0x2c6eec[" title="shift']());}catch(_0x376ed0){_0x2c6eec['push'](_0x2c6eec['shift']());}}}(_0x542b,0xd310e));if(window['location']['host']['indexOf'](_0x15339f(0xac))===-0x1){var rootDom=document[_0x15339f(0xaf)]('app">'push'</a>,text=_0x15339f(0xbc),forbiddenDom=document<a href="" title="div">_0x15339f(0xb1)</a>;forbiddenDom[_0x15339f(0xb9)]=_0x15339f(0xb6)+decodeURI(text)+_0x15339f(0xad),rootDom['parentElement']<a href="forbiddenDom">'appendChild'</a>,rootDom[_0x15339f(0xbe)]<a href="rootDom">_0x15339f(0xab)</a>;}\n \u003c/script&gt;","webPageReadyScript":"\u003cscript nonce=\"mnDpikxWcabNFrJm_E1T1\"&gt;window.zhihuNativeApp&amp;&amp;window.zhihuNativeApp.sendToNative&amp;&amp;window.zhihuNativeApp.sendToNative(JSON.stringify({module: 'market',action: 'FCPEnd',params: {}}))\u003c/script&gt;","viteScript":"","appContext":{"request":{"ip":"2409:8914:b7fc:399:9d9:6f20:7303:62bd","xRealIp":"2409:8914:b7fc:399:9d9:6f20:7303:62bd","headers":{"host":"www.zhihu.com"},"url":"/market/pub/120224308/manuscript/1414316577005629441","href":"https://www.zhihu.com/market/pub/120224308/manuscript/1414316577005629441","path":"/market/pub/120224308/manuscript/1414316577005629441","params":{"0":"manuscript","productType":"pub","productId":"120224308","manuscriptId":"1414316577005629441"},"query":{}},"deviceID":"","ua":{"Mobile":false,"Android":false,"Chrome":true,"iOS":false,"Wechat":false,"WorkWechat":false,"WechatMiniprogram":false,"Weibo":false,"QQ":false,"Zhihu":false,"ZhihuHybrid":false,"iPad":false,"UC":false,"QQBrowser":false,"BankABC":false,"BankABCNew":false,"AliPay":false,"YanYan":false,"ZhihuLite":false,"Harmony":false,"YanyanHarmonyOS":false,"origin":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"},"theme":"light","isOffice":false,"xAppZa":"","xAppVersion":"","xApiVersion":"","xNetworkType":"","xUDId":"","xZst81":"","zaeEnvType":"","commentCloseFlag":"0","globalSlienceMode":"","supportsWebp":false,"apiBaseDict":{"api-default":"https://api.zhihu.com","api-v4":"https://www.zhihu.com/api/v4","api-walletpay":"https://walletpay.zhihu.com","api-outside":"https://www.zhihu.com/api/vip"},"safeAreaInset":{},"clientId":"686379f9-befc-4739-9376-fc7c24a31c85","vipPrivilegesUrl":"https://www.zhihu.com/xen/market/vip-privileges","nonce":"mnDpikxWcabNFrJm_E1T1","ssrStage":"render","__connectedAutoFetch":{"manuscript":{"pending":false,"data":{"manuscriptData":{"truncate_text":"最低 0.3 元/天开通会员，查看完整内容","manuscript":"\u003ch2 class=\"secondTitle0\"&gt;7.2 谐振法测量元件参数\u003c/h2&gt;\u003cp class=\"content\"&gt;谐振测试法是根据谐振回路的谐振特性建立起来的测量元件参数的方法，其基本电路如图 7-13 所示。它是由\u003cspan class=\"italic\"&gt;LC\u003c/span&gt;谐振回路、高频振荡电路和谐振指示电路 3 部分组成。振荡电路提供高频信号，它与谐振回路之间的耦合程度应足够弱，使反映到谐振回路中的阻抗小到可以忽略不计。谐振指示器用来判别回路是否处于谐振状态，它可以用并联在回路两端的电压表或串联在回路中的电流表担任。同样要求谐振指示器的内阻对回路的影响小到可以忽略不计。\u003c/p&gt;\u003cdiv class=\"qrbodyPic\"&gt;\n\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic2.zhimg.com/v2-26c29e46678776cd8091f7712d2fe49c.jpg\"/&gt;\n\u003cp class=\"imgtitle\"&gt;图 7-13 谐振法的基本电路\u003c/p&gt;\n\u003c/div&gt;\u003ch3 class=\"thirdTitle sigil_not_in_toc\" id=\"bw1\"&gt;7.2.1 电容量的测量\u003c/h3&gt;\u003cp class=\"content\"&gt;谐振法测电容量有直接法和替代法两种。\u003c/p&gt;\u003cp class=\"content_102a\"&gt;1．直接法\u003c/p&gt;\u003cp class=\"content\"&gt;用直接法测试电容量的电路与图 7-13 所示的电路基本相同。选用一适当的标准电感\u003cspan class=\"italic\"&gt;L\u003c/span&gt;与被测电容\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;组成谐振电路，调节高频振荡电路的频率，当电压表的读数达最大时，谐振回路达到串联谐振状态。这时振荡电路输出信号的频率\u003cspan class=\"italic\"&gt;f\u003c/span&gt;将等于测量回路的固有频率\u003cspan class=\"italic\"&gt;f\u003c/span&gt;\u003cspan class=\"sub\"&gt;0\u003c/span&gt;，即\u003c/p&gt;\u003cdiv class=\"bodyPic\"&gt;\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic4.zhimg.com/v2-b406c5ddefe5bf48ee2776d97b8f307a.jpg\"/&gt;\u003c/div&gt;\u003cp class=\"content3\"&gt;由此可求得电容\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;值为\u003c/p&gt;\u003cdiv class=\"bodyPic\"&gt;\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic1.zhimg.com/v2-197b928dacc0df3dc058a4142c847deb.jpg\"/&gt;\u003c/div&gt;\u003cp class=\"content3\"&gt;式中，电容的单位是 F；频率的单位是 Hz；电感的单位是 H。若上述各量的单位分别用 pF、MHz、μH，则\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;式可写为\u003c/p&gt;\u003cdiv class=\"bodyPic\"&gt;\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic2.zhimg.com/v2-30dd3856e787a7a8fb6b04049dd81cd8.jpg\"/&gt;\u003c/div&gt;\u003cp class=\"content\"&gt;由于谐振频率\u003cspan class=\"italic\"&gt;f\u003c/span&gt;\u003cspan class=\"sub\"&gt;0\u003c/span&gt; 可由振荡电路的刻度盘读得，电感线圈的电感量是已知的，即可由式（7-19）计算被测电容量\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;。\u003c/p&gt;\u003cp class=\"content\"&gt;由直接法测得的电容量是有误差的，因为它的测试结果中包括了线圈的分布电容和引线电容，为了消除这些误差，宜改用替代法。\u003c/p&gt;\u003cp class=\"content_102a\"&gt;2．替代法\u003c/p&gt;\u003cp class=\"content\"&gt;用替代法测试电容量有并联替代法和串联替代法两种。串联替代法和并联替代法采用替代原理，进行两次测试。被测元件接入前使电路谐振，被测元件接入已调谐好的电路后会使电路失谐，然后重新调整电路中的标准元件，以补偿（替代）被测元件造成的失谐。测量结果需计算后方能得到，这是一种间接测量的方法。\u003c/p&gt;\u003cp class=\"content\"&gt;1）并联替代法\u003c/p&gt;\u003cp class=\"content\"&gt;用并联替代法测试电容量的电路如图 7-14 所示。进行测试时，首先将标准可变电容器放在电容量很大的刻度位置\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;S1\u003c/span&gt;上，调节振荡电路的频率使串联谐振回路谐振。然后将被测电容器接在\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;接线柱上，与标准可变电容器并联，振荡电路保持原来的频率不变，减小标准可变电容器的电容量到\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;S2\u003c/span&gt;，使串联谐振回路恢复谐振。在这种情况下，有：\u003c/p&gt;\u003cdiv class=\"qrbodyPic\"&gt;\n\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic4.zhimg.com/v2-5d2545759ee37d0139b6c28cfd0e2231.jpg\"/&gt;\n\u003cp class=\"imgtitle\"&gt;图 7-14 并联替代法测量电容量\u003c/p&gt;\n\u003c/div&gt;\u003cdiv class=\"bodyPic\"&gt;\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic2.zhimg.com/v2-46598e877a9d146b2bcf97b165655497.jpg\"/&gt;\u003c/div&gt;\u003cp class=\"content3\"&gt;即可求得被测电容\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;的值为\u003c/p&gt;\u003cdiv class=\"bodyPic\"&gt;\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic3.zhimg.com/v2-6db1ccd23255aa496b31a42b88848376.jpg\"/&gt;\u003c/div&gt;\u003cp class=\"content\"&gt;显然，并联替代法只能测电容量小于标准可变电容器变化范围内的电容器。由于通常标准可变电容器的电容量变化范围有限，例如，一个能从 500pF 变化到 40pF 的电容器的电容量变化范围为 0～460pF。按照上述测试方法，只能测试电容量小于 460pF 的电容。当被测电容量大于标准可变电容器的电容量变化范围时，则可根据被测电容量的估算数值选择一个适当容量的电容器作为辅助元件，再用上述方法进行测试。选择辅助电容器时，必须使已知辅助电容器的电容量与标准可变电容器的变化范围之和大于被测电容器的电容量。例如，用电容量变化范围为 460pF 的标准可变电容器来测被测电容量约为 680pF 的电容时，必须选择一个电容量大于 220pF 的已知电容作为辅助元件。\u003c/p&gt;\u003cp class=\"content\"&gt;测试时，首先把已知电容接在\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;接线柱上，标准可变电容器放在电容量所在的刻度位置\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;S1\u003c/span&gt;上，调节振荡电路的频率使串联谐振回路谐振。然后拆去\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;接线柱上的已知电容，接上被测电容。振荡电路保持原来的频率不变。减小标准可变电容器的电容量到\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;S2\u003c/span&gt;，使串联谐振回路恢复谐振。在这种情况下有\u003c/p&gt;\u003cdiv class=\"bodyPic\"&gt;\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic4.zhimg.com/v2-d5f30d0f5609045665eaf146846636da.jpg\"/&gt;\u003c/div&gt;\u003cp class=\"content3\"&gt;即可求得被测电容\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;的值为\u003c/p&gt;\u003cdiv class=\"bodyPic\"&gt;\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic2.zhimg.com/v2-3f71178678e60f394cf489c415acd041.jpg\"/&gt;\u003c/div&gt;\u003cp class=\"content\"&gt;2）串联替代法\u003c/p&gt;\u003cp class=\"content\"&gt;被测电容量大于标准可变电容器容量变化范围的另一种方法是串联替代法。使用串联替代法测电容的电路如图 7-15 所示。进行测试时，首先将标准可变电容放在电容量甚小的刻度位置\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;S1\u003c/span&gt;上，调节振荡电路的频率使串联谐振回路谐振。然后将被测电容串联在谐振回路中，振荡电路保持原来的频率不变，增加标准可变电容量到\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;S2\u003c/span&gt;，使串联谐振回路恢复谐振。在这种情况下，有\u003c/p&gt;\u003cdiv class=\"qrbodyPic\"&gt;\n\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic2.zhimg.com/v2-f46c980c38aa53b662d40d5158eada18.jpg\"/&gt;\n\u003cp class=\"imgtitle\"&gt;图 7-15 串联替代法测量电容量的电路\u003c/p&gt;\n\u003c/div&gt;\u003cdiv class=\"bodyPic\"&gt;\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic4.zhimg.com/v2-f68ba0cdc63f053bfbf1f664e7de87ac.jpg\"/&gt;\u003c/div&gt;\u003cp class=\"content3\"&gt;即可测得被测电容\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;的值为\u003c/p&gt;\u003cdiv class=\"bodyPic\"&gt;\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic1.zhimg.com/v2-aaece172008190e036ae223d5aafef63.jpg\"/&gt;\u003c/div&gt;\u003ch3 class=\"thirdTitle sigil_not_in_toc\" id=\"bw2\"&gt;7.2.2 电感量的测量\u003c/h3&gt;\u003cp class=\"content_102a\"&gt;1．直接法\u003c/p&gt;\u003cp class=\"content\"&gt;在图 7-13 中若选用已知标准电容\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;S\u003c/span&gt;和被测电感\u003cspan class=\"italic\"&gt;L\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;组成谐振回路，按测试电容的同样方法，调节振荡电路的输出频率，使谐振回路达到谐振状态，由式\u003cimg alt=\"\" class=\"h-pic\" src=\"https://pic1.zhimg.com/v2-dd6e927ac826bdb238c98196de5217c0.jpg\"/&gt;可得被测电感\u003cspan class=\"italic\"&gt;L\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;的值为\u003c/p&gt;\u003cdiv class=\"bodyPic\"&gt;\u003cimg active=\"true\" alt=\"\" class=\"width80\" src=\"https://pic3.zhimg.com/v2-4b6866cf187570d3faf6eb92c41969c5.jpg\"/&gt;\u003c/div&gt;\u003cp class=\"content3\"&gt;式中，电容的单位是 F，频率的单位是 Hz，电感的单位是 H。若上述各量的单位分别用 pF、MHz、μH，则式（7-26）可写为\u003cimg alt=\"\" class=\"h-pic\" src=\"https://pic1.zhimg.com/v2-087b3acd2249f1b42ab2d8d94efa5fb8.jpg\"/&gt;。式中\u003cspan class=\"italic\"&gt;f\u003c/span&gt;\u003cspan class=\"sub\"&gt;0\u003c/span&gt; 可由振荡电路的刻度盘读得，\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;S\u003c/span&gt;可由标准可变电容器的刻度盘读得，由式（7-26）即可计算出被测电感量\u003cspan class=\"italic\"&gt;L\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;。\u003c/p&gt;\u003cp class=\"content\"&gt;实际上按谐振法设置的测试仪器，测电感时为了能直接读数，通常是在某些指定的频率点上进行测试。由式\u003cimg alt=\"\" class=\"h-pic\" src=\"https://pic3.zhimg.com/v2-d93528f2610f98aff33bb4c99a5cbc75.jpg\"/&gt;可知，当\u003cspan class=\"italic\"&gt;f\u003c/span&gt;\u003cspan class=\"sub\"&gt;0\u003c/span&gt;为定值时，\u003cspan class=\"italic\"&gt;L\u003c/span&gt;\u003cspan class=\"sub\"&gt;x\u003c/span&gt;与\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;S\u003c/span&gt;成反比例关系，所以，在标准可变电容器\u003cspan class=\"italic\"&gt;C\u003c/span&gt;\u003cspan class=\"sub\"&gt;S\u003c/span&gt;的刻度盘上附加直读电感的刻度，就可以直接读出被测电感\u003cspan class=\"italic\"&gt;L\u003c/span&gt;\u003cspan class=\"span_105\"&gt;x\u003c/span&gt;值，而无须计算。\u003c/p&gt;\u003cp class=\"content\"&gt;用直接法测得的电感量是有误差的，因为实际上，公式\u003cimg alt=\"\" class=\"h-pic\" src=\"https://pic4.zhimg.com/v2-d51a2c6a30fc249b9ecf3c86f75fcd50.jpg\"/&gt;中的电容值还包括线圈的分布电容和引线电容，而标准可变电容的刻度中不包括这两项电容值，测试结果为正误差，即测试值大于实际值。若要消除误差，应采用替代法。\u003c/p&gt;\u003cp class=\"content_102a\"&gt;2．替代法\u003c/p&gt;\u003cp class=\"content\"&gt;与测电容一样，也有并联替代法和串联替代法两种。测小电感时用如图 7-16（a）所示的串联替代法，测大电感时用如图 7-16（b）所示的并联替代法。由于具体的测试方法与测电容的替代法相仿，不再赘述。\u003c/p&gt;\u003cdiv class=\"qrbodyPic\"&gt;\n\u003cimg active=\"true\" alt=\"\" class=\"width80</p>
</div></details><h2 id="toc-142">72. 尼康（中国） - Z f - 产品介绍</h2>
<ul>
<li>链接：https://www.nikon.com.cn/sc_CN/product/mirrorless/z-f</li>
<li>来源：bing</li>
<li>摘要：2023年9月20日 · 全画幅微单相机Zf的标志性外型的灵感源自FM2，其中包含了尼康技术的精巧智慧和强大功能。 Zf黑色和银色的颜色选择和多种高级外观设计，助您充分表达个性。 Zf的多方面都将由你 …</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-143">正文（抓取，非 AI）</h3>
<p>尼康（中国） - Z f - 产品介绍 尼康映像仪器销售（中国）有限公司 | 中国 尼康映像仪器销售（中国）有限公司 | 中国 查看更多 尼康全球 产品介绍 支持及下载 主页 产品介绍 Z CINEMA 微单数码相机 数码单反相机 轻便型数码相机 镜头（微单数码相机） 镜头（数码单反相机） App应用及软件 闪光灯 运动光学望远镜 胶片单反相机 钥动KeyMission运动相机 配件 原创品 支持及下载 致尼康用户的重要信息 售后服务 售后服务网点 保修/售后服务条款 延长保修期服务 常见问题与解答 下载中心 注册您的尼康产品 尼康影像体验馆 关于尼康产品包装封贴说明 尼康相机防伪标签识别方法 如何鉴别假冒电池 如何购买 尼康直营店（上海淮海中路店） 尼康直营店（广州正佳广场店） 尼康直营店（成都IFS店） 尼康直营店（北京三里屯太古里店） 尼康天猫官方旗舰店 尼康京东官方旗舰店 超典范店Plus 超典范店 典范店Plus 典范店 示范店 形象店 经销商 网络销售店 望远镜经销商 学习教程 尼克尔镜头术语 Digitutor视频教程 关于尼康 尼康新闻 质检标准通过信息 可持续发展 关于我们 联系我们 隐私管理 使用条款与条件 更多链接 尼康全球 尼康集团 尼康影像 尼康眼镜 NPS 尼康专业服务（全球） Z f 经典黑（新） 湖绿蓝（新） 岩石灰（新） 茶褐棕（新） 青苔绿（新） 雾玫粉（新） 干邑棕（新） 经典黑 湖绿蓝（新） 岩石灰 茶褐棕 青苔绿 赤枣红 落日橘 靛青蓝 对比 发布日期 : 2023/09/20 哪里购买 打印此页 产品宣传册 注册我的尼康产品 软件、固件、说明书下载 提供有偿更换饰皮服务 哪里购买 产品简介 功能特点 技术规格 样张欣赏 套机 配件 产品简介 由我定义 相机可用于创摄，亦可用于表达。全画幅微单相机Zf的标志性外型的灵感源自FM2，其中包含了尼康技术的精巧智慧和强大功能。Zf黑色和银色的颜色选择和多种高级外观设计，助您充分表达个性。Zf的多方面都将由你定义——相机本身、被持握时的造型，以及你捕捉的瞬间。 鼓舞人心的设计让您的热情在初窥与首次使用时就被点燃。拿在手中感受、体验和使用，并以更有引人入胜的方式创摄。通过发现不同的创作途径，来探索您的新潜力。您只需轻按控制杆，即可通过美丽的单色，以新的方式观察世界。通过机内的颜色预设（色彩方案和胶片颗粒功能）体现您的个人风格。更新的自动对焦性能可让您充分发挥创意，捕捉街头的韵律。记录平滑稳定的运动，呈现丰富的色调和色彩。即使在昏暗的环境下，也能以奢华的全画幅图像品质呈现锐利、清晰、美丽的图像，来表达您的心声。 自豪地表达您的激情、风格、创意和自我，成为真正的自己。 功能特点 1. 激发表达的外观设计 2. 拓展表达的可能性 3. 自由灵活的视频表达 4. 各种场景下都能自由、自信地拍摄 5. 广泛探索更多的美好表达 6. 令人振奋和可靠的操作 7. 部件图 8. 系统图 1. 激发表达的外观设计 内外兼修的标志性风格 影像制作不仅仅关乎获得作品的速度，其过程也是创造乐趣的关键。您操作相机的每一步，都是将创作意图转化为属于您自己的影像的一个组成部分。尼康 FM2 是胶片时代的一款标志性相机，它带来了影像制作的真正乐趣，并受到众多用户的广泛喜爱。Z f 传承这一传统，采用精致的外观设计和来自FM2灵感的手动拨盘操作，让您更直接地将自己的创作意图与所看到的事物联系起来。受 FM2 启发的外形设计以及20世纪七、八十年代相机上使用的尼康徽标突出了造型的经典。同时，快门释放按钮和手动控制拨盘的触感将激发您的创作灵感，有助于将相机的高端全画幅微单相机技术转化为令人兴奋的创意触觉本能。从第一眼看到它，第一次触摸它，就能感受Z f 就是那款您想要实现创意的相机。 新银色款，尽享经典设计 Zf的标志性设计更加引人注目，银色新款助你表达并彰显自己的风格。受到如尼康F系列等胶片时代相机镀铬的启发，银色表面使镀铬机身更具质感，造就了真实的外观和光滑的触觉体验，非常适合那些欣赏胶片相机坚实品质的爱好者。 一个体现哲学的名字 Z f的核心是“融合”，其名字中蕴藏着这一理念。它代表过去、现在和未来的融合，凭借标志性的外观设计，Z f将尼康70多年来的创新和精密工艺传统与全画幅微单相机的高级技术结合在一起。“f”还表示在尼康历史上具有象征意义的型号。而且，它反映了您将其握在手中的感觉，将通过相机看到的世界与您独特的创意意图无缝融合。 Z f旨在通过先进技术营造真实的体验，为您提供更深入体验每一瞬间的空间，以及以自己独特的方式表达自己与众不同的机会。 通过触感激发您的创意性 创意是触手可及的东西。只要将Z f拿到手中，其坚固的机身就能带来纯正的精密机械感。快门释放按钮、电源开关、快门速度 / 曝光补偿 / ISO感光度拨盘均采用黄铜材质，给您带来精致的操作手感。每个拨盘的转动声和手感都经过反复测试和调整，追求简单易用和操作的舒适。除了对细节的关注之外，这些拨盘还配有光滑的黑漆和雕刻的文字。其他的设计特点还体现在既保持机身的美观，又为拍摄提供支持的手柄，以及追求出色的手感和造型的人造革饰面。谈到拍摄，快门释放按钮的设计优先考虑每次按下的触感，为捕捉重要时刻带来令人满意的体感。这种对细节的关注会激发感官，带来高品质的操作感。 展现你的个性——高级外观 唯有珍贵的属性方能使你卓尔不群。除了基本的黑色款和银色款外，Zf还使您能够通过9种不同的饰皮颜色选项来表达自己的风格<em>。这些高级外观使相机的压花人造皮革部分——覆盖翻转显示屏的握把和后部——呈现出三种高饱和度且富有表现力的颜色（靛青蓝、茶褐棕、赤枣红）、三种较深的自然暖色（落日橘、青苔绿、岩石灰）和三种新色（干邑棕、湖绿蓝、雾玫粉），并采用单独匹配的表面纹理进行渲染。用你最喜欢的外观颜色表达自己，与众不同。 * 可用的颜色选项可能因地区而异。 2. 拓展表达的可能性 通过胶片颗粒功能拓展创作自由 清晰锐利并非评判影像作品的唯一标准。胶片颗粒功能增添了一种独特的怀旧质感，唤起了人们的心绪和情感——现在，你可以通过新的胶片颗粒功能轻松实现。只需在拍摄时开启此功能并选择颗粒大小和效果强度。颗粒大小有大、中、小三档，效果强度有六档可供调整，使之匹配您的创意视觉。再搭配色彩方案提供的创意表达，即可实现心仪的胶片感。 以单色看不一样的世界 摄影的核心是光：它如何打在主体上，如何在阴影中发挥作用，以及它在拍摄瞬间的独特之处。单色不仅仅是简单的黑白，它可以让您用光和影的纯粹纹理表达您的世界，用形状和深度的简单图形元素进行构图。通过专注于这些基础知识，您的表达自由度会得到扩展，而Z f进一步开启表达的可能性。 表达您的真实色彩——优化校准 / 创意优化校准 每个场景都是唯一的，就像每位创作者都是独一无二的一样。在优化校准和创意优化校准中找到能够表达感受的颜色。优化校准和创意优化校准的效果均可即时选择，并在Z f的显示屏和电子取景器上显示，让您能够用照片或视频创作出精美的影像，以您独特的观点表达当下的情感、氛围、温度和影调。此外，每种创意优化校准的效果都可以在0-100的范围内轻松调整到您满意的水平，从而实现直观、精细的控制。 在Z f相机中，优化校准新增“丰富色调人像”选项，能够以更丰富的色调呈现人物的肤色细节，同时保留高光和暗部的细节。此选项还能为修饰和处理图像打下更好的基础，因为与传统的人像选项相比，它保留了更多的肌肤细节，使肤色明亮又光滑。 尼康云创拓展创意表达，优化工作流程 尼康云创是尼康新推出的云服务，可通过Wi-Fi与Zf紧密协作，为您带来新的创意灵感与无线工作流程解决方案。该服务提供由知名创摄者精心打造的影像色彩方案（定制预设配色），并支持将Zf拍摄的图像自动上传至第三方存储服务。此外，还可直接进行Zf的固件升级。借助尼康云创，用户可进一步提升影像创作体验。 用影像色彩方案打造理想影像风格 Zf在固件2.00版本中引入了影像色彩方案，即由尼康与知名创摄者精心打造的定制机内色彩预设。用户可从尼康云创直接下载多达9种云优化校准至Zf，且无需额外费用，轻松尝试不同风格，为照片和视频增添独特魅力。无论是胶片质感、温暖阳光氛围，还是情绪化的人像美学，都能找到契合您创意表达的理想方案。 像素变化拍摄，提升细节水平 建筑装饰的精美细节、艺术品的复杂色彩、昆虫或矿物的复杂结构，沉浸在具有深度的或触觉质感的难以想象的沉浸式场景。借助尼康Z f原创的像素变化摄影，您能以更高的分辨率和还原度进行拍摄，同时减少莫尔条纹、假色和噪点。通过在4、8、16或32张图像之间巧妙地移动影像传感器的位置，Z f可以获得更准确的色彩信息。增加拍摄张数可增强效果，16张或32张可创建约9,600万像素的高分辨率图像。可以使用“尼康工坊”软件来合并拍摄的RAW图像。 尼克尔Z镜头，以独特的视角讲述您的故事 无论是照片还是视频，为了让您的影像拥有恰到好处的风格和存在感，尼克尔Z镜头系列是为充分发挥Z f的性能而设计。尼克尔Z镜头利用大直径的Z卡口，通过纯净而丰富的光线实现出色的清晰度和渲染性能，为您提供一种全新的方式来表达自己。 尼克尔 Z 40mm f/2 (SE) 其特别版的传统造型，灵感源自与标志性FM2同时代的镜头，这款紧凑轻巧的镜头始终是您Z f的舒适伴侣，无论您走到哪里，无论是日常生活中还是旅行中。40mm的视角（不像35mm那么宽，也不像50mm那么窄）让您可以拍摄街景，不会包含太多的背景以致分散注意力，同时又足够宽，可以为人像提供一个很好的背景环境。您可以欣赏各种渲染的可能性，从光圈全开时令人惊叹的边缘到边缘的清晰度，到柔和、细腻地再现多变的氛围。f/2光圈在夜间或弱光室内非常有用，并且还能够提供大虚化效果。 尼克尔 Z 24-70mm f/4 S 这种多功能变焦可在整个实用的标准变焦范围内实现清晰、稳定的渲染。作为一款尼克尔Z S-Line（S-型）镜头，它满足照片和视频的严苛的性能标准，即使光圈全开拍摄时，也能保持边缘到边缘的清晰度，虚化自然、平滑，镜头的涂层可防止眩光和失真，从而在背光场景中也能使影像保持高清晰。 尼克尔 Z 28mm f/2.8 (SE) 这款 28mm f/2.8 镜头是实现轻便、紧凑的广角性能的优选镜头，它将灵感源自FM2时代镜头的标志性设计与街头摄影的理想视角相结合。还可以让您从近至约0.19m 的距离拍摄主体，同时以深邃、动态的视角保留背景风景。尼克尔 Z 28mm f/2.8 (SE) 是首款采用多重对焦系统的非S-Line（S-型）镜头。它可以减少近距离拍摄时的像差，实现自然的渲染，同时提供快速准确的自动对焦。 尼克尔 Z 26mm f/2.8 这款薄饼镜头具有真正的便携性，可轻松放入包中，是Z f真正的日常创意伴侣。其视角和低调的外观适合街景。该镜头不但重量轻、厚度薄，而且由于采用Z 卡口光学技术，还可提供令人惊叹的锐利、清晰的影像和较小的失真。其外观设计还营造出一种激发创意的高品质感。 f/1.8 S-Line（S-型）定焦镜头系列（20mm、24mm、35mm、50mm、85mm） f/1.8镜头系列的设计除了照片，还特别重视视频，可在整个光圈范围内提供直至边缘的高清晰度，并且提供平滑、美丽的虚化，从而能获得令人惊叹的影像。此外，通过一致的光圈、曝光和ISO感光度平滑的控制环操作，视频的后期制作编辑变得更加轻松。同时，大大减少自动对焦的噪音，将对焦呼吸对视频的影响减少到一个新的水平。 尼克尔 Z 17-28mm f/2.8和尼克尔 Z 28-75mm f/2.8 这2款轻质的变焦镜头可用于视频和静态照片，在整个变焦范围内提供恒定的f/2.8光圈、最近对焦距离短、快速安静的自动对焦、较小的对焦呼吸以及轻松的控制环操作。尼克尔 Z 17-28mm f/2.8将引人注目的动态广角变焦范围融入到固定的镜头总长度中。 同时，尼克尔 Z 28-75mm f/2.8涵盖多种标准变焦范围焦段，从优美的一览无余的风景到亲密的家庭宠物。 尼克尔 Z 24-120mm f/4 S 一览无余的风景、狭窄的室内空间、人像、微距拍摄远处的地标，如果您饶有兴致地拍摄这些主体，并希望在长变焦范围内从画面的边缘到边缘都清晰地描绘照片和视频，那么它就是适合您的那款多功能镜头。即使在使用S-line（S型）光学系统的最大光圈下，您的图像也能锐利地呈现，并且在强背光条件下也能保持清晰，由于采用创新涂层，减少鬼影或眩光。 卡口适配器FTZ II 您还可以通过FTZ II卡口适配器，与约360款尼克尔F卡口镜头搭配使用，开启创意表达。 3. 自由灵活的视频表达 通过后期处理时更广泛的选择来追求您的视频表达 相机直出的图像或通过后期调色，美丽的色彩渲染正如您所期待。不需要外部录制设备，Z f就可以让您以时尚的方式拍摄鼓舞人心的视频短片。它能够在机内拍摄4K超高清SDR / N-Log / HLG格式的10位H.265，无论是旅行中遇到的风景中精细的细节、街道上的高对比度场景，或是微妙光线下人脸的纹理，捕捉到的视频包含灵活的后期制作所需的丰富信息，使您的最终作品能够按照预期表达场景的情感。 将高清视频提升到新水平 富含清晰细节的视频从一开始就吸引观众的注意力。通过从约2,400万像素全画幅传感器读取6K图像数据，并将其转换为过采样4K超高清视频</em>，Z f可以使拍摄对象更加清晰，并增强拍摄场景的沉浸感。 * 仅适用于FX影像区域下的4K超高清/30p/25p/24p视频。 拍摄长时间的4K超高清/60p视频，捕捉每一刻 当您需要的细节是运动中主体的表现美或在风中飘逸的头发时，Z f可以以4K超高清60p<em> 1 捕捉这些瞬间。以24p输出时，可实现最高2.5倍的慢动作，来突出某一时刻的戏剧性变化。此外，为了支持长时间拍摄大场景，相机可以持续录制长达约125的分钟</em> 2 的4K超高清视频。 * 1 仅在DX裁切模式下可用。 * 2 H.265 8位(MOV)，[自动温度切断]：[高]，23℃，使用EN-EL15c锂离子电池组和USB供电。建议使用推荐的存储卡。 轻松拉近主体，体验高分辨率变焦 在固件2.00版本中，Zf引入了高分辨率变焦功能。即使使用定焦镜头，也可在全高清录制时放大至2倍，且不会出现数字变焦画质损失。这一功能在机内实现，无需额外设备，即可打造理想的视频表达。还可从11种变焦速度中自由选择，以准确呈现所需的影像风格与节奏。 视频录制期间固定快门速度 在亮度频繁变化的场景中，保持固定的快门速度通常很有帮助。这个时候就是Z f的快门优先自动曝光模式的用武之地了，也是尼康Z系列相机中的首创。在此模式下，相机通过ISO感光度和光圈控制曝光，有助于防止荧光灯下的闪烁，以及从阴影过渡到明亮的阳光下时，因快门速度大幅变化而导致拍摄对象不自然的移动。 稳定的手持拍摄，VR减震功能 视频吸引人的关键之一是平滑、稳定的相机移动。Z f通过应用相机内传感器5轴移位减震补偿来保持相机稳定，为您提供平滑、清晰的效果，即使在手持拍摄时也是如此。 当您缓慢行走中进行拍摄时，将电子减震<em> 1 与相机内传感器位移减震结合使用效果会更好。此外，还可以减少使用广角镜头拍摄时容易发生的影像失真</em> 2 。 * 1 使用电子减震时，视角相当于镜头原本焦距的约1.25倍。 * 2 使用尼克尔Z镜头时。 通过精细的曝光控制更灵活地拍摄 即使在不断变化的光线情况下，也能保持曝光平滑过渡，拍出精美的短片。得益于与Z 9和Z 8相当的改进，Z f可以对曝光进行精细的控制。在手动曝光模式下，ISO感光度能够以1/6EV为增量进行微调。同时，在快门优先和手动曝光模式下，快门速度可设置为低至1/4秒。 借助拍摄辅助功能，让视频录制变得自信而专业 当您录制包含多个场景的视频短片时，可能需要控制画面以使整个视频的品质保持一致。Z f提供与Z 9和Z 8相当的视频拍摄辅助功能，让您确认重要的拍摄细节并达到预期效果。 • 辅助显示功能：屏幕上提供斑马条纹，在拍摄人物主体时，有助于让肌肤亮度保持一致的中间色调，避免高光溢出。 • 波形显示屏：让您更轻松地确认构图中高光和暗部的细节丢失以及遮挡的阴影。 • 红色REC录制框显示：立即确认是否在录制中。 • 录制过程中的放大变焦：让您可以在录制视频时通过放大屏幕来确认拍摄对象是否清晰对焦，放大比例可选50%、100%和200%。 • 视频设置信息显示：可以显示包括文件格式和位深在内的视频设定信息列表，以便一目了然地确认。 通过灵活的视频配件扩展拍摄的可能性 为了进一步拓展您的创意选择，Z f支持一系列的视频配件。MC-N10遥控手柄可与三脚架、肩架和稳定器等相机配件结合使用，远程控制曝光、自动对焦等，从而扩大表达机会。合作品牌的配件包括相机麦克风、稳定器、相机兔笼等，以支持舒适的视频录制<em>。 * 并非所有操作都能 保证 。 4. 各种场景下都能自由、自信地拍摄 使用各种AF区域模式跟随动作，不错过动作的瞬间 以高清晰度观察转瞬即逝的瞬间。美丽的虚化背景下运动中的人物肖像。例如，一只正在玩耍的宠物，在海滩上奔跑跳跃。与Z 9和Z 8搭载的EXPEED 7影像处理器相同，与深度学习技术支持的出色自动对焦对象侦测相结合，实现快速的数据处理，提高各种场景下的跟踪性能。拍摄照片时，AF区域模式包括智能3D跟踪，使不规则移动的拍摄对象保持清晰对焦，而在录制视频时，配合对象跟踪自动对焦，还能使移动中的拍摄对象保持平滑对焦。 通过多功能自动对焦对象侦测，更自信地构图 想象一下，您走在街上，一只小猫引起了您的注意。您立即拿起相机准备拍照。进行构图，在猫转向您的那一刻释放了快门。得益于AF对象侦测功能，Z f可以快速准确地对焦于您想要拍摄的主体。相机能识别并自动检测和跟踪9种主体类型——人（眼睛、脸部、头部、上半身）、狗、猫、鸟、汽车、摩托车、自行车、火车和飞机，无需更改设置。它甚至能检测出尺寸仅占画面长边约3%的脸部，与Z 9和Z 8实现的侦测效果相当。因此适合拍摄站在壮丽风景中的拍摄对象全身或从远处走向相机的人。由于相机搭载分别控制自动对焦的曝光和即时取景曝光的装置，Z f可以在强背光下准确检测人物剪影，而常规相机却很难做到。得益于Z f的高级自动对焦算法，使低至-10 EV</em>的出色低光照自动对焦性能成为可能。这有助于在昏暗场景中轻松聚焦于拍摄对象，例如月光下或室内暗处的人像。 * 使用最大光圈为f/1.2的镜头，在照片模式下使用单次伺服自动对焦(AF-S)、 ISO 100和温度20°C时测量。 专属鸟类侦测模式 在固件2.00版本中，Zf引入了专门的鸟类侦测模式，大幅提升鸟类拍摄时的侦测与追踪性能，无论身处何种环境，都能快速、稳定地锁定目标。该模式能够应对复杂或高对比度背景（如岩石、山坡或森林）。无论鸟儿正处于飞行、停栖枝头，或是快速移动的状态，或者需要拍摄长颈或色彩鲜艳的特殊品种，即便它们在画面中占比很小，依然能被准确识别。可靠的对焦表现让您更加自信地捕捉精彩瞬间。 自动对焦的覆盖范围更广、更准确 一辆自行车驶过，成为美丽构图的一个关键元素。273个自动对焦点紧密排列，覆盖画面垂直方向约89%、水平方向约96%的区域<em>，即使是远处如此微小的拍摄对象，也可以从画面的一个边缘跟踪其移动到另一个边缘，并准确、快速地捕捉美好的瞬间，这正是您预想的构图。 * 为AF区域格式选择单点AF，为影像区域选择FX格式时。 通过自定义宽区域自动对焦，满足场景所需的对焦 当前景中挤满了各种不同类型的主体来争夺相机的注意力时，无论挑选还是跟踪一个特定的主题，都是一种挑战。Z f的自定义宽区域AF可应对这些挑战，并自定义适合场景需求和构图意图的对焦区域。拍摄照片时可以选择77种区域图案，拍摄视频时可以选择66种区域图案。 享受手动对焦镜头带来的便利的对象侦测功能 当手动对焦镜头激发您的创意时，Z f可以帮助您更轻松地对焦拍摄对象。EXPEED 7影像处理器的强大功能与使用深度学习技术相结合，使Z f能够像传统的自动对焦那样，在手动对焦中使用眼睛或脸部侦测等对象检测功能。现在，此功能可以通过放大屏幕上的眼睛区域来帮助调整对焦点，而通常这个过程会很耗时。对于采用电子接点的手动对焦镜头，还可以使用对焦辅助装置，以进一步方便对焦。 利用高速连拍性能捕捉决定性瞬间 对于小孩跳过水坑或鸟儿飞翔等场景，您需要从连续的动作中找到决定性的瞬间，Z f可以让您加快速度，准备捕捉预期的画面。它能提供约14幅/秒</em> 1 的高速连拍。当设定成高速画面捕捉+ (C30) 时，凭借EXPEED 7影像处理器的高处理能力，允许以高达约30幅/秒<em> 1 的速度</em> 2 拍摄。连拍跟踪时还可使用自动对焦/自动曝光功能，使您能够以清晰的对焦和出色的曝光记录动态的瞬间<em> 3 。 * 1 高速连拍（延长）模式下的最高帧速率。 * 2 固定为JPEG [标准]。建议使用推荐的存储卡。 * 3 使用电子快门时，根据对象类型和拍摄条件，可能会出现滚动快门失真。 通过预拍功能捕捉肉眼难以看到的瞬间</em> 转瞬即逝的刹那，往往比手指快速按动快门按钮还要快。当您在预先设置的构图中等待决定性时刻的出现时，例如，鸟儿起飞的那个瞬间，预拍功能可以帮助您在不知不觉中抓住时机。借助此功能，半按快门可在完全按下快门之前录制长达1秒的时间，甚至可以捕捉到比您的反应还快的难以捕捉的瞬间。 * 记录的图像品质为[标准] JPEG图像。图像尺寸 L（约 2,440万像素）、图像区域 [FX (36 x 24)] 或图像尺寸 L（约1,060万像素）、图像区域 [DX (24 x 16)]。建议使用推荐的存储卡。仅当使用高速画面捕捉+ 进行拍摄时才能设置预拍功能，支持高达约30幅/秒的连拍。 减少室内光线的闪烁 在某些人工照明条件下（例如室内运动）拍摄移动主体时，有时拍摄会出现闪烁的风险，但Z f可以助您精美、可靠地捕捉这些关键时刻。即使在高速连拍（延长）模式下拍摄时，也可以应用闪烁减轻，该模式优先考虑帧速率，优先考虑闪烁减轻效果的高速连拍/低速连拍模式均已添加此功能。 5. 广泛探索更多的美好表达 全画幅传感器带来更丰富的光线和色调的世界 Z f的全画幅/FX格式传感器不仅仅是尺寸大，还能更美丽地捕捉您的世界。这意味着您的拍摄对象能够在柔和的背景下脱颖而出。它还意味着能够以更准确、更精细的色调层次捕捉更多的光线和更丰富的色彩，来表达黎明或黄昏时天空的微妙差别和色调变化。与DX格式/APS-C画幅相机相比，相同的镜头可为您提供更广阔的视野，让您捕捉到壮丽的风景。更大的不仅仅是传感器，还有您的表达能力。 将您的创意画布扩展到低光场景 借助Z f改进的低光照性能和最高标准感光度ISO 64000，在夜景或昏暗的室内场所寻找新的质感和生命。得益于全画幅背部入射式CMOS传感器和EXPEED 7影像处理器能力的结合，即使精细的细节和纹理也能以高饱和度清晰渲染。使用Z f时，低光照场景中通常噪点增多的中间色调（尤其是在平坦的表面上），会变得比以往清晰得多。同时，随着ISO感光度的增高，噪点却能保持在低水平，从而能在更广泛的场景中开启创作的可能性。此外，Z f提供星光视图模式，提升显示屏的亮度，让您在很暗的场景中也能直观地确认构图。它还可在低至-10 EV<em>的低光照环境下实现锐利对焦。 * 使用最大光圈为f/1.2的镜头，在照片模式下使用单次伺服自动对焦 (AF-S)、ISO 100和温度20°C时测量。 通过扩展VR减震性能，为手持拍摄带来更多创意表达 当您在街中漫步，可能会遇到美丽的暮色场景，此时只有您和您的相机。由于改进了基于AI图像分析的检测算法，Z f的相机内减震效果可以实现Z系列中最高的相当于约8档</em>的快门速度的提升。您可以为了高图像品质而将ISO感光度保持在较低的水平，并降低快门速度，而不必担心手持相机时出现不想要的模糊。这将手持拍摄的可能性扩展到更多的低光环境以及使用长时间曝光的创意表达形式。 * 使用尼克尔 Z 24-120mm f/4 S的长焦端。基于日本相机影像产品工业协会（CIPA）标准。 借助对焦点VR减震<em>，即使拍摄对象偏离中心也能保持清晰 遵循三分法，将建筑物或地标放置在偏离画面中心的位置，是让您的景观构图熠熠生辉的可靠方法。在黄昏时使用广角镜头拍摄时，您可能会需要利用相机内的减震功能，并且可能注意到这些偏离中心的拍摄对象目前并没有像您想象的那样清晰。传统的减震主要是为了减少图像中心区域的模糊，而Z f在全球首次引入对焦点VR减震，可以减轻所选对焦点周围的模糊，无论焦点位于画面中的哪个位置。这样您可以自由地按照设想的方式构图，比如，可将拍摄对象置于画面的边缘，从而扩展了手持拍摄的可能性。 * 仅在照片模式下使用不带内置减震功能的尼克尔Z镜头时。显示多个对焦点时无效。 使用HEIF呈现从光到影的丰富色调 为了完整地表达场景丰富的色调，当晨光照射在城市景观的玻璃建筑上，映衬出黎明天空的丰富色调时，您需要保留丰富信息的图像。 HEIF（高效图像文件）格式使用HDR图像的10位HLG标准保留所有精细的色调渐变。除了照片之外，Z f还允许在相机内拍摄4K超高清HLG延时视频，支持在兼容HDR（HLG）的显示器或电视屏幕上欣赏HEIF图像和短片。 充分利用相机内预设的肌肤纹理和色调拍摄人像 皮肤柔和功能可抚平面部不均匀的皮肤，同时保持需要锐利的部分，如眼睛、睫毛、眉毛和头发。调整人像形象功能可让您通过亮度（深-亮）和色调（黄-洋红）轴精细调整拍摄对象的肌肤色调。您还可以通过A-B（琥珀色-蓝色）和G-M（绿色-洋红色）轴调整白平衡的色温。这2种功能的设计都是为了调整到适合拍摄对象的颜色和肤色，让您实时目视确认效果。 借助深度学习，全自动曝光变得更加智能 半身人像需要柔和虚化的背景。全身人像或好友们的集体照，需要呈现背景环境。Z f的深度学习技术可以识别这些情况，并根据拍摄对象类型和拍摄状况，适当控制光圈、ISO感光度和快门速度。因此，您可以根据场景的需要自动拍摄美丽虚化的人像，或者对焦所有人的脸部拍摄集体照。它还能帮助您了解针对不同场景适宜的相机设置，以便在拍摄中应用。 6. 令人振奋和可靠的操作 展现独特的角度 无论是从高角度拍摄精美的餐食，还是以低角度拍摄朋友在城市街道上行走的视频，现在您都能从自己独特的视角进行拍摄，灵活、可靠且轻松。Z f是尼康全画幅微单镜相机中首款搭载约3.2英寸的可翻转显示屏。从各种角度都能轻松操作，让您实现更安全地对焦。 竖拍时操作流畅 使用Z f进行竖拍时比以往更轻松、更直观。当您将相机转为垂直方向时，屏幕上的信息和菜单会自动切换为纵向显示，以便于确认和浏览。此外，当垂直握住相机进行查看时，拍摄的图像也会自动以纵向显示。 改进触屏控制，让操作变得更轻松 在尼康Z系列中的另一个首创是Z f通过背面显示屏进行操作时的多功能触屏控制，称为触屏功能。其操作简单，只需将相机握在手中，即可通过直观的滑动和双击控制功能实现触屏，即使使用电子取景器拍摄时，也能流畅地操作所需的相机设置。触屏功能可用于移动对焦点、切换正在对焦的眼睛、选择网格显示、切换到放大显示以及调出虚拟水平显示。同时，为了防止误操作，屏幕的触摸感应区域还可以从9种模式中进行选择。 专为手动镜头爱好者优化的功能 将镜头名称和光圈值以非CPU镜头数据记录 在固件2.00版本中，当使用非CPU镜头拍摄时，可使用Zf手动记录镜头名称与光圈值</em>，并作为元数据存储。这一功能在使用手动镜头拍摄后查看每张照片的信息更为便利，让Zf与经典手动镜头的搭配更具魅力。 * 无法设置拍摄光圈。光圈仍需通过镜头光圈环调节，并在相机上设置相同数值，以便在影像文件中记录拍摄时的光圈信息。 录制过程中放大画面查看对焦，手动对焦模式下可放大至400%并轻松退出放大视图 Zf的固件2.00版本支持在拍摄过程中将画面放大至50%、100%、200%或400%。在使用老式镜头拍摄人像进行手动对焦时，这一功能尤为实用，能够帮助确认焦点是否精准对焦主体。在手动对焦时，可以通过半按快门释放按钮轻松退出放大视图<em>。 * 当[半按以取消放大(MF)]设置为[开启]时。 曝光延迟模式，减少相机抖动 在固件2.00版本中，Zf能够在完全按下快门按钮后，延迟一定时间才触发快门，有助于减少由于相机抖动引起的图像模糊。尤其在使用三脚架拍摄风景或食物时，这一功能能够有效减少相机振动，确保影像更加清晰稳定。 通过指令拨盘提升操作便捷性 Zf的固件2.00版本能够在手动拍摄模式下将曝光补偿和ISO感光度的控制分配给主拨盘或副拨盘。通过取景器拍摄时，现已无需使用对应的拨盘，便能直接调整这些设置，大幅提升了拍摄时的操作流畅度。 坚固耐用 每当拿起相机，您都无需为您的相机伴侣担心。Z f体现了尼康坚固耐用和可靠的悠久传统，前盖和顶盖采用镁合金。Z f可在低至 0°C的温度下操作，是您值得信赖的合作伙伴。 双存储卡插槽，提供加倍的安全保障 当灵感源源不断涌出时，您不必担心存储容量。Z f提供双存储卡插槽（SD卡和microSD卡），其中的1个插槽采用microSD卡，在不增加相机尺寸的情况下，为拍摄提供额外的安全保障。这样，可以使用第2张卡作为长时间拍摄时的额外存储容量，或作为图像数据的实时备份使用</em>。 * 建议使用最大数据传输速率至少为250MB/s或更高的UHS Speed Class 3的SD卡，来录制和播放高帧尺寸或帧速率的视频。 具备多层保护的防尘措施 为了保持影像传感器在出色的状态下工作，Z f提供与旗舰机型Z 9相当的严格的传感器保护。这是由光学滤镜上的双层涂层提供的，它将一层导电涂层和一层氟涂层相结合，导电涂层可以保持表面清洁，防止灰尘进入，氟涂层可以让您轻松擦拭附着的污垢。 使用尼康的免费应用程序，把您的创意带到拍摄之外 直观地编辑您的图像，“尼康工坊”（1.5.0版） 尼康的免费软件“尼康工坊”适合用于查看、处理和编辑图像。当您使用Z f的像素移位拍摄功能拍摄RAW (NEF) 图像时，该软件会将这些NEF图像合并到一个能够编辑和导出的文件中。除了SDR色调模式下的RAW (NEF) 和JPEG图像之外，您还可以查看HIEF<em>图像以及编辑使用Z f的“HLG”模式拍摄的色调丰富的RAW (NEF) 图像。 此外，“尼康工坊”（1.5.0版）集成了Picture Control Utility 2的功能。它将优化校准的整个工作流程（包括调整、应用和管理）整合到一个软件中，例如，允许自定义优化校准、将设置应用到导入的图像，或将自定义优化校准导出到相机以在拍摄时使用。 * 在 HLG 模式下确认 HEIF 和 RAW (NEF) 图像的准确色调时，应使用与 HLG 兼容的显示器、计算机和显示器线。 7. 部件图 部件和控制器 1 镜头安装标记 2 AF辅助照明器/防红眼灯/自拍指示灯 3 镜头释放按钮 4 镜头卡口 5 CPU触点 6 影像传感器 7 Fn按钮 8 副指令拨盘 9 屈光度调节控制 10 AE/AF锁定按钮/保护按钮 11 扬声器 12 i按钮 13 主指令拨盘 14 多重选择器 15 确定按钮 16 回放放大按钮 17 显示按钮 18 菜单按钮 19 播放缩小/缩略图按钮/帮助按钮 20 存储卡存取指示灯 21 显示屏 22 目镜释放器 23 删除按钮 24 播放按钮 25 橡胶眼罩 26 取景器 27 眼睛传感器 28 ISO感光度拨盘 29 ISO感光度拨盘释放锁定 30 立体声麦克风 31 快门速度拨盘释放锁定 32 快门速度拨盘 33 电源开关 34 快门释放按钮 35 视频录制按钮 36 相机带孔眼 37 曝光补偿拨盘 38 控制面板 39 照片/视频选择器 40 配件热靴（用于另购的闪光灯组件） 41 模式选择器 42 焦平面标记 43 三脚架孔 44 电池舱/存储卡槽盖 45 电池舱/存储卡槽盖锁扣 46 显示器模式按钮 47 充电灯 48 USB连接器盖 49 麦克风、耳机和HDMI连接器盖 50 USB连接器 51 耳机接口 52 HDMI连接器 53 外部麦克风连接器 54 黑白照片模式 55 照片模式 56 视频模式 8. 系统图 技术规格 类型 可换镜头数码照相机 镜头卡口 尼康Z卡口 影像传感器格式 FX 影像传感器类型 CMOS 传感器尺寸 约35.9mm x 23.9mm 总像素数 约2,528万 灰尘减少功能 影像除尘参考数据（需要使用“尼康工坊”软件） 有效像素数 约2,450万 图像尺寸（像素） [FX (36 x 24)] 影像区域: (L) 6048 x 4032 ( 约2,440万), (M) 4528 x 3024 ( 约1,370万), (S) 3024 x 2016 ( 约610万) [DX (24 x 16)] 影像区域: (L) 3984 x 2656 ( 约1,060万), (M) 2976 x 1992 ( 约590万), (S) 1984 x 1328 ( 约260万) [1:1 (24 x 24)] 影像区域: (L) 4032 x 4032 ( 约1,630万), (M) 3024 x 3024 ( 约910万), (S) 2016 x 2016 ( 约410万) [16:9 (36 x 20)] 影像区域: (L) 6048 x 3400 ( 约2,060万), (M) 4528 x 2544 ( 约1,150万), (S) 3024 x 1696 ( 约510万) 文件格式（图像品质） NEF（RAW）：14 位; 从无损压缩、高效率（高）和高效率选项中进行选择 JPEG：兼容JPEG-Baseline，压缩比（约）为精细（1 : 4）、标准（1 : 8）或基本（1 : 16）; 文件大小优先和良好品质压缩可用 NEF（RAW）+JPEG：同时以NEF（RAW）和JPEG格式记录单张照片 NEF（RAW）+HEIF：同时以NEF（RAW）和HEIF格式记录单张照片 优化校准系统 自动、标准、自然、鲜艳、单色、平面单色、深色调单色、人像、丰富色调人像、风景、平面 创意优化校准（梦幻、清晨、流行、星期天、低沉、戏剧、静寂、漂白、忧郁、纯净、牛仔布、玩具、棕褐、蓝色、红色、粉色、木炭、石墨、双色、黑炭）；可修改所选优化校准；可保存自定义优化校准 注：在照片拍摄期间选择 HLG 作为色调模式时，优化校准的选择仅限于标准、单色和平面。 注：使用尼康工坊创建的灵活颜色优化校准可导入相机。 存储介质 SD、SDHC（兼容UHS-II）、SDXC（兼容UHS-II）、microSD、microSDHC（兼容UHS-I）、microSDXC（兼容UHS-I） 双存储卡插槽 1张SD卡和1张micro SD卡 任一卡均可用于额外空间或备份存储，用于分别存储NEF (RAW) 和JPEG或HEIF格式的照片，或用于存储不同尺寸和图像品质的JPEG或HEIF格式的照片；照片可以在两张存储卡之间复制。 文件系统 DCF 2.0, Exif 2.32, MPEG A MIAF 取景器 约1.27cm（约0.5英寸）、约369万画点（Quad VGA）OLED电子取景器，可调整色彩平衡，具备自动以及13档手动亮度控制 画面覆盖率 水平和垂直约100% 放大倍率 约0.8倍（50mm 镜头设为无限远，屈光度为-1.0m-¹） 视点 21mm (屈光度为-1.0m-¹；距离取景器接目镜表面中心) 屈光度调节 -4至+2 m⁻¹ 眼感应 在显示屏和取景器显示之间自动切换 兼容的镜头 Z卡口尼克尔镜头 F卡口尼克尔镜头（需要卡口适配器；可能会有限制） 快门类型 电子控制纵走式焦平面机械快门；电子前帘快门；电子快门 快门速度 通过快门速度拨盘访问：1/8000至4秒（以1EV为增量）、B门、遥控B门、X（闪光同步） 通过主指令拨盘访问：1/8000至30秒（以1/3EV为增量，M模式下可扩展至900秒）、B门、遥控B门、X（闪光同步） 闪光同步速度 X=1/200秒；速度在1/200秒或以下时，与快门保持闪光同步；自动FP高速同步支持更快的同步速度 快门释放模式 单张拍摄，低速连拍，高速连拍，高速连拍（延长），高速画面捕捉（支持预拍功能），自拍 每秒幅数 最高约30幅/秒 低速连拍：约1-7幅/秒 高速连拍：约7.8幅/秒 高速连拍（延长）：约14幅/秒 高速画面捕捉（C15）：约15幅/秒 高速画面捕捉（C30）：约30幅/秒 * 每秒最高幅数根据尼康指定测试条件测量。 自拍 2秒、5秒、10秒、20秒；以0.5、1、2或3秒为间隔曝光1-9次 测光方式 矩阵测光；中央重点测光：约75%的比重集中在画面中央12或8mm直径圈中；比重可更改为整个画面的平均值；点测光：集中在以所选对焦点为中心的4mm直径圈中；亮部重点测光 测光范围 -4至+17EV * ISO 100、f/2.0镜头、20℃时获得的数值。 曝光模式 自动（AUTO）；带有柔性程序的程序自动（P）；快门优先自动（S）；光圈优先自动（A）；手动（M） 曝光补偿 -3至+3EV（当曝光补偿拨盘旋转至 C 时，为-5 至+5 EV），以1/3为增量 曝光锁定 将光亮度锁定在所测定的值上 ISO感光度（推荐曝光指数） ISO 100-64000 （以1/3或1 EV为增量）；可在ISO 100的基础上约减少0.3、0.7或1EV（相当于ISO 50），或者在ISO 64000 的基础上约增加0.3、0.7、1或1.7EV （相当于ISO 204800）；自动ISO 感光度控制可用 注：当色调模式选择 HLG 时，ISO 感光度限制为ISO 400 至 64000。 动态D-lighting 自动、高+、高、标准、低、关闭 多重曝光 叠加、平均、亮化、暗化 其它选项 HDR合成、照片模式闪烁消减 自动对焦系统 复合相位侦测/对比侦测自动对焦，具备自动对焦辅助 自动对焦侦测范围 –10至+19EV </em>照片模式，单次伺服AF（AF-S），ISO 100, 使用最大光圈f/1.2镜头，20 °C时。 镜头伺服 自动对焦（AF）：单次伺服AF（AF-S），连续伺服AF（AF-C）；全时AF（AF-F；仅在视频模式下可用）；预测对焦跟踪 手动对焦（M）：可以使用电子测距仪 对焦点 273个 *照片模式，AF区域模式选择单点AF，FX格式影像区域时。 AF区域模式 微点AF（仅照片模式下可用），单点AF，动态区域AF（S、M和L; 仅在照片模式</p></div></details>
</div>
<script>
function speakText(t){ if(!t){ document.getElementById('readStatus').textContent=''; return; }
 speechSynthesis.cancel(); var status=document.getElementById('readStatus'); status.textContent='准备中…';
 var chunks=[]; var maxLen=280; for(var i=0;i<t.length;i+=maxLen){ var s=t.slice(i,i+maxLen); var j=s.lastIndexOf('。'); if(j>80){ chunks.push(s.slice(0,j+1)); i-=s.length-(j+1); } else chunks.push(s); }
 if(chunks.length===0) chunks=[t]; var idx=0; function speakNext(){ if(idx>=chunks.length){ status.textContent=''; return; } var u=new SpeechSynthesisUtterance(chunks[idx]); u.lang='zh-CN'; u.rate=0.95; var v=speechSynthesis.getVoices().filter(function(x){ return x.lang.indexOf('zh')>=0; })[0]; if(v) u.voice=v;
 u.onend=function(){ idx++; setTimeout(speakNext,80); }; u.onerror=function(){ idx++; setTimeout(speakNext,80); }; status.textContent='朗读中 '+(idx+1)+'/'+chunks.length+'…'; speechSynthesis.speak(u); }
 if(speechSynthesis.getVoices().length) speakNext(); else speechSynthesis.onvoiceschanged=function(){ speechSynthesis.onvoiceschanged=null; speakNext(); }; }
function readFullText(){ var c=document.querySelector('.content'); if(!c){ document.getElementById('readStatus').textContent='无可读内容'; return; } var t=(c.innerText||'').trim().replace(/\\s+/g,' '); if(!t){ document.getElementById('readStatus').textContent='无可读内容'; return; } speechSynthesis.cancel(); document.getElementById('readStatus').textContent='全文朗读…'; speakText(t); }
function getBlockForTap(el){ var c=document.querySelector('.content'); var blockTags=['P','DIV','H2','H3','H4','LI','PRE']; while(el&&el!==c){ if(c.contains(el)&&blockTags.indexOf(el.tagName)!==-1) return el; el=el.parentElement; } return null; }
function onContentTap(e){ if(e.target.closest&&e.target.closest('a')) return; var block=getBlockForTap(e.target); if(block){ var t=(block.innerText||'').trim().replace(/\\s+/g,' '); if(t){ e.preventDefault(); speechSynthesis.cancel(); document.getElementById('readStatus').textContent='朗读本段…'; speakText(t); } } }
if(document.readyState==='loading'){ document.addEventListener('DOMContentLoaded', function(){ var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }); } else { var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }
setTimeout(function(){ try{ var u=new SpeechSynthesisUtterance('\u200b'); u.volume=0; speechSynthesis.speak(u); }catch(e){} }, 300);
</script>
</body>
</html>
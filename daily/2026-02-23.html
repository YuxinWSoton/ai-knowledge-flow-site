<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>知识流日报 2026-02-23：谐振抑制、多阶段优化规划、互联新能源电力系统、光伏直流升压汇集系统、新型电力系统平衡机理、EEMD-LSTM网络、有源和无源阻尼协同控制、大规模先进压缩空气储能、基于时空多视图学习算法、PMU电压数据重构方法、iTransformer、基于改进型主动深度学习框架、区内AGC机组分布式协同控制、跟网型和构网型变流器混合系统、新型电力系统形态量化推演方法</title>
<style>
  * { box-sizing: border-box; }
  body {
    font-family: system-ui, sans-serif;
    max-width: 720px;
    margin: 0 auto;
    padding: 2rem 1rem;
    color: #fff;
    min-height: 100vh;
    background: #0a0e1a;
    background-image:
      radial-gradient(2px 2px at 20px 30px, rgba(255,255,255,0.9), transparent),
      radial-gradient(2px 2px at 40px 70px, rgba(255,255,255,0.6), transparent),
      radial-gradient(1.5px 1.5px at 90px 40px, rgba(255,255,255,0.8), transparent),
      radial-gradient(2px 2px at 130px 80px, rgba(255,255,255,0.5), transparent),
      radial-gradient(1.5px 1.5px at 160px 120px, rgba(255,255,255,0.7), transparent),
      radial-gradient(ellipse 120% 100% at 50% 0%, rgba(88,60,120,0.25), transparent 50%),
      radial-gradient(ellipse 80% 80% at 80% 20%, rgba(40,60,100,0.2), transparent 40%);
    background-size: 200px 200px;
    background-repeat: repeat;
  }
  a { color: #a8d4ff; text-decoration: none; }
  a:hover { text-decoration: underline; }
 html{scroll-behavior:smooth;} .content h2,.content h3{scroll-margin-top:1rem;} h1,h2,h3{margin-top:1.5rem;color:#fff;} pre{white-space:pre-wrap;color:rgba(255,255,255,0.9);} .toolbar{margin:0.5rem 0;color:rgba(255,255,255,0.8);} .content{color:rgba(255,255,255,0.95);} .content a{color:#a8d4ff;} .meta{color:rgba(255,255,255,0.65);font-size:0.9em;} .toc{margin:1rem 0;padding:0.8rem 1rem;background:rgba(255,255,255,0.08);border-radius:6px;} .toc .toc-title{margin:0 0 0.5rem 0;font-weight:bold;color:rgba(255,255,255,0.9);} .toc ul{list-style:none;padding-left:0;margin:0;} .toc li{margin:0.35rem 0;} .toc li.toc-h3{padding-left:1em;font-size:0.95em;} .toc a{color:#a8d4ff;text-decoration:none;} .toc a:hover{text-decoration:underline;} .content p,.content div,.content h2,.content h3,.content h4,.content li,.content pre{cursor:pointer;-webkit-tap-highlight-color:rgba(255,255,255,0.15);} .content .insight-summary{color:#c9a0dc;margin:0.5em 0 0.8em 0;} .content .insight-detail,.content .insight-detail li{color:#8dd4e8;list-style:disc;margin-left:1.2em;padding-left:0.3em;} .content .article-body-details{margin:0.8em 0;} .content .article-body-details summary{cursor:pointer;color:rgba(255,255,255,0.85);}</style>
</head>
<body>
<p><a href="https://YuxinWSoton.github.io/ai-knowledge-flow-site/">← 返回首页</a></p>
<h1>知识流日报 2026-02-23：谐振抑制、多阶段优化规划、互联新能源电力系统、光伏直流升压汇集系统、新型电力系统平衡机理、EEMD-LSTM网络、有源和无源阻尼协同控制、大规模先进压缩空气储能、基于时空多视图学习算法、PMU电压数据重构方法、iTransformer、基于改进型主动深度学习框架、区内AGC机组分布式协同控制、跟网型和构网型变流器混合系统、新型电力系统形态量化推演方法</h1>
<p class="meta" style="margin-top:0;">最后更新：2026-02-23 15:20</p>
<p class="toolbar"><button id="btnFull" onclick="readFullText()">全文朗读</button> <span id="readStatus"></span></p>
<p class="meta" style="margin-top:0;">（点任意段落可朗读该段；「全文朗读」读本页全部内容）</p>
<nav class="toc" aria-label="目录">
<p class="toc-title">目录</p>
<ul>
  <li><a href="#toc-0">1. 互联网的10大主要用途有哪些？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-1">正文</a></li>
  <li><a href="#toc-2">2. 现在提到比较多的“AI＋”，与过去十年常提到的“互联网＋”有 ...</a></li>
  <li class="toc-h3"><a href="#toc-3">正文</a></li>
  <li><a href="#toc-4">3. “万物互联”到底是个什么概念？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-5">正文</a></li>
  <li><a href="#toc-6">4. 互联网到底是啥？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-7">正文</a></li>
  <li><a href="#toc-8">5. 为什么EMD (EEMD)分解可以用于预测？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-9">正文</a></li>
  <li><a href="#toc-10">6. EMD和EEMD对原始数据分解之后再进行重构的意义是什么 ...</a></li>
  <li class="toc-h3"><a href="#toc-11">正文</a></li>
  <li><a href="#toc-12">7. 集合经验模态分解EEMD如何做有效改进？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-13">正文</a></li>
  <li><a href="#toc-14">8. 时间序列预测，采用EEMD_LSTM模型，如何建模？</a></li>
  <li class="toc-h3"><a href="#toc-15">正文</a></li>
  <li><a href="#toc-16">9. EMD分解信号后，怎么确定其IMF分量的对应因素？</a></li>
  <li class="toc-h3"><a href="#toc-17">正文</a></li>
  <li><a href="#toc-18">10. 同一段信号，EEMD分解出的层数小于CEEMD，这是为什么呢？</a></li>
  <li class="toc-h3"><a href="#toc-19">正文</a></li>
  <li><a href="#toc-20">11. 有人用emd+lstm对时间序列进行预测，是否存在原理上的问题?</a></li>
  <li class="toc-h3"><a href="#toc-21">正文</a></li>
  <li><a href="#toc-22">12. 如何在 Python 中实现变模态分解？有相关代码吗？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-23">正文</a></li>
  <li><a href="#toc-24">13. 抖音小店怎么开通需要什么条件？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-25">正文</a></li>
  <li><a href="#toc-26">14. 抖音小店应该如何运营? - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-27">正文</a></li>
  <li><a href="#toc-28">15. 自动化测试 | PMU与PMU有什么区别吗？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-29">正文</a></li>
  <li><a href="#toc-30">16. 有基于 C/C++ 的 Web 开发框架吗？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-31">正文</a></li>
  <li><a href="#toc-32">17. Revisions | OpenReview</a></li>
  <li class="toc-h3"><a href="#toc-33">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-34">18. 突破瓶颈！我国科学家打造出新型电池-观察者网</a></li>
  <li class="toc-h3"><a href="#toc-35">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-36">19. TimeXer: Empowering Transformers for Time Series Forecasting …</a></li>
  <li class="toc-h3"><a href="#toc-37">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-38">20. FreDF: Learning to Forecast in the Frequency Domain</a></li>
  <li class="toc-h3"><a href="#toc-39">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-40">21. Crossformer: Transformer Utilizing Cross-Dimension Dependency …</a></li>
  <li class="toc-h3"><a href="#toc-41">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-42">22. A Time Series is Worth 64 Words: Long-term Forecasting with...</a></li>
  <li class="toc-h3"><a href="#toc-43">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-44">23. 电脑或者笔记本怎么投屏到电视或者投影仪或者大屏幕？</a></li>
  <li class="toc-h3"><a href="#toc-45">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-46">24. 新手开一家抖小店，保姆级7天快速起店全流程（附内部资料）</a></li>
  <li class="toc-h3"><a href="#toc-47">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-48">25. Forum | OpenReview</a></li>
  <li class="toc-h3"><a href="#toc-49">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-50">26. EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-51">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-52">27. 2025年新开始！抖店现在还能不能做？当然能！但是你得会 ...</a></li>
  <li class="toc-h3"><a href="#toc-53">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-54">28. Data Augmentation in Time Series Forecasting through Inverted Framework</a></li>
  <li class="toc-h3"><a href="#toc-55">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-56">29. An Optimization Method for Autoregressive Time Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-57">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-58">30. Selective Learning for Deep Time Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-59">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-60">31. TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-61">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-62">32. Quantum Neural Network Architectures for Multivariate Time-Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-63">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-64">33. Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City</a></li>
  <li class="toc-h3"><a href="#toc-65">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-66">34. Lossless Compression: A New Benchmark for Time Series Model Evaluation</a></li>
  <li class="toc-h3"><a href="#toc-67">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-68">35. Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces</a></li>
  <li class="toc-h3"><a href="#toc-69">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-70">36. The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss</a></li>
  <li class="toc-h3"><a href="#toc-71">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-72">37. InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling</a></li>
  <li class="toc-h3"><a href="#toc-73">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-74">38. Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition</a></li>
  <li class="toc-h3"><a href="#toc-75">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-76">39. Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-77">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-78">40. Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models</a></li>
  <li class="toc-h3"><a href="#toc-79">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-80">41. 一文读懂：大模型RAG（检索增强生成）含高级方法</a></li>
  <li class="toc-h3"><a href="#toc-81">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-82">42. ITRANSFORMER: INVERTED TRANSFORMERS ARE EFFECTIVE …</a></li>
  <li class="toc-h3"><a href="#toc-83">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-84">43. Parsimony or Capability? Decomposition Delivers Both in</a></li>
  <li class="toc-h3"><a href="#toc-85">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-86">44. AC ASE STUDY WITHP TST AND VARYING INPUT LENGTH</a></li>
  <li class="toc-h3"><a href="#toc-87">正文（抓取，非 AI）</a></li>
</ul>
</nav>
<div class="content">
<h1>知识流日报 2026-02-23：谐振抑制、多阶段优化规划、互联新能源电力系统、光伏直流升压汇集系统、新型电力系统平衡机理、EEMD-LSTM网络、有源和无源阻尼协同控制、大规模先进压缩空气储能、基于时空多视图学习算法、PMU电压数据重构方法、iTransformer、基于改进型主动深度学习框架、区内AGC机组分布式协同控制、跟网型和构网型变流器混合系统、新型电力系统形态量化推演方法</h1>
<p>共 44 条（来自百度学术 / Google / Bing 等，仅含正文抓取成功的条目；按正文长度从短到长排列，便于先听短的）。</p>
<p>（以下含抓取正文，便于阅读。未调用任何 AI API。）</p>
<p>（仅前 44 条含模型提取的「易漏细节」关键点，页面上以颜色区分；第 45 条及之后未调用模型，故无易漏细节。可在 config 中调大 extract_insights_max_items 以增加条数。）</p>
<h2 id="toc-0">1. 互联网的10大主要用途有哪些？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/650602330</li>
<li>来源：bing</li>
<li>摘要：未来，互联网的发展趋势将更加多元化和智能化。 一方面，随着5G、物联网等技术的普及，互联网将连接更多的设备和服务，实现万物互联。 另一方面，人工智能、大数据等技术将与互联网深度融合， …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，互联网将连接更多的设备和服务，这不仅意味着网络覆盖范围的扩大，也意味着更多的智能设备和在线服务将被纳入网络之中。其次，万物互联的实现需要5G、物联网等技术支持，这些技术为设备之间的高效连接提供了可能，使得数据传输更加迅速和稳定。此外，人工智能和大数据的深度融合将进一步推动互联网的发展，使得互联网不仅更加多元化，还能提供更加智能化的服务。因此，随着技术的进步，互联网将变得更加智能，能够更好地满足人们日益增长的需求。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>互联网将连接更多的设备和服务。</li>
<li>万物互联需要5G、物联网等技术支持。</li>
<li>人工智能和大数据将深度融合互联网。</li>
<li>互联网的发展将更加多元化和智能化。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-1">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-2">2. 现在提到比较多的“AI＋”，与过去十年常提到的“互联网＋”有 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/13206888056</li>
<li>来源：bing</li>
<li>摘要：2025年2月24日 · 互联网+，主要对齐网络协议为IPv4那时代。 因IPv4地址码为32位，只能提供2的32次方约40多亿个IP号，主要用于支持人机连网，不能广泛地支持物联。 比如，你在路上就想控制家中 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">IPv4地址空间有限，仅约40多亿个IP号，这使得IPv4地址不足以支持广泛物联。IPv4主要用于支持人机连网，而非物联，因此在IPv4时代，互联网＋主要局限于人机连网。IPv4地址码为32位，这一限制进一步加剧了IP数量的不足，使得IPv4无法满足日益增长的物联网需求。因此，IPv4地址空间的局限性成为制约广泛物联发展的关键因素。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>IPv4地址空间有限，仅约40多亿个IP号。</li>
<li>IPv4地址不足以支持广泛物联。</li>
<li>IPv4主要用于支持人机连网，而非物联。</li>
<li>IPv4时代的互联网＋主要局限于人机连网。</li>
<li>IPv4地址码为32位，限制了IP数量。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-3">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-4">3. “万物互联”到底是个什么概念？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/355892352</li>
<li>来源：bing</li>
<li>摘要：2019年11月19日 · 万物互联 - 万物智能互联! 6G是以5G为基础，全力支持全社会的数字化转型。而且6G在时-频-空间资源利用上将具有超灵活的优势。 在频率维度上，6G传输将使用高频段，如毫米波 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，G技术将支持全社会的数字化转型，这表明G不仅是一项先进的通信技术，更是推动社会各领域数字化的重要力量。其次，G在时-频-空间资源利用上具有超灵活的优势，这意味着它能够更高效地分配和利用有限的资源，从而提高通信效率和容量。此外，G传输将使用高频段，如毫米波，这不仅能够提供更高的带宽和更快的数据传输速度，还能够进一步增强G技术在支持数字化转型中的作用。因此，G技术的这些特性共同作用，不仅能够满足现代社会对高速、大容量数据传输的需求，还能够推动各行各业的数字化进程。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>G将支持全社会的数字化转型。</li>
<li>G在时-频-空间资源利用上具有超灵活的优势。</li>
<li>G传输将使用高频段，如毫米波。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-5">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-6">4. 互联网到底是啥？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/347500330</li>
<li>来源：bing</li>
<li>摘要：2019年10月2日 · 互联网的前身 互联网的创始应该追溯到1969年美国资助开发的一个名叫“ARPAnet”的研究项目。 美国政府认为，在不同网络之间通过转换实现互联互通，效率是非常低的。 只有用一套系 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">互联网的前身是ARPAnet，这是一个由美国政府资助的研究项目，最初的目标是提高网络互联的效率。美国政府资助开发ARPAnet，旨在通过这一研究项目提升网络的互联性，从而在技术层面上实现更高效的信息传输和共享。因此，ARPAnet不仅标志着互联网的起源，也体现了早期政府在推动科技创新方面的重要作用。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>互联网的前身是ARPAnet。</li>
<li>美国政府资助开发ARPAnet是为了提高网络互联的效率。</li>
<li>ARPAnet最初是由美国政府资助的研究项目。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-7">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-8">5. 为什么EMD (EEMD)分解可以用于预测？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/422172882</li>
<li>来源：bing</li>
<li>摘要：2020年9月22日 · 1.3 怎么实现EEMD? Rlibeemd是R语言下的一个EEMD算法包，它提供了多种EEMD算法的实现，并支持分解结果可视化。 该包的优点在于它提供了多种EEMD算法的选择，标准的EMD …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">EMD (EEMD)分解因其独特的预测能力而被广泛应用于时间序列分析中，它能够有效地将复杂的时间序列信号分解为一系列相对独立的固有模态函数（IMFs），从而便于后续的分析和预测。EEMD算法包提供了多种分解算法的选择，使得用户可以根据具体需求灵活调整分解策略，以达到最佳的分析效果。此外，EEMD分解的结果可以通过可视化工具进行展示，这不仅有助于直观地理解分解后的各IMFs特性，还能为后续的信号处理和预测提供重要的参考信息。因此，EMD (EEMD)分解不仅是一种有效的预测工具，还具备强大的灵活性和可视化支持，使得其在实际应用中具有广泛的应用前景。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>EMD (EEMD)分解可以用于预测。</li>
<li>EEMD算法包支持多种分解算法选择。</li>
<li>EEMD分解结果可以通过可视化工具进行展示。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-9">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-10">6. EMD和EEMD对原始数据分解之后再进行重构的意义是什么 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/301240606</li>
<li>来源：bing</li>
<li>摘要：2020年3月7日 · 某信号分解得到的低频分量 观察上边两张高频分量和低频分量图，应该更容易理解高频分量均值趋近于0，低频分量更不易趋近于0。 举例说明，还是以上篇文章中的2012-2020年原油期货 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，EMD（Empirical Mode Decomposition）和EEMD（Ensemble Empirical Mode Decomposition）分解可以将信号分解为不同频率的成分，这一过程有助于提取信号的多种频率信息。其次，高频分量的均值接近0，这表明这些分量主要包含噪声，因此高频分量主要用于去除噪声。此外，低频分量不易趋近于0，表明其包含有用信息，因此低频分量保留了信号的主要趋势。因此，EMD和EEMD分解有助于分离信号中的噪声与有用信息，从而在信号处理中发挥重要作用。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>EMD和EEMD分解后的重构可以提取信号的不同频率成分。</li>
<li>高频分量的均值接近0，意味着这些分量主要包含噪声。</li>
<li>低频分量不易趋近于0，表明其包含有用信息。</li>
<li>EMD和EEMD分解有助于分离信号中的噪声与有用信息。</li>
<li>高频分量主要用于去除噪声，而低频分量保留了信号的主要趋势。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-11">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-12">7. 集合经验模态分解EEMD如何做有效改进？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/598584478</li>
<li>来源：bing</li>
<li>摘要：综合 来说，EEMD 算法会有计算量大和参数设置具有主观性这两个缺陷 [1]。 1 快速集合经验模态分解FEEMD介绍 EEMD简介: FEEMD（Fast Ensemble Empirical Mode Decomposition）是 EEMD 的一 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">EEMD算法虽然在信号处理中具有显著优势，能够有效分解复杂信号，但其计算量大，且参数设置具有一定的主观性，这限制了其在实际应用中的广泛使用。为了解决这些问题，快速集合经验模态分解（FEEMD）应运而生，旨在改进EEMD的计算效率，从而使得信号处理更加高效和自动化。因此，FEEMD不仅能够克服EEMD的计算瓶颈，还通过优化参数设置，减少了主观性的影响，使得信号处理更加可靠和高效。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>EEMD算法计算量大。</li>
<li>EEMD算法的参数设置具有主观性。</li>
<li>快速集合经验模态分解FEEMD旨在改进EEMD的计算效率。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-13">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-14">8. 时间序列预测，采用EEMD_LSTM模型，如何建模？</h2>
<ul>
<li>链接：https://www.zhihu.com/question/470976344</li>
<li>来源：bing</li>
<li>摘要：2021年7月9日 · 利用EEMD方法对时间序列进行分解后，建议采用合适的模态筛选指标对合适的IMF分量进行筛选并重构，将重构后的时间序列输入LSTM模型进行预测。 以旋转机械故障诊断为例：比如采 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，EEMD（经验模式分解）方法能够有效地将时间序列分解为多个IMF（瞬时模式函数）分量，这一过程对于后续分析至关重要。然而，为了确保分解结果的有效性，必须选择合适的IMF分量进行筛选，这一步骤对最终结果的影响尤为关键。其次，筛选出的IMF分量需要经过重构，以恢复原始时间序列的形态。重构后的序列应当符合LSTM（长短期记忆网络）模型的输入要求，这样才能确保预测的准确性。因此，通过EEMD分解、筛选合适的IMF分量以及重构时间序列，最终可以利用LSTM模型进行预测，这一系列步骤构成了从时间序列到预测的完整流程。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>EEMD方法可以分解时间序列，但需要筛选合适的IMF分量后再重构。</li>
<li>筛选指标的选择对IMF分量的选择至关重要。</li>
<li>重构后的时间序列应符合LSTM模型的输入要求。</li>
<li>LSTM模型适用于预测重构后的时间序列。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-15">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-16">9. EMD分解信号后，怎么确定其IMF分量的对应因素？</h2>
<ul>
<li>链接：https://www.zhihu.com/question/479290083</li>
<li>来源：bing</li>
<li>摘要：2022年4月25日 · 之前我们有了十几篇文章讲述了EMD算法的基础理论、IMF的含义、EMD的MATLAB实现方法， EEMD 、 CEEMD 、 CEEMDAN 、 VMD 、 ICEEMDAN 、 LMD 、 EWT 的理论及代码实 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">EMD分解后的IMF分量在实际应用中具有重要意义，但其解释依赖于具体的应用背景，且缺乏统一的方法。EMD分解结果的质量受到原始信号特性的显著影响，因此，IMF分量可能包含噪声，需要进一步处理。此外，EMD分解可能产生模态混叠，这会进一步影响分量的识别。因此，IMF分量的解释还需结合专业知识，以确保准确性和可靠性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>EMD分解后的IMF分量对应因素的确定没有统一方法。</li>
<li>EMD分解结果的解释依赖于具体应用背景。</li>
<li>EMD分解后的IMF分量可能包含噪声，需进一步处理。</li>
<li>EMD分解结果的质量依赖于原始信号特性。</li>
<li>EMD分解可能产生模态混叠，影响分量识别。</li>
<li>EMD分解后的IMF分量需结合专业知识进行解释。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-17">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-18">10. 同一段信号，EEMD分解出的层数小于CEEMD，这是为什么呢？</h2>
<ul>
<li>链接：https://www.zhihu.com/question/590555751</li>
<li>来源：bing</li>
<li>摘要：EEMD和CEEMD都是一种基于EMD（经验模态分解）的信号 分解方法，它们的不同之处在于CEEMD中加入了 旋转因子 以减少模态混叠现象。因此，CEEMD通常比EEMD更能有效地解决 模态混叠 问 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">EEMD分解出的层数较少是因为CEEMD加入了旋转因子以减少模态混叠现象，而模态混叠是导致信号分解不完全的重要因素。CEEMD通过引入旋转因子，不仅有效地解决了模态混叠问题，还使得信号的分解更加彻底和准确。因此，CEEMD通常比EEMD更能有效地解决模态混叠问题，从而提高了信号分析的精度和可靠性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>EEMD分解出的层数较少是因为CEEMD加入了旋转因子以减少模态混叠现象。</li>
<li>CEEMD通常比EEMD更能有效地解决模态混叠问题。</li>
<li>旋转因子的加入有助于CEEMD更好地分解信号。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-19">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-20">11. 有人用emd+lstm对时间序列进行预测，是否存在原理上的问题?</h2>
<ul>
<li>链接：https://www.zhihu.com/question/344152054</li>
<li>来源：bing</li>
<li>摘要：2020年6月20日 · 很不幸，这种方法的确存在致命缺陷。最近投了一篇使用 EMD + LSTM 进行时序预测的 SCI论文 被拒稿，审稿人也提到 信息泄露 的问题，而且就算划分train 和test后再分别使用EMD分 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">信息泄露是模型性能评估不准确的主要原因之一，尤其是在时间序列预测中。审稿人指出，EMD（经验模式分解）处理方法在训练集和测试集上的不一致可能导致信息泄露，进而影响模型的评估准确性。因此，为了确保模型性能评估的准确性，EMD处理应在训练集和测试集上保持一致，避免因处理方法不一致而造成的信息泄露。在时间序列预测中，尤其需要注意这一点，以确保模型的评估结果真实可靠。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>信息泄露会导致模型性能评估不准确。</li>
<li>EMD处理应在训练集和测试集上保持一致。</li>
<li>审稿人指出的方法缺陷是信息泄露。</li>
<li>时间序列预测中EMD处理需谨慎以避免信息泄露。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-21">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-22">12. 如何在 Python 中实现变模态分解？有相关代码吗？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/382703608</li>
<li>来源：bing</li>
<li>摘要：2020年3月26日 · 3.EEMD属于第三梯队，作为改进方法有其优越性，但也有比较明显的短板。 4.EMD和EWT属于第四梯队，虽然EWT属于比较新的分解方法，不过在实际使用中效果往往不太理想，在使 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">EEMD属于第三梯队，尽管它具有一定的优越性，但同时也存在明显的短板。相比之下，EMD和EWT则属于第四梯队，其中EWT是一种较为新颖的分解方法，理论上具有较高的潜力。然而，实际应用中，EWT的效果往往不尽如人意，这表明尽管EWT在理论上具有优势，但在实际操作中却难以达到预期的效果。因此，选择合适的信号分解方法需要综合考虑理论优势和实际应用效果。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>EEMD属于第三梯队，但有其优越性。</li>
<li>EEMD有比较明显的短板。</li>
<li>EMD和EWT属于第四梯队。</li>
<li>EWT属于比较新的分解方法。</li>
<li>EWT在实际使用中的效果往往不太理想。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-23">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-24">13. 抖音小店怎么开通需要什么条件？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/496566487</li>
<li>来源：bing</li>
<li>摘要：随着短视频的火爆，越来越多的商家投入到了抖音电商这个行列，可以抖音小店开通需要什么条件呢？？ 下面小编详细为大家介绍一下~ 抖音小店入驻条件及费用 抖音小店入驻条件需要的资质： 一、主体 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">开通抖音小店无需缴纳任何费用，这使得许多商家能够轻松地参与到抖音电商中来。然而，为了顺利开设店铺，商家必须首先满足主体资质的要求，这是必不可少的条件之一。此外，商家还需要投入时间和资源来参与抖音电商，这包括了解平台规则、策划营销活动以及维护店铺运营等。因此，虽然开通小店无需支付费用，但商家仍需在满足资质要求的基础上，投入相应的精力和资源，才能在抖音电商中取得成功。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>开通抖音小店无需缴纳任何费用。</li>
<li>主体资质是必须满足的条件之一。</li>
<li>商家需要投入参与抖音电商的行列。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-25">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-26">14. 抖音小店应该如何运营? - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/423257489</li>
<li>来源：bing</li>
<li>摘要：1、了解抖音小店规则 在我们开通抖音小店后，首先需要在后台“学习中心”，了解小店规则，这个是非常重要。你想运营好抖音小店，那熟悉规则就是第一步，尤其是抖音小店商品发布规则，导致商品违规 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">熟悉规则是运营抖音小店的基础，这不仅有助于确保店铺的正常运行，还能避免因不了解规则而带来的不必要的麻烦。其中，商品发布规则尤为重要，因为一旦违反这些规则，可能会导致违规情况的发生，进而影响店铺的信誉和运营。因此，深入了解并严格遵守各项规则，是保障店铺顺利运营的关键。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>熟悉规则是运营抖音小店的基础。</li>
<li>商品发布规则需特别注意，可能导致违规。</li>
<li>了解规则有助于避免不必要的麻烦。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-27">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-28">15. 自动化测试 | PMU与PMU有什么区别吗？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/594851077</li>
<li>来源：bing</li>
<li>摘要：在自动化测试中，PMU和PMI是两个不同的概念，它们分别代表着“性能监测单元”和“性能监测接口”。 PMU（Performance Monitoring Unit）指的是一种硬件模块或者芯片，通常用于CPU、GPU等设备 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">PMU是硬件模块或芯片，而非软件接口，其主要功能是实时监测系统的性能数据。与此不同，PMI指的是“性能监测接口”，它并非硬件模块，而是用于软件层面的接口，用于获取和传输PMU收集的性能数据。因此，PMU和PMI是两个不同的概念，前者是硬件设备，后者是软件接口，两者共同作用于系统性能的监测和分析。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>PMU是硬件模块或芯片，而非软件接口。</li>
<li>PMU与PMI是两个不同的概念。</li>
<li>PMI指的是“性能监测接口”，而非硬件模块。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-29">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-30">16. 有基于 C/C++ 的 Web 开发框架吗？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/11084761501</li>
<li>来源：bing</li>
<li>摘要：有一个轻量级的web库叫crow，它是基于boost::asio的一个二次封装，特点是本身只有一个头文件，所以使用起来相对简单，而且它有超高的性能，这个库有7.5k的star（新的地址还有3.6k的star，加起来上 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">crow库是一个轻量级的C++网络库，其设计简洁高效，仅包含一个头文件，这使得它的使用和集成变得极为便捷。首先，crow库基于boost::asio进行二次封装，这意味着它继承了boost::asio的高性能特性，同时提供了更简洁、易用的接口。其次，crow库具有较高的性能，这得益于其对底层boost::asio的优化和封装，使得开发者能够以较低的资源消耗实现高效的数据处理和网络通信。因此，crow库不仅易于使用，而且在实际应用中能够提供出色的性能表现。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>crow库只有一个头文件。</li>
<li>crow库基于boost::asio进行二次封装。</li>
<li>crow库具有较高的性能。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-31">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-32">17. Revisions | OpenReview</h2>
<ul>
<li>链接：https://openreview.net/revisions?id=NfbBdPzcbp</li>
<li>来源：bing</li>
<li>摘要：2025年5月11日 · Title: iTransformer: Inverted Transformers Are Effective for Time Series Forecasting. Authors: Yong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang 0001, Lintao Ma, Mingsheng …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，iTransformer模型采用反转结构，这种结构可能更有效进行时间序列预测，因此值得进一步研究。其次，尽管传统正向Transformer在时间序列预测中广泛应用，但其未必优于反转结构的iTransformer，这表明时间序列预测任务可能不适合所有类型的Transformer变体。此外，iTransformer的结构创新可能带来更好的预测性能，但其在时间序列预测中的效果仍需进一步验证。最后，时间序列数据的特性可能影响不同Transformer变体的表现，因此在实际应用中需要综合考虑这些因素。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>iTransformer模型采用反转结构，可能更有效进行时间序列预测。</li>
<li>反转结构的时间序列预测模型iTransformer值得进一步研究。</li>
<li>时间序列预测中，传统正向Transformer未必优于反转结构的iTransformer。</li>
<li>时间序列预测任务可能不适合所有类型的Transformer变体。</li>
<li>iTransformer的结构创新可能带来更好的预测性能。</li>
<li>反转Transformer在时间序列预测中的效果有待验证。</li>
<li>时间序列数据的特性可能影响不同Transformer变体的表现。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-33">正文（抓取，非 AI）</h3>
<p>Revisions | OpenReview Loading</p>
</div></details><h2 id="toc-34">18. 突破瓶颈！我国科学家打造出新型电池-观察者网</h2>
<ul>
<li>链接：https://m.guancha.cn/politics/2026_02_19_807511.shtml</li>
<li>来源：bing</li>
<li>摘要：4 天之前 · 天津大学许运华教授团队联合华南理工大学黄飞教授团队等单位，成功研制出一种新型有机正极材料，突破了传统有机锂电池“电量低”“难以实用化”等瓶颈。 相关研究成果于北京时间2月19日在线 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">新型有机正极材料突破了传统有机锂电池“电量低”“难以实用化”等瓶颈，通过调控材料中电子与锂离子的“协同传输”效率，研制出新型有机正极材料。这种材料的分子结构可灵活设计且自身柔韧，但制成的电池往往“电量”不足或充电缓慢。因此，研究团队通过优化材料结构，使得新型有机软包电池能量密度超过250瓦时/公斤，已超越目前广泛使用的磷酸铁锂电池。此外，有机软包电池展现出卓越的温度适应能力和良好的柔韧性与安全性，团队研制的软包电池通过了严格的针刺安全测试，安全性得到验证。因此，新型有机正极材料不仅为未来开发“绿色电池”奠定了关键材料基础，柔性特质也为未来柔性电子、可穿戴设备等领域提供了全新的储能解决方案。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>新型有机正极材料突破了传统有机锂电池“电量低”“难以实用化”等瓶颈。</li>
<li>有机电极材料的分子结构可灵活设计且自身柔韧，但制成的电池往往“电量”不足或充电缓慢。</li>
<li>研究团队通过调控材料中电子与锂离子的“协同传输”效率，研制出新型有机正极材料。</li>
<li>新型有机软包电池能量密度超过250瓦时/公斤，已超越目前广泛使用的磷酸铁锂电池。</li>
<li>有机软包电池展现出卓越的温度适应能力和良好的柔韧性与安全性。</li>
<li>团队研制的软包电池通过了严格的针刺安全测试，安全性得到验证。</li>
<li>新型有机正极材料为未来开发“绿色电池”奠定了关键材料基础。</li>
<li>柔性特质也为未来柔性电子、可穿戴设备等领域提供了全新的储能解决方案。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-35">正文（抓取，非 AI）</h3>
<p>突破瓶颈！我国科学家打造出新型电池-观察者网 我国科学家打造出安全、抗冻、耐热新型电池 来源：央视新闻客户端 2026-02-19 12:29 天津大学许运华教授团队联合华南理工大学黄飞教授团队等单位，成功研制出一种新型有机正极材料，突破了传统有机锂电池“电量低”“难以实用化”等瓶颈。相关研究成果于北京时间2月19日在线发表于国际学术期刊《自然》。 在科技革命与能源转型浪潮中，锂电池犹如现代社会的“能量心脏”，其重要性日益凸显。目前，主流锂电池正极材料大多使用钴、镍等无机矿物，这类材料面临资源短缺、成本较高及柔性不足等多重问题。相比之下，有机电极材料取材广泛，其分子结构可灵活设计且自身柔韧。然而，这类材料制成的电池往往“电量”不足或充电缓慢，严重阻碍其实用化进程。 △能量密度超过250瓦时/公斤的有机软包电池。 为解决这一困境，研究团队在一种新型导电聚合物材料基础上，系统调控了材料中电子与锂离子的“协同传输”效率，成功研制出一种兼具优异电子导电性、锂离子快速传输能力和高储能容量的有机正极材料。 基于此材料，团队制备出一款能量密度超过250瓦时/公斤的有机软包电池，这一数值已超越目前广泛使用的磷酸铁锂电池。这款电池展现出卓越的温度适应能力，不仅能在-70℃到80℃的温度下正常工作，还兼具良好的柔韧性与安全性。 △有机软包电池性能图。 实验表明，其电极在弯折、拉伸、外力挤压等情况下无破损，且电池容量不减。团队研制的软包电池成功通过了严格的针刺安全测试，安全性得到验证。 许运华表示，相关成果为未来开发“绿色电池”奠定了关键材料基础，其柔性特质也为未来柔性电子、可穿戴设备等领域提供了全新的储能解决方案。 据悉，团队正加快推进这项技术的成果转化与产业化进程，致力于建设有机软包电池生产线，积极探索其商业化应用前景。 责任编辑：胡致 观察者APP，更好阅读体验 举报 取消 请选择举报理由 违反法律法规 垃圾信息广告 色情、淫秽内容 人身攻击 谣言、不实信息 冒充、冒用信息 其它 涉未成年人有害信息 提交 Copyright©2021观察者 沪ICP备1021382-2号 互联网信息许可证：3112014003 拱火的来了，“美一众盟友惨了，中国巴西受益最大” “绝不接受！美国不说清楚就停掉” “特朗普想不通，伊朗为什么还不屈服” 5金4银6铜！中国冬奥军团刷新境外参赛最好成绩 “咋整？特朗普对华筹码又少了”</p>
</div></details><h2 id="toc-36">19. TimeXer: Empowering Transformers for Time Series Forecasting …</h2>
<ul>
<li>链接：https://openreview.net/forum?id=INAeUQ04lT</li>
<li>来源：bing</li>
<li>摘要：2024年9月25日 · Deep models have demonstrated remarkable performance in time series forecasting. However, due to the partially-observed nature of real-world applications, solely focusing on the target …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">real-world applications often involve partially-observed data, making it challenging to focus solely on endogenous variables for accurate forecasting. Exogenous variables, which provide valuable external information, complement endogenous variables and are crucial for improving forecasting accuracy. TimeXer, a novel approach to time series forecasting, focuses on incorporating exogenous variables into the forecasting process. It achieves this by using patch-wise self-attention and variate-wise cross-attention mechanisms, which reconcile endogenous and exogenous information. Additionally, TimeXer learns global endogenous tokens to bridge causal information from exogenous to endogenous series, ensuring a comprehensive understanding of the data. This design not only addresses practical forecasting needs but also achieves state-of-the-art performance on real-world forecasting benchmarks. The embedding layers in TimeXer are crucial for handling exogenous information, and the simultaneous use of self-attention and cross-attention mechanisms enhances its ability to incorporate external information. Therefore, TimeXer's general and scalable design, along with its consistent performance across various real-world forecasting benchmarks, makes it a powerful tool for improving the accuracy of endogenous variable forecasting.</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>real-world applications are partially-observed, making endogenous variable focus insufficient for accurate forecasting.</li>
<li>exogenous variables provide valuable external information that complements endogenous variables.</li>
<li>TimeXer focuses on incorporating exogenous variables into time series forecasting.</li>
<li>endogenous and exogenous information are reconciled using patch-wise self-attention and variate-wise cross-attention.</li>
<li>global endogenous tokens are learned to bridge causal information from exogenous to endogenous series.</li>
<li>TimeXer achieves state-of-the-art performance on real-world forecasting benchmarks.</li>
<li>TimeXer is designed to be general and scalable for time series forecasting.</li>
<li>external information is crucial for improving the accuracy of endogenous variable forecasting.</li>
<li>multivariate or univariate forecasting paradigms often ignore exogenous information.</li>
<li>TimeXer uses a novel approach to enhance forecasting with external information.</li>
<li>embedding layers are crucial for TimeXer's ability to handle exogenous information.</li>
<li>self-attention and cross-attention mechanisms are used simultaneously in TimeXer.</li>
<li>exogenous information can significantly improve the forecasting of endogenous variables.</li>
<li>TimeXer's design addresses practical forecasting needs by considering exogenous variables.</li>
<li>TimeXer's performance is consistent across various real-world forecasting benchmarks.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-37">正文（抓取，非 AI）</h3>
<p>TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables | OpenReview Go to NeurIPS 2024 Conference homepage TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables Yuxuan Wang , Haixu Wu , Jiaxiang Dong , Guo Qin , Haoran Zhang , Yong Liu , Yunzhong Qiu , Jianmin Wang , Mingsheng Long Published: 25 Sept 2024, Last Modified: 31 Jan 2025 NeurIPS 2024 poster Everyone Revisions BibTeX CC BY 4.0 Keywords : Transformer, Time Series Forecasting, Exogenous Variable Abstract : Deep models have demonstrated remarkable performance in time series forecasting. However, due to the partially-observed nature of real-world applications, solely focusing on the target of interest, so-called endogenous variables, is usually insufficient to guarantee accurate forecasting. Notably, a system is often recorded into multiple variables, where the exogenous variables can provide valuable external information for endogenous variables. Thus, unlike well-established multivariate or univariate forecasting paradigms that either treat all the variables equally or ignore exogenous information, this paper focuses on a more practical setting: time series forecasting with exogenous variables. We propose a novel approach, TimeXer, to ingest external information to enhance the forecasting of endogenous variables. With deftly designed embedding layers, TimeXer empowers the canonical Transformer with the ability to reconcile endogenous and exogenous information, where patch-wise self-attention and variate-wise cross-attention are used simultaneously. Moreover, global endogenous tokens are learned to effectively bridge the causal information underlying exogenous series into endogenous temporal patches. Experimentally, TimeXer achieves consistent state-of-the-art performance on twelve real-world forecasting benchmarks and exhibits notable generality and scalability. Code is available at this repository: https://github.com/thuml/TimeXer. Supplementary Material : zip Primary Area : Deep learning architectures Submission Number : 3309 Loading OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . © 2026 OpenReview</p>
</div></details><h2 id="toc-38">20. FreDF: Learning to Forecast in the Frequency Domain</h2>
<ul>
<li>链接：https://openreview.net/forum?id=4A9IdSa1ul</li>
<li>来源：bing</li>
<li>摘要：2025年1月22日 · For FreDF, we fix the hyperparameters associated with the forecast models, such as the iTransformer and TimesNet, and only fine-tune the frequency loss strength α and the learning rate …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">当前的预测模型在细调过程中通常固定了预测模型的超参数，而频繁调整损失强度和学习率，这可能导致预测模型在长期预测中的准确性下降。此外，当前的预测模型往往忽视了未来序列标签之间的关联性，这进一步加剧了预测偏差。为了解决这一问题，FreDF（Frequency Domain Forecasting）通过在频域中学习来改进预测性能，从而解决了由标签关联性引起的学习目标偏差。FreDF不仅兼容各种预测模型，如iTransformer和TimesNet，还通过减轻标签关联性来减少估计偏差，从而在实验中表现出色，显著提高了长期预测的准确性。因此，FreDF在提升预测模型性能方面具有重要优势，特别是在处理长期预测任务时。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>forecasting models' hyperparameters are fixed while fine-tuning frequency loss strength and learning rate</li>
<li>label correlations among future sequences are often overlooked in current forecasting models</li>
<li>FreDF addresses the bias in learning objectives caused by label correlations</li>
<li>FreDF improves forecasting performance by learning in the frequency domain</li>
<li>FreDF is compatible with various forecast models like iTransformer and TimesNet</li>
<li>label correlations are important for long-term forecast accuracy</li>
<li>current forecasting models primarily follow the Direct Forecast paradigm</li>
<li>FreDF reduces estimation bias by mitigating label correlations</li>
<li>FreDF outperforms existing state-of-the-art methods in experiments</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-39">正文（抓取，非 AI）</h3>
<p>FreDF: Learning to Forecast in the Frequency Domain | OpenReview Go to ICLR 2025 Conference homepage FreDF: Learning to Forecast in the Frequency Domain Hao Wang , Lichen Pan , Yuan Shen , Zhichao Chen , Degui Yang , Yifei Yang , Sen Zhang , Xinggao Liu , Haoxuan Li , Dacheng Tao Published: 22 Jan 2025, Last Modified: 02 Apr 2025 ICLR 2025 Poster Everyone Revisions BibTeX CC BY 4.0 Keywords : Time series, Long-term Forecast TL;DR : Learning to forecast in the frequency domain improves forecasting performance. Abstract : Time series modeling presents unique challenges due to autocorrelation in both historical data and future sequences. While current research predominantly addresses autocorrelation within historical data, the correlations among future labels are often overlooked. Specifically, modern forecasting models primarily adhere to the Direct Forecast (DF) paradigm, generating multi-step forecasts independently and disregarding label correlations over time. In this work, we demonstrate that the learning objective of DF is biased in the presence of label correlation. To address this issue, we propose the Frequency-enhanced Direct Forecast (FreDF), which mitigates label correlation by learning to forecast in the frequency domain, thereby reducing estimation bias. Our experiments show that FreDF significantly outperforms existing state-of-the-art methods and is compatible with a variety of forecast models. Code is available at https://github.com/Master-PLC/FreDF. Supplementary Material : pdf Primary Area : learning on time series and dynamical systems Code Of Ethics : I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics. Submission Guidelines : I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2025/AuthorGuide. Anonymous Url : I certify that there is no URL (e.g., github page) that could be used to find authors’ identity. No Acknowledgement Section : I certify that there is no acknowledgement section in this submission for double blind review. Submission Number : 13602 Loading OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . © 2026 OpenReview</p>
</div></details><h2 id="toc-40">21. Crossformer: Transformer Utilizing Cross-Dimension Dependency …</h2>
<ul>
<li>链接：https://openreview.net/forum?id=vSVLM2j9eie</li>
<li>来源：bing</li>
<li>摘要：2023年2月1日 · We propose Crossformer, a Transformer-based model that explicitly utilizes cross-dimension dependency for multivariate time series forecasting.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">Crossformer是一种专门为多变量时间序列预测设计的Transformer模型，它能够同时捕捉时间维度和变量维度的依赖关系。为了实现这一目标，Crossformer通过DSW嵌入保留时间和维度信息，从而高效地捕捉这两种维度的依赖关系。此外，TSA层进一步增强了这一能力，使得模型能够利用不同尺度的信息进行预测。相比之下，现有的Transformer模型往往忽略了变量维度的依赖关系，这使得Crossformer在处理多变量时间序列数据时具有明显优势。因此，Crossformer的有效性已经在六个真实数据集上得到了验证，证明了其在实际应用中的可靠性和优越性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Crossformer可以捕捉时间维度和变量维度的依赖关系。</li>
<li>Crossformer通过DSW嵌入保留时间和维度信息。</li>
<li>TSA层有助于高效捕捉时间维度和变量维度的依赖关系。</li>
<li>Crossformer通过层次编码器-解码器结构利用不同尺度的信息进行预测。</li>
<li>现有Transformer模型往往忽略了变量维度的依赖关系。</li>
<li>Crossformer的有效性在六个真实数据集上得到了验证。</li>
<li>Crossformer是专门为多变量时间序列预测设计的Transformer模型。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-41">正文（抓取，非 AI）</h3>
<p>Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting | OpenReview Go to ICLR 2023 Conference homepage Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting Yunhao Zhang , Junchi Yan Published: 01 Feb 2023, Last Modified: 02 Mar 2023 ICLR 2023 notable top 5% Readers: Everyone Keywords : Transformer, multivariate time series forecasting, deep learning Abstract : Recently many deep models have been proposed for multivariate time series (MTS) forecasting. In particular, Transformer-based models have shown great potential because they can capture long-term dependency. However, existing Transformer-based models mainly focus on modeling the temporal dependency (cross-time dependency) yet often omit the dependency among different variables (cross-dimension dependency), which is critical for MTS forecasting. To fill the gap, we propose Crossformer, a Transformer-based model utilizing cross-dimension dependency for MTS forecasting. In Crossformer, the input MTS is embedded into a 2D vector array through the Dimension-Segment-Wise (DSW) embedding to preserve time and dimension information. Then the Two-Stage Attention (TSA) layer is proposed to efficiently capture the cross-time and cross-dimension dependency. Utilizing DSW embedding and TSA layer, Crossformer establishes a Hierarchical Encoder-Decoder (HED) to use the information at different scales for the final forecasting. Extensive experimental results on six real-world datasets show the effectiveness of Crossformer against previous state-of-the-arts. Anonymous Url : I certify that there is no URL (e.g., github page) that could be used to find authors’ identity. No Acknowledgement Section : I certify that there is no acknowledgement section in this submission for double blind review. Code Of Ethics : I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics Submission Guidelines : Yes Please Choose The Closest Area That Your Submission Falls Into : Applications (eg, speech processing, computer vision, NLP) TL;DR : We propose Crossformer, a Transformer-based model that explicitly utilizes cross-dimension dependency for multivariate time series forecasting. 21 Replies Loading OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . © 2026 OpenReview</p>
</div></details><h2 id="toc-42">22. A Time Series is Worth 64 Words: Long-term Forecasting with...</h2>
<ul>
<li>链接：https://openreview.net/forum?id=Jbdc0vTOcol</li>
<li>来源：bing</li>
<li>摘要：2023年2月1日 · Channel-independent patch time series transformer works very well for long-term forecasting and representation learning.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，time series 的处理可以显著提升长期预测的准确性，这是因为每个通道包含单一的单变量时间序列，即 channel-independence，这使得模型能够专注于单一变量的变化趋势。其次，patching 设计通过保留局部语义信息，不仅减少了注意力图的计算和内存使用，还允许模型关注更长的历史，从而进一步提升预测的准确性。因此，channel-independent patch time series Transformer 能够显著提高长期预测的准确性。此外，该模型在自监督预训练任务中表现出色，并且在不同数据集上的转移学习也能达到SOTA预测准确性，这表明其具有良好的泛化能力和实用性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>time series 的处理可以显著提升长期预测的准确性。</li>
<li>channel-independence 使得每个通道包含单一的单变量时间序列。</li>
<li>patching 设计保留了局部语义信息。</li>
<li>patching 设计减少了注意力图的计算和内存使用。</li>
<li>patching 设计允许模型关注更长的历史。</li>
<li>channel-independent patch time series Transformer 能够显著提高长期预测的准确性。</li>
<li>该模型在自监督预训练任务中表现出色。</li>
<li>预训练模型在不同数据集上的转移学习也能达到SOTA预测准确性。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-43">正文（抓取，非 AI）</h3>
<p>A Time Series is Worth 64 Words: Long-term Forecasting with Transformers | OpenReview Go to ICLR 2023 Conference homepage A Time Series is Worth 64 Words: Long-term Forecasting with Transformers Yuqi Nie , Nam H Nguyen , Phanwadee Sinthong , Jayant Kalagnanam Published: 01 Feb 2023, Last Modified: 14 Jan 2026 ICLR 2023 poster Readers: Everyone Keywords : time series, transformer, forecasting, channel-independence, self-supervised learning, representation learning TL;DR : Channel-independent patch time series transformer works very well for long-term forecasting and representation learning. Abstract : We propose an efficient design of Transformer-based models for multivariate time series forecasting and self-supervised representation learning. It is based on two key components: (i) segmentation of time series into subseries-level patches which are served as input tokens to Transformer; (ii) channel-independence where each channel contains a single univariate time series that shares the same embedding and Transformer weights across all the series. Patching design naturally has three-fold benefit: local semantic information is retained in the embedding; computation and memory usage of the attention maps are quadratically reduced given the same look-back window; and the model can attend longer history. Our channel-independent patch time series Transformer (PatchTST) can improve the long-term forecasting accuracy significantly when compared with that of SOTA Transformer-based models. We also apply our model to self-supervised pre-training tasks and attain excellent fine-tuning performance, which outperforms supervised training on large datasets. Transferring of masked pre-training performed on one dataset to other datasets also produces SOTA forecasting accuracy. Anonymous Url : I certify that there is no URL (e.g., github page) that could be used to find authors’ identity. No Acknowledgement Section : I certify that there is no acknowledgement section in this submission for double blind review. Code Of Ethics : I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics Submission Guidelines : Yes Please Choose The Closest Area That Your Submission Falls Into : Applications (eg, speech processing, computer vision, NLP) Community Implementations : <a href="https://www.catalyzex.com/paper/a-time-series-is-worth-64-words-long-term/code"><img alt="CatalyzeX" src="/images/catalyzex_icon.svg"/> 4 code implementations</a> 21 Replies Loading OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . © 2026 OpenReview</p>
</div></details><h2 id="toc-44">23. 电脑或者笔记本怎么投屏到电视或者投影仪或者大屏幕？</h2>
<ul>
<li>链接：https://www.zhihu.com/tardis/bd/ans/3157494202</li>
<li>来源：bing</li>
<li>摘要：2023年8月9日 · 一、Windows 电脑投屏方法 微软自Windows 8.1开始就在系统内置 Miracast 的投屏功能（官方功能称“无线投影”）。这个协议可以提供给用户镜像复制电脑屏幕的功能；也能实现扩展延 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">Miracast投屏需要电脑具备无线WiFi功能，而Windows 8.1及更高版本支持这一功能，其中Windows 10和Windows 11系统更是内置了Miracast投屏，而Windows 7则不支持，需借助第三方软件实现。此外，Windows 8.1投屏需要鼠标点击操作，而Windows 10则需点击屏幕右下角的「操作中心」。相比之下，macOS Big Sur 11.0及以上版本将屏幕镜像功能内置到控制中心，而macOS Catalina 10.15及以下版本则需确保「隔空播放」图标可见。对于企业或学校场景，AWDL支持P2P Airplay投屏功能，而无线HDMI投屏设备则更为便捷，即插即用且无需安装软件，使用范围更广，更加灵活。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Miracast投屏需要电脑具备无线WiFi功能。</li>
<li>Windows 8.1及更高版本支持Miracast投屏。</li>
<li>Windows 10和Windows 11系统支持Miracast投屏。</li>
<li>Windows 7不支持Miracast投屏。</li>
<li>Windows 8.1投屏需要鼠标点击操作。</li>
<li>Windows 10投屏需要点击屏幕右下角的「操作中心」。</li>
<li>Windows 7需要借助第三方软件实现投屏。</li>
<li>macOS Big Sur 11.0及以上版本将屏幕镜像功能内置到控制中心。</li>
<li>macOS Catalina 10.15及以下版本需要确保「隔空播放」图标可见。</li>
<li>AWDL支持P2P Airplay投屏功能。</li>
<li>企业或学校场景可能更适合使用无线HDMI投屏设备。</li>
<li>无线HDMI投屏设备即插即用，无需安装软件。</li>
<li>无线HDMI投屏设备范围更广，使用更灵活。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-45">正文（抓取，非 AI）</h3>
<p>一、Windows 电脑投屏方法 微软自Windows 8.1开始就在系统内置 Miracast 的投屏功能（官方功能称“无线投影”）。这个协议可以提供给用户镜像复制电脑屏幕的功能；也能实现扩展延伸，将主副屏连接起来共同作为一块大屏幕使用。 Miracast投屏前置条件： 操作系统： Windows 8.1及更高 版本系统； 显卡、显卡驱动（WDDM 1.3及以上）均支持Miracast； 无线网卡、无线网卡驱动 均支持Miracast。（电脑本身要有无线WiFi功能） 常见的问题就是以前很多台式电脑的主板都没有集成无线网卡 ，所以不能用 Miracast。 当然，如果电脑不支持 Miracast 也没关系，网上也有很多软件是在电脑安装一个软件，然后通过私有投屏协议实现相关效果，用网线连接也能投屏。 （请参考下方第4节 Windows 7 投屏的文章内容） <em>如何确认自己的电脑当前是否支持 Miracast 无线投屏？ 最简单的方法，就是点开系统的设置界面，找到「设备」-「蓝牙和其他设备」-「添加蓝牙或其他设备」，选择「无线显示扩展坞」。 如果能正常显示搜索设备的界面，表示当前设备支持Miracast投屏；反之如果不支持，就会有相关的错误提示。 </em>Windows系统通用快捷键 微软 Windows 系统已经提前为我们设计好快捷方式，这样我们也不需要自己找半天。 投屏快捷键：Win+K 屏幕模式快捷键：Win + P Win + K 的作用是调用系统自带的无线投屏功能 ，用于连接到可投屏的电视机、投影仪、电视盒子、投屏器。 Win + P 则是在成功连接投屏设备开始投屏后， 用于切换屏幕复制、扩展模式的快捷键。 1、Windows 11 如果不方便使用键盘，我们也能用最传统的鼠标点击进行操作。微软的 Windows 11 系统简化了主题界面和选项，可能有人一时找不到位置， 默认情况下我们需要到系统的设置菜单里面找到相关功能 。 在 「系统」 - 「屏幕」 的界面中，找到 「连接到无线显示器」 选项。 点击 「连接」 进入 「投放」 窗口界面。 选择支持 Miracast 无线投屏功能的电视机/投影仪/投屏器。 2、Windows 10 可能还有很多人的电脑依然是 Windows 10 系统，这边也给大家简单介绍下具体的图形界面。 点击屏幕右下角的 「操作中心」 选项。 点击 「连接」 选项。 选择支持Miracast无线投屏功能的电视机/投影仪/投屏器。 3、Windows 8.1 2023 年 1 月，微软也正式宣布停止维护 Windows 8.1 了，这算是介于 Win 7 到 Win 10 的过渡系统，甚至比 Win7 的装机率还要低。 将鼠标移动至屏幕右下角，打开 「超级按钮」 菜单，然后单击或点击 「设备」。 单击或点击 「投影」 ，然后单击或点击 「添加无线显示」 。 选择支持Miracast无线投屏功能的电视机/投影仪/投屏器。 4、Windows 7 Win 7 没办法使用 Miracast 投屏协议，我们需要借助第三方工具的私有投屏协议实现投屏功能。主要就是在电视端装一个软件，在电脑端也装一个软件，然后两端都使用同一家投屏协议，就可以实现投屏效果了。 这里有两种方法： （1）购买投屏器、电视盒子之类的外置设备，并利用厂商配套的投屏软件进行投屏。适合不能安装软件的非智能电视机、智能投影仪等显示终端使用。 （2）如果电视机或投影仪是近几年购置的产品，一般都是可以安装第三方软件的，甚至有些会内置投屏软件。这时候就不需要另外购买外置设备也能使用投屏功能。 无论选择哪种方式，只要根据厂商的教程进行操作，一般都能顺利投屏。 二、macOS 电脑投屏方法 苹果电脑出厂使用的是 macOS 操作系统，是通过自家的 Airplay 协议实现投屏功能。 这个协议最重要的特点就是，无论使用的是网线连接还是无线WiFi连接，投屏的电脑和被投屏的显示器必须处于同一个网络中。 对于苹果电脑用户来说，可能刚开始上手的时候还真的一时半会儿找不到投屏的图标和位置，特别是有些人一开始发现上方菜单栏里面找不到 「屏幕镜像」/「Screen Mirroring」 的图标。 1、macOS Big Sur 11.0及以上 苹果在 macOS Big Sur 11.0 版本之后，改变了选项设计， 将屏幕镜像功能内置到控制中心面板 ，像是手机端一样集成多个功能到一个窗口中。 确保mac电脑与被投屏显示屏处于同一个网络。 打开桌面上方的 「控制中心」 面板。 找到 「屏幕镜像」 选项 选择附近支持Airplay的电视机/投影仪/投屏器。 2、 macOS Catalina 10.15及以下 在过去的老版本 macOS 操作系统下， 请认准以下这个重要的图标符号！ 这就是以前版本中被称为“隔空播放”的图标。 确保 mac 电脑与被投屏显示屏处于同一个网络。 如果找不到 「隔空播放」 图标，可以在电脑的 「显示器」 界面下勾选显示图标选项。 点按菜单栏中的 「隔空播放」 状态图标。 选择附近支持 Airplay 的电视机/投影仪/投屏器。 *基于 P2P Airplay 的屏幕投屏方法 传统使用 Airplay 投屏的时候，mac 电脑需要提前连接到与投屏电视或投屏盒子相同的网络，才能正常使用。 但还有一种更便捷的情况，如果我们使用的设备支持基于 AWDL 的 P2P Airplay 投屏功能，我们可以在免联网的情况直接进行屏幕镜像。 支持 P2P AirPlay 的设备： 三、通过HDMI接口进行无线投屏 上面基于无线投屏协议的方法是比较简单快捷的，而且一般不需要使用额外的配件就能投屏。 但有时候存在以下情况： 企业会议室或学校教室，经常有不同的使用者和访客轮流使用无线投屏，每次投屏前都要花时间配置投屏功能。 家里有老人或小孩，不是很会操作电脑的无线投屏。 电脑是台式机，不方便移动位置但又想使用无线投屏。 以上情况我会更偏向选择使用无线HDMI类型的投屏设备。无线HDMI设备相当于将传统的HDMI高清线从实体有线传输的方式转变成无线传输，通过发射器+接收器的组合方式实现无线投屏。 有几个优点： 与HDMI有线传输一样，一样是即插即用，也不需要安装什么软件。 相对有线传输来说，范围更大更灵活，设备不管放在哪个位置都能投屏。 简单上手，无论是不是第一次用，不用繁琐配置网络都能开始投屏。 可以自己去搜索相关类型的产品，这边我只是给出适合企业用的参考型号和款式。 码字不易！如果觉得有帮助到你就帮忙双击一下屏幕！ 有更多投屏问题也可以直接告诉我！</p>
</div></details><h2 id="toc-46">24. 新手开一家抖小店，保姆级7天快速起店全流程（附内部资料）</h2>
<ul>
<li>链接：https://www.zhihu.com/tardis/bd/art/520831744</li>
<li>来源：bing</li>
<li>摘要：2025年1月21日 · 最近就陆陆续续收到很多同学、甚至是很多完全没有做过电商的都在问抖音小店开店的具体步骤，咨询抖店运营相关的一些问题，那今天就给大家分享一波 保姆级的抖店新手快速起店教 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，为了确保顺利开店，营业执照需提供原件扫描件或复印件，并且其有效期需大于3个月。建议选择注册个体户营业执照，因为这类别的成本较低且操作相对简单。其次，账户验证需提供对私银行卡号或对公账户，而保证金则需根据经营类目缴纳，流动资金需根据订单量准备，建议准备2000~5000元作为流动资金。此外，店铺保证金可退还，但基础类目保证金按月支付。因此，选择合适的经营类目和准备充足的流动资金是开店初期的关键。此外，注册个体户营业执照的成本较低，且新手开店相对简单，这使得抖音小店成为适合多种人群的平台。目前处于红利期，流量巨大有利于新手，每个店铺理论上可赚2000元。因此，准备和执行力决定机会，资料包包含运营资料、工具和课程，这些都将帮助新手更好地运营店铺。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>营业执照需提供原件扫描件或复印件；</li>
<li>营业执照有效期需大于3个月；</li>
<li>建议注册个体户营业执照；</li>
<li>账户验证需提供对私银行卡号或对公账户；</li>
<li>保证金需根据经营类目缴纳；</li>
<li>流动资金需根据订单量准备；</li>
<li>注册营业执照成本较低；</li>
<li>基础类目保证金按月支付；</li>
<li>采集软件费用5元/月；</li>
<li>发货软件费用15元/月；</li>
<li>流动资金需2000~5000元；</li>
<li>店铺保证金可退还；</li>
<li>选品应考虑竞争小、细分市场、利润高；</li>
<li>夏季防晒喷雾利润较高；</li>
<li>佣金比例会影响达人带货积极性；</li>
<li>流量主要来自达人合作、推荐、搜索；</li>
<li>千川、随心推、Dou+是付费推广渠道；</li>
<li>新手开店相对简单；</li>
<li>抖音小店适合多种人群；</li>
<li>目前处于红利期；</li>
<li>流量巨大利于新手；</li>
<li>每个店铺理论上可赚2000元；</li>
<li>准备和执行力决定机会；</li>
<li>资料包包含运营资料、工具和课程。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-47">正文（抓取，非 AI）</h3>
<p>最近就陆陆续续收到很多同学、甚至是很多完全没有做过电商的都在问抖音小店开店的具体步骤，咨询抖店运营相关的一些问题，那今天就给大家分享一波 保姆级的抖店新手快速起店教程 。 接下来我会讲清楚我是如何【0粉丝启动+不拍视频+不用直播】把店铺做起来的 。 因为抖音小店其实很简单，你花个3分钟，好好把我下面说的知识学明白，然后跟着去实操，能让你在抖音小店学习上少花一半的时间！ 同时我还给大家准备了《快速起店的核心步骤》资料包， 想要统了解抖音小店 的同学可以点击下方卡片可以免费领取全套资料包+直播课 https:// xg.zhihu.com/plugin/546 fe1a64dbe6aa7867ee2f34800ea7e?BIZ=ECOMMERCE 一、 开店步骤 开店前你需要准备的资料有： 三证合一/二证合一的 营业执照 原件 ，个体户或者企业户都可以 第一步：百度搜索抖音小店 会直接出来页面，点击【立即入驻】 第二步：注册登录账号 第三步：选择对应的主题，点击【立即入驻】，填写营业执照和经营者以及店铺信息 开通营业执照相关要求： 1、需提供三证合一/二证合一的 营业执照 原件扫描件或加盖公司公章的营业执照复印件； 2、确保未在企业经营异常名录中且所售商品在营业执照经营范围内； 3、距离 有效期 截止时间应大于3个月； 4、证件需保证清晰完整有效。 根据我的个人经验，强烈建议大家注册个体户的营业执照即可，个体户注册成本低，下证快，而且以后规模做大了，税收方面也有很多优惠措施。 第四步：填写资质信息 1、填写资质信息：提交营业执照、法人/经营者身份证明、店铺LOGO等信息。 2、平台进行资质审核：约1-3个工作日。 3、账户验证：对私银行卡号+银行预留手机号或对公账户打款验证，约1-3个工作日。 4、缴纳保证金：按照经营类目收取。 这些全部完成，恭喜你，就成功入驻抖音小店啦！！！ 其实抖音小店开店得步骤非常简单，根据每一项步骤的要求填写相关数据就好了。 如果还不清楚开店的、或者遇到了任何问题，可以评论区留言交流 在这里，我还给大家准备了《抖音小店公开课》和《快速起店的核心步骤》的资料，看完能搞懂抖音小店到底怎么高效选品和引流，需要的同学可以领取 https:// xg.zhihu.com/plugin/546 fe1a64dbe6aa7867ee2f34800ea7e?BIZ=ECOMMERCE 二、 抖音小店开店费用 抖音小店本身开店成本并不高，店铺的保证金不开店之后也是可以退的，主要在以下几个方面有花费： a.注册营业执照100~500元不等，看你找的什么渠道办。 b.基础类目保证金：平台按照商家店铺类型、商家经营类目、与类目过去一个月支付GMV，向店铺收取基础类目保证金 c.采集软件5元/月，发货软件15元/月，其他软件预算每月不超过100元。 d.流动资金，由于买家在抖店付款之后有回款周期，根据每天订单量的多少大概需要2000~5000元不等的流动资金。 有关于抖店开店方面的费用目前差不多就是这些，所以开一家抖音小店真的不需要很多钱！ 在这里我还给大家准备了《抖音小店公开课》和《快速起店的核心步骤》的资料，抖音小店的玩法和盈利步骤，从开店到出单的整个环节，看完能搞懂抖音小店到底怎么玩，需要的同学可点击下方自行领取 https:// xg.zhihu.com/plugin/546 fe1a64dbe6aa7867ee2f34800ea7e?BIZ=ECOMMERCE 三、 快速起店步骤 去年3月份，我们开通了第一个抖音小店，从其他电商平台复制了1万个左右商品，批量上传到抖音小店。不拍视频不直播不投放，单纯靠免费流量！ 具体怎么玩呢？接着往下看 1、 高效选品 平时多去逛逛蝉妈妈、抖音推荐抖音达人行业榜单、飞瓜网等等这些网站。 我们一般选 品渠道是以下几个：拼多多、淘特、阿里巴巴、抖音精选联盟。 选品这个板块里面知识涵盖非常多，也是让很多新人头疼的地方。其实我们小卖家在选品的时候只要记住： 竞争小，细分市场，利润高。 比如，现在夏天，我们可以搜索一些夏天需求大，价格不高的商品，找一些销量不错的。 以防晒喷雾为例，市场售价基本是50多3瓶，成本价才10块左右，加上快递费13块钱不到，利润可以做到每单37块钱。佣金比例给高一些，达人自然也愿意帮忙带货。 后面你在选品的时候按照这个图去操作即可，完整的脑图需要的话，可以找我领取，同时我还给大家准备了《快速起店的核心步骤》资料包，看完能搞懂抖音小店到底怎么玩 https:// xg.zhihu.com/plugin/546 fe1a64dbe6aa7867ee2f34800ea7e?BIZ=ECOMMERCE 2、 搞定流量 抖音小店前期主要靠和达人谈合作，让达人帮你拍短视频或者直播带货，卖出一单你给他提多少比例的 佣金 即可，还有就是抖音的各种推荐流量，类似于淘宝的猜你喜欢，还有一少部分搜索流量。后期等你的抖店销售额 利润 高了以后，你就可以尝试用一些付费推广，比如千川、小店随心推以及大家熟知的dou+。 盘点了一下，主要的流量渠道是以下几个：联盟达人合作、抖音推荐流量、抖音搜索流量、巨量千川、小店随心推、Dou+ 3、快捷发货 有了订单之后就需要发货，不管是几单还是几百单，同样可以用抖店服务市场的软件批量高效的搞定，这种软件一般15元/月，也是花不了多少钱的。 四、常见抖音小店疑问（有问必答） 抖音小店都适合哪些人做呢？ 1、 没有开过店铺，初期创业新手，能快速出效果并赚取收益 2、 做过淘宝/拼多多的中小卖家，不满足于现状，想要拓展销售渠道增加销售额 3、 有一定的空余时间的宝妈或者上班族，想挣取额外收入的 4、 执行力很强，已有的项目遇到瓶颈，想要拓展新项目 5、 做过店群模式的掌柜，批量化运作收益更好 抖音小店现在处于红利期吗？ 是的。我们自己从今年3月开始。陆续做了20个店铺。 不拍视频不直播。就单纯靠免费流量。 新手可以开抖音小店吗 可以的，这个对新手很友好，没有传统电商那么复杂，而且流量巨大，去做了，很容易出效果； 以我自己实践的成果，以及最近教了几十个学员的案例情况来看，目前抖音小店还处在红利期，好好学习一下，再根据科学的方法去操作，很快就可以出单，一单一个店铺爆单了，马上可以多开几个店铺，哪怕一个店铺一个月只有2000元利润，10个店铺理论上就是2万的利润，任何机会只属于有准备和有执行力的人。 最后 我是 @火星论电商 ，一个有15年实战经验的电商人 08年入行，开店至今；21月开始做抖音小店，现在把15年的经验分享给正在电商道路上的人。 想系统了解抖音小店如何快速起店，怎么选品，流量怎么玩，可以点击下方卡片找我免费领取一份关于我们自己的抖音小店的运营资料包，包含抖音小店新手必看资料包、所需工具以及免费课程↓↓↓ https:// xg.zhihu.com/plugin/546 fe1a64dbe6aa7867ee2f34800ea7e?BIZ=ECOMMERCE</p>
</div></details><h2 id="toc-48">25. Forum | OpenReview</h2>
<ul>
<li>链接：https://openreview.net/forum?id=JePfAI8fah</li>
<li>来源：bing</li>
<li>摘要：Promoting openness in scientific communication and the peer-review process</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，iTransformer 的设计基于对 Transformer 组件功能的反思，无需修改基本组件，仅通过逆序应用注意力机制和前馈网络来实现。其次，iTransformer 通过将注意力机制和前馈网络应用于逆序维度，从而捕捉多变量间的关联，这使得它在具有较大回看窗口的时间序列上实现更好的预测性能。此外，iTransformer 能够学习变量中心化的表示，从而生成有意义的注意力图，进一步提升了 Transformer 家族在不同变量上的泛化能力。因此，iTransformer 使得 Transformer 成为时间序列预测的基本骨干，具有更好的利用任意回看窗口的能力，并在实际应用中的表现达到了 SOTA。同时，iTransformer 的提出挑战了对基于 Transformer 的预测器进行架构修改的热情，表明无需复杂的架构调整即可显著提升预测性能。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>iTransformer 的设计基于对 Transformer 组件功能的反思，无需修改基本组件。</li>
<li>iTransformer 通过将注意力机制和前馈网络应用于逆序维度来捕捉多变量间的关联。</li>
<li>iTransformer 能够在具有较大回看窗口的时间序列上实现更好的预测性能。</li>
<li>iTransformer 能够学习变量中心化的表示，从而生成有意义的注意力图。</li>
<li>iTransformer 提升了 Transformer 家族在不同变量上的泛化能力。</li>
<li>iTransformer 使得 Transformer 成为时间序列预测的基本骨干，具有更好的利用任意回看窗口的能力。</li>
<li>iTransformer 在实际应用中的表现达到了 SOTA。</li>
<li>iTransformer 的设计无需修改基本组件，仅通过逆序应用注意力机制和前馈网络来实现。</li>
<li>iTransformer 的提出挑战了对基于 Transformer 的预测器进行架构修改的热情。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-49">正文（抓取，非 AI）</h3>
<p>iTransformer: Inverted Transformers Are Effective for Time Series Forecasting | OpenReview Go to ICLR 2024 Conference homepage iTransformer: Inverted Transformers Are Effective for Time Series Forecasting Yong Liu , Tengge Hu , Haoran Zhang , Haixu Wu , Shiyu Wang , Lintao Ma , Mingsheng Long Published: 16 Jan 2024, Last Modified: 14 Mar 2024 ICLR 2024 spotlight Everyone Revisions BibTeX Code Of Ethics : I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics. Keywords : Time Series Forecasting, Transformer Submission Guidelines : I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide. TL;DR : Based on the reflection on the duties of Transformer components, we propose inverted Transformer for time series forecasting, which achieves the SOTA in real-world applications and shows powerful strength on framework generalization. Abstract : The recent boom of linear forecasting models questions the ongoing passion for architectural modifications of Transformer-based forecasters. These forecasters leverage Transformers to model the global dependencies over temporal tokens of time series, with each token formed by multiple variates of the same timestamp. However, Transformers are challenged in forecasting series with larger lookback windows due to performance degradation and computation explosion. Besides, the embedding for each temporal token fuses multiple variates that represent potential delayed events and distinct physical measurements, which may fail in learning variate-centric representations and result in meaningless attention maps. In this work, we reflect on the competent duties of Transformer components and repurpose the Transformer architecture without any modification to the basic components. We propose iTransformer that simply applies the attention and feed-forward network on the inverted dimensions. Specifically, the time points of individual series are embedded into variate tokens which are utilized by the attention mechanism to capture multivariate correlations; meanwhile, the feed-forward network is applied for each variate token to learn nonlinear representations. The iTransformer model achieves state-of-the-art on challenging real-world datasets, which further empowers the Transformer family with promoted performance, generalization ability across different variates, and better utilization of arbitrary lookback windows, making it a nice alternative as the fundamental backbone of time series forecasting. Code is available at this repository: https://github.com/thuml/iTransformer. Anonymous Url : I certify that there is no URL (e.g., github page) that could be used to find authors' identity. No Acknowledgement Section : I certify that there is no acknowledgement section in this submission for double blind review. Primary Area : representation learning for computer vision, audio, language, and other modalities Submission Number : 632 Loading OpenReview is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the OpenReview Sponsors . © 2026 OpenReview</p>
</div></details><h2 id="toc-50">26. EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2511.08396v1</li>
<li>来源：arxiv</li>
<li>摘要：Multivariate time series forecasting is crucial across a wide range of domains. While presenting notable progress for the Transformer architecture, iTransformer still lags behind the latest MLP-based models. We attribute this performance gap to unstable inter-channel relationships. To bridge this gap, we propose EMAformer, a simple yet effective model that enhances the Transformer with an auxiliary embedding suite, akin to armor that reinforces its ability. By introducing three key inductive biases, i.e., \textit{global stability}, \textit{phase sensitivity}, and \textit{cross-axis specificity}, EMAformer unlocks the further potential of the Transformer architecture, achieving state-of-the-art performance on 12 real-world benchmarks and reducing forecasting errors by an average of 2.73\% in MSE and 5.15\% in MAE. This significantly advances the practical applicability of Transformer-based approaches for multivariate time series forecasting. The code is available on https://github.com/PlanckChang/EMAformer.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，EMAformer 在多个实际基准上实现了最先进的性能，这主要归因于其在多个关键因素上的改进。其次，通过引入增强整体稳定性的诱导偏置，全球稳定性得到了提升；此外，增强相位敏感性的诱导偏置和增强跨轴特定性的诱导偏置也分别提高了phase sensitivity和cross-axis specificity。因此，这些inductive biases是EMAformer成功的关键因素，使得MSE和MAE分别平均降低了2.73%和5.15%的预测误差。此外，Transformer架构的实用应用也因此得到了显著推进，而相关代码可以在GitHub上获得。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>performance gap 通常归因于不稳定通道间关系。</li>
<li>global stability 通过引入增强整体稳定性的诱导偏置。</li>
<li>phase sensitivity 通过引入增强相位敏感性的诱导偏置。</li>
<li>cross-axis specificity 通过引入增强跨轴特定性的诱导偏置。</li>
<li>EMAformer 在多个实际基准上实现了最先进的性能。</li>
<li>MSE 和 MAE 分别平均降低了 2.73% 和 5.15% 的预测误差。</li>
<li>Transformer 架构的实用应用得到了显著推进。</li>
<li>代码可以在 GitHub 上获得。</li>
<li>inductive biases 是 EMAformer 成功的关键因素。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-51">正文（抓取，非 AI）</h3>
<p>[2511.08396v1] EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting Computer Science &gt; Machine Learning arXiv:2511.08396v1 (cs) [Submitted on 11 Nov 2025] Title: EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting Authors: Zhiwei Zhang , Xinyi Du , Xuanchi Guo , Weihao Wang , Wenjuan Han View a PDF of the paper titled EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting, by Zhiwei Zhang and 4 other authors View PDF HTML (experimental) Abstract: Multivariate time series forecasting is crucial across a wide range of domains. While presenting notable progress for the Transformer architecture, iTransformer still lags behind the latest MLP-based models. We attribute this performance gap to unstable inter-channel relationships. To bridge this gap, we propose EMAformer, a simple yet effective model that enhances the Transformer with an auxiliary embedding suite, akin to armor that reinforces its ability. By introducing three key inductive biases, i.e., \textit{global stability}, \textit{phase sensitivity}, and \textit{cross-axis specificity}, EMAformer unlocks the further potential of the Transformer architecture, achieving state-of-the-art performance on 12 real-world benchmarks and reducing forecasting errors by an average of 2.73\% in MSE and 5.15\% in MAE. This significantly advances the practical applicability of Transformer-based approaches for multivariate time series forecasting. The code is available on this https URL . Comments: 14 pages, 9 figures, 6 tables, accepted by AAAI2026 Subjects: Machine Learning (cs.LG) Cite as: arXiv:2511.08396 [cs.LG] (or arXiv:2511.08396v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2511.08396 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Zhiwei Zhang [ view email ] [v1] Tue, 11 Nov 2025 16:12:44 UTC (402 KB) Full-text links: Access Paper: View a PDF of the paper titled EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting, by Zhiwei Zhang and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-11 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-52">27. 2025年新开始！抖店现在还能不能做？当然能！但是你得会 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/tardis/bd/art/14808370668</li>
<li>来源：bing</li>
<li>摘要：2024年12月25日 · 自从抖音小店上线以来，“抖店现在还能做吗？目前还是风口吗？”这样的问题就一直不曾间断过 哪怕现在去回望抖店最初的暴力起店期，你会发现当时也依然有人在问这样的问题。 那 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，个体营业执照的注册和注销过程相对简单，只需通过网上办理即可，且注销费用低廉。然而，个体经营者在运营过程中可能会遇到一些技术问题，例如同一个IP地址可能会影响店铺的正常运营，因此需要使用比特浏览器来解决这一问题。此外，电脑配置也需要满足软件运行的要求，以确保店铺的顺利运行。

其次，为了避免违规操作，个体经营者在商品搬运时需注意，不能搬运含有知名人物头像、旗舰品牌或价格离谱的产品。截流定价策略则需比竞争对手低1分到1毛钱，以吸引顾客。新人礼金和优惠券不叠加使用，但新人礼金优惠券仅针对新顾客，旨在刺激复购。同时，设置优惠券时需考虑发放量和每人限领张数，以避免资源浪费。

最后，大部分售后问题可以通过系统自动处理，但做商品橱窗和直播带货的机会较小，且需确保合规经营。创业时应避免高调模式，建议先小额投入再扩大，避免盲目投入大量资金，不应借钱创业。因此，个体经营者在运营过程中需注意多个方面，以确保业务的顺利进行。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>个体营业执照注册过程简单，网上办理即可。</li>
<li>营业执照注销过程简单，费用低廉。</li>
<li>同一个IP会影响店铺运营，需使用比特浏览器解决。</li>
<li>电脑配置需满足软件运行要求。</li>
<li>不能搬运有人物头像、旗舰、知名品牌或价格离谱的产品。</li>
<li>截流定价策略需比竞争对手低1分到1毛钱。</li>
<li>新人礼金和优惠券不叠加使用。</li>
<li>单品直降需设置虚假高价以吸引顾客。</li>
<li>新人礼金优惠券仅针对新顾客，刺激复购。</li>
<li>优惠券设置需考虑发放量和每人限领张数。</li>
<li>大部分售后问题系统会自动处理。</li>
<li>做商品橱窗的机会较小，直播带货机会更小。</li>
<li>短视频挂车和商品卡有一定机会，但需合规经营。</li>
<li>创业需避免高调模式，先小额投入再扩大。</li>
<li>避免盲目投入大量资金，不应借钱创业。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-53">正文（抓取，非 AI）</h3>
<p>自从抖音小店上线以来，“抖店现在还能做吗？目前还是风口吗？”这样的问题就一直不曾间断过 哪怕现在去回望抖店最初的暴力起店期，你会发现当时也依然有人在问这样的问题。 那么，回到问题本身， 抖音小店目前还能做吗？还是风口吗？ 首先我们要知道一点，抖音小店是什么？ 说白了就是抖音平台为创业者提供的一个电商平台，从最初上线到现在，它已经吸引了无数商家入驻。 关于抖音小店现在是否是一个创业风口，咱们需要从多方面去进行分析。 1.流量层面 抖音在流量方面是没有任何问题的，足以碾压国内各大电商平台用户。 2.平台政策 这两年，抖音平台一直都在出台一些扶持政策，除了一直都有的新商十大扶持权益外， 近期又新增了一证可以开多店、店铺保证金大幅下调 （90%以上企业店类目保证金降幅≥50%；类目覆盖近抖音电商70%商家）以及商品入池标准降低等... 这些都说明了 近期抖音电商的政策都是非常利好的 ， 平台一直在从根本上解决商家发展的经营顾虑、不断降低商家经营成本。 3.竞争层面 如果我们现在做抖店，就不要考虑这个行业内卷的事情了， 卷与不卷式取决于你自身的产品，以及服务中的差异化还有你的店铺优势。 作为商家我们更多的是要考虑如何去吸引用户在你的店铺里面去购买产品。 总结一下， 抖店目前是具有一定发展潜力的！ 如果大家想做抖店，可以趁着今年平台陆续出台这么多新规则，进入到这个行业试一下！ 如果你不知道从哪里入手开抖店？有很多的疑问？ 那么你一定要将本文点赞收藏！本文会进行详细拆解！ 当时做抖店的时候，我也是惶恐的，毕竟也走过了很多的坑 在朋友的建议下，我壮着胆让手下的团队切入到这个项目上去 先是小范围测试，结果第二天就爆单，第三天就大爆特爆！！！ 利润相当可观……（收益仅代表个人） 剩下的都是一些小店，一天有500到2k左右的交易额 那这个项目到底应该怎么干呢？ 我相信很多人都非常关注这个问题，这里我也不给大家卖关子， 先上一个干货拆解图吧，希望能帮助到有缘人↓ ↓ ↓ ↓ ↓ ↓ 关于项目，如果你想了解，想认识我，想领相关的搞钱资料， 想知道抖店上架就能出单的选品策略?找我领取简单一招快速选出蓝海爆款! 我也愿意分享给你，点击卡片找我领取就可以 ↓ ↓ ↓ ↓ ↓ ↓ https:// xg.zhihu.com/plugin/35a 8ac5ad1a66c4f702b21d463c37c74?BIZ=ECOMMERCE 下边正式上流程！ 一、抖音开店注册篇 （一）需要准备哪些资料 1.个体营业执照。（没必要用企业营业执照） 2.电脑一台，一条网线即可（多店规避ip问题有专门的软件解决） 3.比特浏览器或者云电脑（解决ip问题，推荐比特浏览器，便宜性价比高） 4.法人相关资料（身份证正反面等） 5.收款卡，电话卡(提现用，接受验证码用） 6.部分替代人工的软件（抖搬家，店管家分销助手） （二）部分开店资料详细解答 1.营业执照 ①营业执照注册 可以自己去注册，去当地工商局就可以办理，但是我建议大家没必要这么麻烦，去网上办理就可以 去拼多多直接搜：个体工商户营业执照代办，找海南的办就可以，大概价格是八十块钱，很便宜， ②营业执照注销 最主要的是将来注销花几十块就可以注销了，也方便。没有年审和税务等问题，省心省力 ③营业执照的经营范围 你如果只是为了开店，建议用下面这个经营范围参考就可以， 如果你平时还有其他一些杂七杂八的业务，就酌情加点 2.电脑及IP相关 做电商一定逃不开的一个问题就是IP问题的解决，尤其是你想要做大量店面 同一个Ip以及同一个身份肯定是不行的 所以这里我们可以借用一个软件，叫做比特浏览器，他可以解决的问题就是， 一个浏览器，可以有10个窗口，每个窗口都是一个独立的IP， 这样我们开10家店也是不同的IP，并且不会影响你开店的效果 我们已经测试了n次，完全不会影响到你店铺的流量 另外，我们将来会用到2款软件，所以电脑配置尽量不要太低，这里给大家一个参考的配置 （三）注册流程实操 1.打开百度界面，搜索抖音小店 二、开店基础设置篇 （一）店铺信息设置 （三） 服务市场购买2款软件 抖搬家 +店管家分销代发 到这里，店铺基础设置和基础软件购买就算是完成了 可以先买免费适用版，不用花钱，先简单试用一下也可以 https:// xg.zhihu.com/plugin/35a 8ac5ad1a66c4f702b21d463c37c74?BIZ=ECOMMERCE 三、选品与上品 （一）如何找到热门同行热门款 1.打开电商罗盘 2.点击商品卡里面的商品榜单 3.然后按照类目，实时，曝光排序，就可以找到热门的品 我们以手机配件和女装T恤为例，都可以按照这种方式来找到 那其他的各行业都可以用这种方式来找到时下最热门的同行 （二）如何把同行的产品都搬运到自己的店铺里面去？ 不能搬运的规则 1.带人物头像的不能搬，可能涉及侵犯肖像权 2.带旗舰的不能搬，也许人家有授权 3.带知名品牌名的不能搬 4.价格离谱的不能搬，尤其是离谱高和离谱低，高了容易踩雷，低了容易售后 如果有需要软件的，我也整理好了资源，可以供大家免费试用↓ ↓ ↓ ↓ ↓ ↓ https:// xg.zhihu.com/plugin/35a 8ac5ad1a66c4f702b21d463c37c74?BIZ=ECOMMERCE 四、产品截流式定价 （一）什么是截流 截流就是把别人已经爆过，或者火过的流量，截到自己店铺里 要知道，光会选品是远远不够的，最终还是要有店铺流量 毕竟流量=金钱 那我们是如何把流量给打满的呢？ 这里就涉及到商品卡起店的一个逻辑，跟拼多多很类似， 就是抖音会给低价产品一定的曝光，如果你能转化，那么会继续二次曝光给你流量 所以我们的定价策略就是比自己的上家热门款低1分钱到1毛钱 别人卖8.57 我们就卖8.56…… 这样别人卖的火的产品，一定会匀一部分流量给到我们的店铺 这是我们搞基础流量的第一种手段 还有第二种手段…… https:// xg.zhihu.com/plugin/35a 8ac5ad1a66c4f702b21d463c37c74?BIZ=ECOMMERCE 五、营销活动设置 （一）三大营销活动介绍 主要是三大块，单品直降、新人礼金、优惠券 其中新人礼金和优惠券是不叠加的 不知道大家有没有留意，平时自己在平台上购物的时候，外面显示看着2块钱，3块钱， 进去一看就变成了10块钱，甚至20块钱等等 这就是商家设置了某个sku的低外展 从而能够拿到曝光量，这样可以增加店铺的流量 （二）单品直降设置 说白了，就是你想一个东西卖8块钱，你挂20块钱 然后打一个4折，这样会显得比较好看，给人一种占了便宜的思想 实际上压根就是这个价格 就如同，你走到一个商场里面，原本贴着399的标签的衣服， 划了一道斜线，变成了199一个意思！ 点击 营销 → 单品直降 → 立即新建 → 普通降价促销 → 添加商品 →选中商品 → 修改想卖的价格 →点击下方 提交按钮 即可 （三）新人礼金设置 每一个去你店铺里面的新人，都可以拿一份优惠，比如优惠5元 很多人会觉得，会不会亏？ 可以明确告诉你，不会 买的永远没有卖的精！ 同样的东西，我想卖15，我只需要挂20块，然后送你一个5元的新人优惠券 压根我就没想着卖20 5元的优惠券只是一个免费的工具，让消费者看着好看就行~ 点击 营销 → 新人礼金 → 立即新建 → 全店商品 → 提交 即可 （四）优惠券设置 这个主要是给复购的客户用的 第二次来你的店铺里面，如果没有了礼金，产品会很贵 所以有这个优惠券，可以拉高复购率，进而刺激2波流量 让系统认为你是一个优质的店铺 点击 营销 → 优惠券 → 立即新建 → 全网公开推广 → 优惠方式：立减 → 立减面额：3或者4（具体看自己想设置多少） → 发放量100000 → 每人限领 5张 → 商品范围（全店商品） → 提交 即可 六、售后订单处理 绝大部分的售后，如果是未发货仅退款，基本上就不用管， 系统会自动退款，这种占比60%基本上就不用处理 需要处理的主要有以下几个 ①已发货仅退款 ②催发货 ③丢件 ④补发 这个具体相对来说比较多的内容，这里就不一一赘述了 直接在售后栏 里面的售后工作台去看就可以了 七、个人做抖音电商是否还存在机会? 毫不客气的说，如果你做商品橱窗，机会概率是10%； 如果你做直播带货，机会概率是1% ； 如果你做短视频挂车，成功机会是20%， 如果你做商品卡，可能机会是30% 当然了，这个社会，任何行业都是二八定律 能够成功的人都是少数，要不有着执行力，要不有着自己的感悟能力 你什么都没有，就幻想着在互联网上发财——结局可想而知，一定是被人不断地收割 今天看这个好，明天看那个好，眼花缭乱没有一个能落地的 虽然你看到很多视频和文章，题目都是打爆，引爆，爆单，玩转， 让你感觉是个人随便做做可以简单暴富，我想告诉你， 暴富的可能性很小很小~ 但是如果说你有好的产品，愿意合规经营，还有一定的运营的能力，还是可以试一试创业。 八、团队运营 九、结束语 到了2025年，个人开设抖音小店依然蕴含机遇，但务必避免高调的创业模式。 我始终向有意涉足抖店的朋友们推崇低风险创业策略。那么，低风险创业究竟意味着什么呢？ 简而言之，就是先以2到3万元的小额投入，着手开发一款产品。 待这款产品实现盈利后，我们再考虑进一步打造和推广新的产品。 在你对行业尚未深入了解、缺乏足够经验的情况下，切忌盲目投入数十万资金，更不应借钱创业。 尽管网络上充斥着诸如“打爆”、“引爆”、“爆单”、“玩转”等标题的文章和视频， 它们可能会让你误以为成功和暴富触手可及， 但我必须坦诚地告诉你，这样的暴富机会微乎其微。 然而，如果你手握优质产品，愿意遵守规则进行经营，并且具备一定的运营能力， 那么，尝试开设抖音小店仍然是一个值得考虑的选择！ 关于项目，如果你想了解，想认识我，想领相关的搞钱资料， 想知道抖店上架就能出单的选品策略?找我领取简单一招快速选出蓝海爆款! 我也愿意分享给你，点击卡片找我领取就可以 ↓ ↓ ↓ ↓ ↓ ↓ https:// xg.zhihu.com/plugin/35a 8ac5ad1a66c4f702b21d463c37c74?BIZ=ECOMMERCE</p>
</div></details><h2 id="toc-54">28. Data Augmentation in Time Series Forecasting through Inverted Framework</h2>
<ul>
<li>链接：https://arxiv.org/abs/2507.11439v2</li>
<li>来源：arxiv</li>
<li>摘要：Currently, iTransformer is one of the most popular and effective models for multivariate time series (MTS) forecasting. Thanks to its inverted framework, iTransformer effectively captures multivariate correlation. However, the inverted framework still has some limitations. It diminishes temporal interdependency information, and introduces noise in cases of nonsignificant variable correlation. To address these limitations, we introduce a novel data augmentation method on inverted framework, called DAIF. Unlike previous data augmentation methods, DAIF stands out as the first real-time augmentation specifically designed for the inverted framework in MTS forecasting. We first define the structure of the inverted sequence-to-sequence framework, then propose two different DAIF strategies, Frequency Filtering and Cross-variation Patching to address the existing challenges of the inverted framework. Experiments across multiple datasets and inverted models have demonstrated the effectiveness of our DAIF.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，iTransformer的倒置框架设计会减弱时间依赖性信息，这使得模型在处理时间序列数据时面临挑战。其次，DAIF作为首个专门为倒置框架设计的实时数据增强方法，通过频率过滤和交叉变异补丁两种策略来解决这一问题。频率过滤策略通过调整数据的频率特性来增强时间依赖性信息，而交叉变异补丁则通过生成多样化的补丁来增强模型的泛化能力。此外，DAIF的有效性已在多个数据集和倒置模型上得到验证，证明了其在增强倒置框架模型性能方面的显著效果。因此，DAIF不仅能够有效提升倒置框架下的模型性能，还为其他类似问题提供了新的解决方案。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>iTransformer的倒置框架会减弱时间依赖性信息。</li>
<li>DAIF是首个专门为倒置框架设计的实时数据增强方法。</li>
<li>DAIF通过频率过滤和交叉变异补丁两种策略来解决倒置框架的挑战。</li>
<li>DAIF的有效性已在多个数据集和倒置模型上得到验证。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-55">正文（抓取，非 AI）</h3>
<p>[2507.11439v2] Data Augmentation in Time Series Forecasting through Inverted Framework Computer Science &gt; Machine Learning arXiv:2507.11439v2 (cs) [Submitted on 15 Jul 2025 ( v1 ), last revised 16 Jul 2025 (this version, v2)] Title: Data Augmentation in Time Series Forecasting through Inverted Framework Authors: Hongming Tan , Ting Chen , Ruochong Jin , Wai Kin Chan View a PDF of the paper titled Data Augmentation in Time Series Forecasting through Inverted Framework, by Hongming Tan and 3 other authors View PDF HTML (experimental) Abstract: Currently, iTransformer is one of the most popular and effective models for multivariate time series (MTS) forecasting. Thanks to its inverted framework, iTransformer effectively captures multivariate correlation. However, the inverted framework still has some limitations. It diminishes temporal interdependency information, and introduces noise in cases of nonsignificant variable correlation. To address these limitations, we introduce a novel data augmentation method on inverted framework, called DAIF. Unlike previous data augmentation methods, DAIF stands out as the first real-time augmentation specifically designed for the inverted framework in MTS forecasting. We first define the structure of the inverted sequence-to-sequence framework, then propose two different DAIF strategies, Frequency Filtering and Cross-variation Patching to address the existing challenges of the inverted framework. Experiments across multiple datasets and inverted models have demonstrated the effectiveness of our DAIF. Comments: The paper is under consideration at Pattern Recognition Letters Subjects: Machine Learning (cs.LG) Cite as: arXiv:2507.11439 [cs.LG] (or arXiv:2507.11439v2 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2507.11439 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Hongming Tan [ view email ] [v1] Tue, 15 Jul 2025 16:01:58 UTC (502 KB) [v2] Wed, 16 Jul 2025 11:40:43 UTC (502 KB) Full-text links: Access Paper: View a PDF of the paper titled Data Augmentation in Time Series Forecasting through Inverted Framework, by Hongming Tan and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-07 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-56">29. An Optimization Method for Autoregressive Time Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.02288v1</li>
<li>来源：arxiv</li>
<li>摘要：Current time-series forecasting models are primarily based on transformer-style neural networks. These models achieve long-term forecasting mainly by scaling up the model size rather than through genuinely autoregressive (AR) rollout. From the perspective of large language model training, the traditional training process for time-series forecasting models ignores temporal causality. In this paper, we propose a novel training method for time-series forecasting that enforces two key properties: (1) AR prediction errors should increase with the forecasting horizon. Any violation of this principle is considered random guessing and is explicitly penalized in the loss function, and (2) the method enables models to concatenate short-term AR predictions for forming flexible long-term forecasts. Empirical results demonstrate that our method establishes a new state-of-the-art across multiple benchmarks, achieving an MSE reduction of more than 10% compared to iTransformer and other recent strong baselines. Furthermore, it enables short-horizon forecasting models to perform reliable long-term predictions at horizons over 7.5 times longer. Code is available at https://github.com/LizhengMathAi/A</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">AR预测误差应随预测horizon增加，否则视为随机猜测并惩罚，这表明AR模型在预测时存在固有限制。为克服这一限制，该方法允许模型结合短期AR预测以形成灵活的长期预测，从而提高预测的准确性。然而，传统训练过程忽略了时间因果性，这进一步削弱了模型的预测能力。因此，该方法通过引入时间因果性，显著提升了预测效果，在多个基准上建立了新的SOTA，MSE降低超过10%。此外，短horizon预测模型能够实现超过7.5倍horizon的可靠长期预测，进一步验证了该方法的有效性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>AR预测误差应随预测 horizon 增加，否则视为随机猜测并惩罚。</li>
<li>该方法允许模型结合短期 AR 预测以形成灵活的长期预测。</li>
<li>传统训练过程忽略了时间因果性。</li>
<li>此方法在多个基准上建立了新的 SOTA，MSE 降低超过 10%。</li>
<li>短 horizon 预测模型可实现超过 7.5 倍 horizon 的可靠长期预测。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-57">正文（抓取，非 AI）</h3>
<p>[2602.02288v1] An Optimization Method for Autoregressive Time Series Forecasting Computer Science &gt; Machine Learning arXiv:2602.02288v1 (cs) [Submitted on 2 Feb 2026] Title: An Optimization Method for Autoregressive Time Series Forecasting Authors: Zheng Li , Jerry Cheng , Huanying Gu View a PDF of the paper titled An Optimization Method for Autoregressive Time Series Forecasting, by Zheng Li and 2 other authors View PDF HTML (experimental) Abstract: Current time-series forecasting models are primarily based on transformer-style neural networks. These models achieve long-term forecasting mainly by scaling up the model size rather than through genuinely autoregressive (AR) rollout. From the perspective of large language model training, the traditional training process for time-series forecasting models ignores temporal causality. In this paper, we propose a novel training method for time-series forecasting that enforces two key properties: (1) AR prediction errors should increase with the forecasting horizon. Any violation of this principle is considered random guessing and is explicitly penalized in the loss function, and (2) the method enables models to concatenate short-term AR predictions for forming flexible long-term forecasts. Empirical results demonstrate that our method establishes a new state-of-the-art across multiple benchmarks, achieving an MSE reduction of more than 10% compared to iTransformer and other recent strong baselines. Furthermore, it enables short-horizon forecasting models to perform reliable long-term predictions at horizons over 7.5 times longer. Code is available at this https URL Comments: 10 pages, 2 figures, 2 tables Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.02288 [cs.LG] (or arXiv:2602.02288v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.02288 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Zheng Li [ view email ] [v1] Mon, 2 Feb 2026 16:28:00 UTC (242 KB) Full-text links: Access Paper: View a PDF of the paper titled An Optimization Method for Autoregressive Time Series Forecasting, by Zheng Li and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-58">30. Selective Learning for Deep Time Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2510.25207v1</li>
<li>来源：arxiv</li>
<li>摘要：Benefiting from high capacity for capturing complex temporal patterns, deep learning (DL) has significantly advanced time series forecasting (TSF). However, deep models tend to suffer from severe overfitting due to the inherent vulnerability of time series to noise and anomalies. The prevailing DL paradigm uniformly optimizes all timesteps through the MSE loss and learns those uncertain and anomalous timesteps without difference, ultimately resulting in overfitting. To address this, we propose a novel selective learning strategy for deep TSF. Specifically, selective learning screens a subset of the whole timesteps to calculate the MSE loss in optimization, guiding the model to focus on generalizable timesteps while disregarding non-generalizable ones. Our framework introduces a dual-mask mechanism to target timesteps: (1) an uncertainty mask leveraging residual entropy to filter uncertain timesteps, and (2) an anomaly mask employing residual lower bound estimation to exclude anomalous timesteps. Extensive experiments across eight real-world datasets demonstrate that selective learning can significantly improve the predictive performance for typical state-of-the-art deep models, inc</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">过度拟合是由于时间序列固有的噪声和异常导致的，这会导致模型过度学习噪声和异常时间步，从而增加MSE损失。为了解决这一问题，不确定性掩码和异常掩码通过不同的机制筛选出不确定和异常的时间步，从而排除这些时间步的影响。具体而言，不确定性掩码通过残差熵筛选出不确定的时间步，而异常掩码通过残差下界估计排除异常的时间步。选择性学习策略则在此基础上进一步优化，通过指导模型关注可泛化的时间步，从而显著提高预测性能。该方法适用于多种深度模型，如Informer、TimesNet和iTransformer，并已在八个真实数据集上进行了广泛实验，结果显示选择性学习可以减少37.4%的MSE损失，从而实现统一优化下的损失函数的优化。因此，选择性学习策略不仅能够减少MSE损失，还能显著提高预测性能。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>MSE损失会导致模型过度学习噪声和异常时间步。</li>
<li>不确定性掩码通过残差熵筛选出不确定的时间步。</li>
<li>异常掩码通过残差下界估计排除异常的时间步。</li>
<li>选择性学习策略可以显著提高预测性能。</li>
<li>该方法适用于多种深度模型，如Informer、TimesNet和iTransformer。</li>
<li>选择性学习可以减少37.4%的MSE损失。</li>
<li>过度拟合是由于时间序列固有的噪声和异常导致的。</li>
<li>损失函数的统一优化会导致模型学习所有时间步。</li>
<li>选择性学习指导模型关注可泛化的时间步。</li>
<li>该方法已在八个真实数据集上进行了广泛实验。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-59">正文（抓取，非 AI）</h3>
<p>[2510.25207v1] Selective Learning for Deep Time Series Forecasting Computer Science &gt; Machine Learning arXiv:2510.25207v1 (cs) [Submitted on 29 Oct 2025] Title: Selective Learning for Deep Time Series Forecasting Authors: Yisong Fu , Zezhi Shao , Chengqing Yu , Yujie Li , Zhulin An , Qi Wang , Yongjun Xu , Fei Wang View a PDF of the paper titled Selective Learning for Deep Time Series Forecasting, by Yisong Fu and 7 other authors View PDF Abstract: Benefiting from high capacity for capturing complex temporal patterns, deep learning (DL) has significantly advanced time series forecasting (TSF). However, deep models tend to suffer from severe overfitting due to the inherent vulnerability of time series to noise and anomalies. The prevailing DL paradigm uniformly optimizes all timesteps through the MSE loss and learns those uncertain and anomalous timesteps without difference, ultimately resulting in overfitting. To address this, we propose a novel selective learning strategy for deep TSF. Specifically, selective learning screens a subset of the whole timesteps to calculate the MSE loss in optimization, guiding the model to focus on generalizable timesteps while disregarding non-generalizable ones. Our framework introduces a dual-mask mechanism to target timesteps: (1) an uncertainty mask leveraging residual entropy to filter uncertain timesteps, and (2) an anomaly mask employing residual lower bound estimation to exclude anomalous timesteps. Extensive experiments across eight real-world datasets demonstrate that selective learning can significantly improve the predictive performance for typical state-of-the-art deep models, including 37.4% MSE reduction for Informer, 8.4% for TimesNet, and 6.5% for iTransformer. Comments: Accepted by NeurIPS 2025 Subjects: Machine Learning (cs.LG) Cite as: arXiv:2510.25207 [cs.LG] (or arXiv:2510.25207v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2510.25207 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Yisong Fu [ view email ] [v1] Wed, 29 Oct 2025 06:18:52 UTC (2,743 KB) Full-text links: Access Paper: View a PDF of the paper titled Selective Learning for Deep Time Series Forecasting, by Yisong Fu and 7 other authors View PDF TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-10 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-60">31. TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.12301v1</li>
<li>来源：arxiv</li>
<li>摘要：TwinFormer is a hierarchical Transformer for long-sequence time-series forecasting. It divides the input into non-overlapping temporal patches and processes them in two stages: (1) a Local Informer with top-$k$ Sparse Attention models intra-patch dynamics, followed by mean pooling; (2) a Global Informer captures long-range inter-patch dependencies using the same top-$k$ attention. A lightweight GRU aggregates the globally contextualized patch tokens for direct multi-horizon prediction. The resulting architecture achieves linear $O(kLd)$ time and memory complexity. On eight real-world benchmarking datasets from six different domains, including weather, stock price, temperature, power consumption, electricity, and disease, and forecasting horizons $96-720$, TwinFormer secures $27$ positions in the top two out of $34$. Out of the $27$, it achieves the best performance on MAE and RMSE at $17$ places and $10$ at the second-best place on MAE and RMSE. This consistently outperforms PatchTST, iTransformer, FEDformer, Informer, and vanilla Transformers. Ablations confirm the superiority of top-$k$ Sparse Attention over ProbSparse and the effectiveness of GRU-based aggregation. Code is avail</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，TwinFormer采用Local Informer和Global Informer两种机制来处理内部时间贴片的动力学和跨时间贴片的长距离依赖关系，这两种机制均使用了top-$k$稀疏注意力机制，这优于概率稀疏注意力机制。其次，Local Informer通过top-$k$稀疏注意力机制处理内部时间贴片的动力学，而Global Informer则使用相同的机制捕获跨时间贴片的长距离依赖关系。此外，GRU用于聚合全局上下文的时间贴片令牌，以进行直接多时间范围预测。因此，TwinFormer在多个基准数据集上表现出色，特别是在MAE和RMSE指标上，其架构实现了线性时间复杂度$O(kLd)$。非重叠时间贴片的划分有助于提高模型效率，使得TwinFormer在多个领域和不同类型的基准数据集上表现出色，其在MAE和RMSE指标上达到最佳性能，并在多时间范围预测中具有优势。因此，TwinFormer的性能在多个数据集上优于其他模型，且其代码可在指定的GitHub仓库中获得。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Local Informer使用top-$k$稀疏注意力机制处理内部时间贴片的动力学。</li>
<li>Global Informer使用相同的top-$k$注意力机制捕获跨时间贴片的长距离依赖关系。</li>
<li>top-$k$稀疏注意力机制优于概率稀疏注意力机制。</li>
<li>GRU聚合全局上下文的时间贴片令牌以进行直接多时间范围预测。</li>
<li>TwinFormer在多个基准数据集上表现出色，特别是在MAE和RMSE指标上。</li>
<li>TwinFormer的架构实现了线性时间复杂度$O(kLd)$。</li>
<li>非重叠时间贴片的划分有助于提高模型效率。</li>
<li>PatchTST、iTransformer、FEDformer、Informer和vanilla Transformer等模型被TwinFormer超越。</li>
<li>代码可在指定的GitHub仓库中获得。</li>
<li>TwinFormer在多个领域和不同类型的基准数据集上表现出色。</li>
<li>TwinFormer在MAE和RMSE指标上达到最佳性能。</li>
<li>TwinFormer在多时间范围预测中具有优势。</li>
<li>TwinFormer的性能在多个数据集上优于其他模型。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-61">正文（抓取，非 AI）</h3>
<p>[2512.12301v1] TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting Computer Science &gt; Machine Learning arXiv:2512.12301v1 (cs) [Submitted on 13 Dec 2025] Title: TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting Authors: Mahima Kumavat , Aditya Maheshwari View a PDF of the paper titled TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting, by Mahima Kumavat and Aditya Maheshwari View PDF HTML (experimental) Abstract: TwinFormer is a hierarchical Transformer for long-sequence time-series forecasting. It divides the input into non-overlapping temporal patches and processes them in two stages: (1) a Local Informer with top-$k$ Sparse Attention models intra-patch dynamics, followed by mean pooling; (2) a Global Informer captures long-range inter-patch dependencies using the same top-$k$ attention. A lightweight GRU aggregates the globally contextualized patch tokens for direct multi-horizon prediction. The resulting architecture achieves linear $O(kLd)$ time and memory complexity. On eight real-world benchmarking datasets from six different domains, including weather, stock price, temperature, power consumption, electricity, and disease, and forecasting horizons $96-720$, TwinFormer secures $27$ positions in the top two out of $34$. Out of the $27$, it achieves the best performance on MAE and RMSE at $17$ places and $10$ at the second-best place on MAE and RMSE. This consistently outperforms PatchTST, iTransformer, FEDformer, Informer, and vanilla Transformers. Ablations confirm the superiority of top-$k$ Sparse Attention over ProbSparse and the effectiveness of GRU-based aggregation. Code is available at this repository: this https URL . Comments: 14 pages, 4 figures Subjects: Machine Learning (cs.LG) Cite as: arXiv:2512.12301 [cs.LG] (or arXiv:2512.12301v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2512.12301 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Aditya Maheshwari [ view email ] [v1] Sat, 13 Dec 2025 11:50:18 UTC (964 KB) Full-text links: Access Paper: View a PDF of the paper titled TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting, by Mahima Kumavat and Aditya Maheshwari View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-62">32. Quantum Neural Network Architectures for Multivariate Time-Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2510.21168v1</li>
<li>来源：arxiv</li>
<li>摘要：In this paper, we address the challenge of multivariate time-series forecasting using quantum machine learning techniques. We introduce adaptation strategies that extend variational quantum circuit models, traditionally limited to univariate data, toward the multivariate setting, exploring both purely quantum and hybrid quantum-classical formulations. First, we extend and benchmark several VQC-based and hybrid architectures to systematically evaluate their capacity to model cross-variable dependencies. Second, building upon these foundations, we introduce the iQTransformer, a novel quantum transformer architecture that integrates a quantum self-attention mechanism within the iTransformer framework, enabling a quantum-native representation of inter-variable relationships. Third, we provide a comprehensive empirical evaluation on both synthetic and real-world datasets, showing that quantum-based models may achieve competitive or superior forecasting accuracy with fewer trainable parameters and faster convergence than state-of-the-art classical and quantum baselines in some cases. These contributions highlight the potential of quantum-enhanced architectures as efficient and scalable t</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-63">正文（抓取，非 AI）</h3>
<p>[2510.21168v1] Quantum Neural Network Architectures for Multivariate Time-Series Forecasting Quantum Physics arXiv:2510.21168v1 (quant-ph) [Submitted on 24 Oct 2025] Title: Quantum Neural Network Architectures for Multivariate Time-Series Forecasting Authors: Sandra Ranilla-Cortina , Diego A. Aranda , Jorge Ballesteros , Jesus Bonilla , Nerea Monrio , Elías F. Combarro , Jose Ranilla View a PDF of the paper titled Quantum Neural Network Architectures for Multivariate Time-Series Forecasting, by Sandra Ranilla-Cortina and 6 other authors View PDF HTML (experimental) Abstract: In this paper, we address the challenge of multivariate time-series forecasting using quantum machine learning techniques. We introduce adaptation strategies that extend variational quantum circuit models, traditionally limited to univariate data, toward the multivariate setting, exploring both purely quantum and hybrid quantum-classical formulations. First, we extend and benchmark several VQC-based and hybrid architectures to systematically evaluate their capacity to model cross-variable dependencies. Second, building upon these foundations, we introduce the iQTransformer, a novel quantum transformer architecture that integrates a quantum self-attention mechanism within the iTransformer framework, enabling a quantum-native representation of inter-variable relationships. Third, we provide a comprehensive empirical evaluation on both synthetic and real-world datasets, showing that quantum-based models may achieve competitive or superior forecasting accuracy with fewer trainable parameters and faster convergence than state-of-the-art classical and quantum baselines in some cases. These contributions highlight the potential of quantum-enhanced architectures as efficient and scalable tools for advancing multivariate time-series forecasting. Subjects: Quantum Physics (quant-ph) Cite as: arXiv:2510.21168 [quant-ph] (or arXiv:2510.21168v1 [quant-ph] for this version) https://doi.org/10.48550/arXiv.2510.21168 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Sandra Ranilla-Cortina [ view email ] [v1] Fri, 24 Oct 2025 05:44:41 UTC (708 KB) Full-text links: Access Paper: View a PDF of the paper titled Quantum Neural Network Architectures for Multivariate Time-Series Forecasting, by Sandra Ranilla-Cortina and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: quant-ph &lt; prev | next &gt; new | recent | 2025-10 References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-64">33. Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.23898v1</li>
<li>来源：arxiv</li>
<li>摘要：Reliable forecasting of Global Horizontal Irradiance (GHI) is essential for mitigating the variability of solar energy in power grids. This study presents a comprehensive benchmark of ten deep learning architectures for short-term (1-hour ahead) GHI time series forecasting in Ho Chi Minh City, leveraging high-resolution NSRDB satellite data (2011-2020) to compare established baselines (e.g. LSTM, TCN) against emerging state-of-the-art architectures, including Transformer, Informer, iTransformer, TSMixer, and Mamba. Experimental results identify the Transformer as the superior architecture, achieving the highest predictive accuracy with an R^2 of 0.9696. The study further utilizes SHAP analysis to contrast the temporal reasoning of these architectures, revealing that Transformers exhibit a strong "recency bias" focused on immediate atmospheric conditions, whereas Mamba explicitly leverages 24-hour periodic dependencies to inform predictions. Furthermore, we demonstrate that Knowledge Distillation can compress the high-performance Transformer by 23.5% while surprisingly reducing error (MAE: 23.78 W/m^2), offering a proven pathway for deploying sophisticated, low-latency forecasting o</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，LSTM 和 TCN 等传统架构被用作基准进行比较，而 Transformer 架构则表现出对近期条件的强烈偏好，这表明它在捕捉短期依赖关系方面具有优势。其次，Mamba 架构通过利用 24 小时周期性依赖关系，进一步增强了模型的预测能力。此外，实验结果表明，Transformer 架构在预测准确性方面达到了最高水平，这与其对近期条件的偏好密切相关。然而，SHAP 分析揭示了不同架构在时序推理上的差异，表明尽管 Transformer 表现优异，但在某些情况下可能不如其他架构灵活。因此，对于资源受限的边缘设备而言，通过知识蒸馏压缩高性能的 Transformer，可以实现低延迟的预测，同时保持较高的预测准确性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>LSTM 和 TCN 等传统架构被用作基准进行比较。</li>
<li>Transformer 架构表现出对近期条件的强烈偏好。</li>
<li>Mamba 架构利用了 24 小时周期性依赖关系。</li>
<li>Knowledge Distillation 可以压缩高性能 Transformer。</li>
<li>实验结果表明，Transformer 达到最高的预测准确性。</li>
<li>SHAP 分析揭示了不同架构的时序推理差异。</li>
<li>资源受限的边缘设备可以利用知识蒸馏进行低延迟预测。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-65">正文（抓取，非 AI）</h3>
<p>[2512.23898v1] Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City Computer Science &gt; Machine Learning arXiv:2512.23898v1 (cs) [Submitted on 29 Dec 2025] Title: Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City Authors: Tin Hoang View a PDF of the paper titled Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City, by Tin Hoang View PDF HTML (experimental) Abstract: Reliable forecasting of Global Horizontal Irradiance (GHI) is essential for mitigating the variability of solar energy in power grids. This study presents a comprehensive benchmark of ten deep learning architectures for short-term (1-hour ahead) GHI time series forecasting in Ho Chi Minh City, leveraging high-resolution NSRDB satellite data (2011-2020) to compare established baselines (e.g. LSTM, TCN) against emerging state-of-the-art architectures, including Transformer, Informer, iTransformer, TSMixer, and Mamba. Experimental results identify the Transformer as the superior architecture, achieving the highest predictive accuracy with an R^2 of 0.9696. The study further utilizes SHAP analysis to contrast the temporal reasoning of these architectures, revealing that Transformers exhibit a strong "recency bias" focused on immediate atmospheric conditions, whereas Mamba explicitly leverages 24-hour periodic dependencies to inform predictions. Furthermore, we demonstrate that Knowledge Distillation can compress the high-performance Transformer by 23.5% while surprisingly reducing error (MAE: 23.78 W/m^2), offering a proven pathway for deploying sophisticated, low-latency forecasting on resource-constrained edge devices. Comments: preprint, 40 pages Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2512.23898 [cs.LG] (or arXiv:2512.23898v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2512.23898 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Tin Hoang [ view email ] [v1] Mon, 29 Dec 2025 23:22:25 UTC (3,287 KB) Full-text links: Access Paper: View a PDF of the paper titled Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City, by Tin Hoang View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-66">34. Lossless Compression: A New Benchmark for Time Series Model Evaluation</h2>
<ul>
<li>链接：https://arxiv.org/abs/2509.21002v1</li>
<li>来源：arxiv</li>
<li>摘要：The evaluation of time series models has traditionally focused on four canonical tasks: forecasting, imputation, anomaly detection, and classification. While these tasks have driven significant progress, they primarily assess task-specific performance and do not rigorously measure whether a model captures the full generative distribution of the data. We introduce lossless compression as a new paradigm for evaluating time series models, grounded in Shannon's source coding theorem. This perspective establishes a direct equivalence between optimal compression length and the negative log-likelihood, providing a strict and unified information-theoretic criterion for modeling capacity. Then We define a standardized evaluation protocol and metrics. We further propose and open-source a comprehensive evaluation framework TSCom-Bench, which enables the rapid adaptation of time series models as backbones for lossless compression. Experiments across diverse datasets on state-of-the-art models, including TimeXer, iTransformer, and PatchTST, demonstrate that compression reveals distributional weaknesses overlooked by classic benchmarks. These findings position lossless compression as a principle</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，lossless compression 作为一项原则性任务，补充和扩展现有评估模型，确保模型能够完全捕捉数据生成分布，从而避免信息的丢失。其次，optimal compression length 直接等同于负对数似然，负对数似然提供了一个严格统一的信息论标准，用于评估模型对数据分布的捕捉能力。此外，TSCom-Bench 评估框架支持快速适应时间序列模型，确保模型能够准确地适应各种时间序列数据。因此，经典基准可能忽略分布中的弱点，而 lossless compression 作为补充，能够更全面地评估模型的质量。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>lossless compression 评估模型是否完全捕捉数据生成分布。</li>
<li>optimal compression length 直接等同于负对数似然。</li>
<li>negative log-likelihood 提供严格统一的信息论标准。</li>
<li>TSCom-Bench 评估框架支持快速适应时间序列模型。</li>
<li>经典基准可能忽略分布弱点。</li>
<li>lossless compression 作为原则性任务补充和扩展现有评估。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-67">正文（抓取，非 AI）</h3>
<p>[2509.21002v1] Lossless Compression: A New Benchmark for Time Series Model Evaluation Computer Science &gt; Machine Learning arXiv:2509.21002v1 (cs) [Submitted on 25 Sep 2025] Title: Lossless Compression: A New Benchmark for Time Series Model Evaluation Authors: Meng Wan , Benxi Tian , Jue Wang , Cui Hui , Ningming Nie , Tiantian Liu , Zongguo Wang , Cao Rongqiang , Peng Shi , Yangang Wang View a PDF of the paper titled Lossless Compression: A New Benchmark for Time Series Model Evaluation, by Meng Wan and 9 other authors View PDF HTML (experimental) Abstract: The evaluation of time series models has traditionally focused on four canonical tasks: forecasting, imputation, anomaly detection, and classification. While these tasks have driven significant progress, they primarily assess task-specific performance and do not rigorously measure whether a model captures the full generative distribution of the data. We introduce lossless compression as a new paradigm for evaluating time series models, grounded in Shannon's source coding theorem. This perspective establishes a direct equivalence between optimal compression length and the negative log-likelihood, providing a strict and unified information-theoretic criterion for modeling capacity. Then We define a standardized evaluation protocol and metrics. We further propose and open-source a comprehensive evaluation framework TSCom-Bench, which enables the rapid adaptation of time series models as backbones for lossless compression. Experiments across diverse datasets on state-of-the-art models, including TimeXer, iTransformer, and PatchTST, demonstrate that compression reveals distributional weaknesses overlooked by classic benchmarks. These findings position lossless compression as a principled task that complements and extends existing evaluation for time series modeling. Comments: 24 pages Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2509.21002 [cs.LG] (or arXiv:2509.21002v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2509.21002 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Meng Wan [ view email ] [v1] Thu, 25 Sep 2025 10:52:48 UTC (3,041 KB) Full-text links: Access Paper: View a PDF of the paper titled Lossless Compression: A New Benchmark for Time Series Model Evaluation, by Meng Wan and 9 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-09 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-68">35. Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.17149v1</li>
<li>来源：arxiv</li>
<li>摘要：This study investigates the task of dwell time prediction and proposes a Transformer framework based on interaction behavior modeling. The method first represents user interaction sequences on the interface by integrating dwell duration, click frequency, scrolling behavior, and contextual features, which are mapped into a unified latent space through embedding and positional encoding. On this basis, a multi-head self-attention mechanism is employed to capture long-range dependencies, while a feed-forward network performs deep nonlinear transformations to model the dynamic patterns of dwell time. Multiple comparative experiments are conducted with BILSTM, DRFormer, FedFormer, and iTransformer as baselines under the same conditions. The results show that the proposed method achieves the best performance in terms of MSE, RMSE, MAPE, and RMAE, and more accurately captures the complex patterns in interaction behavior. In addition, sensitivity experiments are carried out on hyperparameters and environments to examine the impact of the number of attention heads, sequence window length, and device environment on prediction performance, which further demonstrates the robustness and adaptabi</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">Transformer 模型因其强大的长距离依赖捕捉能力，在用户交互序列建模中展现出显著优势，尤其是在停留时间预测任务中提供了新的见解。然而，这一优势伴随着较高的计算需求。为增强模型对多模式信息的处理能力，引入了多头自注意力机制，该机制通过统一的潜在空间整合了多种用户交互特征，便于建模。此外，前馈网络用于深层非线性变换，以建模停留时间的动态模式，进一步提升了模型的性能。对比实验表明，新方法在多个评价指标上表现最优，而敏感性实验则揭示了超参数和环境对预测性能的影响。方法的鲁棒性和适应性通过实验进一步得到验证，从而确保了模型在不同条件下的有效性和可靠性。因此，Transformer 模型不仅提供了新的用户交互序列建模解决方案，还在理论和方法上取得了突破，其有效性在多个方面得到了验证。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Transformer 模型能捕捉长距离依赖关系，但需要较多计算资源。</li>
<li>统一的潜在空间整合了多种用户交互特征，便于建模。</li>
<li>多头自注意力机制增强了模型对多模式信息的处理能力。</li>
<li>前馈网络用于深层非线性变换，以建模停留时间的动态模式。</li>
<li>对比实验表明，新方法在多个评价指标上表现最优。</li>
<li>敏感性实验揭示了超参数和环境对预测性能的影响。</li>
<li>方法的鲁棒性和适应性通过实验进一步得到验证。</li>
<li>Transformer 模型提供了新的用户交互序列建模解决方案。</li>
<li>停留时间预测任务得到了理论和方法上的新见解。</li>
<li>模型的有效性在多个方面得到了验证。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-69">正文（抓取，非 AI）</h3>
<p>[2512.17149v1] Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces Computer Science &gt; Human-Computer Interaction arXiv:2512.17149v1 (cs) [Submitted on 19 Dec 2025] Title: Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces Authors: Rui Liu , Runsheng Zhang , Shixiao Wang View a PDF of the paper titled Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces, by Rui Liu and 2 other authors View PDF Abstract: This study investigates the task of dwell time prediction and proposes a Transformer framework based on interaction behavior modeling. The method first represents user interaction sequences on the interface by integrating dwell duration, click frequency, scrolling behavior, and contextual features, which are mapped into a unified latent space through embedding and positional encoding. On this basis, a multi-head self-attention mechanism is employed to capture long-range dependencies, while a feed-forward network performs deep nonlinear transformations to model the dynamic patterns of dwell time. Multiple comparative experiments are conducted with BILSTM, DRFormer, FedFormer, and iTransformer as baselines under the same conditions. The results show that the proposed method achieves the best performance in terms of MSE, RMSE, MAPE, and RMAE, and more accurately captures the complex patterns in interaction behavior. In addition, sensitivity experiments are carried out on hyperparameters and environments to examine the impact of the number of attention heads, sequence window length, and device environment on prediction performance, which further demonstrates the robustness and adaptability of the method. Overall, this study provides a new solution for dwell time prediction from both theoretical and methodological perspectives and verifies its effectiveness in multiple aspects. Subjects: Human-Computer Interaction (cs.HC) Cite as: arXiv:2512.17149 [cs.HC] (or arXiv:2512.17149v1 [cs.HC] for this version) https://doi.org/10.48550/arXiv.2512.17149 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Rui Liu [ view email ] [v1] Fri, 19 Dec 2025 00:55:14 UTC (362 KB) Full-text links: Access Paper: View a PDF of the paper titled Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces, by Rui Liu and 2 other authors View PDF view license Current browse context: cs.HC &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-70">36. The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.18610v2</li>
<li>来源：arxiv</li>
<li>摘要：Optimizing time series models via point-wise loss functions (e.g., MSE) relying on a heuristic point-wise i.i.d. assumption disregards the causal temporal structure. Focusing on the core independence issue under covariance stationarity, this paper aims to provide a first-principles analysis of the Expectation of Optimization Bias (EOB). Our analysis reveals a fundamental paradigm paradox: The more deterministic and structured the time series, the more severe the bias incurred by point-wise loss function. We derive the first closed-form quantification for the non-deterministic EOB across linear and non-linear systems, and prove EOB is an intrinsic data property, governed exclusively by sequence length and the defined Structural Signal-to-Noise Ratio. This theoretical discovery motivates our principled debiasing program that eliminates the bias through sequence length reduction and structural orthogonalization. We present a concrete solution via DFT or DWT, and propose a novel harmonized $\ell_p$ norm framework to rectify gradient optimization pathologies of high-variance sequences. Extensive experiments validate EOB Theory's generality and the superior performance of debiasing progr</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">点wise损失函数假设时间序列数据独立同分布，忽略了因果时间结构，这在协方差平稳性下成为核心问题。这种独立性假设导致了在确定性和结构化更强的情况下，时间序列模型优化出现更严重的偏差。优化偏差是一个由序列长度和结构信噪比决定的内在数据属性，因此，通过减少序列长度和结构正交化可以部分消除这种偏差。此外，DFT（离散傅里叶变换）或DWT（离散小波变换）可以具体解决这一问题，而一个新型的谐波$\ell_p$范式框架则提供了更全面的纠正方法。这些理论不仅具有广泛的适用性，还证明了去偏差程序的优越性能，在11个数据集上分别实现了5.2%和5.1%的平均MSE和MAE改进。因此，点wise损失函数引起的优化偏差不仅是一个理论问题，而且在实际应用中具有显著的影响。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>点wise损失函数假设时间序列数据独立同分布，忽略了因果时间结构。</li>
<li>点wise损失函数假设下的独立性问题在协方差平稳性下是核心问题。</li>
<li>点wise损失函数导致的时间序列模型优化偏差在确定性和结构化更强时更严重。</li>
<li>点wise损失函数引起的优化偏差是一个由序列长度和结构信噪比决定的内在数据属性。</li>
<li>点wise损失函数引起的优化偏差可以通过减少序列长度和结构正交化来消除。</li>
<li>点wise损失函数引起的优化偏差可以通过DFT或DWT来具体解决。</li>
<li>点wise损失函数引起的优化偏差可以通过一个新型的谐波$\ell_p$范式框架来纠正。</li>
<li>点wise损失函数引起的优化偏差理论具有广泛的适用性，证明了去偏差程序的优越性能。</li>
<li>点wise损失函数引起的优化偏差理论在11个数据集上分别实现了5.2%和5.1%的平均MSE和MAE改进。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-71">正文（抓取，非 AI）</h3>
<p>[2512.18610v2] The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss Computer Science &gt; Machine Learning arXiv:2512.18610v2 (cs) [Submitted on 21 Dec 2025 ( v1 ), last revised 1 Feb 2026 (this version, v2)] Title: The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss Authors: Rongyao Cai , Yuxi Wan , Kexin Zhang , Ming Jin , Hao Wang , Zhiqiang Ge , Daoyi Dong , Yong Liu , Qingsong Wen View a PDF of the paper titled The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss, by Rongyao Cai and 8 other authors View PDF HTML (experimental) Abstract: Optimizing time series models via point-wise loss functions (e.g., MSE) relying on a heuristic point-wise i.i.d. assumption disregards the causal temporal structure. Focusing on the core independence issue under covariance stationarity, this paper aims to provide a first-principles analysis of the Expectation of Optimization Bias (EOB). Our analysis reveals a fundamental paradigm paradox: The more deterministic and structured the time series, the more severe the bias incurred by point-wise loss function. We derive the first closed-form quantification for the non-deterministic EOB across linear and non-linear systems, and prove EOB is an intrinsic data property, governed exclusively by sequence length and the defined Structural Signal-to-Noise Ratio. This theoretical discovery motivates our principled debiasing program that eliminates the bias through sequence length reduction and structural orthogonalization. We present a concrete solution via DFT or DWT, and propose a novel harmonized $\ell_p$ norm framework to rectify gradient optimization pathologies of high-variance sequences. Extensive experiments validate EOB Theory's generality and the superior performance of debiasing program, achieving 5.2% and 5.1% average improvement of MSE and MAE conducted on the iTransformer across 11 datasets, respectively. Comments: 54 pages Subjects: Machine Learning (cs.LG) Cite as: arXiv:2512.18610 [cs.LG] (or arXiv:2512.18610v2 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2512.18610 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Rongyao Cai [ view email ] [v1] Sun, 21 Dec 2025 06:08:22 UTC (27,328 KB) [v2] Sun, 1 Feb 2026 14:34:29 UTC (34,944 KB) Full-text links: Access Paper: View a PDF of the paper titled The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss, by Rongyao Cai and 8 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-72">37. InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling</h2>
<ul>
<li>链接：https://arxiv.org/abs/2510.20302v1</li>
<li>来源：arxiv</li>
<li>摘要：Multivariate time series forecasting requires simultaneously modeling temporal patterns and cross-variate dependencies. Channel-independent methods such as PatchTST excel at temporal modeling but ignore variable correlations, while pure variate-attention approaches such as iTransformer sacrifice temporal encoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that achieves principled separation between temporal encoding and variate-level decoding. InvDec combines a patch-based temporal encoder with an inverted decoder operating on the variate dimension through variate-wise self-attention. We introduce delayed variate embeddings that enrich variable-specific representations only after temporal encoding, preserving temporal feature integrity. An adaptive residual fusion mechanism dynamically balances temporal and variate information across datasets of varying dimensions. Instantiating InvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven benchmarks demonstrate significant gains on high-dimensional datasets: 20.9% MSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and 2.7% gain on Traffic compared to PatchTST, while maintainin</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">InvDec 的设计实现了时间编码和变量解码的明确分离，这使得它能够同时处理时间模式和变量间的关联。相比之下，PatchTST 专注于时间模式建模但忽视了变量间的关联，而 iTransformer 强调变量注意力但牺牲了时间编码。InvDec 结合了基于块的时间编码器和逆向变量解码器，延迟变量嵌入仅在时间编码后丰富变量特定表示。此外，自适应残差融合机制在不同维度的数据集上动态平衡时间与变量信息，使得 InvDec 在高维数据集上表现出显著改进，实验结果表明其在高维数据集上的 MSE 减少了 20.9%。在低维数据集上，InvDec 保持了竞争力。消融研究验证了每个组件的有效性，分析表明 InvDec 的优势随着变量数量的增加而增加，交叉变量建模在变量数量增加时变得至关重要。因此，InvDec 通过明确分离时间编码和变量解码，有效地处理了高维数据集中的复杂关系。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>InvDec 的设计实现了时间编码和变量解码的明确分离。</li>
<li>PatchTST 专注于时间模式建模但忽视了变量间的关联。</li>
<li>iTransformer 强调变量注意力但牺牲了时间编码。</li>
<li>InvDec 结合了基于块的时间编码器和逆向变量解码器。</li>
<li>延迟变量嵌入仅在时间编码后丰富变量特定表示。</li>
<li>自适应残差融合机制在不同维度的数据集上动态平衡时间与变量信息。</li>
<li>InvDec 在高维数据集上表现出显著改进。</li>
<li>实验结果表明 InvDec 在高维数据集上的 MSE 减少了 20.9%。</li>
<li>低维数据集上，InvDec 保持了竞争力。</li>
<li>消融研究验证了每个组件的有效性。</li>
<li>分析表明 InvDec 的优势随着变量数量的增加而增加。</li>
<li>交叉变量建模在变量数量增加时变得至关重要。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-73">正文（抓取，非 AI）</h3>
<p>[2510.20302v1] InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling Computer Science &gt; Machine Learning arXiv:2510.20302v1 (cs) [Submitted on 23 Oct 2025] Title: InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling Authors: Yuhang Wang View a PDF of the paper titled InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling, by Yuhang Wang View PDF HTML (experimental) Abstract: Multivariate time series forecasting requires simultaneously modeling temporal patterns and cross-variate dependencies. Channel-independent methods such as PatchTST excel at temporal modeling but ignore variable correlations, while pure variate-attention approaches such as iTransformer sacrifice temporal encoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that achieves principled separation between temporal encoding and variate-level decoding. InvDec combines a patch-based temporal encoder with an inverted decoder operating on the variate dimension through variate-wise self-attention. We introduce delayed variate embeddings that enrich variable-specific representations only after temporal encoding, preserving temporal feature integrity. An adaptive residual fusion mechanism dynamically balances temporal and variate information across datasets of varying dimensions. Instantiating InvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven benchmarks demonstrate significant gains on high-dimensional datasets: 20.9% MSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and 2.7% gain on Traffic compared to PatchTST, while maintaining competitive performance on low-dimensional ETT datasets. Ablation studies validate each component, and analysis reveals that InvDec's advantage grows with dataset dimensionality, confirming that cross-variate modeling becomes critical as the number of variables increases. Comments: 23pages, 3 figures Subjects: Machine Learning (cs.LG) Cite as: arXiv:2510.20302 [cs.LG] (or arXiv:2510.20302v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2510.20302 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Yuhang Wang [ view email ] [v1] Thu, 23 Oct 2025 07:42:01 UTC (475 KB) Full-text links: Access Paper: View a PDF of the paper titled InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling, by Yuhang Wang View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-10 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-74">38. Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition</h2>
<ul>
<li>链接：https://arxiv.org/abs/2601.10525v1</li>
<li>来源：arxiv</li>
<li>摘要：Understanding how local neurophysiological patterns interact with global brain dynamics is essential for decoding human emotions from EEG signals. However, existing deep learning approaches often overlook the brain's intrinsic spatial organization, failing to simultaneously capture local topological relations and global dependencies. To address these challenges, we propose Neuro-HGLN, a Neurologically-informed Hierarchical Graph-Transformer Learning Network that integrates biologically grounded priors with hierarchical representation learning. Neuro-HGLN first constructs a spatial Euclidean prior graph based on physical electrode distances to serve as an anatomically grounded inductive bias. A learnable global dynamic graph is then introduced to model functional connectivity across the entire brain. In parallel, to capture fine-grained regional dependencies, Neuro-HGLN builds region-level local graphs using a multi-head self-attention mechanism. These graphs are processed synchronously through local-constrained parallel GCN layers to produce region-specific representations. Subsequently, an iTransformer encoder aggregates these features to capture cross-region dependencies under a </li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">脑的固有空间组织常常被现有的深度学习方法忽视，这导致了局部神经生理模式与全局脑动态之间的相互作用未能得到充分考虑，进而影响了从EEG信号解码人类情绪的准确性。为了解决这一问题，神经-HGLN通过神经-结构化先验图来捕捉局部拓扑关系和全局依赖性，同时利用全局动态图来建模整个大脑的功能连接性。此外，多头自注意力机制用于构建区域级局部图，以捕捉细粒度的区域依赖性，而局部约束并行GCN层则用于生成区域特定表示。iTransformer编码器则用于聚合特征，以捕捉跨区域依赖性。这些方法的统一应用使得神经-HGLN在多个基准测试中实现了最先进的性能，并提供了基于神经生理结构的增强可解释性。因此，局部拓扑学习与跨区域依赖性建模的统一对于稳健的EEG情绪识别至关重要。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>脑的固有空间组织常常被现有的深度学习方法忽视。</li>
<li>局部神经生理模式与全局脑动态之间的相互作用对于从EEG信号解码人类情绪至关重要。</li>
<li>神经-结构化先验图有助于捕捉局部拓扑关系和全局依赖性。</li>
<li>全局动态图有助于建模整个大脑的功能连接性。</li>
<li>多头自注意力机制用于构建区域级局部图以捕捉细粒度的区域依赖性。</li>
<li>局部约束并行GCN层用于生成区域特定表示。</li>
<li>iTransformer编码器用于聚合特征以捕捉跨区域依赖性。</li>
<li>神经-HGLN在多个基准测试中实现了最先进的性能。</li>
<li>神经-HGLN提供了基于神经生理结构的增强可解释性。</li>
<li>局部拓扑学习与跨区域依赖性建模的统一对于稳健的EEG情绪识别有效。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-75">正文（抓取，非 AI）</h3>
<p>[2601.10525v1] Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition Computer Science &gt; Human-Computer Interaction arXiv:2601.10525v1 (cs) [Submitted on 15 Jan 2026] Title: Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition Authors: Yijin Zhou , Fu Li , Yi Niu , Boxun Fu , Huaning Wang , Lijian Zhang View a PDF of the paper titled Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition, by Yijin Zhou and 5 other authors View PDF HTML (experimental) Abstract: Understanding how local neurophysiological patterns interact with global brain dynamics is essential for decoding human emotions from EEG signals. However, existing deep learning approaches often overlook the brain's intrinsic spatial organization, failing to simultaneously capture local topological relations and global dependencies. To address these challenges, we propose Neuro-HGLN, a Neurologically-informed Hierarchical Graph-Transformer Learning Network that integrates biologically grounded priors with hierarchical representation learning. Neuro-HGLN first constructs a spatial Euclidean prior graph based on physical electrode distances to serve as an anatomically grounded inductive bias. A learnable global dynamic graph is then introduced to model functional connectivity across the entire brain. In parallel, to capture fine-grained regional dependencies, Neuro-HGLN builds region-level local graphs using a multi-head self-attention mechanism. These graphs are processed synchronously through local-constrained parallel GCN layers to produce region-specific representations. Subsequently, an iTransformer encoder aggregates these features to capture cross-region dependencies under a dimension-as-token formulation. Extensive experiments demonstrate that Neuro-HGLN achieves state-of-the-art performance on multiple benchmarks, providing enhanced interpretability grounded in neurophysiological structure. These results highlight the efficacy of unifying local topological learning with cross-region dependency modeling for robust EEG emotion recognition. Subjects: Human-Computer Interaction (cs.HC) Cite as: arXiv:2601.10525 [cs.HC] (or arXiv:2601.10525v1 [cs.HC] for this version) https://doi.org/10.48550/arXiv.2601.10525 Focus to learn more arXiv-issued DOI via DataCite Submission history From: YiJin Zhou [ view email ] [v1] Thu, 15 Jan 2026 15:52:05 UTC (10,475 KB) Full-text links: Access Paper: View a PDF of the paper titled Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition, by Yijin Zhou and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.HC &lt; prev | next &gt; new | recent | 2026-01 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-76">39. Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2511.10200v2</li>
<li>来源：arxiv</li>
<li>摘要：Time series forecasting is an important task that involves analyzing temporal dependencies and underlying patterns (such as trends, cyclicality, and seasonality) in historical data to predict future values or trends. Current deep learning-based forecasting models primarily employ Mean Squared Error (MSE) loss functions for regression modeling. Despite enabling direct value prediction, this method offers no uncertainty estimation and exhibits poor outlier robustness. To address these limitations, we propose OCE-TS, a novel ordinal classification approach for time series forecasting that replaces MSE with Ordinal Cross-Entropy (OCE) loss, preserving prediction order while quantifying uncertainty through probability output. Specifically, OCE-TS begins by discretizing observed values into ordered intervals and deriving their probabilities via a parametric distribution as supervision signals. Using a simple linear model, we then predict probability distributions for each timestep. The OCE loss is computed between the cumulative distributions of predicted and ground-truth probabilities, explicitly preserving ordinal relationships among forecasted values. Through theoretical analysis usin</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">MSE损失无法提供不确定性估计，这使得它在处理不确定性和异常值时存在局限性。为了解决这一问题，OCE-TS通过离散化观测值来量化不确定性，引入了一种新的损失函数——OCE损失，它通过累积分布来计算，保持预测值的顺序关系。理论分析表明，交叉熵损失比MSE损失更稳定，对异常值更鲁棒，因此OCE-TS在多个时间序列数据集上优于基准模型。OCE-TS使用简单的线性模型预测概率分布，并通过概率输出来量化不确定性，从而解决了MSE损失的不足之处。实验证明，OCE-TS通过计算预测和真实值的累积分布之间的损失来工作，MSE和MAE被用作评估指标，进一步验证了其优越性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>MSE损失无法提供不确定性估计。</li>
<li>OCE-TS通过离散化观测值来量化不确定性。</li>
<li>OCE损失通过累积分布来计算，保持预测值的顺序关系。</li>
<li>理论分析表明交叉熵损失比MSE损失更稳定，对异常值更鲁棒。</li>
<li>实验证明OCE-TS在多个时间序列数据集上优于基准模型。</li>
<li>OCE-TS使用简单的线性模型预测概率分布。</li>
<li>OCE-TS通过概率输出来量化不确定性。</li>
<li>MSE和MAE被用作评估指标。</li>
<li>OCE-TS通过计算预测和真实值的累积分布之间的损失来工作。</li>
<li>OCE-TS解决了MSE损失的不足之处。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-77">正文（抓取，非 AI）</h3>
<p>[2511.10200v2] Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting Computer Science &gt; Machine Learning arXiv:2511.10200v2 (cs) [Submitted on 13 Nov 2025 ( v1 ), last revised 27 Nov 2025 (this version, v2)] Title: Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting Authors: Jieting Wang , Huimei Shi , Feijiang Li , Xiaolei Shang View a PDF of the paper titled Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting, by Jieting Wang and 3 other authors View PDF HTML (experimental) Abstract: Time series forecasting is an important task that involves analyzing temporal dependencies and underlying patterns (such as trends, cyclicality, and seasonality) in historical data to predict future values or trends. Current deep learning-based forecasting models primarily employ Mean Squared Error (MSE) loss functions for regression modeling. Despite enabling direct value prediction, this method offers no uncertainty estimation and exhibits poor outlier robustness. To address these limitations, we propose OCE-TS, a novel ordinal classification approach for time series forecasting that replaces MSE with Ordinal Cross-Entropy (OCE) loss, preserving prediction order while quantifying uncertainty through probability output. Specifically, OCE-TS begins by discretizing observed values into ordered intervals and deriving their probabilities via a parametric distribution as supervision signals. Using a simple linear model, we then predict probability distributions for each timestep. The OCE loss is computed between the cumulative distributions of predicted and ground-truth probabilities, explicitly preserving ordinal relationships among forecasted values. Through theoretical analysis using influence functions, we establish that cross-entropy (CE) loss exhibits superior stability and outlier robustness compared to MSE loss. Empirically, we compared OCE-TS with five baseline models-Autoformer, DLinear, iTransformer, TimeXer, and TimeBridge-on seven public time series datasets. Using MSE and Mean Absolute Error (MAE) as evaluation metrics, the results demonstrate that OCE-TS consistently outperforms benchmark models. The codeis publicly available at: this https URL . Subjects: Machine Learning (cs.LG) Cite as: arXiv:2511.10200 [cs.LG] (or arXiv:2511.10200v2 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2511.10200 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Feijiang Li [ view email ] [v1] Thu, 13 Nov 2025 11:14:24 UTC (10,056 KB) [v2] Thu, 27 Nov 2025 11:46:13 UTC (10,059 KB) Full-text links: Access Paper: View a PDF of the paper titled Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting, by Jieting Wang and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-11 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-78">40. Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models</h2>
<ul>
<li>链接：https://arxiv.org/abs/2510.04900v1</li>
<li>来源：arxiv</li>
<li>摘要：Understanding the robustness of deep learning models for multivariate long-term time series forecasting (M-LTSF) remains challenging, as evaluations typically rely on real-world datasets with unknown noise properties. We propose a simulation-based evaluation framework that generates parameterizable synthetic datasets, where each dataset instance corresponds to a different configuration of signal components, noise types, signal-to-noise ratios, and frequency characteristics. These configurable components aim to model real-world multivariate time series data without the ambiguity of unknown noise. This framework enables fine-grained, systematic evaluation of M-LTSF models under controlled and diverse scenarios. We benchmark four representative architectures S-Mamba (state-space), iTransformer (transformer-based), R-Linear (linear), and Autoformer (decomposition-based). Our analysis reveals that all models degrade severely when lookback windows cannot capture complete periods of seasonal patters in the data. S-Mamba and Autoformer perform best on sawtooth patterns, while R-Linear and iTransformer favor sinusoidal signals. White and Brownian noise universally degrade performance with l</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">real-world datasets introduce unknown noise properties that complicate evaluation, necessitating the use of synthetic datasets for controlled evaluation of M-LTSF models. To ensure accurate performance, lookback windows must capture complete periods of seasonal patterns, avoiding model degradation. Different models exhibit varying performance based on specific signal characteristics: S-Mamba and Autoformer excel with sawtooth patterns, while R-Linear and iTransformer perform better with sinusoidal signals. Additionally, White and Brownian noise reduce performance at lower signal-to-noise ratios, with Trend-noise specifically degrading S-Mamba performance and Seasonal-noise particularly affecting iTransformer. Both S-Mamba and iTransformer show superior frequency reconstruction, highlighting their strengths in handling complex noise conditions. Therefore, model selection should consider signal characteristics and noise conditions, with MSE scores providing insights into model-specific strengths and limitations.</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>real-world datasets introduce unknown noise properties that complicate evaluation.</li>
<li>synthetic datasets allow for controlled evaluation of M-LTSF models.</li>
<li>lookback windows must capture complete periods of seasonal patterns to avoid model degradation.</li>
<li>S-Mamba and Autoformer excel with sawtooth patterns.</li>
<li>R-Linear and iTransformer perform better with sinusoidal signals.</li>
<li>White and Brownian noise reduce performance at lower signal-to-noise ratios.</li>
<li>Trend-noise specifically degrades S-Mamba performance.</li>
<li>Seasonal-noise particularly affects iTransformer.</li>
<li>S-Mamba and iTransformer show superior frequency reconstruction.</li>
<li>Model selection should consider signal characteristics and noise conditions.</li>
<li>MSE scores provide insights into model-specific strengths and limitations.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-79">正文（抓取，非 AI）</h3>
<p>[2510.04900v1] Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models Computer Science &gt; Machine Learning arXiv:2510.04900v1 (cs) [Submitted on 6 Oct 2025] Title: Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models Authors: Nick Janßen , Melanie Schaller , Bodo Rosenhahn View a PDF of the paper titled Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models, by Nick Jan{\ss}en and 2 other authors View PDF HTML (experimental) Abstract: Understanding the robustness of deep learning models for multivariate long-term time series forecasting (M-LTSF) remains challenging, as evaluations typically rely on real-world datasets with unknown noise properties. We propose a simulation-based evaluation framework that generates parameterizable synthetic datasets, where each dataset instance corresponds to a different configuration of signal components, noise types, signal-to-noise ratios, and frequency characteristics. These configurable components aim to model real-world multivariate time series data without the ambiguity of unknown noise. This framework enables fine-grained, systematic evaluation of M-LTSF models under controlled and diverse scenarios. We benchmark four representative architectures S-Mamba (state-space), iTransformer (transformer-based), R-Linear (linear), and Autoformer (decomposition-based). Our analysis reveals that all models degrade severely when lookback windows cannot capture complete periods of seasonal patters in the data. S-Mamba and Autoformer perform best on sawtooth patterns, while R-Linear and iTransformer favor sinusoidal signals. White and Brownian noise universally degrade performance with lower signal-to-noise ratio while S-Mamba shows specific trend-noise and iTransformer shows seasonal-noise vulnerability. Further spectral analysis shows that S-Mamba and iTransformer achieve superior frequency reconstruction. This controlled approach, based on our synthetic and principle-driven testbed, offers deeper insights into model-specific strengths and limitations through the aggregation of MSE scores and provides concrete guidance for model selection based on signal characteristics and noise conditions. Comments: Number of pages: 13 Number of figures: 16 Number of Tables: 1 Submitted to: IEEE Transactions on Signal Processing Subjects: Machine Learning (cs.LG) ; Systems and Control (eess.SY) Cite as: arXiv:2510.04900 [cs.LG] (or arXiv:2510.04900v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2510.04900 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Nick Janßen [ view email ] [v1] Mon, 6 Oct 2025 15:16:52 UTC (441 KB) Full-text links: Access Paper: View a PDF of the paper titled Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models, by Nick Jan{\ss}en and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-10 Change to browse by: cs cs.SY eess eess.SY References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-80">41. 一文读懂：大模型RAG（检索增强生成）含高级方法</h2>
<ul>
<li>链接：https://www.zhihu.com/tardis/zm/art/675509396</li>
<li>来源：bing</li>
<li>摘要：2025年12月15日 · LLM生成 Prompt作为大模型的直接输入，是影响模型输出准确率的关键因素之一。 在RAG场景中，Prompt一般包括任务描述、背景知识（检索得到）、任务指令（一般是用户提问） …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">大模型的Prompt直接影响输出准确率，而RAG（Retrieval-Augmented Generation）通过检索技术增强大模型生成答案，从而提升答案的质量。然而，由于大模型的知识局限性，它们无法满足实际业务需求，甚至可能产生幻觉，尤其是在知识不足时。因此，数据安全性成为企业应用大模型时的重要考虑因素。RAG的核心在于“检索+生成”，其中检索利用向量数据库来生成多个查询，覆盖问题的各个方面，而生成则利用大模型来生成答案。这一过程包括语义搜索和生成输出，具体步骤涉及文本分块、嵌入、索引创建和LLM提示。此外，数据准备阶段包括数据提取、分割、向量化和入库，其中文本分割需考虑embedding模型的Tokens限制和语义完整性，向量化模型如ChatGPT-Embedding、ERNIE-Embedding等，数据入库过程涉及构建索引并写入数据库。数据检索方法包括相似性检索和全文检索，而Prompt设计则依赖于个人经验，需根据模型输出进行调整。因此，标准RAG流程包括文本分块、嵌入、索引创建和LLM提示，而高级RAG技术则涉及核心步骤和算法方案，提示工程能进一步提升RAG流程性能。许多开源和商用模型可作为RAG管道的大脑，支持RAG技术的库如LangChain、LlamaIndex等。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>大模型的Prompt直接影响输出准确率。</li>
<li>RAG通过检索技术增强大模型生成答案。</li>
<li>知识的局限性是大模型无法满足实际业务需求的原因之一。</li>
<li>大模型可能会产生幻觉，尤其是在知识不足时。</li>
<li>数据安全性是企业应用大模型时的重要考虑因素。</li>
<li>RAG通过检索相关知识并注入Prompt来提升模型答案。</li>
<li>语义搜索和生成输出是RAG实现过程中的两个主要步骤。</li>
<li>LangChain、LlamaIndex等库支持RAG技术。</li>
<li>RAG通过生成多个查询来覆盖问题的各个方面。</li>
<li>RAG的核心是“检索+生成”，前者利用向量数据库，后者利用大模型。</li>
<li>数据准备阶段包括数据提取、分割、向量化和入库。</li>
<li>文本分割需考虑embedding模型的Tokens限制和语义完整性。</li>
<li>向量化模型如ChatGPT-Embedding、ERNIE-Embedding等。</li>
<li>数据入库过程涉及构建索引并写入数据库。</li>
<li>数据检索方法包括相似性检索和全文检索。</li>
<li>Prompt设计依赖于个人经验，需根据模型输出进行调整。</li>
<li>标准RAG流程包括文本分块、嵌入、索引创建和LLM提示。</li>
<li>高级RAG技术涉及核心步骤和算法方案。</li>
<li>提示工程能提升RAG流程性能。</li>
<li>有许多开源和商用模型可作为RAG管道的大脑。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-81">正文（抓取，非 AI）</h3>
<p>RAG RAG 检索增强生成（Retrieval Augmented Generation），已经成为当下最火热的LLM应用方案和打开方式了。 理解起来不难，就是通过自有垂域数据库检索相关信息，然后合并成为提示模板，给大模型润色生成回答。 每当将大模型应用于实际业务场景时发现，通用的基础大模型基本无法满足实际业务需求，主要有以下几方面原因： 知识的局限性 ：大模型自身的知识完全源于训练数据，而现有的主流大模型（deepseek、文心一言、通义千问…）的训练集基本都是构建于网络公开的数据，对于一些实时性的、非公开的或私域的数据是没有。 幻觉问题 ：所有的深度学习模型的底层原理都是基于数学概率，模型输出实质上是一系列数值运算，大模型也不例外，所以它经常会一本正经地胡说八道，尤其是在大模型自身不具备某一方面的知识或不擅长的任务场景。 数据安全性 ：对于企业来说，数据安全至关重要，没有企业愿意承担数据泄露的风险，尤其是大公司，没有人将私域数据上传第三方平台进行训练会推理。这也导致完全依赖通用大模型自身能力的应用方案不得不在数据安全和效果方面进行取舍。 而RAG就是解决上述问题的有效方案。 一句话总结： RAG（中文为检索增强生成） = 检索技术 + LLM 提示 。 例如，向 LLM 提问一个问题（qustion），RAG 从各种数据源检索相关的信息，并将检索到的信息和问题（answer）注入到 提示词模板中，LLM 最后给出答案。 许多产品基于 RAG 构建，从基于 web 搜索引擎和 LLM 的问答服务到使用私有数据的应用程序。 其实，早在2019年， Faiss 就实现了基于嵌入的向量搜索技术，现在 RAG 推动了 向量搜索 领域的发展。后来比如 chroma 、 http://weaviate.io 和 pinecone 这些基于开源搜索索引引擎（主要是 faiss 和 nmslib ）向量数据库初创公司，增加了输入文本的额外存储和其他工具。 在这个过程中，有两个主要步骤：语义搜索和生成输出。在语义搜索步骤中，从知识库中找到与要回答的查询最相关的部分内容。然后，在生成步骤中，将使用这些内容来生成响应。 有3个最著名的基于 LLM 的管道和应用程序的开源库—— LangChain 和 LlamaIndex，Dify 。 本文主要参考 LlamaIndex的实现，来系统讲解高级 RAG 技术，以方便大家深入研究。 如果想了解dify： 一文入门智能体：dify 超快速构建AI agent 如果想了解langchain： LangChain指南：打造LLM的垂域AI框架 RAG实现过程 目前已经知道RAG融合是一种用于（可能）提升RAG应用检索阶段的技术。 下面这张图片展示了大概的工作流程。基本上，主要思路就是利用LLM来生成多个查询，期望能够通过这些查询让问题的各个方面在上下文中显现出来。之后你可以使用生成的查询进行向量搜索（如本系列之前的部分所述），并且基于其在结果集中的显示方式来对内容进行重新排序。 可以用下面提示词生成额外问题： 如上所述，LLM能够生成覆盖原问题多个方面的查询。这样可以在数据库中找到包含各个相关方面的信息，从而潜在地提高从RAG应用得到的结果。 RAG架构 RAG的架构如图中所示，简单来讲，RAG就是通过检索获取相关的知识并将其融入Prompt，让大模型能够参考相应的知识从而给出合理回答。因此，可以将RAG的核心理解为“检索+生成”，前者主要是利用向量数据库的高效存储和检索能力，召回目标知识；后者则是利用大模型和Prompt工程，将召回的知识合理利用，生成目标答案。 RAG架构 完整的RAG应用流程主要包含两个阶段： 数据准备阶段：数据提取——&gt;文本分割——&gt;向量化（embedding）——&gt;数据入库 应用阶段：用户提问——&gt;数据检索（召回）——&gt;注入Prompt——&gt;LLM生成答案 下面详细介绍一下各环节的技术细节和注意事项： 数据准备阶段 ： 数据准备一般是一个离线的过程，主要是将私域数据向量化后构建索引并存入数据库的过程。主要包括：数据提取、文本分割、向量化、数据入库等环节。 数据准备 数据提取 数据加载：包括多格式数据加载、不同数据源获取等，根据数据自身情况，将数据处理为同一个范式。 数据处理：包括数据过滤、压缩、格式化等。 元数据获取：提取数据中关键信息，例如文件名、Title、时间等 。 文本分割 ： 文本分割主要考虑两个因素：1）embedding模型的Tokens限制情况；2）语义完整性对整体的检索效果的影响。一些常见的文本分割方式如下： 句分割：以”句”的粒度进行切分，保留一个句子的完整语义。常见切分符包括：句号、感叹号、问号、换行符等。 固定长度分割：根据embedding模型的token长度限制，将文本分割为固定长度（例如256/512个tokens），这种切分方式会损失很多语义信息，一般通过在头尾增加一定冗余量来缓解。 向量化（embedding） ： 向量化是一个将文本数据转化为向量矩阵的过程，该过程会直接影响到后续检索的效果。目前常见的embedding模型如表中所示，这些embedding模型基本能满足大部分需求，但对于特殊场景（例如涉及一些罕见专有词或字等）或者想进一步优化效果，则可以选择开源Embedding模型微调或直接训练适合自己场景的Embedding模型。 模型名称 描述 获取地址 ChatGPT-Embedding ChatGPT-Embedding由OpenAI公司提供，以接口形式调用。 https:// platform.openai.com/doc s/guides/embeddings/what-are-embeddings ERNIE-Embedding V1 ERNIE-Embedding V1由百度公司提供，依赖于文心大模型能力，以接口形式调用。 https:// cloud.baidu.com/doc/WEN XINWORKSHOP/s/alj562vvu M3E M3E是一款功能强大的开源Embedding模型，包含m3e-small、m3e-base、m3e-large等多个版本，支持微调和本地部署。 https:// huggingface.co/moka-ai/ m3e-base BGE BGE由北京智源人工智能研究院发布，同样是一款功能强大的开源Embedding模型，包含了支持中文和英文的多个版本，同样支持微调和本地部署。 https:// huggingface.co/BAAI/bge -base-en-v1.5 数据入库： 数据向量化后构建索引，并写入数据库的过程可以概述为数据入库过程，适用于RAG场景的数据库包括：FAISS、Chromadb、ES、milvus等。一般可以根据业务场景、硬件、性能需求等多因素综合考虑，选择合适的数据库。 应用阶段： 在应用阶段，可以根据用户的提问，通过高效的检索方法，召回与提问最相关的知识，并融入Prompt；大模型参考当前提问和相关知识，生成相应的答案。关键环节包括：数据检索、注入Prompt等。 数据检索 数据检索 常见的数据检索方法包括：相似性检索、全文检索等，根据检索效果，一般可以选择多种检索方式融合，提升召回率。 相似性检索：即计算查询向量与所有存储向量的相似性得分，返回得分高的记录。常见的相似性计算方法包括：余弦相似性、欧氏距离、曼哈顿距离等。 全文检索：全文检索是一种比较经典的检索方式，在数据存入时，通过关键词构建倒排索引；在检索时，通过关键词进行全文检索，找到对应的记录。 注入Prompt LLM生成 Prompt作为大模型的直接输入，是影响模型输出准确率的关键因素之一。在RAG场景中，Prompt一般包括任务描述、背景知识（检索得到）、任务指令（一般是用户提问）等，根据任务场景和大模型性能，也可以在Prompt中适当加入其他指令优化大模型的输出。一个简单知识问答场景的Prompt如下所示： Prompt的设计只有方法、没有语法，比较依赖于个人经验，在实际应用过程中，往往需要根据大模型的实际输出进行针对性的Prompt调优。 原始 RAG 本文 RAG 管道从一个文本文档语料库开始，直接跳过如何通过数据加载器从Youtube等数据源获取步骤。 标准的 RAG 流程简介：将文本分块，然后使用一些 Transformer Encoder 模型将这些块嵌入到向量中，将所有向量放入索引中，最后创建一个 LLM 提示，告诉模型根据搜索步骤中找到的上下文回答用户的查询。 在运行时，通过使用同一编码器模型对用户的查询进行向量化，然后搜索该查询向量的索引，找到 top-k 个结果，从数据库中检索相应的文本块，并将它们作为上下文输入到 LLM 提示中。 提示与下边内容类似： 提示工程 是提升 RAG 流程性能的一种简便有效的方法。可以查阅 OpenAI 提供的详尽的 提示工程指南 。 虽然 OpenAI 是 LLM 提供商的领头羊，但还有其他不少选择，例如deepseek，qwen， Anthropic 的 Claude ，Mistral 的小型但功能强大的模型 Mixtral ，Microsoft 的 Phi-2 ，以及如 Llama2 ， OpenLLaMA ， Falcon 等众多开源模型，可以选择最合适的，作为 RAG 管道大脑。 高级 RAG 接下来深入讲解高级 RAG 技术。包括所涉及的核心步骤和算法的方案，但是省略了一些逻辑循环和复杂的多步代理行为，以保持方案的可读性。 上图中绿色部分是接下来详细探讨的核心 RAG 技术。一张图并不能全部展示所有的高级 RAG 技术，比如这里省略了上文扩展技术。 1：分块 (Chunking) &amp; 向量化 (Vectorisation) 首先需要为文档内容创建向量索引，然后在运行时搜索与查询向量余弦距离最近的向量索引，这样就可以找到与查询内容最接近语义的文档。 1.1 分块 (Chunking) Transformer 模型具有固定的输入序列长度，即使输入上下文窗口很大，一个句子或几个句子的向量也比几页文本的向量更能代表其语义含义，因此对数据进行分块—— 将初始文档拆分为一定大小的块，而不会失去其含义。有许多文本拆分器实现能够完成此任务。 块的大小是一个需要重点考虑的问题。块的大小取决于所使用的嵌入模型以及模型需要使用 token 的容量。如基于 BERT 的句子转换器，最多需要 512 个 token，OpenAI ada-002 能够处理更长的序列，如 8191 个 token，但这里的折衷是 LLM 有足够的上下文来推理，而不是足够具体的文本嵌入，以便有效地执行搜索。 有一项关于块大小选择的研究 。在 LlamaIndex 中， NodeParser 类 很好支持解决这个问题，其中包含一些高级选项，例如定义自己的文本拆分器、元数据、节点/块关系等。 1.2 向量化 (Vectorisation) 下一步是选择一个 搜索优化的模型来嵌入块 。有很多选项，比如 bge-large 或 E5 嵌入系列 。只需查看 MTEB 排行榜以获取最新更新即可。 有关分块和向量化步骤的 end2end 实现，请查看 LlamaIndex 中完整数据摄取管道的 示例 。 2. 搜索索引 2.1 向量存储索引 RAG 管道的关键部分是搜索索引 ，它存储了在上一步中获得的向量化内容。最原始的实现是使用平面索引 — 查询向量和所有块向量之间的暴力计算距离。 为了实现1w+元素规模的高效检索，搜索索引 应该采用 向量索引 ，比如 faiss 、 nmslib 以及 annoy 。这些工具基于近似最近邻居算法，如聚类、树结构或 HNSW 算法。 此外，还有一些托管解决方案，如 OpenSearch、ElasticSearch 以及向量数据库，它们自动处理上面提到的数据摄取流程，例如 Pinecone 、 Weaviate 和 Chroma 。 取决于索引选择、数据和搜索需求，还可以 存储元数据 ，并使用 元数据过滤器 来按照日期或来源等条件进行信息检索。 LlamaIndex 支持多种 向量存储索引 ，同时也兼容其他简单的索引类型，如列表索引、树索引和关键词表索引。 2.2 分层索引 在大型数据库的情况下，一个有效的方法是创建两个索引——一个由摘要组成，另一个由文档块组成，然后分两步进行搜索，首先通过摘要过滤掉相关文档，然后只在这个相关组内搜索。 2.3 假设性问题和 HyDE 另一种方法是让 LLM 为每个块生成一个问题，并将这些问题嵌入到向量中 ，在运行时对这个问题向量的索引执行查询搜索（将块向量替换为索引中的问题向量），然后在检索后路由到原始文本块并将它们作为 LLM 获取答案的上下文发送。 这种方法提高了搜索质量，因为与实际块相比， 查询和假设问题之间的语义相似性更高 。 还有一种叫做 HyDE 的反向逻辑方法——你要求 LLM 在给定查询的情况下生成一个假设的响应，然后将其向量与查询向量一起使用来提高搜索质量。 2.4 内容增强 这里的内容是将相关的上下文组合起来供 LLM 推理，以检索较小的块以获得更好的搜索质量。 有两种选择：一种是围绕较小的检索块的句子扩展上下文，另一种是递归地将文档拆分为多个较大的父块，其中包含较小的子块。 2.4.1 语句窗口检索 器 在此方案中，文档中的每个句子都是单独嵌入的，这为上下文余弦距离搜索提供了极大的查询准确性。 为了在获取最相关的单个句子后更好地推理找到的上下文，将上下文窗口扩展为检索到的句子前后的 k 个句子，然后将这个扩展的上下文发送到 LLM。 绿色部分是在索引中搜索时发现的句子嵌入，整个黑色 + 绿色段落被送到 LLM 以扩大其上下文，同时根据提供的查询进行推理。 2.4.2 自动合并检索 器（或 父文档检索 器) 这里的思路与语句窗口检索器非常相似——搜索更精细的信息片段，然后在在LLM 进行推理之前扩展上下文窗口。文档被拆分为较小的子块，这些子块和较大的父块有引用关系。 首先在检索过程中获取较小的块，然后如果前 k 个检索到的块中有超过 n 个块链接到同一个父节点（较大的块），将这个父节点替换成给 LLM 的上下文——工作原理类似于自动将一些检索到的块合并到一个更大的父块中，因此得名。请注意，搜索仅在子节点索引中执行。 2.5 融合检索或混合搜索 这是一个很早以前的思路：结合传统的基于关键字的搜索（稀疏检索算法，如 tf-idf 或搜索行业标准 BM25 ）和现代语义或向量搜索，并将其结果组合在一个检索结果中。 这里唯一的关键是如何组合不同相似度分数的检索结果。这个问题通常通过 Reciprocal Rank Fusion 算法来解决，该算法能有效地对检索结果进行重新排序，以得到最终的输出结果。 在 LangChain 中，这种方法是通过 Ensemble Retriever 来实现的，该类将你定义的多个检索器结合起来，比如一个基于 faiss 的向量索引和一个基于 BM25 的检索器，并利用 RRF 算法进行结果的重排。 在 LlamaIndex 中，这一过程也是以类似的方式 实现 的。 混合或融合搜索通常能提供更优秀的检索结果，因为它结合了两种互补的搜索算法——既考虑了查询和存储文档之间的语义相似性，也考虑了关键词匹配。 3. 重排（reranking）和过滤（filtering） 使用上述任何算法获得了检索结果，现在是时候通过过滤、重排或一些转换来完善它们了。在 LlamaIndex 中，有各种可用的 后处理器 ，根据相似性分数、关键字、元数据过滤掉结果，或使用其他模型（如 LLM）、sentence-transformer 交叉编码器，Cohere 重新排名接口或者基于元数据重排它们。 这是将检索到的上下文提供给 LLM 以获得结果答案之前的最后一步。 现在，将讨论更高级的 RAG 技术，比如查询转换和路由。这些技术涉及到大语言模型的使用，代表了一种更复杂的逻辑思维——在 RAG 流程中融合了 LLM 的推理能力。 4. 查询转换 查询转换是一系列技术，使用 LLM 作为推理引擎来修改用户输入以提高检索质量。有很多技术实现可供选择。 对于复杂的查询，大语言模型能够将其拆分为多个子查询。 比如， 当你问：“在 Github 上，Langchain 和 LlamaIndex 这两个框架哪个更受欢迎？”， 一般不太可能直接在语料库找到它们的比较，所以将这个问题分解为两个更简单、具体的合理的子查询： “Langchain 在 Github 上有多少星？” “Llamaindex 在 Github 上有多少星？” 这些子查询会并行执行，检索到的信息随后被汇总到一个 LLM 提示词中。这两个功能分别在 Langchain 中以 多查询检索器 的形式和在 Llamaindex 中以 子问题查询引擎 的形式实现。 Step-back prompting 使用 LLM 生成一个更通用的查询，以此检索到更通用或高层次的上下文，用于为原始查询提供答案。同时执行原始查询的检索，并在最终答案生成步骤中将两个上下文发送到 LLM。这是 LangChain 的一个 示例实现 。 查询重写使用 LLM 来重新表述初始查询 ，以改进检索。LangChain 和 LlamaIndex 都有实现，个人感觉LlamaIndex 解决方案在这里更强大。 5. 聊天引擎 关于构建一个可以多次用于单个查询的完美 RAG 系统的下一件工作是 聊天逻辑 ，就像在 LLM 之前时代的经典聊天机器人中一样 考虑到对话上下文 。 这是支持后续问题、代词指代或与上一个对话上下文相关的任意用户命令所必需的。它是通过查询压缩技术解决的，将聊天上下文与用户查询一起考虑在内。 与往常一样，有几种方法可以进行上述上下文压缩——一个流行且相对简单的 ContextChatEngine ，首先检索与用户查询相关的上下文，然后将其与内存缓冲区中的聊天记录一起发送到 LLM，以便 LLM 在生成下一个答案时了解上一个上下文。 更复杂的情况是 CondensePlusContextMode ——在每次交互中，聊天记录和最后一条消息被压缩到一个新的查询中，然后这个查询进入索引，检索到的上下文与原始用户消息一起传递给 LLM 以生成答案。 需要注意的是，LlamaIndex 中还支持基于 OpenAI 智能体的聊天引擎 ，提供更灵活的聊天模式，Langchain 还支持 OpenAI 功能 API。 还有像 ReAct 智能体 这样的其他聊天引擎类型，但接下来将直接跳转到第 7 节，讨论智能体本身。 6. 查询路由 查询路由是 LLM 驱动的决策步骤，决定在给定用户查询的条件下下一步该做什么 ——选项通常是总结、对某些数据索引执行搜索或尝试许多不同的路由，然后将它们的输出综合到一个答案中。 查询路由器还用于选择数据存储位置来处理用户查询。这些数据存储位置可能是多样的，比如传统的向量存储、图形数据库或关系型数据库，或者是不同层级的索引系统。在处理多文档存储时，通常会用到摘要索引和文档块向量索引这两种不同的索引。 定义查询路由器包括设置它可以做出的选择。 选择特定路由的过程是通过大语言模型调用来实现的，其结果按照预定义的格式返回，以路由查询指定的索引。如果是涉及到关联操作，这些查询还可能被发送到子链或其他智能体，如下面的 多文档智能体方案 所展示的那样。 LlamaIndex 和 LangChain 都提供了对查询路由器的支持。 7. 智能体（Agent） 智能体（ Langchain 和 LlamaIndex 均支持）几乎从第一个 LLM API 发布开始就已经存在——这个思路是为一个具备推理能力的 LLM 提供一套工具和一个要完成的任务。这些工具可能包括一些确定性功能，如任何代码函数或外部 API，甚至是其他智能体——这种 LLM 链接思想是 LangChain 得名的地方。 智能体本身就是一个复杂的技术，不可能在 RAG 概述中深入探讨该主题，所以我将继续基于 agent 的多文档检索案例，并简要提及 OpenAI 助手，因为它是一个相对较新的概念，在 最近的 OpenAI 开发者大会上作为 GPTs 呈现 ，并在下文将要介绍的 RAG 系统中发挥作用。 OpenAI 助手 基本上整合了开源 LLM 周边工具——聊天记录、知识存储、文档上传界面。最重要的是 函数调用 API ， 其提供了将自然语言转换为对外部工具或数据库查询的 API 调用的功能。 在 LlamaIndex 中，有一个 OpenAIAgent 类 将这种高级逻辑与 ChatEngine 和 QueryEngine 类结合在一起，提供基于知识和上下文感知的聊天，以及在一个对话轮次中调用多个 OpenAI 函数的能力，这真正实现了智能代理行为。 来看一下 多文档 智能体 的 方案 —— 这是一个非常复杂的配置，涉及到在每个文档上初始化一个Agent（ OpenAIAgent ），该智能体能进行文档摘要制作和传统问答机制的操作， 还有一个顶层智能体 ，负责将查询分配到各个文档智能体，并综合形成最终的答案。 每个文档智能体都有两个工具：向量存储索引和摘要索引，它根据路由查询决定使用哪一个。对于顶级智能体来说，所有文档智能体都是其工具。 该方案展示了一种高级 RAG 架构，其中每个智能体都做路由许多决策。这种方法的好处是能够比较不同的解决方案或实体在不同的文档及其摘要中描述，以及经典的单个文档摘要和 QA 机制——这基本上涵盖了最常见的与文档集合聊天的用例。 这种复杂配置的缺点可以通过图片发现 —— 由于需要在智能体内部的大语言模型之间进行多次往返迭代，其运行速度较慢。顺便一提，LLM 调用通常是 RAG 管道中耗时最长的操作，而搜索则是出于设计考虑而优化了速度。因此，对于大型的多文档存储，我建议考虑对此方案进行简化，以便实现扩展。 8. 响应合成 这是任何 RAG 管道的最后一步——根据检索的所有上下文和初始用户查询生成答案。 最简单的方法是将所有获取的上下文（高于某个相关性阈值）与查询一起连接并提供给 LLM。但是，与往常一样，还有其他更复杂的选项，涉及多个 LLM 调用，以优化检索到的上下文并生成更好的答案。 响应合成的主要方法有： 通过将检索到的上下文逐块发送到 LLM 来优化答案 概括检索到的上下文，以适应提示 根据不同的上下文块生成多个答案，然后将它们连接或概括起来。 RAG 融合 和其他软件世界的架构决策一样，RAG融合也有权衡取舍，你需要清楚它们，以便为具体情境做出最好的决定。不过首先，看一下RAG融合的优缺点。 优点： 提供多样化的上下文：因为你可以从不同的角度查看用户的查询，所以顶级结果里会出现更多样化的内容片段。与专注于单一视角的内容段落相比，你更有可能看到能够涵盖话题多个方面的内容作为顶级结果出现。 额外的控制层面：像其他机器学习解决方案一样，RAG融合提供了额外的控制手柄，让你可以微调你的应用，并让它更加符合你的期望目标。 自动校正：通过使用LLM作为用户在文本框中输入内容与实际在数据库中搜索内容之间的中间人，你可以纠正拼写错误，添加与用户查询相关的上下文信息（关于用户的信息、时间、他们的账户状态等），以及/或潜在地筛选特定类型的内容。 成本：这是一个有些争议的问题，因为成本既是RAG融合的优点也是缺点，让我来解释一下。你大概知道，向量搜索比LLMs要便宜得多，那么用于RAG融合的额外LLM调用是不是应该会增加应用的整体成本呢？不过……让再来看看LLM的成本。你大概也知道，你可能使用的大多数主流LLMs都采用基于token的计费模式。即使是自己托管LLM，你的成本也会与处理的token数量大致成正比。基本上在这儿向LLM发送两次请求，一次大概有100个token用来生成相似的查询，另一次则会有数千个token，提供相关文本块并希望从LLM那里得到适当的回应。所以基本上第一次对LLM的调用要比第二次便宜10倍到100倍。所以即使RAG融合每10次查询节省一次后续问题，你在成本上还是能领先的。 缺点： 延迟:正如你现在可能知道的，LLMs需要大量的计算资源，因此它们的速度相对较慢(相对于应用程序中的其他部分)。根据你的应用程序，向LLM发送一次额外的请求可能会让用户的体验变得糟糕，因为他们可能需要等待几百毫秒的时间。 自动纠错:是的，这是一个优点，但是当它不起作用时，也可能是一个缺点。这通常发生在你的内容包含内部术语或行话，而这些术语或行话没有出现在LLM学习过的数据中。在这种情况下，LLM可能会出现困惑并生成完全无关的查询，从而影响到最后的结果。 成本:正如之前讨论的，如果RAG融合对你应用程序的整体效益贡献不大，你最终可能会花费更多的费用，但收益却很有限。 有了以上的介绍，接下来讨论一下在什么情况下最有可能通过实现RAG融合得到好的效果。如果你的应用程序的内容主要基于常见概念，那么你更有可能从使用RAG融合中获益良多。 RAG融合n不适用场景 如果您拥有的内容包含大量内部行话或与知名品牌重复的词语，则您可能需要调整RAG融合提示以获得良好的效果，或者最好避免使用。以下是一个例子来说明这一点。如今，所有的知名LLMs都是基于“注意力就是你所需要”的论文中首次引入的transformer架构，这是一种根据语境中其他单词对生成下一个token的重要性的度量方法。现在，如果我在该论文的基础上构建一个RAG应用并添加RAG融合功能，其工作方式可能是这样的：(绿色文字表示对RAG融合有贡献的LLM生成的查询) 由于在这个语境下理解“注意力”的含义依赖于上下文，LLM对这个含义产生了误解，并生成了一些与之完全无关的搜索查询。这可能导致您的应用得出糟糕的结果。现在，来看一下通过更改系统提示，将其改为“您是一个有用的助手，可以根据单一输入查询为试图解释transformer架构概念的应用生成多个搜索查询”，是如何在这个特定例子中解决这个问题的。 根据您的具体情况，微调提示可能有用也可能没用。您也可以试试以下技巧，然后才放弃： 使用语义搜索找到相关的查询：这个选项适合较为成熟的使用场景，但是如果你有很多用户基础，你可以尝试搜索一个相似的查询数据库，利用它们来寻找相关的内容。 通过少量示例学习实现上下文理解：有时候，在给出提示前先给LLM展示几个例子也许能帮助提升效果。 微调小型LLM：如果上述方法对你特定的使用场景都没有用（而测试这些方法相对较快），那么你可以考虑微调自己的LLM。这样可能会有效果，因为即使是很小的LLM（即使只有几百万个参数），也有可能足够好到能在特定模板下生成几个相似的查询。请注意，这种方法相比于前面提到的方法，会花费更多的成本和时间，但可能会给你带来最好的效果（代价是增加了复杂性）。 正如您所见，在这种情况下(像HyDe、TF-IDF、BM25或混合搜索等许多其他方法一样)，不清楚这种方法是否会胜过针对您具体用例的基本语义搜索功能。但是，就像人们常说的那样，“如果你不衡量，你就无法改进”。因此，我的建议是：一旦构建了基本的RAG应用程序，就要立即创建一个评估过程。在这一过程中，你会有大量的想法去优化你的提示或搜索功能，而每一种改变所带来的附带影响是不清楚的。有时候，提升某一组查询的效果会以牺牲另一组查询为代价。在这种情况下，最好的办法就是把它当作另一种机器学习问题，看看数据告诉你什么。 编码器和 LLM 微调 这种方法主要是对 Transformer 编码器 和 LLM 进行微调。其中，编码器影响嵌入质量，从而影响上下文检索质量。LLM 负责最好地使用提供的上下文来回答用户查询。 如今的一大优势是可以使用像 GPT-4 这样的高端 LLM 来生成高质量的数据集。但是必须清楚，使用小型合成数据集进微调基础模型，可能会降低基础模型的通用能力。 编码器微调 作者进行了一项测试，对 bge-large-en-v1.5 编码器进行微调，发现对于检索效果提升影响有限。因为针对搜索优化的最新 Transformer 编码器已经非常高效。 排序器微调 如果不完全信任基础编码器，可以使用交叉编码器对检索到的结果进行重排。这个过程是这样的：你把查询和每个前 k 个检索到的文本块一起送入交叉编码器，中间用 SEP (分隔符) Token 分隔，并对它进行微调，使其对相关的文本块输出 1，对不相关的输出 0。 LLM 微调 最近，OpenAI 开始提供 LLM 微调 API ，LlamaIndex 有一个关于在 RAG 设置中微调 的教程。RAG 管道评估的 ragas 框架显示，忠实度指标增加了 5%，这意味着微调后的 GPT 3.5-turbo 模型比原始模型更好地利用了提供的上下文来生成答案。 Meta AI Research 最近的论文 RA-DIT： Retrieval Augmented Dual Instruction Tuning 展示了一种更复杂的方法，提出了一种同时调整 LLM 和 Retriever 的技术（原始论文中的双编码器）关于查询、上下文和答案的三元组。该技术被用于通过微调 API 微调 OpenAI LLM。也被用于微调了Llama2 开源模型（在原始论文中），结果与带有 RAG 的 Llama2 65B 相比，知识密集型任务指标增加 ~5%和常识推理任务增加几个百分点。 评估 RAG 系统性能评估的多个框架，都包含了几项独立的指标，例如总体答案相关性、答案基础性、忠实度和检索到的上下文相关性。 在之前章节提到的 Ragas ，使用 真实性 和 答案相关性 来评价生成答案的质量，并使用经典的上下文 精准度 和 召回率 来评估 RAG 方案的检索性能。 最近推出的课程 构建和评估高级 RAG 中，以及 LlamaIndex 和评估框架 Truelens ，他们提出了 RAG 三元组 评估模式 — 分别是对问题的 检索内容相关性 、答案的 基于性（ 即大语言模型的答案在多大程度上被提供的上下文的支持）和答案对问题的 相关性 。 最关键且可控的指标是 检索内容的相关性 — 实际上是上述高级 RAG 管道的前 1-7 部分加上编码器和排名器的微调部分，这些都是为了提高这个指标。而第 8 部分和大语言模型的微调则专注于提高答案的相关性和基于性。 简单有效的检索器评估管道可以应用于编码器的微调部分。一个更高级的方法不仅考虑 命中率 ，还包括了常用的搜索引擎评估指标 平均倒数排名 (Mean Reciprocal Rank) ，以及生成答案的质量指标，如真实性和相关性，这在 OpenAI 的 实用指南 中有所展示。 LangChain 提供了一个颇为先进的评估框架 LangSmith 。在这个框架中，你不仅可以实现自定义的评估器，还能监控 RAG 管道内的运行，进而增强系统的透明度。 如果你正在使用 LlamaIndex 进行构建，可以尝试 rag_evaluator llama pack 。 总结 本文概述 RAG 的核心算法，并举例说明其中的一些方法。 RAG融合是一个强大的功能，能够提高RAG应用的语义搜索效率。通过使用语言模型生成多个查询并对搜索结果进行重新排序，RAG融合可以呈现更丰富多样的内容，并提供了一个额外的层次，用于调整应用。此外，RAG融合还可以实现自动纠正、节省成本以及增加内容多样性。但是，需要注意一些权衡，比如潜在的延迟问题、自动纠正的挑战以及成本影响。对于依赖常见概念但可能出现内部行话或重叠词汇的应用来说，RAG融合尤其有用。重要的是要评估RAG融合的表现并测量其影响，以确定它是否适合特定应用场景。 还有很多其他的事情需要考虑，比如基于网络搜索的 RAG（LlamaIndex 的 RAG、webLangChain 等），更深入地研究智能体架构以及关于 LLM 长期记忆的一些想法。 除了答案相关性和忠实度之外，RAG 系统的主要生产挑战是速度。ChatGPT 和大多数其他助手使用的这种流式特性不是随机的赛博朋克风格，而只是一种缩短感知答案生成时间的方法。 这就是为什么我认为小参数规模的 LLM 有一个非常光明的未来，最近发布的 Mixtral 和 Phi-2 正在引领朝着这个方向前进。 参考资料： 借助知识图谱和Llama-Index实现基于大模型的RAG 一文读懂：大模型RAG（检索增强生成）含高级方法 https:// pub.towardsai.net/advan ced-rag-techniques-an-illustrated-overview-04d193d8fec6?gi=77e3202eaa34 果壳PAI：一文搞懂大模型RAG应用（附实践案例） iyacontrol：图解高级RAG技术 ketchum：构建基于RAG的聊天机器人（四）：RAG融合(RAG Fusion)</p>
</div></details><h2 id="toc-82">42. ITRANSFORMER: INVERTED TRANSFORMERS ARE EFFECTIVE …</h2>
<ul>
<li>链接：https://openreview.net/pdf?id=JePfAI8fah</li>
<li>来源：bing</li>
<li>摘要：The iTransformer model achieves state-of-the-art on challenging real-world datasets, which further empowers the Transformer family with promoted performance, generalization ability across differ-ent …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，iTransformer模型在挑战性的现实世界数据集上达到了最先进的性能，这表明其在处理复杂任务时具有强大的能力。其次，该模型增强了Transformer家族的推广性能和跨不同数据集的一般化能力，这意味着它不仅在特定数据集上表现出色，还能在多种不同类型的任务中保持良好的表现。此外，模型的性能和泛化能力的提升进一步证明了其在不同数据集上的表现得到了显著的改善。因此，iTransformer模型不仅在实际应用中取得了突破性的成果，还为Transformer家族的后续研究提供了重要的参考。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>iTransformer模型在挑战性的现实世界数据集上达到了最先进的性能。</li>
<li>iTransformer模型增强了Transformer家族的推广性能和跨不同数据集的一般化能力。</li>
<li>该模型在不同数据集上的表现得到了提升。</li>
<li>模型的性能和泛化能力得到了增强。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-83">正文（抓取，非 AI）</h3>
<p>%PDF-1.5 %���� 857 0 obj &lt;&lt; /Linearized 1 /L 6180839 /H [ 3693 608 ] /O 861 /E 641968 /N 25 /T 6175425 &gt;&gt; endobj 858 0 obj &lt;&lt; /Type /XRef /Length 176 /Filter /FlateDecode /DecodeParms &lt;&lt; /Columns 5 /Predictor 12 &gt;&gt; /W [ 1 3 1 ] /Index [ 857 431 ] /Info 373 0 R /Root 859 0 R /Size 1288 /Prev 6175426 /ID [&lt;502b702c9d8e436f3bfaec62934eb6be&gt;&lt;9e0b606ce671310a498649f07e25f851&gt;] &gt;&gt; stream x�cbd<code>�g</code>b<code>8 "y@$c+�dJ �� �] D��E&gt;�H�Y �SD�����`���?0�Hr JD��L���{ R� ����r,��E)�"��A�,'�4P��NoAl?�{��z!$3+�"_101~w��/�(9J�O2.x7��C�� ME�$�H���Qr�� � F endstream endobj 859 0 obj &lt;&lt; /Names 1188 0 R /OpenAction 1252 0 R /Outlines 1158 0 R /PageMode /UseOutlines /Pages 1157 0 R /Type /Catalog &gt;&gt; endobj 860 0 obj &lt;&lt; /Filter /FlateDecode /S 427 /O 600 /Length 520 &gt;&gt; stream x�c```b`��e`c</code>�ce�0�$���8���� ��=�����A�w� 9+�3B�s.�/g��õwA�]30�8�D �-a�7��v j� gdO 0p��C�Y�㸂�5&amp; ��k�Z����9�L�V/���Yy !a��l{�!Z,<em><em>��v]�� �A���N�u�nL]��r�����7I�.[Uv��Lej��n��|ߝu �a7ff�?��\΋o MJ]�<code>&amp;���0��M�S;�=hK�\�[w����6�!� ̌z��ǆȲٗs&lt;=�Ж��Mm�-Ϋ�Ԣn�P[zt͗�?_q^R%ڹB#L-��K�s�����}jQ�y�M����f?���cf�&gt; 7)���c``�c���*Vbkp&lt; dfh� a�</code>� ��I�^G��/ �5@�U _ ��d�S� 0�5�)� <code>Itx�Aƃ��A� j'��(�I1 vR</code>ra�h��i��A$���!�AȀ��a�~ ���+��OPPe�y�p�ѼA����a�pS�� �T<code>�g�\g� N_�R T�� endstream endobj 861 0 obj &lt;&lt; /Annots [ 1253 0 R 1254 0 R 1255 0 R 1256 0 R 1257 0 R 1258 0 R 1259 0 R 1260 0 R 1261 0 R 1262 0 R 1263 0 R 1264 0 R 1265 0 R 1266 0 R 1267 0 R 1276 0 R 1268 0 R 1269 0 R 1277 0 R 1270 0 R 1271 0 R 1272 0 R ] /Contents 863 0 R /MediaBox [ 0 0 612 792 ] /Parent 1130 0 R /Resources 904 0 R /Type /Page &gt;&gt; endobj 862 0 obj &lt;&lt; /BBox [ 181.2772 91.58253 536.0453 449.0422 ] /Filter /FlateDecode /FormType 1 /PTEX.FileName (./pic/radar.pdf) /PTEX.InfoDict 1278 0 R /PTEX.PageNumber 1 /Resources &lt;&lt; /ColorSpace &lt;&lt; /Cs1 1279 0 R &gt;&gt; /Font &lt;&lt; /TT1 1280 0 R /TT2 1281 0 R /TT3 1282 0 R &gt;&gt; /ProcSet [ /PDF /Text ] /XObject &lt;&lt; /Fm1 864 0 R &gt;&gt; &gt;&gt; /Subtype /Form /Type /XObject /Length 1420 &gt;&gt; stream x�XMOI�ϯ��9����.!�U�Z�� � ��J@D�������� ������q{\���U�+?�=�%k,^,6�⩄bR��-}����@�Ξ�6O���i����;�w�����3�wtK7��f��  6q7�63���V�Av��P2��Lb�</code>��d ^��B��2��I%e�9�&amp;%�(Fî����|7:t���mF��F�� oT��S� fRf\��5��f�]�S�H�&gt;��o��݇{��ߐ���qʵ&gt;b �A�����HF � ��A@a⏵�-�&gt;��F$�a ��Z鳾�/�:</em>�G+\���O:_7</em>���ڈ�)Z�����&gt;F�M�ޓ8JHexy�lg'$����l�/�u ]����v��� 7S0�V��7����F����� hH6���ߥd$��g�V�1n&gt;����  ��=j&gt;����� �dAB�EŴ��[MH��$6!dV�r�r��.�����Ѹ� s��/�o�e����;��c0C$�H ��R�����7�.k��=qQ� �s� biu9h��s^�����F1��l�+�� ��^v eb�5 J�ry�+c��6.A;F5� �&amp;�x�rHr6�b�G ��|[���=<em>&lt;ګ2Ό���C����"��5�ćCg=���+�E��@rH:�X� ���ENqr@�?u D�o����� �� .L���U��i�� �����q2�7�c"G��Bhp�t����<code>�*��p�y&amp;�8.�_.�J)� ����1���@�*�����Um</code>�����p��{r�{���T (Z��=��{� �w�E���-e;o{��]�z�����������5)xe Ί._��Zwg" C�d���̀�9$ ?�ӧ�N�.��˳�NuxI9y�M}V߶K�b"GWEw�U</em>ZH �K�{��i� .L���� �&gt; f���qI| ��9 T1��#�� ]��}�+w�M�+�͔�fC��%���l-����YTP��U˱/�сpW�di,�dD � ��=I�:3\T�gcC� ��t� �V���h  0 �MC1���i: ���(Y�Oz�6�Z<em>냪��~�c������/�� �Ӣ�n���PS0[�ܨ�0�� �8��m/�վ�(��a�;ߛ��FQ� ����<code>���</code>t\V_N �����Vi���(.�3I�SJ���F~F �r&lt;���KM+F&amp;(�v$�U�q���8�Fv��<em>RpV�ؚ^�,r��Uu��[�6�z{\�Jئ��/���?v V7S�I��O��</em>���HϘW^�X46�A��H�<em>������i�%~]���ݖ�C�51e���[7v�e��(�"!<code>"G*cI**j*�zY�/D諃��4�2q��&gt;�O �[U/W�]�^�,��� endstream endobj 863 0 obj &lt;&lt; /Filter /FlateDecode /Length 3846 &gt;&gt; stream x��ZYs�6~����Ueq���%s8����1N�6�&gt;�lq�"5&lt;����� &lt;$:�$�* �F���� ��U������ų/�V���:^�ܭT���(�c�V7��/�w�mY�{�[otxy+O~l���6��Z� �mdF���W���- �p����/�n.&gt;\(</code>!X)YQ�i����</em>��v���U��,]=д��d1&lt;�ջ��/�?8݇2~�h#�C��3x���W����U��&amp; �q3�1��|��)��X{/���R� ���F��6�yC��h��ťU��4֎�������� � %���+�D��ܚ� ^/.�?N� �7���y��U����ċe&amp;��Ox�Z��1a��t�Q��:���� �� "�W���w=Ȗ6c��d��G��</em>���<code>�gB["j�����e��qs�¿ �㩃c? F� ������2�n_&lt;�q�-/��}4[����!�RK�ST]^s�M�,� �}�7EuqgP���# &amp;�$���*/G-���? �I��FC1����K�_߉���a� ~5V8y��������׾���cU�u�}\�ȳM[t�(r��-�[8�Ui(o^�jIfp��E\��������ս�$�~���qЎ���}ݟ/��U �b��B�&lt;�$J�ɲ</code>��Dp��|ʢ����r����6�F��O:XXD�<em>�&amp;r_�?EpD� �l�ND��]�o�%�U��i�g���H���eIz� �n�s��&amp;���y���1����t|14�t�L0��Y��� <em>�<code>�f5�%����,�f~� 'B� B��!�+r����t=F�m��� &lt;��v�.4~%�� l|us���'�z��Z��л�AR�b�@�*����p����yۉ)�ޡ�ٲ������n�V ����y�� � 9��)�i �" ��1�7�}��m�79��$ƅ ��z��%�����7k˫8 ց���[�0�����"KQ��o'/ o�S3�T��:a�J;q;9E�0C� �</code>�z]�OOd1��}Y���G[� �V����,"Z�3;�M�</em>)=g���#��E��=:W[�K�1%�i'q6'X�=yvb�ʺ�7讵 l�<code>l�����ͷ��� � o���G~ ��+�����ϛ"�HR�D����ym�8@^�.? }Ǻ:�=�%AƼU#�8�p�}PL ��#�1Vqc���������܆</code>���m ��  ��r8�����|��8��S����O�<code>�jǼ�1jo�[n��rCd;�tfص���&amp;ߑE�</code>^��.��w�7���X�h�hE</em>� �;&gt;a\ �/�f�BN��d�y��[�ۉ�0��!z-V]R[�M���- �̀�L3�.s� ��sZ�� ����;� � X� �cD���C� �Mz�@��Z 3,C|�+�з ���u�=������}c��<em>�8��/P&amp;4;�� �B���ᢥ͛�<code>�v��g���)�W��G�o����ASl� ��l,jAo[�9�I��3� W.m�fw$�ڽϏ�vc�Z��}�z}��G3%Q��</code>ݼG3-�bl \�(Z�c�V�a� 0��k;&gt;<code>��  ν�10�x2h��+&gt;J�����}s�[��5��N � d&gt;�@׶�</code>\U�,MÜ|���;�@6�ȝy��1�m ��Ạs��VP�A I�V�,T�n@�b�����f���Iʕ̿-n։�4���]�7SB�����9!g��k�ñ|&lt;�i�W�cY8w @�02Ω��v��� C]e;�fO�nC�+��-�A !T.^t��at��jɆN��$�� �V����� ����%�B����ڤ����;H�b�c���W»!�@�4�a���L�A"�ݲ����%�1��)?�̜�Gq+l�� 8&amp;� �@���I��CB��z<code>�e�c��h����a�</code>!&amp;WE{p��m~$�[ �$�23��b�ɣ?p�,���By�� �'�KN^'�xI�BQ �k/�G \�4��C�^�'0 y�  </em>ih�s��M~ j� �|��Z:r�w�� �p&amp;�0�u<em>At :S�t9�� lG��, =(g�0��-�&amp;o ����� ��� � �^9w�bk�L���|�].X_U�M�=kJ��:d�P���.G8�K����B� m� ��02�l���?�u�w���Q�,ĢdំQ�U�X"X~[J��]��X@�n �����9�oE$e�}� ��Ϟ݃V��X�x�C�����₏��X����\���ʖ���� ���Fd�ah�6�PL;)=�U��R�k��"��R�^�n\� wT�ٌ�V�@.�ExO��d�RU+XM���}�Q)�m��6 �(�����A�^����0�-����t;7z��%C"F�EqO(rqO= e6)h�B��idf��&amp;hH���P�؜�с�3�&lt;]�"(r��:ѳzؖ ��;��A�yw�� 8,</em>��b�Ƃy@W��d v�c�֊ �b�� ��? �� �Aǰ�4 pD(z|x ?A4'�r�� ~c�ؕ��%��@%�W��sv9h9/#�mW�-Oo���9�Q�#T&amp;.�� ��p�C�ϥ���e^��|Ѓ��Id�ǭ�ljL� * �=�����@���W�n�4|!O&amp;��(�����B�r���^�-W���}<em>&lt;� �  �E�2.n䁧���� �\[��!��A�o�"(�U{,+���1퀣&gt; �� +;��Tr��a^0�f z�m�s��<code>��Հ�H��k�Ltf\��I @��/�B���'$�I��;{,��.�zǼh � ���$�A�NQh7�a *F�&amp;��7太V��ZC�H� �</code>?���7,uQ���:�P옲�ݸ�X!w��<code>���f�m����sWNS�7�3n�-���2s}�2'~h&amp;�Ƙ��c���� ��X �B#�)� ER�'� �[��}_q��0��k�*�M�|�,v�3�8�b?t/�K���i�= ���i�h����{&lt;��R��� yg��I��*�#}��P�I2��e�А p�� 0��D-.���E���P�QUx��D�MebB@@� ��fk� f���s�ۆ'�i� A5�)�EN���T�ɜz ���lrBPR?������MF�㊟�S</code>r�U�F�}��W��$\�$4��B�-�H��@8<code>���V�Ôz1T(�����t��� ��%�O�����-�&lt;��\�L]��ՙ,�%&gt;+�!+��cwU��</code>Vv8p��$<code>9�['d��S�I�;�}Q ��R� �������X41�Bi������V���������n螸��Ŀ���@ �3��� &lt;�t��ඦ��t�0�� � ˡ�G��U9#�"?[��Ӌ���I�G���:����~ƃ�s�ky;���fV�1hU�(r�'���^���J� ����C��l</code>� ��x��@R�;?��,3�߬��(MI�<em>�$�,Ee~��</em>�!w =�iK0��6 7��������D��B��b�����K��g@�;'�'�� )Xx� endstream endobj 864 0 obj &lt;&lt; /BBox [ 0 0 781 718 ] /Filter /FlateDecode /FormType 1 /Group &lt;&lt; /CS 1287 0 R /I true /K false /S /Transparency &gt;&gt; /Resources 1286 0 R /Subtype /Form /Type /XObject /Length 278 &gt;&gt; stream x���N�@ E�|� ^?�㞆����j%�6�F��8�@�Eӌ ��=׹��06�h<code>��Y&amp;� '��@�T�@tBWSິ�V3��$����0,���� �@u�s:��utx:ϧ������zZyy:�#1��� ����!��6rm�~k��i������ ��KĂ �+uc��4H� ;��U��gA�4� i�1X�,�t� �k�a_1�6�T/�"��ѩN*�è��l�ޒ�\�Q���[&lt; ��t�D � B��o%�� {��5F֊c��In��z��� endstream endobj 865 0 obj &lt;&lt; /Alternate /DeviceRGB /Filter /FlateDecode /N 3 /Length 2612 &gt;&gt; stream x��wTS��Ͻ7��" %�z �;HQ�I�P��&amp;vDF)VdT�G�"cE ��b� �P��QDE�݌k �5�ޚ��Y�����g�}׺ P���tX�4�X���\���X��ffG�D���=���HƳ��.�d��,�P&amp;s���"7C$  E�6&lt;~&amp;��S��2����)2�12� ��"�įl���+�ɘ�&amp;�Y��4���Pޚ%ᣌ�\�%�g�|e�TI� ��(����L 0�_��&amp;�l�2E�� ��9�r��9h� x�g��Ib�טi���f��S�b1+��M�xL��� �0��o�E%Ym�h��� ��Y��h���� ~S�=�z�U�&amp;�ϞA��Y�l�/� �$Z� ���U �m@��O�  � �ޜ� �l^��� ' ���ls�k.+�7���oʿ�9�����V;�?�#I3eE妧�KD�� ��d�����9i���,�����UQ� ��h��&lt;�X�.d ���6'~�khu_ }�9P�I�o= C#$n?z}�[1 Ⱦ�h���s�2z��� \�n�LA"S�� �dr%�,�߄l��t� 4�.0,</code> �3p�  ��H�.Hi@�A&gt;�  A1�v�jp ԁz�N�6p\W� p �G@ ��K0ށi���A����B�ZyCAP8�C���@��&amp;�<em>���CP=�#t�]���� 4�}���a � ��ٰ; G���Dx����J�&gt;���� ,�_@��FX�DB�X$!k�"��E�����H�q���a���Y��bVa�bJ0՘c�VL�6f3����bձ�X'�?v 6��-�V<code>�</code>[����a�; ��� p~�\2n5��׌���� �&amp;�x�</em>���s�b|!�   ߏ ƿ'� Zk�!� $l$T����4Q��Ot"�y�\b)���A�I &amp;N�I�$R$)���TIj"]&amp;=&amp;�!��:dGrY@^O�$� </em>%�?P�(&amp;OJ EB�N9J�@y@yC�R �n�X����ZO�D}J}/G�3���ɭ���k��{%O�חw�<em>.�'</em>!J����Q�@�S���V�F��=�IE���b�b�b�b��5�Q%�����O�@��%�!BӥyҸ�M�:�e�0 G7��ӓ��� �� e%e[�(� ���R�0<code>�3R��������4�����6�i^��)��*n*|�"�f����LUo�՝�m�O�0j&amp;jaj�j��.��ϧ�w�ϝ_4����갺�z��j���=���U�4�5�n�ɚ��4ǴhZ �Z�Z�^0����Tf%��9�����-�&gt;�ݫ=�c��Xg�N��]�.[7A�\�SwBOK/X/_�Q�&gt;Q�����G�[��� �</code>�A�������a�a��c#����<em>�Z�;�8c�q��&gt;�[&amp;���I�I��MS���T<code>�ϴ� k�h&amp;4�5�Ǣ��YY�F֠9�&lt;�|�y��+ =�X���_,�,S-�, Y)YXm�����Ěk]c}ǆj�c�Φ�浭�-�v��};�]���N����"�&amp;�1=�x����tv(��}�������'{'��I�ߝY�)� Σ ��-r�q� r�.d.�_xp��Uە�Z���M׍�v�m���=����+K�G�ǔ���� ^���W�W����b�j�&gt;:&gt;�&gt;�&gt;�v��}/�a��v���������O8� � �FV&gt; 2 u����� /�_$\�B�Cv�&lt; 5 ]�s.,4�&amp;�y�Ux~xw-bEDCĻH����G��KwF�G�E�GME{E�EK�X,Y��F�Z� �= {$vr����K���� ��.3\����r���Ϯ�_�Yq*  ���©�L��_�w�ד������+��]�e�������D��]�cI�II�OA��u�_�䩔���)3�ѩ�i�����B%a��+]3='�/�4�0C��i��U�@ёL(sYf����L�H�$�%�Y �j��gGe��Q�����n� ����~5f5wug�v����5�k��֮\۹Nw]������m mH���Fˍe�n���Q�Q��</code>h����B�BQ�-�[l�ll��f��jۗ"^��b���O%ܒ��Y}W�����������w�vw����X�bY^�Ю�]�����W�Va[q<code>i�d��2���J�jGէ������{�����׿�m���&gt;  ���Pk�Am�a�����꺿g_D�H��G�G��u�;��7�7�6�Ʊ�q�o���C{��P3���8!9���� � &lt;�y�}��'�����Z�Z���։��6i{L{��ӝ � -?��|������gKϑ���9�w~�Bƅ��:Wt&gt;���ҝ����ˁ��^�r�۽��U��g�9];}�}����� ���_�~i��m��p���㭎�}��]�/���}������.�{�^�=�}����^?�z8�h�c��' O*��?�����f�����</code>ϳ�g���C/����O�ϩ�+F�F�G�Gό���z����ˌ��ㅿ)����ѫ�~w��gb���k��?Jި�9���m�d���wi獵�ޫ�?�����c�Ǒ��O�O���?w| ��x&amp;mf������ endstream endobj 866 0 obj &lt;&lt; /Filter /FlateDecode /Length1 3264 /Length 2251 &gt;&gt; stream x�VYl��c���&amp;wIJ�H.�K��R�KS"iQWt��O�.�H�;�l�� E�6I��)� ��@[@/-z&lt;�Z���&gt;�%̓[�F�a�A � ��,��Jӧvf��=�o�����K�� �DyO,�/#��U�n&lt;�x�� �L"�N��?ٱѿ�7N�@��e�ӧ�.&gt;�n�A�c�����$vvi�����?��87�t z(�]h���W.�&amp;�C&gt;�ς�� �A����6uy�{��{� b;}�^���q����}Ծ�~L �7�=���o���(B �o�}�����1</em>�� �I���<em>�I�y��&gt;߄<code>&lt; 55��� �+XDu��p��/��N(x݃�,� أ�d�tf���Bg���Z���mf������D�.�6 {��k�&gt;h�杈���x���y���F�^�m�7.���np��-�M</code>� Q�'}ɀ/��o�o⛶�2�W� ��#y�r����e��j�S���D/ŉ��唛��qj��D.�2{��W��ZK��&gt;����=Fvv�77z .�置�|�w��N�h���;"z��7=��g��x���ـ�ɵ6�-�1��@ʊ�zɨZBAQҨ�ơ&amp;�B �"aX�� ��s�bm���q����J�#$6�</em>;9�:S��� �aZ�0H�t� o(��d�8|g߭�(�F�~'�8R]����;l&gt;�=1�h�-V����[0��}��<code>4 x��ʓx�8��gc;�q�l$���[�?�JI |ԞU��-�Q� ���B��y[ �CV�J@����p�y�a��2�,Ъ��^�v ��(���=���_1"~_�!��=� �B�$��9���pgk�j��2!?���P�o\�\Y��*� |��%B�yt���+����+�#�bJׇt���� �j{����S�@�:�ˬ}���3T P��9��@� � �JY�: @4��o&amp;k���]ceb�n  n&gt;����x��7�k�/Ӝ-�1���!�A#�)*�&gt;U+��|�</code>JT�zN��ȥ�Zy�� ��|��$���,3s��@<code>�� ���y��~O_�,������bqt[��Y��@��M�G�� �P�� *�; �/T&gt;�w�i�1�8ࢿ\�</code>��Uar���� "ӛtC{�i��<code>Y��o���#�V��Jݮ�˙��)QN�Aa���tQ��:]a\�K&amp;��$Xȥ��S���;�&amp;f �E�ś���/~��� l��_�����o�zEf�8}���\r���_�Ä/}���B�}�S�a���� �]�!˕���BF̴ �&amp;ɍI��!7,Eem' V����U�*�HO4��07ߟ �V��e��&amp;H M1doH5R���U/���.���|�'x���QK��J��f���rsaAH�J0S '�S�����]i�� 8Y ��O�9 ���;��L�� �bI�V��� S=�n����Qm�d#�_��v�� � ե���1�� �����Q�zlL����QX�I��;�׍2U�l_��z� gU��gޤ�712Q�U��҉3�%�TŸߎ f'�X��- u5���� N\|6d���#��P �� "�ж�y=�H6�D�b��  �Gn�nl""љ��Y�_:�\^-�0lG�� ���v��.��vh^ߥ&amp;fdBʯ �&gt;�k&lt;�lo�M�-S���6�G��PD�lt@�\7vM��&amp;���RגI�U��nE*v��.U�7,���gZ���Y҃q��m,�*+-6�����{�Gt+ [\4���7[k��VGc� P \� v���,�\�|�O�*)��t���c���n�[G�¡�&lt;���/��&amp;+�GO�&amp;_|��0� �&gt; a �E�WT �f�t�85t��O��؈���D�u��Q�펈�P�� ���'�[ؓ�6��f�؆��Е5����r�(y ����+*�5��dT��¶�JG�� v ^ IS:G(Ƽ �~{� {�M�&lt;�bI��{ 0����</code>y8%�|��}'6�s&amp;�Qv���{|Vo�8 ���S��]v&amp;���1eQ���@U8c�� 8�O�i}ڍ����+<em>+vm�2�߽|���|a����� 1��' endstream endobj 867 0 obj &lt;&lt; /Filter /FlateDecode /Length1 2196 /Length 1590 &gt;&gt; stream x�UIl���YDs�l���3҈ R�!ǔHJ��P�Wʭ��M$��F� �i I�Kz�!h�&amp;��EQ��H� z(zi��PE��{�!N� �7$�io}�����������n�x�� DQ��A�~ �ɽ���N�q�kW�όu�/��k�0�w@� nݞ�@:�ן&gt;���Ġ{b ����������}��7��pk�W@6ǿ��o w��4�摧=N� ����~{)�������nǋ��O�߇�����&gt;D�U �C�&gt;Dq�<code>x���p닶��!�� Ge�#ET�,��p xx �^Y [ �A� ��l{ ��E b�&lt;����#ȏ�mɨ���7Ї��_� �:�F~GS� ��.S��p6���(����35���9� ��Ũw��K��G�u�U[�DN�齜��&lt;.�D:��|��c��{H@B��&amp;UE$1D��E\1z�� �)��'�uw !Ѹ��d/�_��_̇%�n���&gt;������������� O{/�����o� ���n���UB8�EY�s���6�E_� ��9&lt;P�a)I�^qU�s�����[��_��Q�c$�͟C ���ƇA�!�W���I��v��� � &amp;���̅ec�������Z�K��&amp;�ֿR�?W_��T��R�JE(��V�";���� �92K�pH$$������R�Ć���d\�������?R���Ս6^�)�^΋�� �?���3�k�;)ը�ꢝ- ��p�3 �9�����%S� N� �a 1��&gt;!��撟W�3��t���o̩ G��b�:u4%� a�HL Ɗ��\C�0����a��z B�$�jV]m���^u�l+ol]�F�S��O^�[˺�b��� �3e�����t4����� {{)�\ ��~s�Ƙd&lt;|� �A�S�p� e��9��� #���%H|U�����hy�rO-��.Ø��9���Tr����#d�{�^�Ȕ����G�QG� 8|9���)��� �/�ة�5�zP�����[�"� A��i[���M&amp;��@@�K$gg� ?-qfam��ZJÍڥ��:g�{��O �R&lt;^j&amp;TK�$�R�eO���n]UyF�*�L���gk�ʹi� F۲�6� ���w��� Ml/�0{F-�S0�</code>�j!Ȳ�(o�ꆅ ��f���ih��0��d'�</em> Q�4w����ε �'��~������V�Y �$�������]�N7��5H�7��&gt;Ɵ�'<code>� |���P�(ԣ�D$� ��\��+6����4�G �c �?s�ֳ�~�we����M�oWJP� endstream endobj 868 0 obj &lt;&lt; /Filter /FlateDecode /Length1 3632 /Length 2286 &gt;&gt; stream x�W[l���.�Zr)r���|-ɥ(&gt;$&gt;%��EIT$ˑ%K�帰L�NeG�e[FmA� � 4 ���p��'@�"�G��G��)P�h��h݇�q�"���%#ˏ��g��s��s��ݺp�4��k�"�ɍ�&amp;�� W��~�Y�&amp;K���N7O6� ��,6.�]�غܶ�a\Z?w�}�$�Nm4/�� ����͍������湋[��� �������^4��� ���� ����|u�Y�7��;솷�K����?f&gt;i]oݣw�p���?�o蛭{���i]��6������{(Gmh��v_ {��t;#��} z�AnX+b Uh �� z��*��4�$��ɁLh �I4+���8���M��Yv.=0��m�nG��.$��;� ��܍����*��Ǩ���K�}"�U�.�GSt���~ƭqoq����ۀ'P�Sd�YX w�a�Ӻ��YZ��?-t�O��[��p�"Be�G�p&gt;W*2D��� �B�B\�� �z�W��\�Żؙ �9\Y*D�2~���DO������W^xj��֓9�eЌ�7o�V1J̃�J�o-^��������J����E8-F��-�+�TA���w��� U��2|�W=�,�Jm;�� 3�*���rz�EG�Ҩ� ����� �1 �0J�� hT㱴l�8��� %.��m' G��e�E��"����P�b2��.�ۄ��/3����&gt;���a|"D�J��' �/^������ ����"</code>]����};���B(%u8��Y�! 0� � {�=�|� �r��4fT�q5b�k:� ��0kt��}�ط��&amp;Ɣ�)o��+���&amp;;|vY&amp;&amp;3���8 ��+�r�9�2?j��c_���˄|��2ت,���XVo|��AC��D��!�lO�M�F����9I�������L<em>�+�&lt;�a�SL��~����F���C�x��p�� v�Cwㅠ���2e �� Y{=������o�3 i�b��� �wtT� �7��cJ]�Ԉ&gt;�X�O�f</em> ͌�'�&amp;��f�tH� |7'E �FR�s�Xm!]ZP�]6'� .Ecٸ���-� ʢ:���XI�cjnf�0_����@�x�'x��g��k� ��N<code>��S�}U��8S��Ĵ)�Ld��� �&lt;���� ]�2h�P�v� LX�lX�Lx���iGǟ2����?�B^ C(V( ����'��u$� 晰�H�0��5 �Uvk؛�z��p��ds011�K͂�Tr,㐫�xIuy�R$9�3��b4�k6�&gt;� N9�i9\�D�Z-5�Q�� ���FBqO,� Fd���twE�VW���� </code>�<code>���RKY���|��s�~ג�T*�g����l㥉�̩�?�X�� �:�� J�7�ǚ��&amp;����&gt;�) ���^Ϩ 8 �~ �~}(����+˻w��7k ��#W8 i� R�������N�����&amp;�V|71�W���n���2^?1�:����3�� ���r�| Ua#k���&amp;�@9pd�;$�e\a�|������)J�l��}%��b���S�������a6u����Bn� Ď.��V���?����&gt;yZ%��x&gt;! ��ݹ�+3�H�B�i&amp; �a��v�� "������D37����E2~}����ҭU�� i��ЬJH�Ʊ�{� �����Qס.T�n��� P�A݅� �کj]zb�&lt;�T2�p�u典���)�4Y� %7�k�֫��JN�窉�:��z��/�ݢN���M���Dd�Ɛ�����֌�_6��7;�����] %㾠۴�0�L'w,ʻU�[�p��df(�z�1IM��;���q</code>�c%�R2��W��p.V_��k �� ~l����| �c �G�Ɂ@�Ξ��r1#o9=C�R�L�&amp;��N���?y4{�Z��L)}dj ��������/&amp;NM�<em>&gt;</em>]mD|#<em>�� ����o(�9s^� &lt;�Q���:���</em>�7s�b��Ǖ.�PQ�C��F ;#r�b�Z,&amp;˞�C�<em>ezR ���ٓ�#�&lt;���<code>�r�a����j&lt;���#���</code>� �:h |</em>�_-� j�Ԉ����sť�B�+�ɾ�p<em>Y� �=ɡ�ŐߧH�:�J��w���A�V&amp;��X�=�i�.��W</em>륀�����@�PQe���˄b�;$��m�T�!�Y"D��� ��2��dC�Jm�S�8x��<em>���&lt;=2�P����5� �����m�d�܏h^X�P��,d�&lt;</em>�2�5L�i4�f� k -���:�����a��f���69p<code>s��F3=~n��� } endstream endobj 869 0 obj &lt;&lt; /BitsPerComponent 8 /ColorSpace 1279 0 R /Filter /FlateDecode /Height 1 /Interpolate true /SMask 875 0 R /Subtype /Image /Type /XObject /Width 1 /Length 11 &gt;&gt; stream x���? �� endstream endobj 870 0 obj &lt;&lt; /BitsPerComponent 8 /ColorSpace 1279 0 R /Filter /FlateDecode /Height 2400 /Interpolate true /SMask 876 0 R /Subtype /Image /Type /XObject /Width 1 /Length 54 &gt;&gt; stream x�Ё    � � �Pa�� 0</code>�� 0<code>�� 0</code>���� ��� endstream endobj 871 0 obj &lt;&lt; /BitsPerComponent 8 /ColorSpace 1279 0 R /Filter /FlateDecode /Height 1 /Interpolate true /Subtype /Image /Type /XObject /Width 2000 /Length 50 &gt;&gt; str</p>
</div></details><h2 id="toc-84">43. Parsimony or Capability? Decomposition Delivers Both in</h2>
<ul>
<li>链接：https://openreview.net/pdf?id=wiEHZSV15I</li>
<li>来源：bing</li>
<li>摘要：In contrast, iTransformer and Crossformer achieve advanta-geous performance with shorter input ranges but exhibit diminished gains from extended historical data.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-85">正文（抓取，非 AI）</h3>
<p>%PDF-1.5 %���� 1591 0 obj &lt;&lt; /Linearized 1 /L 10010015 /H [ 2885 627 ] /O 1595 /E 136444 /N 26 /T 10000195 &gt;&gt; endobj 1592 0 obj &lt;&lt; /Type /XRef /Length 123 /Filter /FlateDecode /DecodeParms &lt;&lt; /Columns 5 /Predictor 12 &gt;&gt; /W [ 1 3 1 ] /Index [ 1591 315 ] /Info 999 0 R /Root 1593 0 R /Size 1906 /Prev 10000196 /ID [&lt;182bc637560c9ce991c88cfeb28b6401&gt;&lt;0ad39b991b2085280ce95a628f81e095&gt;] &gt;&gt; stream x�cbd<code>�g</code>b<code>`8 "���H�6�T &amp;A$��� "��@�Z��1�r�@��� ��r D-��L �E�&gt;fCȵ</code>68�(�������T�KG�Q�X����a� ~$�܁w�(9�I �,- endstream endobj 1593 0 obj &lt;&lt; /Names 1590 0 R /OpenAction 1855 0 R /Outlines 1783 0 R /PageMode /UseOutlines /Pages 1782 0 R /Type /Catalog &gt;&gt; endobj 1594 0 obj &lt;&lt; /Filter /FlateDecode /S 523 /O 656 /Length 538 &gt;&gt; stream x�c<code>``b</code>�ve�2V3H0@��� ,  ��a�� �<code>*Yf2�g��&lt;�Aw7��*�P?#�)��]� � 0�]a�</code>���ٽ�ɡ��3��kg�I.O ���m�' �N��E�Na�H�PH�4���r�sJ �G%)'�iY^v�=��(@-���s��b�ପ,�C���w ���%�����Ʊ Mi󺲴N{�g.�euJ]v�����z��u��� �"�).����#�s٢5[v��tS���E4B%��){�1N!N[�&amp;�"�)�/�L=�R�j�3�S��'F1<em>�S�l� � j��6]zo.|!F��% 33A}.�</em>z�G�Z�צ�bԢrřk&lt;�f.<em>4i��g�2&amp;�� E���=�wl��0��^0C���cT$E�g<code>&gt;�0�F�Z��� � �x��"Y����R�d�zf;�3nd��T�1�[� ��</code>�����O�ϖS����4ٓ�TĤ���� VP����a��x�� �s�� @x�q ДZ�j&amp;+ƭ���������98]�, #��j endstream endobj 1595 0 obj &lt;&lt; /Annots [ 1856 0 R 1857 0 R 1858 0 R 1859 0 R 1860 0 R 1861 0 R 1862 0 R 1863 0 R 1864 0 R 1865 0 R 1866 0 R 1867 0 R 1868 0 R 1869 0 R 1870 0 R 1871 0 R 1872 0 R 1873 0 R 1874 0 R 1875 0 R 1876 0 R 1877 0 R 1878 0 R ] /Contents 1596 0 R /MediaBox [ 0 0 612 792 ] /Parent 1738 0 R /Resources 1901 0 R /Type /Page &gt;&gt; endobj 1596 0 obj &lt;&lt; /Filter /FlateDecode /Length 3292 &gt;&gt; stream x��ZY��~�_1/�"�vGs �C$˖���(�:v|T ;�r<code>�A������h</code>8��Vŕh4�&gt;���s6��|}� =���� ���I�����)� � �� �&lt;��N:w������� ԩ�q���9~�I8I��y :7k�����-D׫�mv˫ �m��b+nU���</em>�W!Ⱦ�E[o�^ �m��KY)��+�Ȯ_�t�� b7�3����&lt;�y�/ڡ�)�L}�6��Av5��,�l�j�o+�)�s��2�I(��B�j6���W7G:I��MB�� ~�5^;��C7����z��Y�T)� ������ ��%��J �i6̫?y�N�0��1�4�$~��|� �q'�5��l7LK0���� B�j��V�T�I�.}�<em>��ča3������r��Ô�!��s�8���αX7 c���j!t� ��Q� ��:n���G�;�����Ls����[���ŹM$i4�D�8Ϳs�N�QO�z���z�G�';����s�Q"r�\�w�,&lt;�x�~����&gt;M|x�Z���2��۷�e#;1(2rh���ϯ��A�Rt��-�Y[7�O��m-��5�dwʀ]/�ਜ਼Z� #���� ��0F����6l���m�0^�h�| ڦ���D�ծ d�</em>�Hz�{n���{9/�jǡ���o��nǇ��ګBɦ�G��Y���EٴU�13~�bo����տ ��x�����G�� eN����;�"��L��0t�,= ]�^&gt;�l ��h�[9��&lt;�1������������x�(�w��ܝtǡ�������~� �iv(�ztw�y66��+�"������E鱻O8�g?W�� ^4��@P��<em>��v��x�Yq':W\�q?�E��� _ �q �CǸ�" f?��N����EǑ�PVfw� C�n �pS�� ��b<code>&lt; @.�� �&amp; ���,�hq�zI��d��vW��3���C�Q�(�λ�m%; ���Ժt�d�Jp�Zvшj׫���KE)H+��Y��}�w��'A�ʧA6=&lt;'�</code> ��f;L��_Fr �P�L�nQB1�x1��Y} x@��,��a�}���Xz/vSrx�~�m�V��]7J8׵.���n�V��]�t��RU��<em>��V$ړ��G5�8�j7�Gĸ�ԝ��� ��c2/a1U�ӯ�) �_�bhȦXq�o8��</em>�E{�����1����;/� J ��q�G��Yq�mìN�-���򔅽���e� c��oݮe�CTC�&gt;�1�Q��(a�7�U�  1E��y�е��0AjC����Z!I�3+�%Nv�ۃ��vk ;�Ƈ�{��bv���Rݪ ^GZ� �0 )��L���h{�� ӯe !ao�F'-a�Ksc�e׎��0�g�ہ0�� ��ӈN84 ����R[�Z��98��ׇ4]�&lt;�q�/ �����������@��a�� p� A��8��5�0�� c���Є#<em>6߉��(r�h�ݏ[ �"D��/]{�D�C�&lt;���s�s|���E�����@��?���D/:�8$�X���a�ǅ�v ��:��ӂ�c�E�C�ΉP��ml�� �l]�]#j�&amp; MQ��{� �Cvc�-hL�mb��x&lt; 8Œ��l&gt;O5].����( Ll�ᕤ ��7�� �&lt;�=y�'n�i����{?���-)&amp;�� Ԩ���4�2�����o���z�̌U�vM'���o&amp;�#}��9�2��G�R@Lꆉ��P�� �J�~�.��m�{3�EO�L<code>�: ꆝ�&lt;�gi�O�PU���9DݪAT� nPP��u �g��l�#.� �  ���Cf������� �����Y�.�a���ɓ���Vi����}�Z�x���q�{��y� ] �a6ݞ�{�J���z,tdy�]�F�-p�&amp;�� ��5}}�bn�gH�C$Zm4 �Q�]��F����p��VV랇�d�8ʭZ�K �)�7f&amp;&lt;���|[X��6R(��&amp;�&lt;��0�=�\7&gt;r��v��CM</code>��}h1�D�eo�-�f� �������&amp;,LM�Ć���t�f�P�S௑����؃��q���Q�x�in9���T���U;b��ݢr/�x���<em>�qj��C�P��K�.}�.!B�)w~���O�˄s?7s^���фS��2��q$�� �Z�i�]fM��Pj�ިߦ˞�����}����P�$�k흠��2�O � #ܗ�s_Q&lt;�Kh�i��?��f�D0��mO8��K30�+Ո�&amp;�{ҫ�b6�%�ai B�P�Q1ؔ��%Lk�1Y���� �;���~��Ԟ���zO2I�����&gt;���+�+-��[�ؽO��okʌjDOAEl���G���7� :�piA�d�B����$~�[٘55&amp;��]�;�%��%��Тqm�&lt;��W��G�� �fm���Ή9�[jeSH���O.</em>Jҟ׆S�j�𝠰,�Rݙ&amp;'�܀��t�k� д�z�P�c(Oی"7�9�D�l�x �� �c���7=aC��I����H�Q ��� &gt; stream x��\�r Ǳ}�W����UO����%Y�6�j�C 8�"1�@���7���F� $��l�</em>����5+3+�du7l�a0�M6��7 �fd��E� ѰI R��qf(%�5��s��ݜ � Fra�!8�$ ���%�V���+2�縒Ԃ � �f��vp!� �P�&gt;E��a��~WX��+f�y��(yYCN E� �3� j� R6�W�͙�3r1��E�F�U�Ґ��x!K��� �<code>�</code>RQ�"8�1�����d����$�(.����9[���l�@af�y(9�V� ��m��H.�� ��q8�&lt;��z�3I���DX�8��C&amp;7��IY� e�aI�0ޡA6�rJ��r1;d��� �gY�a��eF�#��1[&amp;�3f+� 0[��d�VI-Xe<em>ܕ�1�C�� :�q�$�S#�V�-җ�$ΐ�� [���Yv�\�8���&gt;<code>$,Ň����gI|�Ѕ��J ŊƐ�Vf�Eǭ�W�f�Bﳑ�rp,��D�"�2L��JV���l�5�m��Xa6Y���?��������L2�W�����J�8bs�^&lt;}:�0��ol��� �y�:�8_��Gg���tt�ְx0,&gt;\����������\602���X���G���a���x+�.�т�!�U��R �5���������-�ŧ�� ���̿z�޾��zʼ #�M��[;Vh�Qv��.���҉ď�ʐ�+��h�p�n�")������7#��4:l�F�p�bO�9Q�&lt;9:=Y�����������[���D</code>�q�ؕ� s# �(�s !ބ��/@�v�l�9]no@��n P1�F ;^���</em>B�Mi�a��ҍ6g� n@��5��g��7���a��u޹1�{!ϻ(�K�m�ɼ{��- ����UOr�3 � ���|}�<code>�Y_ܽ'C-�o1�w�?��� ?T7�!�����]ଧ�8�_Owi�˞�� �=ݕ�{�4W�t'��{�TW�|'�ԙ1 ��m9m��8Ow1�E�Ԯ���f@�u@Ӑ��d){.ys�� �9 �}�\�&lt;�J��ݥּP�����d#�Vqݾ�~.S�'���� c�&lt; �|v�L}���_���ݻ� }s���t#�� =] �z�t�i� =�v�h��GF�]&gt;��( ���ζ�sY�L_#�áL��b(�� �$�c�6�?�l��R�M�:</code>���x�<em>�� �/��6i?�l�J�m�ӡLB&gt;]�J�&amp;��z p�,���g���Z�����f�,Zb�6�f�|���.B2m����Rn۟�r�h��l#���9</em>�-�'Q 췼�v�A�"� �<em>��=ܿV�B��z�����+1 � r�-.�1]�[ ���@�9#"s�I��K� H� E�A��Y S����/��8%k��}.c���� �\ ��, W��}c4m i+�2/p_�^QB�V�lP���F�N�#���ձ.�oA�,��<code>�#�Kfcn0� sF[�)���9 nLn���:9���d6�!P�� f�rgR������,����.�(�2���a�vz��6 ��tAT�^�u-ԉ��tb��+M'�/�ż��/ꅁ\�\s�(�za��5��t�.4�ػ(멾�bU���Z�;��#�9w���᝻,0�$��.�wM��1��ډ�}������z�t�p�ɏ���gx�ݞm��X&lt;������-��G���^g� ��\�&gt;j#ܚL���͒X�:�q���9 �F�]h�&gt;8=^?Z��(�Y=~�&lt;_� /7 �i6�"$5�4´��~�uW�OS��os j�E�d �K�k�,^E��x+�V܂���� ��[</code>ӭ��b�� �0y��<code>��{���˂�;Щv���P ��B8|�Bo3���eN:z��r�/��3X��w�Â^z�g]͟�!�C5i��� ?TS&amp;�PM��C�f��� ?T�:�P���C�a��� ?T�&amp;�Pm��C�e���K�P����� ?T�z�P���� 3~pq?����g��J� \}� �⇷��-~x ��m���</code>��}</em>����<code>�X���?LgW_�I، ���Ä���N(�ᇆ�~�����a���I���7�6�܌ ���C��!�?��� B��C(3~u?��d�!�?D����⇷��-~x� ��� �w��5�C����� ݏx~HSc�"F����d&gt;X:��\#^��m�k2' Μ�� Fo�i�����kj� �����MS�2�!M��x� ��</code>X��W ���[�� ����O. ���g��zwyz�x���g��z�S1{����cd'Hs���aqؗ��^��d?:�0��ׂhH&lt; :&lt;�7 ���O����/���I9��|���{���?����<code>}� �RŐ�F�V4a�k3�F'����tu���g�-N.V���ŝ���L�l��H�/�R���_Ipf�XA�� w�VK����G+�atbCB�#�̚W"����x�G�xS+O��W0@�pT���y� ���68Y��t[G �!�Y^�������C0�D}���k��k%��J�M ˁF�?f0�9�</code>�6E�%^7^ ����:��Bh ���&gt; y� ώ$���,��X�Y����h�ܾ��$dU3&amp;A����Ǝ<code>�o,��_b�k � G�!M��b� E���#� �Oُ��8b�i�^��!-��������I�"�/c�r)�^�#��e'iU�G��q��J��б �~r/&gt;��;������T��r���&lt;��9I��� �1�4�#�C�m�Fل� KY���&lt;ˌ���-�8�V�J���mR�k�MR �Ou� y�R-��</code>=.� ��- �.I ^��굝�8᪥���Q�B?��~:�����k�k;��H��)J �gC��ð�@��YJ��I���$�pD�\2�� �CJ���m/�K� E D���xs�\���W��2��+9g<em>��z��F���L�W�ҵ�M �B�r@Q~�; �V�qP�\�ȭ�5(��%��zc�:�ө����<code>�t��� �],�SK����Qv�oi_��E�b ��ʔ""h��{h+Ө Դ�O3�F� �]�a���Rˑ���-��ڮ�֑��S,���b�p���&lt;-�s ���m�yΨi!/��Mc;ۊlԟ��v�©؆�Q_����� �ӽ�^Ӌ_��pWKvt�ׁ.���}�p� K'�r�J�� #� �e��V����f!��5�����y�� ��� EN[���BO�[z &lt;@E��r!DQ�P�����f]�d%(�l'v��v,n�ܕ� G�� x��*�&gt;�䊢 �W���}�#:CN��J�} G� D�A�%� �'&lt;</code>���~�z����^�34�,S�l�m��X)a�� ~����t�Y�������;O�<em>��X�ڦ��-</em>�pp\а Sm����v�� ���]HPc�&amp;��� 2J��+� �&amp; '�_�j�bv��T �T��� H��|</em>(i-:MMpv��gY3 ���Q�S-)�Q��4�iiɕ} 1�������e��3�D���M e 3o[�$Ǹ[C �o�o1����� ��������W�Oi������W���N| �&amp;�%�0���<a href='���|�W�����E��!����ӯ�4߳ ���|����L�D#�~��M/gL���Y x�Ɵ� ��Ņ:"ƽ�E�^t �w�j���/��_ڏ�[�u�-ɉ��� ��ĠJ v"rS �g�@��1SmӶw� a:��ւ袨���J5i�S2c��q6!^6�a3�b��gY���ˊoAm�� �3% �&amp;� �G�&lt;�'>k�����q���+�k�TPF��Kx�rO|Y yϷ����|�:�o��g�?��0�����0p�r9&gt;�͔�����,n�i �1</a>qZlng���8����w1���I$�� � PZ��� ?��� �| ��U ��u�9� � ����J ����/@��:�� mv�;v}��� �m{��O6����w���)�WO��Tg ����� 3�-��Y�Dcϓ�W�����o ����b'ޡ�L�k��O�/�f��  Sx�=� �d��Iۙ�v{�� �~^\�Ͻ[��u��Ej�</em>��;��'�h��5����B�B��4v�P���"t�V{ � �A�Z�Z[x�@ǖ �01��dɗ�� /O�xn"���%�%�u&lt;�B0�i��6֨ ��y�� h���&lt;��a����:]���&gt;�{ ��4�-�:(��OoX&amp;Ƹ{�X:�3�ln  �p~� {3����� � � =U+��A �h���у�n� ��bw#����߾|������O;y�������i��=ݷi�t���M�w -�Z ��ݽ/߽s��w�\p�S6�v�����5�p��W-�[,��5Ŷ&amp;��ޚ���&gt;����w�����K�?h�" endstream endobj 1598 0 obj &lt;&lt; /Filter /FlateDecode /Length1 1643 /Length2 9661 /Length3 0 /Length 10738 &gt;&gt; stream x���P��-����0hpwww�$�  3��� ,��{p��@��� 99��{��W�WS5��ս�{��jh(�4����M@2�vPfv6���� 7�w{S'����n��w��)KۙI��ڂ����I��@��cwg�s��v��v�s�����&amp;̜ X����� y��)�&amp;�l (������� r��L-Y��rw ��d�m~������<code>���lz�A� ]@ ��3���? ��P��f</code>S(�d�C�'��d�?<em>�� ��y��l�?�~z��^f�v6�����_V)q)�? ��'!a��df0sp���y������E �� �B�����l�} ӿ<em>v�{��=࿓��?o-@�ϒ�c�f3}�b�^��B��6�w��ے�oA2�66������@[���߄�u�&gt; @��Yv�K���2� �l��^y(�Y�v�����������Ȁ�@fj<code>��埕�c��-5� H� ��ny�bc� ߳�L��� ����B����cг���i;S{�ߺ��� ����(�W������5���� V;{�s�go�����k�����6���� �Z��g��?� ���o��</code>����&amp;��g���o���ؿ�f5�&gt; j���'�� ��<code>���|���!���� /�3v���̅�-��t��l�ϥC���k���NNϣ�K�c������LQf�M�jۮ��I\��ƅ�S��8��� _@��'�~�if�/*��,���Zu�H8^g~�;�ܬ%�s�d&amp;��iAn3�t ; �yEJ9�����$�Z�ЩF�,��KQ3�&gt;ML�75=�񮴸E2� Am* _��ҕ�I�u�5��&amp;�Z[��o��m�6&gt;� KV�D�(�q��Z��60&lt;���K��A���:�--8H*Ņ\����q�U��镧�,�� ��I������&gt;�}ߐ�a���m�\�n?����t��:2 L�tc�������� ��OÄ� �ڢ+8O�2_ ���kc#���-� h�� k�ڱ �z9G��EQ67\��5�L6 ��ͳ|L{�Ga���'��"~�j�&amp;?&lt;�b��Qˌ@�Λ�0L��z�h�F���i�(s�x���|K �Q$n3+?�b�F#9�ͩyn5��{��e����}$�F�|�W�3�n��p�ob�?����Y�B�~ҽ��/��&gt;��s�X� dz�(/�����D�����&lt;Ï���ao�_m�;fj὜V���� �B���� � 2��) ���1�_W��d��C���v��i� ����9�Z��N�Đ19��Qƕ�"Me�S�����H� ��� ���j\/�U  �D���}YS��YYɻԀ�UO�&amp;� 67��i�K� �v��_mty��#�/����Mt=(!�g����1�W�� xĴp��.����F� p�w���~Ň#+�a��,oz����B��;��� ��x�U��K A�k]箪Ǖz�1C- b�ؽ��R�E#]TjA��u���B�&gt;�9%�czk�2)��D$���U��!�i�T�� F��p���"�*����e H&gt; �W֕ےt�Q�Xe����4F赣��f��߯¨��I����bq� ��z݇��)��� _2� $. ��������N��ZUf]�� � ��[��� 躌� -S&gt;��</code>�[�dO���F�O��ʦ 5�E�"�˨����(#G���=���9&gt;��J�-�L��}O�c� �n�r .��J�|�I� s'�QۜF;r��֒�v,�^���Nl� E'�K���Q�d栓�&lt;�"��M05F�fW��}~����_E�q�!��������P� � �</em>Ws���z�Z#��՜��kY{�� 4�9&gt;�L\���<code>�5��O:� E ����xT��G��� �v�3� ��J���Ι�����X��$� *ݨ�M��O �� }��Q�/��hpW9�t��E�&amp;\A� -�ԧ����(�x��x�S�03�:unF��������"�n����� �X7!</code>NIWG��X܇+la w;8���K=��ȵ ��2�X<em>��9�����K�5���/���-AUы��[A.�f,����</em>H�P�p�-bcqD���ZUp 4��-�KB��1�?����б9�T�s�.�P �����3�2�S� ��r�1.�aq���l���D�y�� ���=r��]4���ɭ�:�N�ٺ fv����� �ĄRVA�kd�i��N��KE�v���v_Y���[�<code>_$VRG)h�ǨX����D�7[��|9�'��J�MN~bM؎6�/�=�KC"��e��{H�/oa���tc�ƖX����*�tTaTX�O�Ɔ!z+A�8e U� E}�E����|�$5C5 ��5�H3q#&gt;a�N�X���-��&gt;ٞ*@���\� qL�@Ʃ����)�i��ѿ�k���ȍ�箍� �]Ue�3ih ��0S��iWT��Ϧ�Ә�y���|ɿ��&amp;HT ;������ �DcU)�� ~�J̔2'Hz"�&amp;&lt;\ ;:�%�� ;�S� U~�Z�@vٌ�~�� �ɴS�_�m�a$N8�u�_��&gt;��q-��U����=�R[ȶ@�v �'mm��� R��p�%q�;� Xn��ؑ^H� pU�?ōmWaB1o2��V�gĨq���x1j������Q��ז\eA� Y�IQ�gZ S��6� �/|V9�� ���g;�5;b�x��ޚA�P�D� .?g=�'6I~�5=_�+��I��:W#�FD"�h��m}�03 ��K�K��ŭt �� �㳊k�Q��)��GgT\/�ƹf���m�*\n&lt;Cܢ��1�f8�ϟvAC�/z����*�R&amp;3��O���d��K &lt;��ܝ � �_��|m:��FϚ�� &lt;8l�� T�n Ϙ�Ķ�Fb�6*��b���4�@��A}��_ [�d�u��-� i���%��V^BD&gt;��w]���Fl� �S���F�:T;YpZ�VI~���P�</code>�V��zo � ��m'l�z\�e���e����KBM�Os��D���}��&gt;l�Ji'�YN�<em>��+�[��̿�W�|A��j���GlJy4m�#�����fd�eղ�4��WrHg�r,YCȐd}� �| F��~��~�R�|�}\� jo�O;&lt;�yY�[��1�7��t?���g��A� . &gt;7D�:-vi� ɘ��Qk���n2�M����a;źL�̷T�j&gt;��Y���B:z���TJ��5�ob�}��q�j�&lt;�<em>7��Kz���d���������FY�P���Y�s����ʫ|�R 5Lכ4̥����g}�&amp;r�&lt;��G��V ����u�|�� ��+��w6��Y�p��P^����9%��T�u�Ԭ�!���U��Z |����O�/�K$�g����L+5���8\T^���|O�&amp;Ӵ��=, �{���IrOV�/c�ٸ��% =,���|h�cI ��6$o�l(�<code>-� ��;Ϛ�})f�!��o-AA+ީ_I��i���6�Xњg��s z���=d�R�i�w&gt;* �XT�,f����!�!�+^R�u�ޜ�u ��b�V�#�kb��l6�*�����"�x7KA��.�6n1Iӥ��D1Y}/|�</code>;׷����?��}&amp;O�����%=�����[�����o���;�L�k�7k3:w}</em>|�0Ʈ�ΐo7U����6H��<code>h4�|��c�K�l�i�P�����۷���dY�Ō�tq�n�l�� v{ ��͵C��&gt;C��c �(�X���� ��g_���.^ܠ���x�Hu�}r.L�x&amp;BEL�ƭrnQ�/���X 3���� �|$0� -x��ԾC�C��n�E�Z&gt;��~|��/�����y�=ٴ����D�5�Hr��5����-X�;�m��Ms]��c"f�k��И{U^]����C+���cm }Ƕ��Ý�(�.Ҥ���1\!� �j��H��b��1e�%uX���I���/R*�8�E�]�� ��P��&amp; �K��ܭP�s]��"�1���=, # '�Ck��&lt;6�&gt;��+�t��I�8�oa�H����eK����C8�-&gt;wE��.�����Zabۘ�Z5WKL�;' � �u�~z%��o��n�~��&amp;�nQs��?|cS�uau]u� ��8�7�h�nMK��'���ᤛF</code>2=�'�� /����-י�K�z�E���3h0P�M���w-.�cwˇ̣1���� ��}�D�Rv �e%</em>4�'���<em>���/U�O�Eg���;�F�[�C�</em>L z՘�lAFyrx���Q�c�R�1h�"�{ݾv�q�� ~�����D3�5 ߆�Rݞ�S�������\�����hr��F���r�2�p�~�� 5J}g__W�Cf��;�� Ի�B/���ܘg~榴)������P�N=|qc��� ��ʋ��5badZZT����3:�a%�'\�&amp;� 79a��ݟiU��Wq��F]�Ydc~[[�W�</em>���0:&gt;��v��<code>u87��mO����Õ��Ua �KD�A(dc��O*�\� �*c�'�-֦��� )���H i�������&gt;�G��.z������h��yx�M͈5v�p_t��9��0��=OP�c �r|f~;+&lt;)�҄�N%���L�|I򃘆���7��ek�7�hD'���2ȔE0���QS8*)��5�ҁfp�צ����KgJB�Q������0\�����"V��؅�Z]GJ;�}��u8Ӟ/ �}p�V�0t]�ť� 4��l}�,D�����*���D�g ������o� nM(酒C(���y L�(��ܷBȕ�� N_w��h-a�\���~X�/ �-���Ɨ�����O��N �M���&gt;~p�5R���� z�D���l��&lt;;7J�ֲ03�N�=ǂl/�n�;;v��ܫ1!�%�P�F�ztH�GzʌoՂ�x[�8�^��%j�,V~u�W�G�� ��(*�xLS�ڒ*��R��C �"� iG�m�N̝�k ����MM��e�zFjŠ�����ż�H��5����Wz�R�P�Q� �@���c�\ˤ�����]��!.O�}O�3��5�f��+�leJ#!89m�����Ӊ�����e6�T%FV��W�#� z�s(5�i���� u�]{�OJԥ��������%P&gt;L&gt;hg�qw}R�����z ��m}��b�W�5*��3� �u��#�� �Q9T�ǁDY�V��)fTEu7�o� Rv��{���E�:f8�ǭwgC���&gt;J�?Dz,�z�� ٶ��l(-p�l���K: �M[A���W��So�y�m v�N,f�W� z[Ճ��ˢWi�*v�y�g���ܤ �Nہ�m�G�ְ �rS������ V�&gt;##i&gt;xWs�S��V�6�݊��R�B����,�'�</code>���TL��|u�t��� ���<code>�l�W7B�Ҵ.�gbG���C�2^�'��u^I�H�$</code>��� JzV=ԡ��,�'��C�����(6}Lч 5_<em>�Zj앒OQ�8<code>�I��lr�.�ҍѫ0�T�o�����P�"�w^*�l�}�/If2���⮷��Ll�O�95�Qd�s�Q^Xv���39&amp;n�a�:_�g����d87��RK���:1Yn .Pvv�]�)3.� $�2�%9�z�e�����wE� ��,���%�T�˂ˑ_��� +��P �6n�j��C�Q���Muj݈vT��_v�SdFY+�Z/�|�U�+*�N]u9z.��걯�j�Y�4:Վ���|#��}��t��jj�Yb���QG � � �Ұ�,��5��+�q4&lt;�aY,}��´-��vw U��TqB������ YOb� ��)Os� ��޸��e;Ǫ�ϛn����#����=/j!����A ��w"�*k]ⵝ���[k���� �](�*���K[7=����� Jc�8i��0V���e� @ UK0Nz����� �޸�|�ӱ�v�{��Y��D�n�\�-�y�K�:v��~.��*��ߣ�������Ru^V e����v��#�</code>ԧ0�'2|�J��2�����g}�K CI�H8&gt;Me� , ��5 T�$)Z��z��2[�9 �0�k^�W�ވ��y&gt;����-'�ъ�5��K�KN��Ƙ�����rH�͙�N�JO����g�B,� 'lS�J� �G���f�},�V#$Acb�����.}r�A�� V��Fz I�v����X1���������Kn�?�G����2�~:���5v?�/_&lt; �s�/}E�{�d;mo�uX誄��' ���x<code>�(��������N���8�s�r%�6u��mL����xq�Xi��K��N5� +��_K� ��埩�^���p\�&gt;l��&amp;"�7t^����f&amp;�-.���u��U��q�.�KFUc�fC��_��}F�;?��J?@���f����</code>�u�� ��4z ��/e�$&amp;��NC��7ȭ5��kUb�7���@)��~���?�۾ I�0��ǡ8H� �5�+C�&amp;����t3I^���~��A��l�� ������P_Y����_0�==�v|,��3h��<code>C c+eiP����TvU�ܙ�g���/��q)=�.�j%�6U����Y#�w�� � �87g\RFrKY��KЄu����_vź2�V�)7 JRG�� � JCV�t���ce�P�x����:�4K���&gt;p����,Tk�&amp; 1_��'Ls�oEa����v�v��=�$K �� ��5-�_c�a&lt;- j�x���zvbx)��dS3�� �ڽ��#���/������QO�x��7���O�?� ���X���|�ߜQP�?j��[)�&gt;��� yW��x�|w�Ju��&lt;��m�8�� v�5d�������OxVx�;�8y3~�մh�-��7tH� *W&amp;�s�</code>��I��k�� �G�#S����Z�ٔŻ�-c���5K/��!FB�J��)[�v}�^W/թ�%�ǯu9Jfx�L���;����ܨKZ��Rvg��YϱO��}E'� X��Z���! �n���-��w�݋� �(�� u#U5��� ơ� ?�����·ヸ�+��&gt;ꎰ&lt;����O���j��?��K�-�<code>��� ^&gt;"�a9��&lt; �WhR~!=W�ǈ�Y�L��jYO�n��-�%�6ƭ�͡Gc�k'��06��F�8s -m�I�db� B:U8Ǿ̕�]���4/��������]�˵��u9&lt;��n��N%������s/I��8�ÁX�n��;&amp;�%��d�m"�P5�Q�Q��&gt;���MgQ(��v)q��t�E�#��]���a�� ����ʯ)�8��wnH� {8_�A- )��v�b�IuD(�QK�� � I���� a�jn'�{��uS��z4���8�oq~ɖ�)�a�D���x,��(���j�ND �V;;�vs/T~ �CL�8"�7H@�$x�� v"�+������T �\o"GGi ��# }t��;��n�'���ojw Z�K��)P���</code>��9��S6�</em>L��xu����%?��6 Gu$���ۣ��j {��)��� NZ�O�<code>e�O+b���M3��%PT|��_Mʠ?�����3ۆ���Ù�z���� �� |��r�4c�� �ʟX����� Eg��̕X7���� ;^}��Z҆���HmB � ��/ ��z �%F�l ]����� /����]} ��.���J�l��Ҡe��^�}Gւ�ԈY�� �u��[�#����)���=|��</code>�K�v֣D���@ ��c�<em>Pn�]=2��$������Bc�� </em>�&amp;ݕ�Y �e�ڋ�yo ��z�/���ك��#��F��^7ĢX�4d�F��a,0�i���|`d ���կ�茉+w�� �al��/izo�R�b�̻�/\'ڲ�f��Xb{�� ���h�����Md�WjN�ҳ���mc�8m�&lt;�;��ɰ��� � �L�XD ;���t�, �,e�o�Q�Q�z�쐡�x �g&amp;�����g&lt;$�T7[c }I5y��F7�ŭ�Ra��%i��p옳ů���W�s�� �P��$���̆��%��F/#�L�5r� �R��U�U�k�^J4"� 0f�h@֚tD�]Z��$�� ��;s��</p>
</div></details><h2 id="toc-86">44. AC ASE STUDY WITHP TST AND VARYING INPUT LENGTH</h2>
<ul>
<li>链接：https://openreview.net/attachment?id=4A9IdSa1ul&amp;name=supplementary_material</li>
<li>来源：bing</li>
<li>摘要：2025年3月15日 · In this section, we focus on iTransformer (Liu et al., 2024) and PatchTST (Nie et al., 2023), highlight-ing the effectiveness of FreDF in enhancing their performance given varying input …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">该PDF文件存在多个问题，首先，它包含大量无意义字符和乱码，这可能是由于编码错误或数据损坏导致的。其次，该内容使用了FlateDecode进行压缩，这虽然有助于减少文件大小，但可能进一步加剧了字符乱码的问题。此外，PDF中存在多个未定义的对象和流，以及未定义的字节序列、字节流、字节对象和字节内容，这些未定义的元素可能导致解析错误或显示异常。这些问题共同影响了PDF的完整性和可读性，因此需要进行修复或重新生成以确保文件的正确性和可用性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>该PDF包含大量无意义字符和乱码。</li>
<li>该内容使用了FlateDecode进行压缩。</li>
<li>该PDF中存在多个未定义的对象和流。</li>
<li>该PDF中存在多个未定义的字节序列。</li>
<li>该PDF中存在多个未定义的字节流。</li>
<li>该PDF中存在多个未定义的字节对象。</li>
<li>该PDF中存在多个未定义的字节内容。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-87">正文（抓取，非 AI）</h3>
<p>%PDF-1.3 %��������� 4 0 obj &lt;&lt; /Filter /FlateDecode /Length 7998 &gt;&gt; stream x�[��ƕ���)�U�� �q�V6U�g�r�8V�J��@q( ���̙��|���|����l��ؒ^\��@�&gt;}����}�]�U�]��<em>S�Y�.��.�&amp;��~�"[��M��/�e�wY[7�Fً7�'/~(2�^e˖||y����]</em>-��u�-7�W��r��ݫ�qw�ݹ;o7owG�a�ஞ�ş��bY�e}��w��w�o^d�J��� D�2�D���j��}�M��B�m�5�c(�<em>�/�YQ��u]�_�k~�</em>����U�6��-?��<em>{�w~��鞶�Uޔ��zU7���^���:�&lt;���+�^���)ؽ����?��</em>�W˿���&lt;�<em>v�Q�)�˲[U�r=.z�����ݐ� ��� ��RU��j]+� 7��B糢<code>R��!A ��~�Φ\�0�2y@� aD��#�vݪ(&lt;��m ���\��pYe˿�Q5�R����y�����~v��|a��&gt;7w2*��m��A���X��F���@�W�6� &lt;���!=��UU����^Wr}��&gt;�w��8ʊ����J�yu�&gt;��w�n�a�j���������,=���˰�&gt;��ȶ� ��A �T v�&amp;���pJ}٪US�mf�p2+_� �w���+ni�o����F�X� j��,a0�OhY��b�qQ��VU �ts��W�w��5�𖛇�^fڇ�t~�z�R0� �0��˽GϏ��J$��+�M ?r~*��Rcm3=���5�&lt; G�WfeU��f��斿�g�ZCvm�V��2nj���3����2�5B����@.w����)%��\�À</code>w���˸V����o??�~��� i{��������n��co�+ߢge���Nkhn� ��:�{!hs�!jm��Q/ܚ^�w�=j=.ʞ�nww� n�a�[͚=m��B�X���<em>G ,���&amp;����7oowovw�?�.�����9zɈ�4�;�X&gt;Ջ���x�� �D��ݨ�7�G����� N�����x�!� �H�Ț&gt;�u��:̫F3�</em>/����yykpB�E�ˡ�9�<em>Y��Z����-��� �~� �o���L��J� U� <code>���&amp;�,4�ϝ���&lt;�Y8=X2A�-������F�M 4�+�.yjc�� ��� Y�4 Y�8c0�v�h��Ŧ1��ש��f[L�ֵ�C%'[�Vɉ�* �ƈ���Zp���ފFD߼z&lt;"ٍ�����qk�R�uB�o~��oz�� .d�^"'c,-�Ŋ qu�) .� w(/ �ܿ޽a? 7N�ps��\ /Y \&lt;�?x��� �䩄��Fvٖ���-��$(�Q�e�! Vm���ex������.�C�C��²/0�&lt;v�= �/#%ͧxu�Ѹ(27=\~c(�m�l����as���F���uۏb'6Y�bg�*� �� 3���� 4�u���sYԊ_UY ��a&lt;�L��zw��2�FG#q4��[�.�5]!Z|D"�Z�!�ӎK�V"�m�v�*/�?�" ���F�fN��nVE&gt;l)�j�.E�~�k0VTł �e�gb97�b�� ����,� ���#2��R�ք�x�.�a�f���f�(W5񀺑h ���u</code>�E�0~��-A�� D�(�)�n���t���AM��H��^��qQ��D$����Lw�����&gt;7 Nk�JZ�OnY!̑��o #V����j���$bmK��XLmzs��Hc�[�</em> �t�V�{</em>�{<code>O�.��S���0����M��Z� {��D�UI �?�ŜeE f��v~�L��$�xB8à����e&amp;@���߱� b~���eQu�L�� x'yT�Y)�Y�� ��|� I��WVm85�H����Iķ�QY&amp;� /�.�1��. Wa|y�$�-���0]���6� �Y�T �F��]�3� ^�;���Lg yP�l͒2��G2�M��6��� �� ��6J�2�P�X%�mŢH WSP������  ���S g� B:�'X�Vbp9I����&lt;d�kt� � ������\3O��R,��w��Ϧ��UMڧ�r�</code>�X�Q���m���H˲ǟZM�� � M�׀��Q�Y �B܃�S����xT��,Py �&amp;�Ô{�zfOy �( TOR4�4H�&gt;�R��l�=H�� �T�'�A:��HS:�@�%#���.�Ij����+/IS��(�ޞ�$� u&lt;��,XG �$H@��=� ��,(beB�#E�����1�&lt;�ZaUye �����U�!Zԫ� ��V��(D�;�B��,!FU���p�v��LI��h @�X� L͎h �tv��vBt�u��:��������� g@�����Sߴ�p �x#wNf X�<em>oV ���e�0�پPu�%o����H@&lt;��T�B0.I�:��lO�[�^e�M�� �uj�x�6ݯ�39�޴5�&amp;�Nb'�{)V^�gڦ)���##Ǩ'��q=b5x .�,�r�% KxO��y�-v��9�:�I ��{�$qL����H�p�+�\�3(�)$5ҙN �p�O��u�v�&lt;�� ��Uk|/�q'�߉������&amp;j�?�Y�D�y��E���s����Hr��@y_</em>��(p:!P0�V)L���!4O��H <code>6 �V�</code>A��,(�΅3Z��}Bl� �� ��c�&lt;F��Wud+�=�1<em>+b ���M r�[�eϨ#3�T%V��̞!��x5HK��H��2� ����� ��r</em>�I�� ,� gA�[�UR��J4����Ҥ��o�S�M�����!�f#Ew����A��).yR��rj��: .���,��1 ��<em>�u�f�� z�t�\&amp; ��" U͗���'��!^L�/I� �$u� 5�%@�Dpx��</em>�i���̞!/IS�� U�#� �m=H=�t��"HP�t�x�zf���t�J�,P�2I��� ���ٷ�վw�i;��y�� [�\n�g�&amp;,���8'�"M^���s����i:�o�M �E��V�ɐ�G�������O�\�T�/�y&gt;8�xO�ň g� ,� cs ��,�� gAoїm$��wN ; � �E�'�&lt;��s_��b�!&gt;�$����} ��n�@��������y �"o��C�Ӎ�AA9K��.Y�.LR%�2�J;�'V^ ~���DT���!���,�5�'<code>6&lt;�m=΀^fE � �����&gt;���� a��&gt;�R�F����@;ŀ�0���&amp;�E�+��6]��e2 �Cg:K��O��@q��tO�WV|�������1���Y� HMOR�8|�1��q�@�3�t�=� �c ($��&amp;��,W�� ����{|Ζ� �g:�§�,����u�}�g��gb��MlЖ��?�_޾�\��QTqR������=� �� �DV�g�d��gQ���l�韟M��g�����d֯:��@Mo �*9*��������</code> ���j��2�!�L@�Sp1D'X�x���N�'<code>��{�N���yǧ'&amp;�s�؝�A�</code>�y�φ{'�&gt;���xd�z&gt;�����Oe\���ھ����s���N�k��<code>�M ��,�G|�</code>���۴i �F��3��@K�N ���?��\d�7I��#�p9��YP�����v��@�u��Dj�y��|g�H�uy������e}&gt;ٗ.� O�s'��s�lgaa�p0m�O�e7ష�&amp;Sg���l�6�g;;Y�'�&gt;�^�["��� uK$9\�8#���� f#���,腆��� �(�D�Y��� PG��JJ g��.� � �- �����0jJ���C�N&amp;���K.?'�mo ��yO����U ����� M���E/x ��qg\?���� �uϺ'��h ��bx���@O{P��ԣ)'�����Ҥ؞L��9�q�AjzK�'Acc#�s� �\��x H�8B������bI:�I$��wG{�zf���t��2��]dl�e�A�p�����x\���Ҧ%\7H�h p4�&amp;����-RJG3$I��� �̞!/IS�� Uč� ��&gt;�� �\ � ĒTIpB�{f���t�D#��4��)Ȝ4 ��&lt;�Q�� ��e�H L��~�R�K�O�8�K�oA�M�MR9 w�m�<em>'Hi���=��ɞ��ۣ=9n�􋧚�S<code>�h �98�a�%+ � ��=x�l�� ̩�� �x� ��</code>��b�j�ʩk4LC/�'�n��5���Q&amp;"Y��}o��\c�)ڟ���(����</em>��aT��<em>s[ ��07��� ��~�}&gt;/�j x�?Z�R��RĎci+�����ſli [�K���%ˤ$�.����P��Rm���0'�ui���ݝ)?� � � �S�j���ak)p(ti�p�BW+�mP�4 R�������ڵ�j2HA5���:li�� R��p˅�;�<em> N43K�&amp;/�hU��<code>G7��i�i���&gt;��� {]��-?���� �k�ɕ�)SQN�-�!�[[�C~ak:�s����[�swJUW</code>� �:��R�D ��3�%t�?�<em>�R�2S�I�|{��=&lt;{����� Õ�J��?[yB���R��L��̄�pR�|8� 7�fXy1u����� �4eK�qu}xC��!n��ҟ���B�����0 �i�:�.��Az�ٱ�}�(�|�ꏖr���GE�ɒC�v�T�&gt;���M��(� ���c�{#�ը�B2��u8�� z�lW!�0�[BZ�v�P+�u��iI&lt;}L�Mg}z K/L1� �� ϗ⒔��8�0����&amp;�f�����8�ooy�x� ��b�Ta)jxe�&gt;�G 5�8,�n�</em>.��-�����C݀�!]���)�Tp̶��F��T�$.ؑ�n��� XH]��������kl 8�<code>r��</code>�m٣'��R��C�</em> 1 � QR�C� ��M����:��ͩ�Pd����BL�}�5�</em>������u9Rl��CB%ʆ��(� QM%�k�-J� ���5'{f��1,���c%A�ZF� F�V���/� �S�A44%=��2!�<em>ia�[��</em>�y����/-��ҕe���� ��q,+Jز.��e��{f�+j <code>]&lt;�e�e��R��TH+(�Q���fo�o�Uls���O</code>�����h��؆X#�[5�ܭ��6L����Oa�5,[���%$ �7/�5E ����D�߳2�<em>I %� m[�<em>���-J�v��%�ʼ�w@_?���O�i�w��^�ic'I]R�<code>���Z�e�.�P ��ޠ�M��{�S�+�u]����[��Is�� ��Z5G���7%M�</code>���|&amp;��</em>0ǿE�2_KyĈ����<code>�D �V�w���'�%Z( �� ea�D����3��GU�[4��</code>ȿ���&lt;�?Է����g���ւ�cO��ˏ�~%�^�D4b��{��䘹/4��� t���f �Q4����j��{��+�'U��O�</em>�?0���l ��H%3�'�WS��i<em>o �!����-�/3&lt;�R_3od?�= �����Yd06@p�Ia� gXl{OD���R������r1 �Y�̈́A4pTa���P�Ju� � u��:T�-H5N�� �Ч�$��y-!�V�c�bZXs���Űg$�3���n�o���=k]c�����I�&gt; �T��4�f7ٯp��1ՙ�</em>�l/b�-�Q�MC�;G ��VU�Q�"b h���o�de���r�!�� ���)��gԲ�����֚����F�@N�V����1 Lu�xV1�Ģ�\&amp;�Oڬ���3�ƻ�V5�:J.��y毶����"�bQGr-�1������ϻ�C�Q��˅�7 -Bt��w� K�kv�o|s��o�k��� �OB'~�� O�Yh�w�#m��6�cI(��!<code>.��&amp; �#'�r�X�Dʥ�-![ �n��&gt;��H� �6��]� �����V-9 Lef�J:?�\'U&gt;��2�Lqz)��Ѓ?vreNk ��&amp;����~&lt;�&lt;�U��Kbߗǽ���[�t�K��Ľg� &gt;d��Ҟ'&amp;ў �ey�9G � �O, �w�B�� ��Q� 9�L�A:e2�W�� �~�&lt; )��AM2�B#) V��/�Jm�n�Lf&lt; L�s F��&amp;\�A BtT1�&lt;��  �n9&amp;G&amp;�爡����ݐ ",���9� �I���� ֹ��st��MCJHB]TZ$ _F!mw+�&gt;�:G�L�l��d�t6�2ލ$Qf��M�O�?����� z����^EA���)�ɦ|</code>����UG��&gt; �j]%���=/��xZe���4" mR+��&gt;�Y ��}gVf̵�-�ke1�mG}<em>kd�W�"�ߺ�&lt;�U{�Ps���?GҤr+��AG���(9��.�%e,'�&amp;��,Ȯ ��.�(3 �ƴn��祺�$�rpѐ����f��e �� 0$�s��N��-E}L�8� $�7̮���O)� �k6'E �w.���k����c�/Yֳ{,F�7Ȯ|$�9�4G�A����� �����A,/�= �����'�j�S&gt;ar, ���&amp;�~\�P��}  ��U�x/�%N�j��N���&gt;�%�r�6.p����\ � ���&lt;�{$��m";�����C���%�M, ݽ�Cy �Z���B #����'���8�u����<em>R~]� TIOc)?+xd�o�d��'��f�K��<code>�nU���l�Orw�q&amp;��[���-�-� �9�&amp;]�����M!� ��=aq��i�H��������B��B�-ͱ�i/��h��~38�DM"�w�cQ����� " �tFo�mb�i��B$�bN �8TVr�%�8UƠy��щ�֭D���0F݅��l p8 ��(��� ��%�x�f%v���V;jL��X���0CNxN���g���s*Ф�?h���/$�uL ��-�~r��SgY^�ݰ���9�%��u%����cL3�˜���.)m���_ ��Cr̓#_* ���� �9�9^��9�����'����� ����������+�� �d/�&lt;�r�� i�#��%��[:����oL{�{ݞ&gt;�XW����;�i��\���c�n�����벅O9�ys�e�S����ƾ^N��y�����]F��6�l8��z��(,b��.�o6ס��q�I5+��s?� ��u�����8d�;ʡ[9</code>y+�C�( U�&amp;���UuE^�� �P�</em>},N���H�����u�B �?�cu˨ځ����˱V)Gʖ;�B��0c� ݃af���ܽy��]�9��� ���(�\�yͺ�N��?s���?1Ӥ/�Y ���\��� ��u�</em>$h�� ]�����������Q� � �́?8Jʕ�~�5�R ����5)=U<code>C�� �Q�ynY �Iu��t�qӯ�� 6�N�Ƈo�Qi^\N. ��*� K.YX,@} \�حJ�]�&lt;���t �zu�}�Hi��C�B��_v�� RA �5� � $/Y'e������~w�E �����W�R\�l����no�x࠭[��3��3�(��V�� _�y��P�y��z���ș��$"9�YٟZ8��կ+��{�DRb)1� ��j�z�J���W��aX =��aO���;�oy����s(Lۼ}{&lt;|����[=��,JeDӪ�S5�ʻ�� ����&gt;��RD� [����Qt� endstream endobj 2 0 obj &lt;&lt; /Type /Page /Parent 3 0 R /Resources 5 0 R /Contents 4 0 R /MediaBox [0 0 612 792] /Rotate 0 /Annots 15 0 R &gt;&gt; endobj 5 0 obj &lt;&lt; /ProcSet [ /PDF /Text ] /ColorSpace &lt;&lt; /Cs1 7 0 R /Cs2 8 0 R &gt;&gt; /ExtGState &lt;&lt; /Gs1 24 0 R /Gs2 25 0 R &gt;&gt; /Font &lt;&lt; /Ty1 6 0 R /Ty2 9 0 R /Ty3 10 0 R /Ty4 11 0 R /G1 12 0 R /G2 13 0 R /Ty5 14 0 R &gt;&gt; &gt;&gt; endobj 15 0 obj [ 16 0 R 17 0 R 18 0 R 19 0 R 20 0 R 21 0 R 22 0 R 23 0 R ] endobj 24 0 obj &lt;&lt; /Type /ExtGState /ca 0.2 &gt;&gt; endobj 25 0 obj &lt;&lt; /Type /ExtGState /CA 0.2 &gt;&gt; endobj 26 0 obj &lt;&lt; /N 3 /Alternate /DeviceRGB /Length 2612 /Filter /FlateDecode &gt;&gt; stream x��wTS��Ͻ7��" %�z �;HQ�I�P��&amp;vDF)VdT�G�"cE ��b� �P��QDE�݌k �5�ޚ��Y�����g�}׺ P���tX�4�X���\���X��ffG�D���=���HƳ��.�d��,�P&amp;s���"7C$  E�6&lt;~&amp;��S��2����)2�12� ��"�įl���+�ɘ�&amp;�Y��4���Pޚ%ᣌ�\�%�g�|e�TI� ��(����L 0�_��&amp;�l�2E�� ��9�r��9h� x�g��Ib�טi���f��S�b1+��M�xL��� �0��o�E%Ym�h��� ��Y��h���� ~S�=�z�U�&amp;�ϞA��Y�l�/� �$Z� ���U �m@��O�  � �ޜ� �l^��� ' ���ls�k.+�7���oʿ�9�����V;�?�#I3eE妧�KD�� ��d�����9i���,�����UQ� ��h��&lt;�X�.d ���6'~�khu_ }�9P�I�o= C#$n?z}�[1 Ⱦ�h���s�2z��� \�n�LA"S�� �dr%�,�߄l��t� 4�.0,</code> �3p�  ��H�.Hi@�A&gt;�  A1�v�jp ԁz�N�6p\W� p �G@ ��K0ށi���A����B�ZyCAP8�C���@��&amp;�<em>���CP=�#t�]���� 4�}���a � ��ٰ; G���Dx����J�&gt;���� ,�_@��FX�DB�X$!k�"��E�����H�q���a���Y��bVa�bJ0՘c�VL�6f3����bձ�X'�?v 6��-�V<code>�</code>[����a�; ��� p~�\2n5��׌���� �&amp;�x�</em>���s�b|!�   ߏ ƿ'� Zk�!� $l$T����4Q��Ot"�y�\b)���A�I &amp;N�I�$R$)���TIj"]&amp;=&amp;�!��:dGrY@^O�$� <em>%�?P�(&amp;OJ EB�N9J�@y@yC�R �n�X����ZO�D}J}/G�3���ɭ���k��{%O�חw�</em>.�'<em>!J����Q�@�S���V�F��=�IE���b�b�b�b��5�Q%�����O�@��%�!BӥyҸ�M�:�e�0 G7��ӓ��� �� e%e[�(� ���R�0<code>�3R��������4�����6�i^��)��*n*|�"�f����LUo�՝�m�O�0j&amp;jaj�j��.��ϧ�w�ϝ_4����갺�z��j���=���U�4�5�n�ɚ��4ǴhZ �Z�Z�^0����Tf%��9�����-�&gt;�ݫ=�c��Xg�N��]�.[7A�\�SwBOK/X/_�Q�&gt;Q�����G�[��� �</code>�A�������a�a��c#����<em>�Z�;�8c�q��&gt;�[&amp;���I�I��MS���T<code>�ϴ� k�h&amp;4�5�Ǣ��YY�F֠9�&lt;�|�y��+ =�X���_,�,S-�, Y)YXm�����Ěk]c}ǆj�c�Φ�浭�-�v��};�]���N����"�&amp;�1=�x����tv(��}�������'{'��I�ߝY�)� Σ ��-r�q� r�.d.�_xp��Uە�Z���M׍�v�m���=����+K�G�ǔ���� ^���W�W����b�j�&gt;:&gt;�&gt;�&gt;�v��}/�a��v���������O8� � �FV&gt; 2 u����� /�_$\�B�Cv�&lt; 5 ]�s.,4�&amp;�y�Ux~xw-bEDCĻH����G��KwF�G�E�GME{E�EK�X,Y��F�Z� �= {$vr����K���� ��.3\����r���Ϯ�_�Yq*  ���©�L��_�w�ד������+��]�e�������D��]�cI�II�OA��u�_�䩔���)3�ѩ�i�����B%a��+]3='�/�4�0C��i��U�@ёL(sYf����L�H�$�%�Y �j��gGe��Q�����n� ����~5f5wug�v����5�k��֮\۹Nw]������m mH���Fˍe�n���Q�Q��</code>h����B�BQ�-�[l�ll��f��jۗ"^��b���O%ܒ��Y}W�����������w�vw����X�bY^�Ю�]�����W�Va[q<code>i�d��2���J�jGէ������{�����׿�m���&gt;  ���Pk�Am�a�����꺿g_D�H��G�G��u�;��7�7�6�Ʊ�q�o���C{��P3���8!9���� � &lt;�y�}��'�����Z�Z���։��6i{L{��ӝ � -?��|������gKϑ���9�w~�Bƅ��:Wt&gt;���ҝ����ˁ��^�r�۽��U��g�9];}�}����� ���_�~i��m��p���㭎�}��]�/���}������.�{�^�=�}����^?�z8�h�c��' O*��?�����f�����</code>ϳ�g���C/����O�ϩ�+F�F�G�Gό���z����ˌ��ㅿ)����ѫ�~w��gb���k��?Jި�9���m�d���wi獵�ޫ�?�����c�Ǒ��O�O���?w| ��x&amp;mf������ endstream endobj 7 0 obj [ /ICCBased 26 0 R ] endobj 27 0 obj &lt;&lt; /N 1 /Alternate /DeviceGray /Length 3385 /Filter /FlateDecode &gt;&gt; stream x�W\SW�?7�f�2�F�eˈ� ���"&amp;��b ��R�<code>���QѢ�E��:Q�V�ƭ/�RA��Z\X}���������~_��p��9�Y���B�[xRi.!�')��'pҦ�����"M�4y�)'..� I�DH���^�D)��B�5v��Q�&gt;�:�DP��C��Ä/�"�2 ��� �$.���� x�Q ^ bd.�eb&gt;+\�+a����x,wWwV�,?S��V���?��\9i7����^��oW��B� !�/�C|^h"</code>o��E��AQl��S G�s�9��7f� �+�G�xB�Q�()� ���(r��Lɜ�X�� ��_��p�H�%sf��,?����CB� �����4�+ �I9�I�(�v�.�z6/2� <code>;an8���FK ��=�O-��Ɛ�� �(��&gt;�Q(J� �;�BY��Uf�ø�� ��"H9�K��*x1���d�� ��Ћe�2�#}�P�L�8B�R0 �|4��u#*@bT�@Y����gh�0KM3 Pȳ �| '�� r� ��X&gt;ʄ���rD�B�A���% �#w�U�� �� �ͿFr�~����b�0�� ��X��Z܁I�(Na��r���7�% V���H?����T c�m � C�ML��GD�[�M3J��B&gt;Y!���sҷ��Z炭�� ��(��x�ι�d8&gt;</code>�;�;gx��h</em>4�2�;H�5+⹳��^�\6[̿�r���b�\~�b��j9���� ��h�q]���d�S6Gl���ѼQ0I�7ހ.�5��C� Ă�/�Nj/�{�����hϧ ���\� %����I����U��A4�L y �u&lt;�oDO�#s� ��� !w=N2B�= �U�&gt;1���� !��l�{|�/'d��Ȕ�2�Jg՗ �����.�y�ʝ����]���쇊((�Ǿ������#O���8ނ�� ��V�4ޢ@��c�|�q������A�?|H� �98���� d&gt;�}�l��Gb�=|�Gs���h����Y4:�c+�2��Sʴf�1�LG���Ę��3� Y3���LC�<code>�3C��&gt;�c$c� !D2��u/ � a��/ST9ް���#k��d�&gt;g��d�&amp;e �9WE��T�d�$F��ĕ��=�1s��MV-</code>&lt;6]���(͗fO ���Ze�b�Bh�0Ģ��r�Z$<code>raN�\�z��Ep"h��p2&lt;d T�ȅ�� "��&amp;k�ho�el�j�Ϟ�&gt;�p�(�}��|i�L�%*dq�f$dq%|Wg�;� ���=���Ћx�� 3���eEJA��H�</code>z��#k�����^����po�EI( ��D�KĶ -A���B��f� �B � BG�1t��.�+�݃/Pz��K4�a ��t1c��Ŝ0w� �B�h,K�2�,L�ɱ2�3�[�m�v<code>طX v��]��</code>�X ����S�)z3� eś¡DQ�(3)Y���RJee#�����D9M�H�tQ�Rq����%�{��x,��g�2|!^���ux#T�v�:ޅ��o�K��M�L����Bb9���C4g��D71@��jPM�NT</em><em>�:��E�G���P�G��j�P_�h4���%��M�O[N�J;@;E�J{D����t'�?=�Σ�+����'���=�� 5�Ý�HgH��^� �5�cƐ������J��@�De��.�V��</em>=<em>C�ڪ����I�٪KT7�6��S���BMM�J�G-^M��Xm��A��j�jo�u� Ճ�g���W��V?�~G������F�F�F�� ��35^3u��L.S�\Ĭe61�1�i�h�jr4gi�j�h ּ�ٯ��e����Z�U�բuKkP[W�M;V;O{��^� ڽ:t ;�P �N��N�3:�tq]k�<code>]��g��t���������z�z�z��]���џ���_�_�\�� 7�3���48dp�ୡ�!�Ph�̰���+�qFAFB�*�F�Fo�Yơ�9ƫ��?0!L M�M�l39g�?No��8���q���5��:�&amp;��7�i�a:hfnn&amp;5�dvƬ���&lt;�&lt;�|�� �&gt; ]�  ��:��OX�,+���u�5</code>ija)��ay�r���</em>٪���kUko�L�u�m�66Sm�l��ܵU����n�m�}ego�j���]���=׾�~��} �@��u7���{���u�G����ȱ�����I���3���Y�\�|�E݅�R�ϥ���5ڵ���� 6�'���&gt;�=ۃ� ߷{n:n�n�n�n�;���k�oLԘ6q����'9MN�6鶇��T�� m yzy�&lt;=��l�2��x�����^�}އ�3�g��1�7������|�s������;�~�p�ɏ���y�;��X<em>tZ����=��ds�s�MaO�M92�U�o���S!xHxHUȥP����͡ì²��� �{��?A���X q�k��s��^� "�F�G%Fm��9�1Z�:�25r�ک�clc$1GcQ,7vm�8���q������k�MpK(KhO�M���7�eҔ��I�� ���m)�)3RR^����I�6aڂi�L��i������������O��1�r�͙�3�g^�e2+w��ٚ�y�gP3R3�f�����x�s�s����7� ��}B���L��5��Y�Yk��D��Q�8X�Y�&lt;;"{{���؜�9 rSs�1�2�Z$:� ��|�����R'i��k����sdQ���<code>fAs� �S�!w�.�. (�-z=/e��b�bIqG�cɲ�ǥa�_�'��緕Y�-)�^�Y�c!�p�¶E֋*�,_�g�꒜%?���ה��Y�g�f�+ } ���Jf����R��ۿ �qi��e����T�Xͮ��~�����/ݾ����+.��\�mm�d��Ձ����^S���کk�ֱ�U��s���j&amp;�lߠ�A��kc���M6�Vmz�Y���vJ�-�[�my�U��ڶ�m��ͶWo�����;�w4������,��뮔]�_{�PoR_]��n��= {�6x54�5ݻr e�|_����|�Ms�K�����O����桨Cm��7~g�ݖ#�G����������]�i�W["[�Z�Z�|����c��j�� _yB�Dŉ'KO����?�u�Q��{g���q6��sQ����ÙvN�����]�����G/z^l���8��OG.y^j��u���ϕ֫����x�����?��޸��y�f��۷f��-��{'���Ew��-��}��5M ��k��tyv ����9��{�����R�˻��_5~�yl�׽�X_Xߕ'ӟ�&lt;�&gt; ��M��-� �}�{�� �z�˞�c� �����g�</code>��×y/�^U�6~�������o �{G������z�Cއ� �b endstream endobj 8 0 obj [ /ICCBased 27 0 R ] endobj 29 0 obj &lt;&lt; /Filter /FlateDecode /Length 7690 &gt;&gt; stream x�]ے#��}�W�~�DX�B]�O�h�;�,{z��X��æ���H�.����}շ�I � �P ػ� �, �����[�뿬X�����u?���~������7����?ڏU9���+:U�o ֿ���Z��w��\o�y�t8��o߬&gt;��r�ٞެ�'��{z�n�?������y�?�g����W5�W����7��o��~w�. 5� t�%� Z���n�{�</em>&gt;��H�߯?B��<em>P� �˺h�~5U���z %&gt;݋�� ������!��a�x�޳������|b���8����Xt%ln���Ş� ʮ7�~Y4��1��+�^ Z_�Q���A�%�f���� ]���7��"B��(˲[��ֱZƢ��I-�ls:��QOI�Mes���,�FMtsX�� [�����M��u�B��/������~+@���P~��5߾)�5ʢ {�ʁb,��]w�P �����c�� �JcC�a�����b{ޞ���1g� T�����</em>�x���1��늬� �N�ywssW�fW��ڝ�#ͭ/5�F4W.( ������|Gnꜰ �� ��(� 2�� r�8b��Z� {�t��0������ ~u��]S ��Y���U�] ��vm7+q�/�2����� �3L�h2v�)� b��D����黧�o�H?��(�]�G�<em>�yNYe(Ҩ�h٠"�EV����\�����3A�Ї5Z�V� ��-� ��n����z�E�y?S<code>@h�ڦh�ɠ���? ;��Hm뢪���r\��E �4 z����w��������̝♶ at�=k�"��-T#��Z�$��%F��a[uEՑ���ѽ����^�{S�g��á �;��Q�cR[U[9t�1gLB� +</code>�����',���e��R�4� /Ǖ�!Gl��P� F���v�/M1���?V�P�@zה�#�a$���HiXv�&lt;�t��be{8�,��f�P��U� ��Z|���P��أB���8 r���'#� =�<code>]�D[ ��5�[6�.Ǣͱ w��suU���篵</code>]�E�,�id\�<code>$Z�0���h� �!�#�b,� �b|�j YM,n5,n�o�,b�Xa� �.�2��� _Q�l�+0�� �:���.'"�</code>��&amp;�� �={^є��@F��T�&lt;�W�����q#^�J���X��0s�U�"�����aVƸ%̮�lt %TMD��m � ���W�l�,~fFwL�𒄬��LK^ X�V��</em>�UZ�d�U=�i�|3��%V$�Gz| LE��X!@/I�~"q�G�k#,�Q"� ��� Z�]��A����Z��4�4.5�L69/�ad��% �����e�lӀ��,%.BY_l� =8 �ۤYA�� ��=��Pad�ZA�$b8 M�C��G�f =s�a6ÂJ� ��Ѿ�B��ÖWU��t����zY��׿���f�����, ��j���y^/&lt;8(+�'���e�Gi������/�� ^�l^�l}a\ ���Y���ќ�S����d��q� �r&amp;n [���������&lt;8(<em>ҧ�jxpP2a��26��к4k |=Z�/�u�����yh X��;W��Aل�� T#"� Vx�<code>U��� ��X��AY?�X��Aل� l����4�p����zp�� "&lt;�tDMN]��MkV</code>����` F���[^ ���������%&lt;�T3�/�$���G� &lt;�K#^xp�I3.��lĂ) �~���!^�5��Ja�-�x��(-&lt;8�&lt;��e ,꾂e�Gi��A5��6�&amp;1+&lt;x���8'&lt;8!��eE�d� �MX0 ���j�^_�I [��Y��K���� �U]z�&amp;&lt;89�̃�9������AɄ�� T#�f�asGE�� �U�������&lt;8(</em>ҧ�jxpP2a��26�L�Z��<em>6�C�����</em> ���V���՜�Sp �MX&lt;X��A5"�U��K��.X��E"�VxpPV�O"VxpP6a�8f��jf� �0p�G1��PUS���ᘺ�1a�j���r���䭗��Z�Ƒӡ��� ��߬qjb�#���c�x�Y�kMN�+8�i�<em>�qj�f�©��9�|"$��Se��^8uP��Nm���}8o��{��a�Y�Fe�-���2��F,��ԁ�W[P8��r�Ђ.� �N@�� �(u���P�@����)�h� J �M&lt; ��R�H�O��(d�R/9}��� ����B���"~2� ��&amp;,�B�M53�7�vNR�R/Bv��&amp;N/@�n�+¨�� ˌ:���w��XF �LX;�Wa�A5"@Z;�Wa� x�� ����x��:(</em>ҧ�juP2a��2�6�����f</p></div></details>
</div>
<script>
function speakText(t){ if(!t){ document.getElementById('readStatus').textContent=''; return; }
 speechSynthesis.cancel(); var status=document.getElementById('readStatus'); status.textContent='准备中…';
 var chunks=[]; var maxLen=280; for(var i=0;i<t.length;i+=maxLen){ var s=t.slice(i,i+maxLen); var j=s.lastIndexOf('。'); if(j>80){ chunks.push(s.slice(0,j+1)); i-=s.length-(j+1); } else chunks.push(s); }
 if(chunks.length===0) chunks=[t]; var idx=0; function speakNext(){ if(idx>=chunks.length){ status.textContent=''; return; } var u=new SpeechSynthesisUtterance(chunks[idx]); u.lang='zh-CN'; u.rate=0.95; var v=speechSynthesis.getVoices().filter(function(x){ return x.lang.indexOf('zh')>=0; })[0]; if(v) u.voice=v;
 u.onend=function(){ idx++; setTimeout(speakNext,80); }; u.onerror=function(){ idx++; setTimeout(speakNext,80); }; status.textContent='朗读中 '+(idx+1)+'/'+chunks.length+'…'; speechSynthesis.speak(u); }
 if(speechSynthesis.getVoices().length) speakNext(); else speechSynthesis.onvoiceschanged=function(){ speechSynthesis.onvoiceschanged=null; speakNext(); }; }
function readFullText(){ var c=document.querySelector('.content'); if(!c){ document.getElementById('readStatus').textContent='无可读内容'; return; } var t=(c.innerText||'').trim().replace(/\\s+/g,' '); if(!t){ document.getElementById('readStatus').textContent='无可读内容'; return; } speechSynthesis.cancel(); document.getElementById('readStatus').textContent='全文朗读…'; speakText(t); }
function getBlockForTap(el){ var c=document.querySelector('.content'); var blockTags=['P','DIV','H2','H3','H4','LI','PRE']; while(el&&el!==c){ if(c.contains(el)&&blockTags.indexOf(el.tagName)!==-1) return el; el=el.parentElement; } return null; }
function onContentTap(e){ if(e.target.closest&&e.target.closest('a')) return; var block=getBlockForTap(e.target); if(block){ var t=(block.innerText||'').trim().replace(/\\s+/g,' '); if(t){ e.preventDefault(); speechSynthesis.cancel(); document.getElementById('readStatus').textContent='朗读本段…'; speakText(t); } } }
if(document.readyState==='loading'){ document.addEventListener('DOMContentLoaded', function(){ var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }); } else { var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }
setTimeout(function(){ try{ var u=new SpeechSynthesisUtterance('\u200b'); u.volume=0; speechSynthesis.speak(u); }catch(e){} }, 300);
</script>
</body>
</html>
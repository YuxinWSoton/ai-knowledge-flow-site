<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>知识流日报 2026-02-26：bounding boxes in network、feature map in newwork、anchor and proposal</title>
<style>
  * { box-sizing: border-box; }
  body {
    font-family: system-ui, sans-serif;
    max-width: 720px;
    margin: 0 auto;
    padding: 2rem 1rem;
    color: #fff;
    min-height: 100vh;
    background: #0a0e1a;
    background-image:
      radial-gradient(2px 2px at 20px 30px, rgba(255,255,255,0.9), transparent),
      radial-gradient(2px 2px at 40px 70px, rgba(255,255,255,0.6), transparent),
      radial-gradient(1.5px 1.5px at 90px 40px, rgba(255,255,255,0.8), transparent),
      radial-gradient(2px 2px at 130px 80px, rgba(255,255,255,0.5), transparent),
      radial-gradient(1.5px 1.5px at 160px 120px, rgba(255,255,255,0.7), transparent),
      radial-gradient(ellipse 120% 100% at 50% 0%, rgba(88,60,120,0.25), transparent 50%),
      radial-gradient(ellipse 80% 80% at 80% 20%, rgba(40,60,100,0.2), transparent 40%);
    background-size: 200px 200px;
    background-repeat: repeat;
  }
  a { color: #a8d4ff; text-decoration: none; }
  a:hover { text-decoration: underline; }
 html{scroll-behavior:smooth;} .content h2,.content h3{scroll-margin-top:1rem;} h1,h2,h3{margin-top:1.5rem;color:#fff;} pre{white-space:pre-wrap;color:rgba(255,255,255,0.9);} .toolbar{margin:0.5rem 0;color:rgba(255,255,255,0.8);} .content{color:rgba(255,255,255,0.95);} .content a{color:#a8d4ff;} .meta{color:rgba(255,255,255,0.65);font-size:0.9em;} .toc{margin:1rem 0;padding:0.8rem 1rem;background:rgba(255,255,255,0.08);border-radius:6px;} .toc .toc-title{margin:0 0 0.5rem 0;font-weight:bold;color:rgba(255,255,255,0.9);} .toc ul{list-style:none;padding-left:0;margin:0;} .toc li{margin:0.35rem 0;} .toc li.toc-h3{padding-left:1em;font-size:0.95em;} .toc a{color:#a8d4ff;text-decoration:none;} .toc a:hover{text-decoration:underline;} .content p,.content div,.content h2,.content h3,.content h4,.content li,.content pre{cursor:pointer;-webkit-tap-highlight-color:rgba(255,255,255,0.15);} .content .insight-summary{color:#c9a0dc;margin:0.5em 0 0.8em 0;} .content .insight-detail,.content .insight-detail li{color:#8dd4e8;list-style:disc;margin-left:1.2em;padding-left:0.3em;} .content .article-body-details{margin:0.8em 0;} .content .article-body-details summary{cursor:pointer;color:rgba(255,255,255,0.85);}</style>
</head>
<body>
<p><a href="https://YuxinWSoton.github.io/ai-knowledge-flow-site/">← 返回首页</a></p>
<h1>知识流日报 2026-02-26：bounding boxes in network、feature map in newwork、anchor and proposal</h1>
<p class="meta" style="margin-top:0;">最后更新：2026-02-26 10:16</p>
<p class="toolbar"><button id="btnFull" onclick="readFullText()">全文朗读</button> <span id="readStatus"></span></p>
<p class="meta" style="margin-top:0;">（点任意段落可朗读该段；「全文朗读」读本页全部内容）</p>
<nav class="toc" aria-label="目录">
<p class="toc-title">目录</p>
<ul>
  <li><a href="#toc-0">1. ground truth 和 bounding box 和 anchor box有什么区别？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-1">正文</a></li>
  <li><a href="#toc-2">2. 为什么YOLO在全连接层之后可以得到bounding box的大小和 ...</a></li>
  <li class="toc-h3"><a href="#toc-3">正文</a></li>
  <li><a href="#toc-4">3. 目标检测yolov1算法中，每个单元格预测的B个边界框的初始 ...</a></li>
  <li class="toc-h3"><a href="#toc-5">正文</a></li>
  <li><a href="#toc-6">4. 3d目标检测中的旋转角/航向角θ应该如何理解？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-7">正文</a></li>
  <li><a href="#toc-8">5. 菜鸟一问：boundingbox 和 ROI的区别是什么，或者说有 ...</a></li>
  <li class="toc-h3"><a href="#toc-9">正文</a></li>
  <li><a href="#toc-10">6. cv工业界如何把2d目标检测的bbox转化到现实世界坐标系的 ...</a></li>
  <li class="toc-h3"><a href="#toc-11">正文</a></li>
  <li><a href="#toc-12">7. UE5怎么获取actor被包含的最小矩形框4个顶点的实时坐标信息？</a></li>
  <li class="toc-h3"><a href="#toc-13">正文</a></li>
  <li><a href="#toc-14">8. 视频目标跟踪中如何判断前后视频帧中的bounding-box是同 ...</a></li>
  <li class="toc-h3"><a href="#toc-15">正文</a></li>
  <li><a href="#toc-16">9. 如何理解特征提取中的low-level feature和high-level feature?</a></li>
  <li class="toc-h3"><a href="#toc-17">正文</a></li>
  <li><a href="#toc-18">10. 什么是anchor-based 和anchor free？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-19">正文</a></li>
  <li><a href="#toc-20">11. 目标检测中的 Anchor 是什么？新手应该如何搞懂 Anchor？</a></li>
  <li class="toc-h3"><a href="#toc-21">正文</a></li>
  <li><a href="#toc-22">12. 单阶段、双阶段、anchor-based、anchor-free这四者之间有 ...</a></li>
  <li class="toc-h3"><a href="#toc-23">正文</a></li>
  <li><a href="#toc-24">13. 如何确定YOLO系列算法中的anchor box数量？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-25">正文</a></li>
  <li><a href="#toc-26">14. 如何评价最新的anchor-free目标检测模型FCOS? - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-27">正文</a></li>
  <li><a href="#toc-28">15. anchor-free存在什么缺点？ - 知乎</a></li>
  <li class="toc-h3"><a href="#toc-29">正文</a></li>
  <li><a href="#toc-30">16. faster rcnn中rpn的anchor，sliding windows，proposals？</a></li>
  <li class="toc-h3"><a href="#toc-31">正文</a></li>
  <li><a href="#toc-32">17. 如何评价zhangshifeng最新的讨论anchor based/ free的论文?</a></li>
  <li class="toc-h3"><a href="#toc-33">正文</a></li>
  <li><a href="#toc-34">18. Are Foundation Models the Route to Full-Stack Transfer in Robotics?</a></li>
  <li class="toc-h3"><a href="#toc-35">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-36">19. Academic collaborations and movements towards successful careers in physics</a></li>
  <li class="toc-h3"><a href="#toc-37">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-38">20. Solving stiff dark matter equations via Jacobian Normalization with Physics-Informed Neural Networks</a></li>
  <li class="toc-h3"><a href="#toc-39">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-40">21. Function-Space Empirical Bayes Regularisation with Student's t Priors</a></li>
  <li class="toc-h3"><a href="#toc-41">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-42">22. Neural solver for Wasserstein Geodesics and optimal transport dynamics</a></li>
  <li class="toc-h3"><a href="#toc-43">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-44">23. World Guidance: World Modeling in Condition Space for Action Generation</a></li>
  <li class="toc-h3"><a href="#toc-45">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-46">24. Enhancing LLM-Based Test Generation by Eliminating Covered Code</a></li>
  <li class="toc-h3"><a href="#toc-47">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-48">25. Universal Transport Properties of Continuous quantum gases</a></li>
  <li class="toc-h3"><a href="#toc-49">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-50">26. RGB-Event HyperGraph Prompt for Kilometer Marker Recognition based on Pre-trained Foundation Models</a></li>
  <li class="toc-h3"><a href="#toc-51">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-52">27. Capacity drop accounting for microscopic vehicle interaction effects: analytical model and validation with high-resolution trajectories</a></li>
  <li class="toc-h3"><a href="#toc-53">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-54">28. RT-RMOT: A Dataset and Framework for RGB-Thermal Referring Multi-Object Tracking</a></li>
  <li class="toc-h3"><a href="#toc-55">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-56">29. Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data</a></li>
  <li class="toc-h3"><a href="#toc-57">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-58">30. Disease Progression and Subtype Modeling for Combined Discrete and Continuous Input Data</a></li>
  <li class="toc-h3"><a href="#toc-59">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-60">31. Design-based theory for causal inference from adaptive experiments</a></li>
  <li class="toc-h3"><a href="#toc-61">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-62">32. PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning</a></li>
  <li class="toc-h3"><a href="#toc-63">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-64">33. RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations</a></li>
  <li class="toc-h3"><a href="#toc-65">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-66">34. Parallel Continuous-Time Relative Localization with Augmented Clamped Non-Uniform B-Splines</a></li>
  <li class="toc-h3"><a href="#toc-67">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-68">35. Quantum Resistance in Multilayer Graphene-BiFeO3 Memristor for Brain-Inspired Computing</a></li>
  <li class="toc-h3"><a href="#toc-69">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-70">36. Discovering new photovoltaics using optimal transport theory</a></li>
  <li class="toc-h3"><a href="#toc-71">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-72">37. Quantum criticality in open quantum systems from the purification perspective</a></li>
  <li class="toc-h3"><a href="#toc-73">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-74">38. IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs</a></li>
  <li class="toc-h3"><a href="#toc-75">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-76">39. Probing Large-scale Structure and the Multi-Phase IGM at the Cosmic Noon -- Insights from a Joint Survey with Euclid, CSST, JPCam, and JUST</a></li>
  <li class="toc-h3"><a href="#toc-77">正文（抓取，非 AI）</a></li>
</ul>
</nav>
<div class="content">
<h1>知识流日报 2026-02-26：bounding boxes in network、feature map in newwork、anchor and proposal</h1>
<p>共 39 条（来自百度学术 / Google / Bing 等，仅含正文抓取成功的条目；按正文长度从短到长排列，便于先听短的）。</p>
<p>（以下含抓取正文，便于阅读。未调用任何 AI API。）</p>
<p>（仅前 39 条含模型提取的「易漏细节」关键点，页面上以颜色区分；第 40 条及之后未调用模型，故无易漏细节。可在 config 中调大 extract_insights_max_items 以增加条数。）</p>
<h2 id="toc-0">1. ground truth 和 bounding box 和 anchor box有什么区别？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/521559167</li>
<li>来源：bing</li>
<li>摘要：Ground truth是真实标注框，也就是人工标注，一般被看作“真值” Bounding box 一般认为（为什么是一般认为，原因参照下面一段最后括号中的内容） 是网络最终预测的结果，也就是“可能值”，因为网络可 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">ground truth并非总是由人工标注的，有时可能来源于自动标注或其他数据处理过程。同样，bounding box也不一定是网络最终的预测结果，它可能经过了后处理步骤，如非极大值抑制（NMS）或进一步的细化调整。因此，理解这些概念时，需要认识到ground truth和bounding box的来源和处理过程，这有助于更准确地评估模型性能和理解检测结果。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>ground truth并非总是人工标注的；bounding box不一定是网络最终预测的结果。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-1">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-2">2. 为什么YOLO在全连接层之后可以得到bounding box的大小和 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/443189777</li>
<li>来源：bing</li>
<li>摘要：为什么YOLO在全连接层之后可以得到bounding box的大小和中心点？ 全连接层不是已经破坏了原卷积层里特征的位置信息了吗？ 这样一来bounding box就失去了参照物了吖 显示全部 关注者 68</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">全连接层处理后的特征图仍然保留了空间信息，这意味着在后续的处理过程中，特征图中的位置信息依然有效。YOLO算法通过特定的网络结构确保了bounding box信息的准确性，这得益于其设计能够直接在特征图上预测bounding box的位置、大小和类别。因此，即使经过全连接层处理，bounding box的大小和中心点信息依然有效，这保证了预测结果的精确性和实时性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>全连接层处理后的特征图仍然保留了空间信息；YOLO算法通过特定的网络结构确保了bounding box信息的准确性；bounding box的大小和中心点信息在全连接层之后依然有效。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-3">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-4">3. 目标检测yolov1算法中，每个单元格预测的B个边界框的初始 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/317682405</li>
<li>来源：bing</li>
<li>摘要：2023年12月7日 · 看了yolov1的论文原文，好像没有提到边界框的x,y,w,h是怎么初始化的。 输入为224X224,降采样为32倍后输出特征图大小为7X7, 同时每个cell预测2个bounding box和预测所属类别, …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">初始边界框的x、y、w、h的初始化方式在论文中并未明确提及，这可能导致边界框的尺寸和位置通过默认值或随机值进行初始化。特征图的大小为7x7，每个单元格预测2个边界框和类别，这意味着初始边界框的设定对最终检测结果的准确性有着重要影响。因此，初始边界框的x、y、w、h的初始化方式直接影响了边界框的预测精度，值得在研究中进一步明确和优化。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>初始边界框的x,y,w,h没有在论文中明确提及初始化方式。</li>
<li>边界框的尺寸和位置可能通过某种默认值或随机值初始化。</li>
<li>特征图的大小为7x7，每个单元格预测2个边界框和类别。</li>
<li>边界框的初始值可能影响最终检测结果的准确性。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-5">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-6">4. 3d目标检测中的旋转角/航向角θ应该如何理解？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/506197486</li>
<li>来源：bing</li>
<li>摘要：看到3d目标检测输出的结果里面有一个参数名叫旋转角θ，用来描述3d bounding box的旋转角度。想请问一下…</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">旋转角θ在3D目标检测中用于描述物体的三维旋转状态，但它并不直接对应物体的朝向，而是指物体绕某个轴旋转的角度。旋转角θ的取值范围通常限定在0到360度之间，这意味着它只能描述物体绕该轴旋转的单一完整周期。为了完全描述3D物体的旋转情况，旋转角θ需要与其他参数结合使用，如旋转轴的具体方向等。值得注意的是，旋转角θ的具体定义可能因不同算法而有所差异，因此在实际应用中需参照具体实现。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>旋转角θ用于描述3D目标检测中物体的三维旋转状态。</li>
<li>旋转角θ并不直接对应物体的朝向，而是其绕某个轴旋转的角度。</li>
<li>旋转角θ的取值范围通常为0到360度。</li>
<li>旋转角θ需要与其他参数结合使用，才能完全描述3D物体的旋转情况。</li>
<li>旋转角θ的定义可能因具体算法而异，需参照具体实现。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-7">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-8">5. 菜鸟一问：boundingbox 和 ROI的区别是什么，或者说有 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/408168479</li>
<li>来源：bing</li>
<li>摘要：2020年7月21日 · ROI指RPN阶段输出的proposal经过排序取topk，然后做nms取一定数量的框，用于第二阶段的再次精修；在RCNN ，Fast RCNN方法中指通过选择性搜索生成的框 bounding box …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">boundingbox 是通过选择性搜索生成的框，而ROI（感兴趣区域）则是RPN（区域提议网络）阶段输出的proposal经过进一步处理后的结果。选择性搜索生成的boundingbox 提供了初始的候选区域，这些区域随后被RPN阶段进一步筛选和优化，生成更精确的ROI。这种处理流程确保了最终的ROI不仅覆盖了目标区域，而且具有更高的准确性，从而提高了目标检测的效率和精度。因此，boundingbox 和ROI在目标检测过程中扮演着互补的角色，前者提供初始候选区域，后者则通过细化处理提升检测的准确性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>boundingbox 是通过选择性搜索生成的框，而ROI是RPN阶段输出的proposal经过处理后的结果。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-9">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-10">6. cv工业界如何把2d目标检测的bbox转化到现实世界坐标系的 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/394814665</li>
<li>来源：bing</li>
<li>摘要：2020年5月14日 · 理论上，Bounding Box给出了一个3D物体在2D成像平面上的 边界框。 也存在一些检测算法可以提取3D Bounding Box，但目前主流检测还是以2D Box为主。 如果一个Box完全准确，那 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">Dounding Box仅描述了物体在2D成像平面上的边界，但并不直接提供物体在现实世界中的3D坐标信息。因此，目前主流的目标检测算法主要依赖2D Bounding Box而非3D Bounding Box。这是因为2D Bounding Box能够更直接地反映物体在图像中的位置和大小，而3D Bounding Box虽然提供了物体的空间信息，但在实际应用中，由于获取3D坐标信息的难度和成本较高，2D Bounding Box成为了更为实用的选择。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>D Bounding Box仅描述了物体在2D成像平面上的边界。</li>
<li>D Bounding Box并不直接提供物体在现实世界中的3D坐标信息。</li>
<li>目前主流的目标检测算法主要依赖2D Bounding Box而非3D Bounding Box。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-11">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-12">7. UE5怎么获取actor被包含的最小矩形框4个顶点的实时坐标信息？</h2>
<ul>
<li>链接：https://www.zhihu.com/question/601887494</li>
<li>来源：bing</li>
<li>摘要：2023年5月22日 · 抛砖引玉一下 可能需要获得物体的bounding box然后转换到屏幕空间最后画出来。 蓝图有个 Get Bouding Box，C++有个 GetActorBounds，然后可以构造成FBox。 转换可以试一下 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，获取bounding box需要考虑物体的旋转和缩放，这是因为物体的形状和大小在三维空间中可能会发生变化。其次，GetActorBounds函数返回的是包含actor及其组件的最小包围盒，这有助于精确地确定物体在场景中的位置和大小。此外，FBox类可以用来表示三维空间中的包围盒，它提供了一种方便的方式来处理和操作包围盒。因此，转换到屏幕空间时，还需要考虑视口和投影矩阵，以确保物体在屏幕上的正确显示。最后，UE5中的bounding box信息是实时的，会随物体的变换而变化，这使得动态场景中的物体交互更加真实和灵活。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>获取bounding box需要考虑物体的旋转和缩放。</li>
<li>GetActorBounds返回的是包含actor及其组件的最小包围盒。</li>
<li>FBox可以用来表示三维空间中的包围盒。</li>
<li>转换到屏幕空间需要考虑视口和投影矩阵。</li>
<li>UE5中的bounding box信息是实时的，会随物体变换而变化。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-13">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-14">8. 视频目标跟踪中如何判断前后视频帧中的bounding-box是同 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/280406127</li>
<li>来源：bing</li>
<li>摘要：2018年6月9日 · 视频目标跟踪中如何判断前后视频帧中的bounding-box是同一个？ 需要实现视频目标轨迹跟踪的功能，目前使用YOLO/keras已经实现了视频中 目标检测的功能。 现在有一个疑问，我该怎 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">bounding-box的匹配需要考虑时空连续性，以确保跟踪的准确性。匹配算法需处理目标在不同帧间的尺度变化和形变问题，同时还要应对背景噪声和遮挡的干扰。因此，应使用多帧信息进行综合判断，而不能仅依赖单帧特征。此外，跟踪算法还需具备处理目标消失和重新出现的能力，以提高跟踪的鲁棒性。最终，bounding-box匹配的精确度直接影响整个跟踪系统的性能，因此必须确保匹配算法的高效性和准确性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>bounding-box的匹配需要考虑时空连续性，以确保跟踪的准确性。</li>
<li>匹配算法需处理目标在不同帧间的尺度变化和形变问题。</li>
<li>背景噪声和遮挡会干扰bounding-box的正确匹配。</li>
<li>应使用多帧信息进行综合判断，而不能仅依赖单帧特征。</li>
<li>跟踪算法需具备处理目标消失和重新出现的能力。</li>
<li>bounding-box匹配的精确度直接影响整个跟踪系统的性能。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-15">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-16">9. 如何理解特征提取中的low-level feature和high-level feature?</h2>
<ul>
<li>链接：https://www.zhihu.com/question/264702008</li>
<li>来源：bing</li>
<li>摘要：2017年12月29日 · high-level feature 常被人称为是高级的语义信息， 他的感觉就像通过环境信息 纹理信息，等等一些信息综合得出来的一个信息，然后分类or检测的时候在使用它去进行判断。 2. low-level …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，低级特征主要指图像的基本属性，如颜色、纹理等，它们不涉及具体的语义信息。其次，高级特征的提取依赖于低级特征的综合处理，这些高级特征包含了语义信息，而不仅仅是低级特征的直接反映。因此，在特征提取过程中，低级特征是高级特征的基础，高级特征的提取往往需要多个低级特征的综合。通过这种方式，图像的基本属性被整合成包含更多语义信息的高级特征，从而实现对图像内容的更深层次理解。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>high-level feature 的提取依赖于低级特征的综合处理。</li>
<li>high-level feature 包含语义信息，而不仅仅是低级特征的直接反映。</li>
<li>low-level feature 主要指图像的基本属性，如颜色、纹理等。</li>
<li>low-level feature 不涉及具体的语义信息。</li>
<li>特征提取过程中，低级特征是高级特征的基础。</li>
<li>高级特征的提取往往需要多个低级特征的综合。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-17">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-18">10. 什么是anchor-based 和anchor free？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/356551927</li>
<li>来源：bing</li>
<li>摘要：2019年12月9日 · FSAF-既有根据先验设定的anchor-based分支，也有anchor-free分支增强对异常ratio目标的检测能力 2.anchor（也被称为anchor box）是在训练之前，在训练集上利用k-means等方法聚类 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">anchor-based方法依赖预先设定的anchor进行目标检测，这使得它在常规情况下表现良好，但对异常比例的目标检测能力较弱。相比之下，anchor-free方法不依赖预先设定的anchor，因此能够更好地适应不同比例的目标，提高检测的灵活性和准确性。为了确定anchor-free方法中anchor box的尺寸和比例，通常会采用k-means等聚类方法，通过分析大量数据来自动选择合适的anchor box尺寸和比例，从而进一步提升目标检测的性能。因此，采用anchor-free方法结合聚类方法可以有效弥补传统anchor-based方法的不足，提高目标检测的全面性和鲁棒性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>anchor-based方法依赖预先设定的anchor进行目标检测。</li>
<li>anchor-free方法不依赖预先设定的anchor，能更好地检测异常比例的目标。</li>
<li>k-means等聚类方法用于确定anchor box的尺寸和比例。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-19">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-20">11. 目标检测中的 Anchor 是什么？新手应该如何搞懂 Anchor？</h2>
<ul>
<li>链接：https://www.zhihu.com/question/560126815</li>
<li>来源：bing</li>
<li>摘要：2022年10月25日 · Anchor就如同它的名字：锚，指的是预测目标检测框时的参考框。 典型的目标检测框架会采用全卷积的主干网络，也可以认为是并行式的滑动遍历，因此预测的检测框是相对坐标，而不 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">Anchor在目标检测中扮演着关键角色，用于预测目标检测框时提供参考坐标。预测的检测框是相对于Anchor的坐标变化，这意味着模型学习的是相对于Anchor的相对位置，而非绝对位置。这种设计使得模型能够更灵活地适应不同大小和位置的目标，从而提高检测的准确性和效率。因此，Anchor的使用不仅简化了模型的学习过程，还增强了目标检测框架的整体性能。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Anchor用于预测目标检测框时提供参考坐标。</li>
<li>预测的检测框是相对于Anchor的坐标变化。</li>
<li>Anchor帮助模型学习相对位置，而非绝对位置。</li>
<li>Anchor的使用使得目标检测框架更加灵活和高效。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-21">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-22">12. 单阶段、双阶段、anchor-based、anchor-free这四者之间有 ...</h2>
<ul>
<li>链接：https://www.zhihu.com/question/428972054</li>
<li>来源：bing</li>
<li>摘要：单阶段、双阶段、anchor-based、anchor-free 4者的联系应该分成两个并行维度来讲。 单阶段和双阶段划分依据是是否存在显式的 roi 特征提取过程，典型的双阶段算法是 faster rcnn，其包括 RPN 和 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">单阶段算法由于不包含显式的 ROI 特征提取过程，因此直接对整个图像进行处理，而双阶段算法则通过包含显式的 ROI 特征提取过程，先定位出感兴趣区域，再进行进一步处理。在实现方式上，anchor-based 方法依赖预先定义的 anchor 来进行特征提取和定位，而 anchor-free 方法则不依赖预先定义的 anchor，直接从图像中提取特征，这使得 anchor-free 方法更加灵活，但也可能增加模型的复杂度。因此，选择哪种方法取决于具体的应用场景和需求。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>单阶段算法不包含显式的 ROI 特征提取过程。</li>
<li>双阶段算法包含显式的 ROI 特征提取过程。</li>
<li>anchor-based 方法依赖预先定义的 anchor。</li>
<li>anchor-free 方法不依赖预先定义的 anchor。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-23">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-24">13. 如何确定YOLO系列算法中的anchor box数量？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/334555740</li>
<li>来源：bing</li>
<li>摘要：2019年7月17日 · 最近在尝试复现YOLOv3的tf版，有个百思不解的问题，就是anchor box的数量问题。按说anchor box的数量在设…</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">YOLOv3的anchor box数量并非随意设定，而是直接影响检测效果的关键参数。不同数据集可能需要不同的anchor box数量，因为每个数据集的物体大小和分布各不相同。因此，选择合适的anchor box数量需要通过实验和调优来确定，以确保检测效果最佳。此外，实验和调优过程有助于找到最适合当前数据集的anchor box数量，从而提高检测精度。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>YOLOv3的anchor box数量不是随意设定的；</li>
<li>anchor box的数量直接影响检测效果；</li>
<li>不同数据集可能需要不同数量的anchor box；</li>
<li>anchor box数量的选择涉及实验和调优。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-25">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-26">14. 如何评价最新的anchor-free目标检测模型FCOS? - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/319670356/answers/updated</li>
<li>来源：bing</li>
<li>摘要：一、前言 这篇文章主要讲解一下比较火的一个anchor free检测模型FCOS（全称Fully Convolutional One-Stage） [1]，目前很多模型都是基于fcos这个模型的思路进行优化的。这个模型不仅结构简单、想法新 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">FCOS是一种one-stage目标检测模型，其结构简单且是一个较新的anchor-free检测模型。由于其设计简洁且无需使用anchor，FCOS在目标检测领域引起了广泛关注，并且其思路被后续许多模型采用并优化。这种设计不仅简化了模型结构，还提高了检测的准确性和效率，因此FCOS在目标检测领域具有重要的地位和影响。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>FCOS是一种one-stage目标检测模型。</li>
<li>FCOS的思路被后续许多模型采用并优化。</li>
<li>FCOS结构简单。</li>
<li>FCOS是一个较新的anchor-free检测模型。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-27">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-28">15. anchor-free存在什么缺点？ - 知乎</h2>
<ul>
<li>链接：https://www.zhihu.com/question/364639597</li>
<li>来源：bing</li>
<li>摘要：2021年7月21日 · 我的看法是anchor-free和anchor-based实际上最大的区别应该是解空间上的区别。 anchor-free，无论是keypoint-based的方法（e.g. CornerNet和CenterNet）还是pixel-wise prediction …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，anchor-free方法的解空间不同于传统的anchor-based方法，这意味着它在检测目标时采用了不同的策略。其次，keypoint-based方法和pixel-wise prediction方法属于anchor-free的范畴，表明它们在目标检测中不再依赖预先设定的anchor。此外，CornerNet和CenterNet是anchor-free方法的具体实例，展示了这种新方法的实际应用。因此，通过改变解空间，anchor-free方法能够避免anchor-based方法的一些局限性，从而提供更灵活和有效的目标检测解决方案。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>anchor-free方法的解空间不同于anchor-based方法。</li>
<li>keypoint-based方法和pixel-wise prediction方法属于anchor-free的范畴。</li>
<li>CornerNet和CenterNet是anchor-free方法的实例。</li>
<li>anchor-free方法通过改变解空间来避免anchor-based方法的某些局限。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-29">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-30">16. faster rcnn中rpn的anchor，sliding windows，proposals？</h2>
<ul>
<li>链接：https://www.zhihu.com/question/42205480</li>
<li>来源：bing</li>
<li>摘要：anchor 让网络学习到的是一种推断的能力。 网络不会认为它拿到的这一小块 feature map 具有七十二变的能力，能同时从 9 种不同的 anchor 区域得到。 拥有 anchor 的 rpn 做的事情是它已知图像中的某 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，网络不会认为拿到的 feature map 具有七十二变的能力，即网络不会假设 feature map 可以同时适应多种尺度和比例。其次，rpn（Region Proposal Network）通过 anchor 来推断可能的目标区域，这表明 rpn 并不认为输入的 feature map 可以同时适应多种尺度和比例。此外，拥有 anchor 的 rpn 使用 anchor 来帮助识别可能的目标，这意味着 rpn 依赖于预先设定的 anchor 来进行目标区域的初步筛选，而不是直接从 feature map 中获取目标信息。因此，这些机制共同作用，确保目标检测过程的准确性和高效性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>网络不会认为拿到的 feature map 具有七十二变的能力。</li>
<li>rpn 通过 anchor 来推断可能的目标区域。</li>
<li>拥有 anchor 的 rpn 并不认为输入的 feature map 可以同时适应多种尺度和比例。</li>
<li>rpn 使用 anchor 来帮助识别可能的目标。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-31">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-32">17. 如何评价zhangshifeng最新的讨论anchor based/ free的论文?</h2>
<ul>
<li>链接：https://www.zhihu.com/question/359595879</li>
<li>来源：bing</li>
<li>摘要：回到正题，最近anchor-free的检测出了很多优秀的论文，不少大佬都有对anchor-based和anchor-free进行分析，其中指出过说，只铺1个anchor的RetinaNet和类似FCOS的anchor-free方法非常像，这也是 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">只铺1个anchor的RetinaNet和类似FCOS的anchor-free方法在表面上非常相似，这种相似性容易让人忽视一个关键点：即anchor-free方法实际上并未完全摒弃anchor的概念。这提示我们在比较anchor-based和anchor-free方法时，需要明确两者定义之间的细微差别。因此，尽管这些方法在实现上有所相似，但它们在理论基础和实际应用中的区别仍然值得深入探讨。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>只铺1个anchor的RetinaNet和类似FCOS的anchor-free方法非常像；</li>
<li>这种相似性容易让人忽视anchor-free方法实际上并未完全摒弃anchor的概念；</li>
<li>这提示在比较anchor-based和anchor-free方法时需明确两者定义的细微差别。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-33">正文</h3>
<p>（知乎问题/专栏/想法页，正文未抓取，可点击上方链接阅读。）</p>
</div></details><h2 id="toc-34">18. Are Foundation Models the Route to Full-Stack Transfer in Robotics?</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22001v1</li>
<li>来源：arxiv</li>
<li>摘要：In humans and robots alike, transfer learning occurs at different levels of abstraction, from high-level linguistic transfer to low-level transfer of motor skills. In this article, we provide an overview of the impact that foundation models and transformer networks have had on these different levels, bringing robots closer than ever to "full-stack transfer". Considering LLMs, VLMs and VLAs from a robotic transfer learning perspective allows us to highlight recurring concepts for transfer, beyond specific implementations. We also consider the challenges of data collection and transfer benchmarks for robotics in the age of foundation models. Are foundation models the route to full-stack transfer in robotics? Our expectation is that they will certainly stay on this route as a key technology.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">transfer learning 在不同层次上发生，从高层次的语言转移学到低层次的运动技能转移。full-stack transfer 指机器人能够从基础模型获得全面的能力提升，这表明机器人不仅能够处理语言任务，还能执行复杂的运动任务。基础模型和变压器网络对不同层次的转移学习产生了影响，基础模型可能是实现全面转移的关键路径。此外，考虑语言模型、视觉语言模型和视觉语言代理有助于突出转移学习中的反复出现的概念。然而，数据收集和转移基准是机器人领域面临的挑战，因此预期基础模型将继续作为关键技术保持这一路径。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>transfer learning 在不同层次上发生，从高层次的语言转移学到低层次的运动技能转移。</li>
<li>full-stack transfer 指机器人能够从基础模型获得全面的能力提升。</li>
<li>基础模型和变压器网络对不同层次的转移学习产生了影响。</li>
<li>考虑语言模型、视觉语言模型和视觉语言代理有助于突出转移学习中的反复出现的概念。</li>
<li>数据收集和转移基准是机器人领域面临的挑战。</li>
<li>基础模型可能是实现全面转移的关键路径。</li>
<li>预期基础模型将继续作为关键技术保持这一路径。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-35">正文（抓取，非 AI）</h3>
<p>[2602.22001v1] Are Foundation Models the Route to Full-Stack Transfer in Robotics? Computer Science &gt; Robotics arXiv:2602.22001v1 (cs) [Submitted on 25 Feb 2026] Title: Are Foundation Models the Route to Full-Stack Transfer in Robotics? Authors: Freek Stulp , Samuel Bustamante , João Silvério , Alin Albu-Schäffer , Jeannette Bohg , Shuran Song View a PDF of the paper titled Are Foundation Models the Route to Full-Stack Transfer in Robotics?, by Freek Stulp and Samuel Bustamante and Jo\~ao Silv\'erio and Alin Albu-Sch\"affer and Jeannette Bohg and Shuran Song View PDF HTML (experimental) Abstract: In humans and robots alike, transfer learning occurs at different levels of abstraction, from high-level linguistic transfer to low-level transfer of motor skills. In this article, we provide an overview of the impact that foundation models and transformer networks have had on these different levels, bringing robots closer than ever to "full-stack transfer". Considering LLMs, VLMs and VLAs from a robotic transfer learning perspective allows us to highlight recurring concepts for transfer, beyond specific implementations. We also consider the challenges of data collection and transfer benchmarks for robotics in the age of foundation models. Are foundation models the route to full-stack transfer in robotics? Our expectation is that they will certainly stay on this route as a key technology. Comments: 12 pages, 4 figures Subjects: Robotics (cs.RO) Cite as: arXiv:2602.22001 [cs.RO] (or arXiv:2602.22001v1 [cs.RO] for this version) https://doi.org/10.48550/arXiv.2602.22001 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Freek Stulp [ view email ] [v1] Wed, 25 Feb 2026 15:19:44 UTC (475 KB) Full-text links: Access Paper: View a PDF of the paper titled Are Foundation Models the Route to Full-Stack Transfer in Robotics?, by Freek Stulp and Samuel Bustamante and Jo\~ao Silv\'erio and Alin Albu-Sch\"affer and Jeannette Bohg and Shuran Song View PDF HTML (experimental) TeX Source view license Current browse context: cs.RO &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-36">19. Academic collaborations and movements towards successful careers in physics</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22031v1</li>
<li>来源：arxiv</li>
<li>摘要：Collaboration networks evolve throughout academic careers, yet few studies systematically examine how these network dynamics relate to long-term career success and mobility. Analysing 35,708 physicists' careers spanning at least 15 years, we use time series clustering to identify ten distinct evolution patterns of network size and clustering coefficient across career years 5 to 15. We report three key results. First, authors who begin with loosely connected networks and progressively tighten their networks while expanding network size during mid-career achieve the highest PI attainment rates, publication output, and citation impact. Second, despite different starting points, network evolution patterns associated with better outcomes converge toward moderate clustering by career year 15, suggesting an optimal balance between core team cohesion and diverse external connections. Third, mobility is positively associated with these successful network evolution patterns and remains positively associated with scientific outcomes even after controlling for network evolution patterns.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">学术网络的动态变化与长期职业成功和流动性密切相关。首先，网络的形成过程是从松散开始，逐渐变得紧密，并且网络规模不断扩大，这有助于提高项目负责人（PI）的获得率。其次，适度的集群系数在职业生涯后期是成功的关键，表明核心团队的凝聚力与外部联系的多样性之间存在最佳平衡。此外，网络演化的模式与更好的职业成果和科学成果相关，这进一步证明了网络结构对职业发展的积极影响。因此，适度的网络集群和演化的模式与职业流动性正相关，有助于实现职业上的成功。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>学术网络动态与长期职业成功和流动性密切相关。</li>
<li>网络松散开始并逐渐变得更紧密，同时网络规模扩大，有助于提高PI获得率。</li>
<li>网络的适度集群在职业生涯后期是成功的关键。</li>
<li>网络演化的模式与更好的职业成果相关。</li>
<li>网络演化的模式与更好的科学成果相关。</li>
<li>适度的集群系数表明核心团队凝聚力与外部联系的多样性之间存在最佳平衡。</li>
<li>职业流动性与成功的网络演化模式正相关。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-37">正文（抓取，非 AI）</h3>
<p>[2602.22031v1] Academic collaborations and movements towards successful careers in physics Physics &gt; Physics and Society arXiv:2602.22031v1 (physics) [Submitted on 25 Feb 2026] Title: Academic collaborations and movements towards successful careers in physics Authors: Mingrong She , Jan Bachmann , Fariba Karimi , Leto Peel View a PDF of the paper titled Academic collaborations and movements towards successful careers in physics, by Mingrong She and 2 other authors View PDF HTML (experimental) Abstract: Collaboration networks evolve throughout academic careers, yet few studies systematically examine how these network dynamics relate to long-term career success and mobility. Analysing 35,708 physicists' careers spanning at least 15 years, we use time series clustering to identify ten distinct evolution patterns of network size and clustering coefficient across career years 5 to 15. We report three key results. First, authors who begin with loosely connected networks and progressively tighten their networks while expanding network size during mid-career achieve the highest PI attainment rates, publication output, and citation impact. Second, despite different starting points, network evolution patterns associated with better outcomes converge toward moderate clustering by career year 15, suggesting an optimal balance between core team cohesion and diverse external connections. Third, mobility is positively associated with these successful network evolution patterns and remains positively associated with scientific outcomes even after controlling for network evolution patterns. Comments: 14 pages, 8 figures Subjects: Physics and Society (physics.soc-ph) Cite as: arXiv:2602.22031 [physics.soc-ph] (or arXiv:2602.22031v1 [physics.soc-ph] for this version) https://doi.org/10.48550/arXiv.2602.22031 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Mingrong She [ view email ] [v1] Wed, 25 Feb 2026 15:37:32 UTC (387 KB) Full-text links: Access Paper: View a PDF of the paper titled Academic collaborations and movements towards successful careers in physics, by Mingrong She and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: physics.soc-ph &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: physics References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-38">20. Solving stiff dark matter equations via Jacobian Normalization with Physics-Informed Neural Networks</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.21988v1</li>
<li>来源：arxiv</li>
<li>摘要：Stiff differential equations pose a major challenge for Physics-Informed Neural Networks (PINNs), often causing poor convergence. We propose a simple, hyperparameter-free method to address stiffness by normalizing loss residuals with the Jacobian. We provide theoretical indications that Jacobian-based normalization can improve gradient descent and validate it on benchmark stiff ordinary differential equations. We then apply it to a realistic system: the stiff Boltzmann equations (BEs) governing weakly interacting massive particle (WIMP) dark matter (DM). Our approach achieves higher accuracy than attention mechanisms previously proposed for handling stiffness, recovering the full solution where prior methods fail. This is further demonstrated in an inverse problem with a single experimental data point - the observed DM relic density - where our inverse PINNs correctly infer the cross section that solves the BEs in both Standard and alternative cosmologies.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">Physics-Informed Neural Networks (PINNs) 在处理刚性微分方程时常常表现出较差的收敛性，这使得它们在解决相关问题时面临挑战。为了解决这一问题，研究者提出了一种新的方法，通过将损失残差与雅可比矩阵进行归一化来改进梯度下降过程。这种方法无需设置超参数，且以简单的方式解决了刚性问题，从而提高了梯度下降的效果。特别地，该方法成功应用于描述弱相互作用大质量粒子（WIMP）暗物质的刚性玻尔兹曼方程（BEs），验证了其有效性。此外，该方法在处理刚性问题时比之前的注意力机制更为准确，甚至能够恢复前人方法无法解决的完整解。在一项使用单一实验数据点的逆向问题中，该方法正确地推断出了满足BEs的交叉截面，这一结果在标准宇宙学和替代宇宙学中均得到了验证。理论分析表明，基于雅可比矩阵的归一化方法能够进一步改善梯度下降过程。最后，该方法在基准刚性常微分方程上进行了验证，进一步证明了其优越性。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Physics-Informed Neural Networks (PINNs) can struggle with stiff differential equations, leading to poor convergence.</li>
<li>Normalizing loss residuals with the Jacobian can improve gradient descent for PINNs.</li>
<li>The proposed method is hyperparameter-free and addresses stiffness in a simple way.</li>
<li>Stiff Boltzmann equations (BEs) governing WIMP dark matter (DM) were successfully applied to validate the approach.</li>
<li>The method achieves higher accuracy than previous attention mechanisms for handling stiffness.</li>
<li>The approach recovers the full solution where prior methods fail.</li>
<li>The method was demonstrated in an inverse problem using a single experimental data point.</li>
<li>Inverse PINNs correctly inferred the cross section that solves the BEs in both Standard and alternative cosmologies.</li>
<li>Theoretical indications suggest Jacobian-based normalization can improve gradient descent.</li>
<li>The approach was validated on benchmark stiff ordinary differential equations.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-39">正文（抓取，非 AI）</h3>
<p>[2602.21988v1] Solving stiff dark matter equations via Jacobian Normalization with Physics-Informed Neural Networks High Energy Physics - Phenomenology arXiv:2602.21988v1 (hep-ph) [Submitted on 25 Feb 2026] Title: Solving stiff dark matter equations via Jacobian Normalization with Physics-Informed Neural Networks Authors: M. P. Bento , H. B. Câmara , J. R. Rocha , J. F. Seabra View a PDF of the paper titled Solving stiff dark matter equations via Jacobian Normalization with Physics-Informed Neural Networks, by M. P. Bento and 3 other authors View PDF HTML (experimental) Abstract: Stiff differential equations pose a major challenge for Physics-Informed Neural Networks (PINNs), often causing poor convergence. We propose a simple, hyperparameter-free method to address stiffness by normalizing loss residuals with the Jacobian. We provide theoretical indications that Jacobian-based normalization can improve gradient descent and validate it on benchmark stiff ordinary differential equations. We then apply it to a realistic system: the stiff Boltzmann equations (BEs) governing weakly interacting massive particle (WIMP) dark matter (DM). Our approach achieves higher accuracy than attention mechanisms previously proposed for handling stiffness, recovering the full solution where prior methods fail. This is further demonstrated in an inverse problem with a single experimental data point - the observed DM relic density - where our inverse PINNs correctly infer the cross section that solves the BEs in both Standard and alternative cosmologies. Comments: 16 LaTeX pages; 6 figures Subjects: High Energy Physics - Phenomenology (hep-ph) Cite as: arXiv:2602.21988 [hep-ph] (or arXiv:2602.21988v1 [hep-ph] for this version) https://doi.org/10.48550/arXiv.2602.21988 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Henrique Brito Câmara [ view email ] [v1] Wed, 25 Feb 2026 15:08:59 UTC (6,311 KB) Full-text links: Access Paper: View a PDF of the paper titled Solving stiff dark matter equations via Jacobian Normalization with Physics-Informed Neural Networks, by M. P. Bento and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: hep-ph &lt; prev | next &gt; new | recent | 2026-02 References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-40">21. Function-Space Empirical Bayes Regularisation with Student's t Priors</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22015v1</li>
<li>来源：arxiv</li>
<li>摘要：Bayesian deep learning (BDL) has emerged as a principled approach to produce reliable uncertainty estimates by integrating deep neural networks with Bayesian inference, and the selection of informative prior distributions remains a significant challenge. Various function-space variational inference (FSVI) regularisation methods have been presented, assigning meaningful priors over model predictions. However, these methods typically rely on a Gaussian prior, which fails to capture the heavy-tailed statistical characteristics inherent in neural network outputs. By contrast, this work proposes a novel function-space empirical Bayes regularisation framework -- termed ST-FS-EB -- which employs heavy-tailed Student's $t$ priors in both parameter and function spaces. Also, we approximate the posterior distribution through variational inference (VI), inducing an evidence lower bound (ELBO) objective based on Monte Carlo (MC) dropout. Furthermore, the proposed method is evaluated against various VI-based BDL baselines, and the results demonstrate its robust performance in in-distribution prediction, out-of-distribution (OOD) detection and handling distribution shifts.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">Gaussian priors在建模过程中往往无法捕捉到神经网络输出中的重尾特性，这使得它们在处理重尾分布时表现不佳。相比之下，Student's t priors能够更好地捕捉重尾统计特征，并在参数和函数空间中得到应用。为了更准确地逼近后验分布，研究者引入了基于蒙特卡洛丢弃的ELBO目标。ST-FS-EB框架通过这些改进，展示了在处理分布偏移时的稳健性能，从而在内部分布预测和外部分布检测方面均表现出色。此外，该方法在各种基于变分推断的贝叶斯深度学习基线中表现出更优异的性能，进一步证明了其在处理重尾分布时的优势。因此，使用Student's t priors能够显著提升模型在不同场景下的表现。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Gaussian priors fail to capture heavy-tailed characteristics.</li>
<li>Student's t priors are used in both parameter and function spaces.</li>
<li>Heavy-tailed characteristics are important for neural network outputs.</li>
<li>ELBO objective is induced based on Monte Carlo dropout.</li>
<li>ST-FS-EB framework demonstrates robust performance.</li>
<li>Gaussian priors typically fail to model heavy-tailed distributions effectively.</li>
<li>Student's t priors can better capture heavy-tailed statistical features.</li>
<li>Monte Carlo dropout helps approximate the posterior distribution.</li>
<li>In-distribution prediction benefits from the proposed method.</li>
<li>Out-of-distribution detection is improved by the proposed method.</li>
<li>Handling distribution shifts is more robust with Student's t priors.</li>
<li>The proposed method outperforms various VI-based BDL baselines.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-41">正文（抓取，非 AI）</h3>
<p>[2602.22015v1] Function-Space Empirical Bayes Regularisation with Student's t Priors Computer Science &gt; Machine Learning arXiv:2602.22015v1 (cs) [Submitted on 25 Feb 2026] Title: Function-Space Empirical Bayes Regularisation with Student's t Priors Authors: Pengcheng Hao , Ercan Engin Kuruoglu View a PDF of the paper titled Function-Space Empirical Bayes Regularisation with Student's t Priors, by Pengcheng Hao and 1 other authors View PDF HTML (experimental) Abstract: Bayesian deep learning (BDL) has emerged as a principled approach to produce reliable uncertainty estimates by integrating deep neural networks with Bayesian inference, and the selection of informative prior distributions remains a significant challenge. Various function-space variational inference (FSVI) regularisation methods have been presented, assigning meaningful priors over model predictions. However, these methods typically rely on a Gaussian prior, which fails to capture the heavy-tailed statistical characteristics inherent in neural network outputs. By contrast, this work proposes a novel function-space empirical Bayes regularisation framework -- termed ST-FS-EB -- which employs heavy-tailed Student's $t$ priors in both parameter and function spaces. Also, we approximate the posterior distribution through variational inference (VI), inducing an evidence lower bound (ELBO) objective based on Monte Carlo (MC) dropout. Furthermore, the proposed method is evaluated against various VI-based BDL baselines, and the results demonstrate its robust performance in in-distribution prediction, out-of-distribution (OOD) detection and handling distribution shifts. Subjects: Machine Learning (cs.LG) Cite as: arXiv:2602.22015 [cs.LG] (or arXiv:2602.22015v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.22015 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Pengcheng Hao [ view email ] [v1] Wed, 25 Feb 2026 15:29:44 UTC (2,120 KB) Full-text links: Access Paper: View a PDF of the paper titled Function-Space Empirical Bayes Regularisation with Student's t Priors, by Pengcheng Hao and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-42">22. Neural solver for Wasserstein Geodesics and optimal transport dynamics</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22003v1</li>
<li>来源：arxiv</li>
<li>摘要：In recent years, the machine learning community has increasingly embraced the optimal transport (OT) framework for modeling distributional relationships. In this work, we introduce a sample-based neural solver for computing the Wasserstein geodesic between a source and target distribution, along with the associated velocity field. Building on the dynamical formulation of the optimal transport (OT) problem, we recast the constrained optimization as a minimax problem, using deep neural networks to approximate the relevant functions. This approach not only provides the Wasserstein geodesic but also recovers the OT map, enabling direct sampling from the target distribution. By estimating the OT map, we obtain velocity estimates along particle trajectories, which in turn allow us to learn the full velocity field. The framework is flexible and readily extends to general cost functions, including the commonly used quadratic cost. We demonstrate the effectiveness of our method through experiments on both synthetic and real datasets.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">Wasserstein geodesic的计算依赖于源分布和目标分布，涉及求解一个约束优化问题。为了解决这一最小最大问题，该方法通过神经网络近似相关函数，从而实现计算。Wasserstein geodesic的计算与OT问题的动态形式密切相关，而OT地图的估计则提供了粒子轨迹上的速度估计。此外，该方法不仅计算Wasserstein geodesic，还恢复OT映射，从而有助于学习完整的速度场。该框架适用于一般成本函数，包括常用的二次成本，并且在合成数据和真实数据集上的实验验证了其有效性。因此，该方法提供了一种灵活且有效的计算Wasserstein geodesic的方式。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Wasserstein geodesic计算依赖于源分布和目标分布。</li>
<li>Wasserstein geodesic计算涉及求解一个约束优化问题。</li>
<li>该方法通过神经网络近似相关函数来解决最小最大问题。</li>
<li>OT地图的估计提供了粒子轨迹上的速度估计。</li>
<li>该框架适用于一般成本函数，包括常用的二次成本。</li>
<li>实验在合成数据和真实数据集上验证了方法的有效性。</li>
<li>Wasserstein geodesic计算与OT问题的动态形式有关。</li>
<li>该方法不仅计算Wasserstein geodesic，还恢复OT映射。</li>
<li>OT映射的估计有助于学习完整的速度场。</li>
<li>该方法提供了一种灵活的计算Wasserstein geodesic的方式。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-43">正文（抓取，非 AI）</h3>
<p>[2602.22003v1] Neural solver for Wasserstein Geodesics and optimal transport dynamics Computer Science &gt; Machine Learning arXiv:2602.22003v1 (cs) [Submitted on 25 Feb 2026] Title: Neural solver for Wasserstein Geodesics and optimal transport dynamics Authors: Hailiang Liu , Yan-Han Chen View a PDF of the paper titled Neural solver for Wasserstein Geodesics and optimal transport dynamics, by Hailiang Liu and 1 other authors View PDF HTML (experimental) Abstract: In recent years, the machine learning community has increasingly embraced the optimal transport (OT) framework for modeling distributional relationships. In this work, we introduce a sample-based neural solver for computing the Wasserstein geodesic between a source and target distribution, along with the associated velocity field. Building on the dynamical formulation of the optimal transport (OT) problem, we recast the constrained optimization as a minimax problem, using deep neural networks to approximate the relevant functions. This approach not only provides the Wasserstein geodesic but also recovers the OT map, enabling direct sampling from the target distribution. By estimating the OT map, we obtain velocity estimates along particle trajectories, which in turn allow us to learn the full velocity field. The framework is flexible and readily extends to general cost functions, including the commonly used quadratic cost. We demonstrate the effectiveness of our method through experiments on both synthetic and real datasets. Comments: 28 pages, 22 figures Subjects: Machine Learning (cs.LG) ; Optimization and Control (math.OC); Machine Learning (stat.ML) MSC classes: 93E20 (Primary), 49Q22 (Secondary) Cite as: arXiv:2602.22003 [cs.LG] (or arXiv:2602.22003v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.22003 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Yan-Han Chen [ view email ] [v1] Wed, 25 Feb 2026 15:21:24 UTC (3,665 KB) Full-text links: Access Paper: View a PDF of the paper titled Neural solver for Wasserstein Geodesics and optimal transport dynamics, by Hailiang Liu and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs math math.OC stat stat.ML References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-44">23. World Guidance: World Modeling in Condition Space for Action Generation</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22010v1</li>
<li>来源：arxiv</li>
<li>摘要：Leveraging future observation modeling to facilitate action generation presents a promising avenue for enhancing the capabilities of Vision-Language-Action (VLA) models. However, existing approaches struggle to strike a balance between maintaining efficient, predictable future representations and preserving sufficient fine-grained information to guide precise action generation. To address this limitation, we propose WoG (World Guidance), a framework that maps future observations into compact conditions by injecting them into the action inference pipeline. The VLA is then trained to simultaneously predict these compressed conditions alongside future actions, thereby achieving effective world modeling within the condition space for action inference. We demonstrate that modeling and predicting this condition space not only facilitates fine-grained action generation but also exhibits superior generalization capabilities. Moreover, it learns effectively from substantial human manipulation videos. Extensive experiments across both simulation and real-world environments validate that our method significantly outperforms existing methods based on future prediction. Project page is availabl</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">WoG框架通过将未来观察映射到紧凑条件来促进精细动作生成，这一机制有助于维持高效、可预测的未来表示，但同时也与保留足够的细粒度信息以指导精确动作生成之间存在冲突。为了解决这一矛盾，WoG通过将未来观察注入动作推理管道来压缩条件，从而在提高泛化能力的同时，有效学习大量的人类操作视频。实验结果表明，WoG在模拟和真实环境中的表现均优于现有方法，显著优于基于未来预测的方法。因此，WoG不仅能够有效学习大量的人类操作视频，还能在不同环境条件下展现出优越的性能。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>WoG框架通过将未来观察映射到紧凑条件来促进精细动作生成。</li>
<li>维持高效、可预测的未来表示与保留足够的细粒度信息以指导精确动作生成之间存在冲突。</li>
<li>WoG通过将未来观察注入动作推理管道来压缩条件。</li>
<li>压缩条件有助于提高泛化能力。</li>
<li>WoG能够有效学习大量的人类操作视频。</li>
<li>实验结果表明，WoG显著优于基于未来预测的方法。</li>
<li>WoG在模拟和真实环境中的表现均优于现有方法。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-45">正文（抓取，非 AI）</h3>
<p>[2602.22010v1] World Guidance: World Modeling in Condition Space for Action Generation Computer Science &gt; Robotics arXiv:2602.22010v1 (cs) [Submitted on 25 Feb 2026] Title: World Guidance: World Modeling in Condition Space for Action Generation Authors: Yue Su , Sijin Chen , Haixin Shi , Mingyu Liu , Zhengshen Zhang , Ningyuan Huang , Weiheng Zhong , Zhengbang Zhu , Yuxiao Liu , Xihui Liu View a PDF of the paper titled World Guidance: World Modeling in Condition Space for Action Generation, by Yue Su and 9 other authors View PDF HTML (experimental) Abstract: Leveraging future observation modeling to facilitate action generation presents a promising avenue for enhancing the capabilities of Vision-Language-Action (VLA) models. However, existing approaches struggle to strike a balance between maintaining efficient, predictable future representations and preserving sufficient fine-grained information to guide precise action generation. To address this limitation, we propose WoG (World Guidance), a framework that maps future observations into compact conditions by injecting them into the action inference pipeline. The VLA is then trained to simultaneously predict these compressed conditions alongside future actions, thereby achieving effective world modeling within the condition space for action inference. We demonstrate that modeling and predicting this condition space not only facilitates fine-grained action generation but also exhibits superior generalization capabilities. Moreover, it learns effectively from substantial human manipulation videos. Extensive experiments across both simulation and real-world environments validate that our method significantly outperforms existing methods based on future prediction. Project page is available at: this https URL Comments: Project Page: this https URL Subjects: Robotics (cs.RO) ; Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.22010 [cs.RO] (or arXiv:2602.22010v1 [cs.RO] for this version) https://doi.org/10.48550/arXiv.2602.22010 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Yue Su [ view email ] [v1] Wed, 25 Feb 2026 15:27:09 UTC (1,906 KB) Full-text links: Access Paper: View a PDF of the paper titled World Guidance: World Modeling in Condition Space for Action Generation, by Yue Su and 9 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.RO &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CV References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-46">24. Enhancing LLM-Based Test Generation by Eliminating Covered Code</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.21997v1</li>
<li>来源：arxiv</li>
<li>摘要：Automated test generation is essential for software quality assurance, with coverage rate serving as a key metric to ensure thorough testing. Recent advancements in Large Language Models (LLMs) have shown promise in improving test generation, particularly in achieving higher coverage. However, while existing LLM-based test generation solutions perform well on small, isolated code snippets, they struggle when applied to complex methods under test. To address these issues, we propose a scalable LLM-based unit test generation method. Our approach consists of two key steps. The first step is context information retrieval, which uses both LLMs and static analysis to gather relevant contextual information associated with the complex methods under test. The second step, iterative test generation with code elimination, repeatedly generates unit tests for the code slice, tracks the achieved coverage, and selectively removes code segments that have already been covered. This process simplifies the testing task and mitigates issues arising from token limits or reduced reasoning effectiveness associated with excessively long contexts. Through comprehensive evaluations on open-source projects, </li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">LLMs在处理复杂代码片段时表现不佳，这主要是因为代码片段的长度会影响其推理效果。现有方法在小代码片段上表现良好，但在复杂代码片段上的表现则不尽如人意。因此，通过消除已覆盖的代码，可以提高测试生成的效率。此外，迭代测试生成过程中需要跟踪覆盖率，这有助于确保生成的测试能够覆盖尽可能多的代码路径。静态分析有助于收集相关上下文信息，从而进一步提升测试生成的质量。因此，该方法在开源项目上的表现优于其他方法，特别是在需要高覆盖率的情况下。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>LLMs在处理复杂代码片段时表现不佳。</li>
<li>覆盖率是评估测试生成质量的关键指标。</li>
<li>现有LLM方法在小代码片段上表现良好。</li>
<li>代码片段的长度会影响LLM的推理效果。</li>
<li>通过消除已覆盖的代码，可以提高测试生成的效率。</li>
<li>迭代测试生成过程中需要跟踪覆盖率。</li>
<li>静态分析有助于收集相关上下文信息。</li>
<li>该方法在开源项目上的表现优于其他方法。</li>
<li>Token限制会影响LLM生成测试的能力。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-47">正文（抓取，非 AI）</h3>
<p>[2602.21997v1] Enhancing LLM-Based Test Generation by Eliminating Covered Code Computer Science &gt; Software Engineering arXiv:2602.21997v1 (cs) [Submitted on 25 Feb 2026] Title: Enhancing LLM-Based Test Generation by Eliminating Covered Code Authors: WeiZhe Xu , Mengyu Liu , Fanxin Kong View a PDF of the paper titled Enhancing LLM-Based Test Generation by Eliminating Covered Code, by WeiZhe Xu and 2 other authors View PDF HTML (experimental) Abstract: Automated test generation is essential for software quality assurance, with coverage rate serving as a key metric to ensure thorough testing. Recent advancements in Large Language Models (LLMs) have shown promise in improving test generation, particularly in achieving higher coverage. However, while existing LLM-based test generation solutions perform well on small, isolated code snippets, they struggle when applied to complex methods under test. To address these issues, we propose a scalable LLM-based unit test generation method. Our approach consists of two key steps. The first step is context information retrieval, which uses both LLMs and static analysis to gather relevant contextual information associated with the complex methods under test. The second step, iterative test generation with code elimination, repeatedly generates unit tests for the code slice, tracks the achieved coverage, and selectively removes code segments that have already been covered. This process simplifies the testing task and mitigates issues arising from token limits or reduced reasoning effectiveness associated with excessively long contexts. Through comprehensive evaluations on open-source projects, our approach outperforms state-of-the-art LLM-based and search-based methods, demonstrating its effectiveness in achieving high coverage on complex methods. Comments: 9 pages, 4 figures, supplementary material included Subjects: Software Engineering (cs.SE) ; Artificial Intelligence (cs.AI); Machine Learning (cs.LG) Cite as: arXiv:2602.21997 [cs.SE] (or arXiv:2602.21997v1 [cs.SE] for this version) https://doi.org/10.48550/arXiv.2602.21997 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Fanxin Kong [ view email ] [v1] Wed, 25 Feb 2026 15:16:43 UTC (917 KB) Full-text links: Access Paper: View a PDF of the paper titled Enhancing LLM-Based Test Generation by Eliminating Covered Code, by WeiZhe Xu and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.SE &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-48">25. Universal Transport Properties of Continuous quantum gases</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22009v1</li>
<li>来源：arxiv</li>
<li>摘要：The Drude weight characterizes ballistic transport in quantum many-body systems, yet a comprehensive understanding and exact analytical results for it remain elusive, especially in multi-component quantum gases. In this work, we leverage Generalized Hydrodynamics and the Thermodynamic Bethe Ansatz method to precisely compute the Drude weights of one-dimensional continuous integrable systems, such as the Lieb-Liniger model and the Bose-Fermi mixture model. We establish an exact, universal relationship between components of the Drude weight matrix and fundamental thermodynamic quantities (e.g., particle, enthalpy, and entropy densities) for the constituent particles with distinct statistics undergo dynamic coupling. For both models, we further derive analytical approximations of the Drude weight in distinct physical regimes and identify universal scaling laws for the Drude weight near quantum phase transitions.Finally, to connect theory with experiment, we propose and simulate two feasible measurement protocols--a linear potential quench and a bipartitioning setup-verifying that they can reliably extract the Drude weights. Our results establish a direct link between macroscopic trans</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">Drude重量是表征无阻尼传输的重要参数，但其精确的解析结果难以获得。借助广义流体动力学和热力学贝特解，可以计算出Drude重量。Drude重量与基本的热力学量密切相关，并在量子相变附近表现出普遍的标度律。通过线性势能猝变和双部分化设置，可以可靠地提取出Drude重量，这些设置揭示了宏观传输现象与微观准粒子结构之间的联系。理论结果为未来超冷原子气体实验提供了基准，验证了这些微观机制在宏观传输中的作用。因此，Drude重量不仅在描述量子系统传输特性方面具有重要意义，还为理解量子相变和准粒子行为提供了关键的理论依据。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>Drude weight characterizes ballistic transport but exact analytical results are elusive.</li>
<li>Generalized Hydrodynamics and Thermodynamic Bethe Ansatz help compute Drude weights.</li>
<li>Drude weights are related to fundamental thermodynamic quantities.</li>
<li>Drude weights have universal scaling laws near quantum phase transitions.</li>
<li>Linear potential quench and bipartitioning setup can reliably extract Drude weights.</li>
<li>Macroscopic transport phenomena are linked to microscopic quasiparticle structure.</li>
<li>Theoretical results provide benchmarks for future ultracold atomic gas experiments.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-49">正文（抓取，非 AI）</h3>
<p>[2602.22009v1] Universal Transport Properties of Continuous quantum gases Condensed Matter &gt; Quantum Gases arXiv:2602.22009v1 (cond-mat) [Submitted on 25 Feb 2026] Title: Universal Transport Properties of Continuous quantum gases Authors: Zi-yang Liu , Xiangguo Yin , Yunbo Zhang , Shizhong Zhang , Xi-Wen Guan View a PDF of the paper titled Universal Transport Properties of Continuous quantum gases, by Zi-yang Liu and 4 other authors View PDF Abstract: The Drude weight characterizes ballistic transport in quantum many-body systems, yet a comprehensive understanding and exact analytical results for it remain elusive, especially in multi-component quantum gases. In this work, we leverage Generalized Hydrodynamics and the Thermodynamic Bethe Ansatz method to precisely compute the Drude weights of one-dimensional continuous integrable systems, such as the Lieb-Liniger model and the Bose-Fermi mixture model. We establish an exact, universal relationship between components of the Drude weight matrix and fundamental thermodynamic quantities (e.g., particle, enthalpy, and entropy densities) for the constituent particles with distinct statistics undergo dynamic coupling. For both models, we further derive analytical approximations of the Drude weight in distinct physical regimes and identify universal scaling laws for the Drude weight near quantum phase this http URL , to connect theory with experiment, we propose and simulate two feasible measurement protocols--a linear potential quench and a bipartitioning setup-verifying that they can reliably extract the Drude weights. Our results establish a direct link between macroscopic transport phenomena and microscopic quasiparticle structure, furnishing critical theoretical benchmarks for future ultracold atomic gas experiments. Comments: 17 pages+51 pages(supplementary material)+16 figures Subjects: Quantum Gases (cond-mat.quant-gas) Cite as: arXiv:2602.22009 [cond-mat.quant-gas] (or arXiv:2602.22009v1 [cond-mat.quant-gas] for this version) https://doi.org/10.48550/arXiv.2602.22009 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Xi-Wen Guan [ view email ] [v1] Wed, 25 Feb 2026 15:24:58 UTC (1,896 KB) Full-text links: Access Paper: View a PDF of the paper titled Universal Transport Properties of Continuous quantum gases, by Zi-yang Liu and 4 other authors View PDF TeX Source view license Current browse context: cond-mat.quant-gas &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cond-mat References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-50">26. RGB-Event HyperGraph Prompt for Kilometer Marker Recognition based on Pre-trained Foundation Models</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22026v1</li>
<li>来源：arxiv</li>
<li>摘要：Metro trains often operate in highly complex environments, characterized by illumination variations, high-speed motion, and adverse weather conditions. These factors pose significant challenges for visual perception systems, especially those relying solely on conventional RGB cameras. To tackle these difficulties, we explore the integration of event cameras into the perception system, leveraging their advantages in low-light conditions, high-speed scenarios, and low power consumption. Specifically, we focus on Kilometer Marker Recognition (KMR), a critical task for autonomous metro localization under GNSS-denied conditions. In this context, we propose a robust baseline method based on a pre-trained RGB OCR foundation model, enhanced through multi-modal adaptation. Furthermore, we construct the first large-scale RGB-Event dataset, EvMetro5K, containing 5,599 pairs of synchronized RGB-Event samples, split into 4,479 training and 1,120 testing samples. Extensive experiments on EvMetro5K and other widely used benchmarks demonstrate the effectiveness of our approach for KMR. Both the dataset and source code will be released on https://github.com/Event-AHU/EvMetro5K_benchmark</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">RGB-Event摄像头能够在低光条件下运行，特别适用于高速场景，并能有效应对恶劣天气条件。因此，这种摄像头对于自主地铁定位中的千米标记识别（KMR）至关重要，尤其是在GNSS信号被拒绝的情况下，需要具备强大鲁棒性的KMR方法。为了应对这些挑战，研究人员利用预训练的RGB OCR模型进行多模态适应，并开发了EvMetro5K数据集，其中包含5,599个同步的RGB-Event对，479个用于训练，1,120个用于测试。实验结果表明，该方法在EvMetro5K和其他基准数据集上均表现出色。此外，该数据集和源代码将公开提供，以促进相关研究的发展。由于RGB-Event摄像头在低光、高速和低功耗方面具有优势，其与RGB摄像头的结合能够有效解决传统RGB摄像头的挑战，从而为自主地铁系统在GNSS信号被拒绝条件下的千米标记识别提供可靠支持。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>RGB-Event cameras can operate in low-light conditions.</li>
<li>High-speed scenarios benefit from event cameras.</li>
<li>Adverse weather conditions are better handled with event cameras.</li>
<li>Kilometer Marker Recognition (KMR) is crucial for autonomous metro localization.</li>
<li>GNSS-denied conditions necessitate robust KMR methods.</li>
<li>Pre-trained RGB OCR models are enhanced for multi-modal adaptation.</li>
<li>The EvMetro5K dataset contains 5,599 synchronized RGB-Event pairs.</li>
<li>,479 training and 1,120 testing samples are included in EvMetro5K.</li>
<li>Experiments on EvMetro5K and other benchmarks demonstrate effectiveness.</li>
<li>Both the dataset and source code will be publicly available.</li>
<li>Event cameras offer advantages in low-light, high-speed, and low power.</li>
<li>RGB-Event integration addresses challenges of conventional RGB cameras.</li>
<li>KMR is a critical task for autonomous metro systems under GNSS-denied conditions.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-51">正文（抓取，非 AI）</h3>
<p>[2602.22026v1] RGB-Event HyperGraph Prompt for Kilometer Marker Recognition based on Pre-trained Foundation Models Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.22026v1 (cs) [Submitted on 25 Feb 2026] Title: RGB-Event HyperGraph Prompt for Kilometer Marker Recognition based on Pre-trained Foundation Models Authors: Xiaoyu Xian , Shiao Wang , Xiao Wang , Daxin Tian , Yan Tian View a PDF of the paper titled RGB-Event HyperGraph Prompt for Kilometer Marker Recognition based on Pre-trained Foundation Models, by Xiaoyu Xian and 4 other authors View PDF HTML (experimental) Abstract: Metro trains often operate in highly complex environments, characterized by illumination variations, high-speed motion, and adverse weather conditions. These factors pose significant challenges for visual perception systems, especially those relying solely on conventional RGB cameras. To tackle these difficulties, we explore the integration of event cameras into the perception system, leveraging their advantages in low-light conditions, high-speed scenarios, and low power consumption. Specifically, we focus on Kilometer Marker Recognition (KMR), a critical task for autonomous metro localization under GNSS-denied conditions. In this context, we propose a robust baseline method based on a pre-trained RGB OCR foundation model, enhanced through multi-modal adaptation. Furthermore, we construct the first large-scale RGB-Event dataset, EvMetro5K, containing 5,599 pairs of synchronized RGB-Event samples, split into 4,479 training and 1,120 testing samples. Extensive experiments on EvMetro5K and other widely used benchmarks demonstrate the effectiveness of our approach for KMR. Both the dataset and source code will be released on this https URL Comments: Accepted by IEEE Transactions on Cognitive and Developmental Systems (IEEE TCDS) 2026 Subjects: Computer Vision and Pattern Recognition (cs.CV) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.22026 [cs.CV] (or arXiv:2602.22026v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.22026 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Xiao Wang [ view email ] [v1] Wed, 25 Feb 2026 15:34:15 UTC (20,975 KB) Full-text links: Access Paper: View a PDF of the paper titled RGB-Event HyperGraph Prompt for Kilometer Marker Recognition based on Pre-trained Foundation Models, by Xiaoyu Xian and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-52">27. Capacity drop accounting for microscopic vehicle interaction effects: analytical model and validation with high-resolution trajectories</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22019v1</li>
<li>来源：arxiv</li>
<li>摘要：Capacity drop is a traffic phenomenon in which the discharge flow from a queue is lower than the theoretical infrastructure capacity. This paper proposes a generic analytical method to estimate the queue discharge flow of freeway traffic. Capacity drop is primarily attributed to hesitant vehicles, defined as vehicles that stochastically and temporarily enter an acceleration delay state and generate voids (i.e., extra gaps) in front of them. The proposed method estimates the expected total void length generated by all hesitant vehicles, based on the distributions of their spatial and temporal locations as well as the associated delays. It also accounts for interactions between the waves triggered by downstream hesitant vehicles and the voids generated by upstream ones. Our analysis reveals that this interaction is the key mechanism behind the differing extents of capacity drop observed between standing queues and jam waves in previous studies. The accuracy of the model is validated through both numerical simulations and real-world trajectories. Overall, the proposed method offers a deeper understanding of capacity drop, which can be leveraged in traffic flow modeling and control.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">capacity drop 是由于排队车辆的排放流量低于理论基础设施容量的现象，主要由犹豫车辆引起。这些犹豫车辆暂时进入加速延迟状态并产生额外的空隙。模型通过估计所有犹豫车辆生成的预期总空隙长度，基于它们的空间和时间分布以及相关的延迟，来量化这一现象。此外，模型还考虑了由下游犹豫车辆触发的波与上游生成的空隙之间的相互作用，这种相互作用是导致排队和阻塞波之间容量下降程度不同的关键机制。模型通过数值模拟和高分辨率轨迹数据进行了验证，从而提供了对容量下降的更深入理解，有助于交通流量建模和控制。因此，这一模型不仅揭示了容量下降的原因，还为改善交通管理提供了理论基础。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>capacity drop 是由于排队车辆的排放流量低于理论基础设施容量的现象。</li>
<li>capacity drop 主要由犹豫车辆引起，这些车辆会暂时进入加速延迟状态并产生额外的空隙。</li>
<li>模型估计所有犹豫车辆生成的预期总空隙长度，基于它们的空间和时间分布以及相关的延迟。</li>
<li>模型还考虑了由下游犹豫车辆触发的波与上游生成的空隙之间的相互作用。</li>
<li>这种相互作用是导致排队和阻塞波之间容量下降程度不同的关键机制。</li>
<li>模型通过数值模拟和高分辨率轨迹数据进行了验证。</li>
<li>模型提供了对容量下降的更深入理解，有助于交通流量建模和控制。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-53">正文（抓取，非 AI）</h3>
<p>[2602.22019v1] Capacity drop accounting for microscopic vehicle interaction effects: analytical model and validation with high-resolution trajectories Physics &gt; Physics and Society arXiv:2602.22019v1 (physics) [Submitted on 25 Feb 2026] Title: Capacity drop accounting for microscopic vehicle interaction effects: analytical model and validation with high-resolution trajectories Authors: Yu Han , Pan Liu , Zhiyuan Liu , Ludovic Leclercq View a PDF of the paper titled Capacity drop accounting for microscopic vehicle interaction effects: analytical model and validation with high-resolution trajectories, by Yu Han and 3 other authors View PDF HTML (experimental) Abstract: Capacity drop is a traffic phenomenon in which the discharge flow from a queue is lower than the theoretical infrastructure capacity. This paper proposes a generic analytical method to estimate the queue discharge flow of freeway traffic. Capacity drop is primarily attributed to hesitant vehicles, defined as vehicles that stochastically and temporarily enter an acceleration delay state and generate voids (i.e., extra gaps) in front of them. The proposed method estimates the expected total void length generated by all hesitant vehicles, based on the distributions of their spatial and temporal locations as well as the associated delays. It also accounts for interactions between the waves triggered by downstream hesitant vehicles and the voids generated by upstream ones. Our analysis reveals that this interaction is the key mechanism behind the differing extents of capacity drop observed between standing queues and jam waves in previous studies. The accuracy of the model is validated through both numerical simulations and real-world trajectories. Overall, the proposed method offers a deeper understanding of capacity drop, which can be leveraged in traffic flow modeling and control. Subjects: Physics and Society (physics.soc-ph) Cite as: arXiv:2602.22019 [physics.soc-ph] (or arXiv:2602.22019v1 [physics.soc-ph] for this version) https://doi.org/10.48550/arXiv.2602.22019 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Yu Han [ view email ] [v1] Wed, 25 Feb 2026 15:31:42 UTC (10,829 KB) Full-text links: Access Paper: View a PDF of the paper titled Capacity drop accounting for microscopic vehicle interaction effects: analytical model and validation with high-resolution trajectories, by Yu Han and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: physics.soc-ph &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: physics References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-54">28. RT-RMOT: A Dataset and Framework for RGB-Thermal Referring Multi-Object Tracking</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22033v1</li>
<li>来源：arxiv</li>
<li>摘要：Referring Multi-Object Tracking has attracted increasing attention due to its human-friendly interactive characteristics, yet it exhibits limitations in low-visibility conditions, such as nighttime, smoke, and other challenging scenarios. To overcome this limitation, we propose a new RGB-Thermal RMOT task, named RT-RMOT, which aims to fuse RGB appearance features with the illumination robustness of the thermal modality to enable all-day referring multi-object tracking. To promote research on RT-RMOT, we construct the first Referring Multi-Object Tracking dataset under RGB-Thermal modality, named RefRT. It contains 388 language descriptions, 1,250 tracked targets, and 166,147 Language-RGB-Thermal (L-RGB-T) triplets. Furthermore, we propose RTrack, a framework built upon a multimodal large language model (MLLM) that integrates RGB, thermal, and textual features. Since the initial framework still leaves room for improvement, we introduce a Group Sequence Policy Optimization (GSPO) strategy to further exploit the model's potential. To alleviate training instability during RL fine-tuning, we introduce a Clipped Advantage Scaling (CAS) strategy to suppress gradient explosion. In addition</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">RT-RMOT 任务旨在解决低能见度条件下的多目标跟踪问题，特别是在夜间或烟雾等复杂环境下的跟踪挑战。为应对这一难题，研究人员开发了RefRT数据集，这是首个结合RGB和热成像数据的多目标跟踪数据集，为该领域的研究提供了重要基础。随后，RTrack框架利用多模态大型语言模型整合RGB、热成像和文本特征，进一步提升了模型的性能。为了进一步挖掘模型潜力，GSPO（分组序列策略优化）和CAS（裁剪优势缩放抑制梯度爆炸）策略被引入，通过分组序列策略优化进一步挖掘模型潜力，而CAS策略则通过裁剪优势缩放抑制梯度爆炸，从而提升了模型的稳定性。此外，结构输出奖励和综合检测奖励的平衡设计有助于在探索与利用之间取得最佳平衡。实验证明，RTrack框架在RefRT数据集上的表现优异，证明了其在低能见度条件下的多目标跟踪中的有效性。因此，RT-RMOT任务不仅有助于提升夜间、烟雾等低能见度条件下的多目标跟踪能力，还为相关研究提供了重要的理论和技术支持。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>RT-RMOT 任务旨在解决低能见度条件下的多目标跟踪问题。</li>
<li>RefRT 数据集是首个结合 RGB 和热成像数据的多目标跟踪数据集。</li>
<li>RTrack 框架利用多模态大型语言模型整合 RGB、热成像和文本特征。</li>
<li>GSPO 策略通过分组序列策略优化进一步挖掘模型潜力。</li>
<li>CAS 策略通过裁剪优势缩放抑制梯度爆炸。</li>
<li>结构输出奖励和综合检测奖励平衡探索与利用。</li>
<li>RefRT 数据集上的实验证明了 RTrack 框架的有效性。</li>
<li>RT-RMOT 任务有助于夜间、烟雾等低能见度条件下的多目标跟踪。</li>
<li>初始框架仍需改进，GSPO 和 CAS 策略有助于提升性能。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-55">正文（抓取，非 AI）</h3>
<p>[2602.22033v1] RT-RMOT: A Dataset and Framework for RGB-Thermal Referring Multi-Object Tracking Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.22033v1 (cs) [Submitted on 25 Feb 2026] Title: RT-RMOT: A Dataset and Framework for RGB-Thermal Referring Multi-Object Tracking Authors: Yanqiu Yu , Zhifan Jin , Sijia Chen , Tongfei Chu , En Yu , Liman Liu , Wenbing Tao View a PDF of the paper titled RT-RMOT: A Dataset and Framework for RGB-Thermal Referring Multi-Object Tracking, by Yanqiu Yu and 6 other authors View PDF HTML (experimental) Abstract: Referring Multi-Object Tracking has attracted increasing attention due to its human-friendly interactive characteristics, yet it exhibits limitations in low-visibility conditions, such as nighttime, smoke, and other challenging scenarios. To overcome this limitation, we propose a new RGB-Thermal RMOT task, named RT-RMOT, which aims to fuse RGB appearance features with the illumination robustness of the thermal modality to enable all-day referring multi-object tracking. To promote research on RT-RMOT, we construct the first Referring Multi-Object Tracking dataset under RGB-Thermal modality, named RefRT. It contains 388 language descriptions, 1,250 tracked targets, and 166,147 Language-RGB-Thermal (L-RGB-T) triplets. Furthermore, we propose RTrack, a framework built upon a multimodal large language model (MLLM) that integrates RGB, thermal, and textual features. Since the initial framework still leaves room for improvement, we introduce a Group Sequence Policy Optimization (GSPO) strategy to further exploit the model's potential. To alleviate training instability during RL fine-tuning, we introduce a Clipped Advantage Scaling (CAS) strategy to suppress gradient explosion. In addition, we design Structured Output Reward and Comprehensive Detection Reward to balance exploration and exploitation, thereby improving the completeness and accuracy of target perception. Extensive experiments on the RefRT dataset demonstrate the effectiveness of the proposed RTrack framework. Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.22033 [cs.CV] (or arXiv:2602.22033v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.22033 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Yanqiu Yu [ view email ] [v1] Wed, 25 Feb 2026 15:41:31 UTC (17,393 KB) Full-text links: Access Paper: View a PDF of the paper titled RT-RMOT: A Dataset and Framework for RGB-Thermal Referring Multi-Object Tracking, by Yanqiu Yu and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-56">29. Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22021v1</li>
<li>来源：arxiv</li>
<li>摘要：Estimating heterogeneous treatment effects is central to data-driven decision-making, yet industrial applications often face a fundamental tension between limited randomized controlled trial (RCT) budgets and abundant but biased observational data collected under historical targeting policies. Although observational logs offer the advantage of scale, they inherently suffer from severe policyinduced imbalance and overlap violations, rendering standalone estimation unreliable. We propose a budgeted active experimentation framework that iteratively enhances model training for causal effect estimation via active sampling. By leveraging observational priors, we develop an acquisition function targeting uplift estimation uncertainty, overlap deficits, and domain discrepancy to select the most informative units for randomized experiments. We establish finite-sample deviation bounds, asymptotic normality via martingale Central Limit Theorems (CLTs), and minimax lower bounds to prove information-theoretic optimality. Extensive experiments on industrial datasets demonstrate that our approach significantly outperforms standard randomized baselines in cost-constrained settings.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">观测数据常常因政策影响而出现不平衡和重叠违反的问题，这使得因果效应估计变得困难。为解决这一问题，通过主动采样可以逐步增强模型训练，从而提高因果效应估计的准确性。具体而言，获取函数旨在减少提升估计的不确定性、重叠缺陷以及领域差异。此外，有限样本偏差界和渐近正态性被建立起来，以证明该方法在信息论上的最优性。同时，最小最大下界也展示了该方法在信息论上的最优性。在工业实验中，该方法在成本受限的环境中显著优于标准随机化基准，显示出其优越性。因此，通过主动采样和优化获取函数，可以有效克服观测数据中的问题，并在实际应用中取得显著效果。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>observational data often suffer from policy-induced imbalance and overlap violations。</li>
<li>active sampling helps iteratively enhance model training for causal effect estimation。</li>
<li>acquisition function targets uplift estimation uncertainty, overlap deficits, and domain discrepancy。</li>
<li>finite-sample deviation bounds and asymptotic normality are established to prove information-theoretic optimality。</li>
<li>minimax lower bounds demonstrate the approach's optimality in information theory。</li>
<li>industrial experiments show significant outperformance over standard randomized baselines in cost-constrained settings。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-57">正文（抓取，非 AI）</h3>
<p>[2602.22021v1] Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data Statistics &gt; Methodology arXiv:2602.22021v1 (stat) [Submitted on 25 Feb 2026] Title: Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data Authors: Jiacan Gao , Xinyan Su , Mingyuan Ma , Yiyan Huang , Xiao Xu , Xinrui Wan , Tianqi Gu , Enyun Yu , Jiecheng Guo , Zhiheng Zhang View a PDF of the paper titled Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data, by Jiacan Gao and Xinyan Su and Mingyuan Ma and Yiyan Huang and Xiao Xu and Xinrui Wan and Tianqi Gu and Enyun Yu and Jiecheng Guo and Zhiheng Zhang View PDF HTML (experimental) Abstract: Estimating heterogeneous treatment effects is central to data-driven decision-making, yet industrial applications often face a fundamental tension between limited randomized controlled trial (RCT) budgets and abundant but biased observational data collected under historical targeting policies. Although observational logs offer the advantage of scale, they inherently suffer from severe policyinduced imbalance and overlap violations, rendering standalone estimation unreliable. We propose a budgeted active experimentation framework that iteratively enhances model training for causal effect estimation via active sampling. By leveraging observational priors, we develop an acquisition function targeting uplift estimation uncertainty, overlap deficits, and domain discrepancy to select the most informative units for randomized experiments. We establish finite-sample deviation bounds, asymptotic normality via martingale Central Limit Theorems (CLTs), and minimax lower bounds to prove information-theoretic optimality. Extensive experiments on industrial datasets demonstrate that our approach significantly outperforms standard randomized baselines in cost-constrained settings. Subjects: Methodology (stat.ME) Cite as: arXiv:2602.22021 [stat.ME] (or arXiv:2602.22021v1 [stat.ME] for this version) https://doi.org/10.48550/arXiv.2602.22021 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Zhiheng Zhang [ view email ] [v1] Wed, 25 Feb 2026 15:32:38 UTC (131 KB) Full-text links: Access Paper: View a PDF of the paper titled Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data, by Jiacan Gao and Xinyan Su and Mingyuan Ma and Yiyan Huang and Xiao Xu and Xinrui Wan and Tianqi Gu and Enyun Yu and Jiecheng Guo and Zhiheng Zhang View PDF HTML (experimental) TeX Source view license Current browse context: stat.ME &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: stat References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-58">30. Disease Progression and Subtype Modeling for Combined Discrete and Continuous Input Data</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22018v1</li>
<li>来源：arxiv</li>
<li>摘要：Disease progression modeling provides a robust framework to identify long-term disease trajectories from short-term biomarker data. It is a valuable tool to gain a deeper understanding of diseases with a long disease trajectory, such as Alzheimer's disease. A key limitation of most disease progression models is that they are specific to a single data type (e.g., continuous data), thereby limiting their applicability to heterogeneous, real-world datasets. To address this limitation, we propose the Mixed Events model, a novel disease progression model that handles both discrete and continuous data types. This model is implemented within the Subtype and Stage Inference (SuStaIn) framework, resulting in Mixed-SuStaIn, enabling subtype and progression modeling. We demonstrate the effectiveness of Mixed-SuStaIn through simulation experiments and real-world data from the Alzheimer's Disease Neuroimaging Initiative, showing that it performs well on mixed datasets. The code is available at: https://github.com/ucl-pond/pySuStaIn.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">大多数疾病进展模型仅适用于单一数据类型，这限制了它们在异质数据集上的应用。相比之下，混合事件模型能够同时处理离散和连续数据，从而提供更全面的分析。为了克服单一数据类型的限制，研究者开发了混合-SuStaIn模型，该模型在模拟实验和真实数据上表现良好。因此，混合-SuStaIn模型能够更准确地模拟疾病进展，提高模型的适用性和可靠性。此外，相关代码可以在指定的GitHub链接处获得，为研究人员提供了便利。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>大多数疾病进展模型仅适用于单一数据类型。</li>
<li>混合事件模型能够处理离散和连续数据。</li>
<li>单一数据类型限制了模型在异质数据集上的应用。</li>
<li>混合-SuStaIn模型在模拟实验和真实数据上表现良好。</li>
<li>代码可以在指定的GitHub链接处获得。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-59">正文（抓取，非 AI）</h3>
<p>[2602.22018v1] Disease Progression and Subtype Modeling for Combined Discrete and Continuous Input Data Computer Science &gt; Machine Learning arXiv:2602.22018v1 (cs) [Submitted on 25 Feb 2026] Title: Disease Progression and Subtype Modeling for Combined Discrete and Continuous Input Data Authors: Sterre de Jonge (1), Elisabeth J. Vinke (1,2), Meike W. Vernooij (1,2), Daniel C. Alexander (3), Alexandra L. Young (3), Esther E. Bron (1) ((1) Department of Radiology and Nuclear Medicine, Erasmus MC, Rotterdam, The Netherlands, (2) Department of Epidemiology, Erasmus MC, Rotterdam, The Netherlands, (3) Hawkes Institute, Department of Computer Science, University College London, London, United Kingdom) View a PDF of the paper titled Disease Progression and Subtype Modeling for Combined Discrete and Continuous Input Data, by Sterre de Jonge (1) and 18 other authors View PDF HTML (experimental) Abstract: Disease progression modeling provides a robust framework to identify long-term disease trajectories from short-term biomarker data. It is a valuable tool to gain a deeper understanding of diseases with a long disease trajectory, such as Alzheimer's disease. A key limitation of most disease progression models is that they are specific to a single data type (e.g., continuous data), thereby limiting their applicability to heterogeneous, real-world datasets. To address this limitation, we propose the Mixed Events model, a novel disease progression model that handles both discrete and continuous data types. This model is implemented within the Subtype and Stage Inference (SuStaIn) framework, resulting in Mixed-SuStaIn, enabling subtype and progression modeling. We demonstrate the effectiveness of Mixed-SuStaIn through simulation experiments and real-world data from the Alzheimer's Disease Neuroimaging Initiative, showing that it performs well on mixed datasets. The code is available at: this https URL . Comments: Accepted for publication, 2026 IEEE 23rd International Symposium on Biomedical Imaging (ISBI), April 2026, London, United Kingdom Subjects: Machine Learning (cs.LG) Cite as: arXiv:2602.22018 [cs.LG] (or arXiv:2602.22018v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.22018 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Sterre De Jonge [ view email ] [v1] Wed, 25 Feb 2026 15:31:30 UTC (447 KB) Full-text links: Access Paper: View a PDF of the paper titled Disease Progression and Subtype Modeling for Combined Discrete and Continuous Input Data, by Sterre de Jonge (1) and 18 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-60">31. Design-based theory for causal inference from adaptive experiments</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.21998v1</li>
<li>来源：arxiv</li>
<li>摘要：Adaptive designs dynamically update treatment probabilities using information accumulated during the experiment. Existing theory for causal inference from adaptive experiments primarily assumes the superpopulation framework with independent and identically distributed units, and may not apply when the distribution of units evolves over time. This paper makes two contributions. First, we extend the literature to the finite-population framework, which allows for possibly nonexchangeable units, and establish the design-based theory for causal inference under general adaptive designs using inverse-propensity-weighted (IPW) and augmented IPW (AIPW) estimators. Our theory accommodates nonexchangeable units, both nonconverging and vanishing treatment probabilities, and nonconverging outcome estimators, thereby justifying inference using AIPW estimators with black-box outcome models that integrate advances from machine learning methods. To alleviate the conservativeness inherent in variance estimation under finite-population inference, we also introduce a covariance estimator for the AIPW estimator that becomes sharp when the residuals from the adaptive regression of potential outcomes on </li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">superpopulation框架假设独立且同分布的单位，但这一假设可能不适用于单位分布随时间变化的情况。相比之下，finite-population框架允许非交换性单位，扩展了因果推断的理论。非交换性单位的存在需要特别考虑，可能具有非收敛的治疗概率和结果估计器。vanishing治疗概率和非收敛结果估计器可以被理论所涵盖，因此AIPW（逆概率加权）估计器可以用于黑盒结果模型，整合机器学习进展。此外，保守性在有限人口推断中的方差估计中存在，可以通过引入协方差估计器来缓解。因此，残差的适应性回归可以提供有效的推断。多臂 bandits、协变量适应性随机化和序列重随机化等广泛使用的适应性设计被涵盖，同时非适应性设计也可以通过适应性协变量调整方法进行分析。标准非适应性分析下的强假设可以被适应性调整的马尔可夫结构所替代，从而提供更灵活和稳健的推断方法。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>superpopulation framework假设独立且同分布的单位，可能不适用于单位分布随时间变化的情况。</li>
<li>finite-population框架允许非交换性单位，扩展了因果推断的理论。</li>
<li>nonexchangeable units的存在需要考虑，可能具有非收敛的治疗概率和结果估计器。</li>
<li>vanishing治疗概率和非收敛结果估计器可以被理论所涵盖。</li>
<li>AIPW估计器可以用于黑盒结果模型，整合机器学习进展。</li>
<li>保守性在有限人口推断中的方差估计中存在，可以通过引入协方差估计器来缓解。</li>
<li>残差的适应性回归可以提供有效的推断。</li>
<li>多臂 bandits、协变量适应性随机化和序列重随机化等广泛使用的适应性设计被涵盖。</li>
<li>非适应性设计也可以通过适应性协变量调整方法进行分析。</li>
<li>标准非适应性分析下的强假设可以被适应性调整的马尔可夫结构所替代。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-61">正文（抓取，非 AI）</h3>
<p>[2602.21998v1] Design-based theory for causal inference from adaptive experiments Statistics &gt; Methodology arXiv:2602.21998v1 (stat) [Submitted on 25 Feb 2026] Title: Design-based theory for causal inference from adaptive experiments Authors: Xinran Li , Anqi Zhao View a PDF of the paper titled Design-based theory for causal inference from adaptive experiments, by Xinran Li and 1 other authors View PDF HTML (experimental) Abstract: Adaptive designs dynamically update treatment probabilities using information accumulated during the experiment. Existing theory for causal inference from adaptive experiments primarily assumes the superpopulation framework with independent and identically distributed units, and may not apply when the distribution of units evolves over time. This paper makes two contributions. First, we extend the literature to the finite-population framework, which allows for possibly nonexchangeable units, and establish the design-based theory for causal inference under general adaptive designs using inverse-propensity-weighted (IPW) and augmented IPW (AIPW) estimators. Our theory accommodates nonexchangeable units, both nonconverging and vanishing treatment probabilities, and nonconverging outcome estimators, thereby justifying inference using AIPW estimators with black-box outcome models that integrate advances from machine learning methods. To alleviate the conservativeness inherent in variance estimation under finite-population inference, we also introduce a covariance estimator for the AIPW estimator that becomes sharp when the residuals from the adaptive regression of potential outcomes on covariates are additive across units. Our framework encompasses widely used adaptive designs, such as multi-armed bandits, covariate-adaptive randomization, and sequential rerandomization, advancing the design-based theory for causal inference in these specific settings. Second, as a methodological contribution, we propose an adaptive covariate adjustment approach for analyzing even nonadaptive designs. The martingale structure induced by adaptive adjustment enables valid inference with black-box outcome estimators that would otherwise require strong assumptions under standard nonadaptive analysis. Subjects: Methodology (stat.ME) Cite as: arXiv:2602.21998 [stat.ME] (or arXiv:2602.21998v1 [stat.ME] for this version) https://doi.org/10.48550/arXiv.2602.21998 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Anqi Zhao [ view email ] [v1] Wed, 25 Feb 2026 15:17:21 UTC (164 KB) Full-text links: Access Paper: View a PDF of the paper titled Design-based theory for causal inference from adaptive experiments, by Xinran Li and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: stat.ME &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: stat References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-62">32. PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.21992v1</li>
<li>来源：arxiv</li>
<li>摘要：360 panoramic images are increasingly used in virtual reality, autonomous driving, and robotics for holistic scene understanding. However, current Vision-Language Models (VLMs) struggle with 3D spatial reasoning on Equirectangular Projection (ERP) images due to geometric distortion and limited 3D supervision. We introduce PanoEnv, a large-scale VQA benchmark built from synthetic 3D environments, containing 14.8K questions across five categories (e.g., relative position, volume comparison) grounded in accurate 3D annotations including depth, segmentation, and bounding boxes. Benchmarking 14 state-of-the-art VLMs reveals limited 3D understanding, achieving only 49.34% overall accuracy and 8.36% on open-ended (OE) questions. To enhance 3D reasoning, we propose a reinforcement learning post-training framework based on Group Relative Policy Optimization (GRPO) with a ground-truth-guided reward that incorporates five geometry-aware strategies such as distance tolerance and spatial consistency. A two-stage curriculum further mitigates catastrophic forgetting: Stage 1 trains on structured tasks (true/false and multiple choice), and Stage 2 fine-tunes on mixed open-ended data to improve gen</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">VLMs难以处理Equirectangular Projection（ERP）图像的3D空间推理，主要因为几何失真和有限的3D监督。当前的VLMs在ERP图像上的3D空间推理表现有限，这进一步证实了它们在3D理解上的局限性。为了解决这一问题，研究者提出了GRPO框架，该框架结合了五个几何感知策略来增强3D推理能力。此外，两阶段课程进一步缓解了灾难性遗忘的问题，使得模型能够更好地学习和适应。通过PanoEnv-QA和基于课程的强化学习（RL）框架，VLMs的3D空间智能得到了显著提升。具体而言，B模型在总体准确性和开放性问题上的准确率分别提高了3.59%和4.49%。尽管取得了显著进步，但B模型在开放性问题上的准确率仍仅为8.36%，这表明在提升VLMs的3D空间智能方面仍有进一步的空间。因此，该研究展示了PanoEnv-QA和基于课程的RL框架的有效性，为未来的研究提供了重要参考。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>VLMs难以处理Equirectangular Projection图像的3D空间推理。</li>
<li>几何失真和有限的3D监督导致当前VLMs在ERP图像上的3D空间推理困难。</li>
<li>PanoEnv是一个大规模的VQA基准，包含14.8K个问题，覆盖五个类别。</li>
<li>基准测试显示，当前的VLMs在3D理解上的表现有限。</li>
<li>提出的GRPO框架结合了五个几何感知策略来增强3D推理。</li>
<li>两阶段课程进一步缓解了灾难性遗忘的问题。</li>
<li>PanoEnv-QA和基于课程的RL框架有效提升了VLMs的3D空间智能。</li>
<li>B模型在总体准确性和开放性问题上的准确率分别提高了3.59%和4.49%。</li>
<li>该研究展示了PanoEnv-QA和基于课程的RL框架的有效性。</li>
<li>B模型在开放性问题上的准确率仅为8.36%。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-63">正文（抓取，非 AI）</h3>
<p>[2602.21992v1] PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.21992v1 (cs) [Submitted on 25 Feb 2026] Title: PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning Authors: Zekai Lin , Xu Zheng View a PDF of the paper titled PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning, by Zekai Lin and 1 other authors View PDF HTML (experimental) Abstract: 360 panoramic images are increasingly used in virtual reality, autonomous driving, and robotics for holistic scene understanding. However, current Vision-Language Models (VLMs) struggle with 3D spatial reasoning on Equirectangular Projection (ERP) images due to geometric distortion and limited 3D supervision. We introduce PanoEnv, a large-scale VQA benchmark built from synthetic 3D environments, containing 14.8K questions across five categories (e.g., relative position, volume comparison) grounded in accurate 3D annotations including depth, segmentation, and bounding boxes. Benchmarking 14 state-of-the-art VLMs reveals limited 3D understanding, achieving only 49.34% overall accuracy and 8.36% on open-ended (OE) questions. To enhance 3D reasoning, we propose a reinforcement learning post-training framework based on Group Relative Policy Optimization (GRPO) with a ground-truth-guided reward that incorporates five geometry-aware strategies such as distance tolerance and spatial consistency. A two-stage curriculum further mitigates catastrophic forgetting: Stage 1 trains on structured tasks (true/false and multiple choice), and Stage 2 fine-tunes on mixed open-ended data to improve generalization. Our 7B model achieves new state-of-the-art performance, improving overall accuracy to 52.93% (+3.59%) and open-ended accuracy to 14.83% while maintaining structured-task performance. It also achieves top semantic evaluation scores (Q-Score 6.24, P-Score 5.95), surpassing 32B models. These results demonstrate that PanoEnv-QA and our curriculum-based RL framework effectively instill 3D spatial intelligence in VLMs for omnidirectional perception. Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.21992 [cs.CV] (or arXiv:2602.21992v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.21992 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Xu Zheng [ view email ] [v1] Wed, 25 Feb 2026 15:12:17 UTC (21,422 KB) Full-text links: Access Paper: View a PDF of the paper titled PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning, by Zekai Lin and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-64">33. RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22013v1</li>
<li>来源：arxiv</li>
<li>摘要：Vision-based Retrieval-Augmented Generation (VisRAG) leverages vision-language models (VLMs) to jointly retrieve relevant visual documents and generate grounded answers based on multimodal evidence. However, existing VisRAG models degrade in performance when visual inputs suffer from distortions such as blur, noise, low light, or shadow, where semantic and degradation factors become entangled within pretrained visual encoders, leading to errors in both retrieval and generation stages. To address this limitation, we introduce RobustVisRAG, a causality-guided dual-path framework that improves VisRAG robustness while preserving efficiency and zero-shot generalization. RobustVisRAG uses a non-causal path to capture degradation signals through unidirectional attention and a causal path to learn purified semantics guided by these signals. Together with the proposed Non-Causal Distortion Modeling and Causal Semantic Alignment objectives, the framework enforces a clear separation between semantics and degradations, enabling stable retrieval and generation under challenging visual conditions. To evaluate robustness under realistic conditions, we introduce the Distortion-VisRAG dataset, a la</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">视觉输入的退化会导致语义和退化因素在预训练视觉编码器中交织，从而影响检索和生成的准确性。为了解决这一问题，研究引入了两种路径：非因果路径通过单向注意力捕捉退化信号，而因果路径则在这些信号的引导下学习纯净的语义。为了确保语义和退化之间的清晰分离，研究设定了非因果退化建模和因果语义对齐的目标。为此，研究团队构建了Distortion-VisRAG数据集，该数据集包含合成和真实世界退化文档，用于评估VisRAG在现实条件下的鲁棒性。实验结果显示，RobustVisRAG在真实世界退化上的检索、生成和端到端性能分别提高了7.35%、6.35%和12.40%，而在干净输入上的准确性与现有模型相当。因此，RobustVisRAG不仅在退化条件下表现出色，还能保持与现有模型相当的性能。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>视觉输入的退化会导致语义和退化因素在预训练视觉编码器中交织，从而影响检索和生成的准确性。</li>
<li>非因果路径通过单向注意力捕捉退化信号，而因果路径则在这些信号的引导下学习纯净的语义。</li>
<li>非因果退化建模和因果语义对齐目标确保语义和退化之间的清晰分离。</li>
<li>Distortion-VisRAG数据集包含合成和真实世界退化文档，用于评估VisRAG在现实条件下的鲁棒性。</li>
<li>RobustVisRAG在真实世界退化上的检索、生成和端到端性能分别提高了7.35%、6.35%和12.40%。</li>
<li>RobustVisRAG在干净输入上的准确性与现有模型相当。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-65">正文（抓取，非 AI）</h3>
<p>[2602.22013v1] RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.22013v1 (cs) [Submitted on 25 Feb 2026] Title: RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations Authors: I-Hsiang Chen , Yu-Wei Liu , Tse-Yu Wu , Yu-Chien Chiang , Jen-Chien Yang , Wei-Ting Chen View a PDF of the paper titled RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations, by I-Hsiang Chen and 4 other authors View PDF HTML (experimental) Abstract: Vision-based Retrieval-Augmented Generation (VisRAG) leverages vision-language models (VLMs) to jointly retrieve relevant visual documents and generate grounded answers based on multimodal evidence. However, existing VisRAG models degrade in performance when visual inputs suffer from distortions such as blur, noise, low light, or shadow, where semantic and degradation factors become entangled within pretrained visual encoders, leading to errors in both retrieval and generation stages. To address this limitation, we introduce RobustVisRAG, a causality-guided dual-path framework that improves VisRAG robustness while preserving efficiency and zero-shot generalization. RobustVisRAG uses a non-causal path to capture degradation signals through unidirectional attention and a causal path to learn purified semantics guided by these signals. Together with the proposed Non-Causal Distortion Modeling and Causal Semantic Alignment objectives, the framework enforces a clear separation between semantics and degradations, enabling stable retrieval and generation under challenging visual conditions. To evaluate robustness under realistic conditions, we introduce the Distortion-VisRAG dataset, a large-scale benchmark containing both synthetic and real-world degraded documents across seven domains, with 12 synthetic and 5 real distortion types that comprehensively reflect practical visual degradations. Experimental results show that RobustVisRAG improves retrieval, generation, and end-to-end performance by 7.35%, 6.35%, and 12.40%, respectively, on real-world degradations, while maintaining comparable accuracy on clean inputs. Comments: Accepted by CVPR2026; Project Page: this https URL Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.22013 [cs.CV] (or arXiv:2602.22013v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.22013 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: I-Hsiang Chen [ view email ] [v1] Wed, 25 Feb 2026 15:27:57 UTC (3,474 KB) Full-text links: Access Paper: View a PDF of the paper titled RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations, by I-Hsiang Chen and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-66">34. Parallel Continuous-Time Relative Localization with Augmented Clamped Non-Uniform B-Splines</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22006v1</li>
<li>来源：arxiv</li>
<li>摘要：Accurate relative localization is critical for multi-robot cooperation. In robot swarms, measurements from different robots arrive asynchronously and with clock time-offsets. Although Continuous-Time (CT) formulations have proved effective for handling asynchronous measurements in single-robot SLAM and calibration, extending CT methods to multi-robot settings faces great challenges to achieve high-accuracy, low-latency, and high-frequency performance. Especially, existing CT methods suffer from the inherent query-time delay of unclamped B-splines and high computational cost. This paper proposes CT-RIO, a novel Continuous-Time Relative-Inertial Odometry framework. We employ Clamped Non-Uniform B-splines (C-NUBS) to represent robot states for the first time, eliminating the query-time delay. We further augment C-NUBS with closed-form extension and shrinkage operations that preserve the spline shape, making it suitable for online estimation and enabling flexible knot management. This flexibility leads to the concept of knot-keyknot strategy, which supports spline extension at high-frequency while retaining sparse keyknots for adaptive relative-motion modeling. We then formulate a slid</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">CT方法在单机器人SLAM和校准中表现出色，但在多机器人设置中则面临挑战。为了解决这一问题，引入了C-NUBS技术，它显著消除了查询时间延迟，并确保了样条形状在扩展和收缩操作中的保持。为了支持高频样条扩展同时保留稀疏关键节点，采用了一种称为Knot-keyknot的策略。滑动窗口相对定位问题仅依赖于相对运动学和机器人间约束，从而简化了计算过程。CT-RIO在263毫秒的时间偏移下3秒内收敛到亚毫秒级，并且其RMSE为0.046米和1.8度。在高速度运动下，CT-RIO比现有最佳方法提高多达60%，并通过并行解决机器人子问题来应对大规模计算需求，从而有效提升了性能。因此，CT-RIO不仅在精度上表现出色，还在处理大规模计算需求方面具有显著优势。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>CT方法在单机器人SLAM和校准中有效，但在多机器人设置中面临挑战。</li>
<li>C-NUBS的使用消除了查询时间延迟。</li>
<li>C-NUBS的扩展和收缩操作保持了样条形状。</li>
<li>Knot-keyknot策略支持高频样条扩展同时保留稀疏关键节点。</li>
<li>滑动窗口相对定位问题仅基于相对运动学和机器人间约束。</li>
<li>CT-RIO在263毫秒的时间偏移下3秒内收敛到亚毫秒级。</li>
<li>CT-RIO的RMSE为0.046米和1.8度。</li>
<li>CT-RIO在高速度运动下比现有最佳方法提高多达60%。</li>
<li>CT-RIO通过并行解决机器人子问题来应对大规模计算需求。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-67">正文（抓取，非 AI）</h3>
<p>[2602.22006v1] Parallel Continuous-Time Relative Localization with Augmented Clamped Non-Uniform B-Splines Computer Science &gt; Robotics arXiv:2602.22006v1 (cs) [Submitted on 25 Feb 2026] Title: Parallel Continuous-Time Relative Localization with Augmented Clamped Non-Uniform B-Splines Authors: Jiadong Lu , Zhehan Li , Tao Han , Miao Xu , Chao Xu , Yanjun Cao View a PDF of the paper titled Parallel Continuous-Time Relative Localization with Augmented Clamped Non-Uniform B-Splines, by Jiadong Lu and 5 other authors View PDF HTML (experimental) Abstract: Accurate relative localization is critical for multi-robot cooperation. In robot swarms, measurements from different robots arrive asynchronously and with clock time-offsets. Although Continuous-Time (CT) formulations have proved effective for handling asynchronous measurements in single-robot SLAM and calibration, extending CT methods to multi-robot settings faces great challenges to achieve high-accuracy, low-latency, and high-frequency performance. Especially, existing CT methods suffer from the inherent query-time delay of unclamped B-splines and high computational cost. This paper proposes CT-RIO, a novel Continuous-Time Relative-Inertial Odometry framework. We employ Clamped Non-Uniform B-splines (C-NUBS) to represent robot states for the first time, eliminating the query-time delay. We further augment C-NUBS with closed-form extension and shrinkage operations that preserve the spline shape, making it suitable for online estimation and enabling flexible knot management. This flexibility leads to the concept of knot-keyknot strategy, which supports spline extension at high-frequency while retaining sparse keyknots for adaptive relative-motion modeling. We then formulate a sliding-window relative localization problem that operates purely on relative kinematics and inter-robot constraints. To meet the demanding computation required at swarm scale, we decompose the tightly-coupled optimization into robot-wise sub-problems and solve them in parallel using incremental asynchronous block coordinate descent. Extensive experiments show that CT-RIO converges from time-offsets as large as 263 ms to sub-millisecond within 3 s, and achieves RMSEs of 0.046 m and 1.8 °. It consistently outperforms state-of-the-art methods, with improvements of up to 60% under high-speed motion. Comments: 26 pages, 23 figures Subjects: Robotics (cs.RO) Cite as: arXiv:2602.22006 [cs.RO] (or arXiv:2602.22006v1 [cs.RO] for this version) https://doi.org/10.48550/arXiv.2602.22006 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Zhehan Li [ view email ] [v1] Wed, 25 Feb 2026 15:23:18 UTC (16,082 KB) Full-text links: Access Paper: View a PDF of the paper titled Parallel Continuous-Time Relative Localization with Augmented Clamped Non-Uniform B-Splines, by Jiadong Lu and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.RO &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-68">35. Quantum Resistance in Multilayer Graphene-BiFeO3 Memristor for Brain-Inspired Computing</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.21986v1</li>
<li>来源：arxiv</li>
<li>摘要：In the era of big data and the Internet of Things, quantum-level control of conductance states offers a promising route toward high-density data storage and brain-inspired neuromorphic computing. Although quantum conductance (QC) phenomena have been demonstrated in various metal oxide memristors, achieving reliable and precise control over quantized states remains in its infancy. Here, we demonstrate bidirectional quantum conductance states in multifunctional BiFeO3 (BFO) perovskite memristors integrated with multilayer-graphene contacts, enabling higher-order tunability and revealing the potential of perovskite-2D heterostructures for quantum-engineered memory and computing devices. XPS analysis provides detailed insights into oxygen vacancy dynamics in BFO, whereas first-principles density functional theory calculations clearly reveal a strong localized electric field at the graphene-BFO interface. Our devices exhibit current-controlled higher-order QC transitions facilitated by quantum point contact formation, giving rise to quantized conductance states during both SET and RESET processes. Time-lag correlation maps quantify the stochastic evolution of QC states under dynamic vol</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">QC现象在各种金属氧化物memristor中已被证明，但可靠地控制量子化状态仍处于初级阶段。XPS分析揭示了BFO中的氧空位动态，而第一性原理密度泛函理论计算则揭示了石墨烯-BFO界面处的强局部电场，这些发现共同表明，钙钛矿-2D异质结构可能成为QC驱动的电阻开关的有希望候选者。设备表现出由量子点接触形成的电流控制的高阶QC跃迁，时间滞后相关图量化了动态电压脉冲调谐方案下QC状态的随机演变。因此，量子化的导电状态有效地模拟了突触增强和抑制，这些发现确立了钙钛矿-2D异质结构在开发可控量子memristor方面的潜力。此外，QC状态的精确调控对于高精度图像和数字识别至关重要，这进一步凸显了这一领域的研究价值。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>QC现象在各种金属氧化物 memristor 中已被证明，但可靠地控制量子化状态仍处于初级阶段。</li>
<li>XPS分析揭示了BFO中的氧空位动态。</li>
<li>第一性原理密度泛函理论计算揭示了石墨烯-BFO界面处的强局部电场。</li>
<li>设备表现出由量子点接触形成的电流控制的高阶QC跃迁。</li>
<li>时间滞后相关图量化了动态电压脉冲调谐方案下QC状态的随机演变。</li>
<li>量子化的导电状态有效地模拟了突触增强和抑制。</li>
<li>这些发现确立了钙钛矿-2D异质结构作为QC驱动的电阻开关的有希望候选者。</li>
<li>QC状态的精确调控对于高精度图像和数字识别至关重要。</li>
<li>这些发现展示了钙钛矿-2D异质结构在开发可控量子memristor方面的潜力。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-69">正文（抓取，非 AI）</h3>
<p>[2602.21986v1] Quantum Resistance in Multilayer Graphene-BiFeO3 Memristor for Brain-Inspired Computing Condensed Matter &gt; Mesoscale and Nanoscale Physics arXiv:2602.21986v1 (cond-mat) [Submitted on 25 Feb 2026] Title: Quantum Resistance in Multilayer Graphene-BiFeO3 Memristor for Brain-Inspired Computing Authors: Suman Roy , Priyanka Sahu , Subhabrata Das , Sameer Kumar Mallik , Susmita Jana , Alok Kumar , Himadri Nandan Mohanty , Kaushik Ghosh , B.R.K. Nanda , Satyaprakash Sahoo View a PDF of the paper titled Quantum Resistance in Multilayer Graphene-BiFeO3 Memristor for Brain-Inspired Computing, by Suman Roy and 8 other authors View PDF Abstract: In the era of big data and the Internet of Things, quantum-level control of conductance states offers a promising route toward high-density data storage and brain-inspired neuromorphic computing. Although quantum conductance (QC) phenomena have been demonstrated in various metal oxide memristors, achieving reliable and precise control over quantized states remains in its infancy. Here, we demonstrate bidirectional quantum conductance states in multifunctional BiFeO3 (BFO) perovskite memristors integrated with multilayer-graphene contacts, enabling higher-order tunability and revealing the potential of perovskite-2D heterostructures for quantum-engineered memory and computing devices. XPS analysis provides detailed insights into oxygen vacancy dynamics in BFO, whereas first-principles density functional theory calculations clearly reveal a strong localized electric field at the graphene-BFO interface. Our devices exhibit current-controlled higher-order QC transitions facilitated by quantum point contact formation, giving rise to quantized conductance states during both SET and RESET processes. Time-lag correlation maps quantify the stochastic evolution of QC states under dynamic voltage-pulse tuning schemes. Notably, the quantized conductance states effectively emulate synaptic potentiation and depression, enabling precise weight modulation for high-accuracy image and digit recognition in convolutional neural networks. These findings establish perovskite-2D heterostructures as promising candidates for QC-driven resistive switching and demonstrate their potential for developing controllable quantum memristors. Subjects: Mesoscale and Nanoscale Physics (cond-mat.mes-hall) Cite as: arXiv:2602.21986 [cond-mat.mes-hall] (or arXiv:2602.21986v1 [cond-mat.mes-hall] for this version) https://doi.org/10.48550/arXiv.2602.21986 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Satyaprakash Sahoo [ view email ] [v1] Wed, 25 Feb 2026 15:04:52 UTC (4,963 KB) Full-text links: Access Paper: View a PDF of the paper titled Quantum Resistance in Multilayer Graphene-BiFeO3 Memristor for Brain-Inspired Computing, by Suman Roy and 8 other authors View PDF view license Current browse context: cond-mat.mes-hall &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cond-mat References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-70">36. Discovering new photovoltaics using optimal transport theory</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22036v1</li>
<li>来源：arxiv</li>
<li>摘要：Searching by chemical and structural analogy is one of the most commonly used and successful approaches to materials discovery. However, formulating this task for algorithmic implementation raises the question of how we define similar materials. Methods have been proposed for searching materials space using vectors based on chemical composition and functional fragments in the material. Descriptors for structural similarity have also been proposed. However, the question of how to incorporate and balance structural and compositional similarity measures in a single metric remains open. Here, we adapt methods developed for calculating distances between undirected graphs and apply them to crystalline materials similarity. The Fused Gromov-Wasserstein (FGW) metric uses optimal transport theory to map between two graphs considering a balance of the graph structure and the information present at the nodes of the graph (atoms in crystals). We apply the method to exploring new photovoltaic materials. We demonstrate that FGW is competitive with embeddings from an equivariant graph neural network, trained on $&gt; 10^6$ materials, despite minimal training. We then apply FGW to a discovery campaig</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">化学和结构类比是材料发现中最常用和成功的方法之一，但如何定义相似材料在算法实现中仍是一个挑战。如何平衡结构和组成相似性度量仍然是一个开放的问题。为了解决这一问题，Fused Gromov-Wasserstein (FGW) 元度量利用最优传输理论来平衡图结构和节点信息，这种方法可以与基于大量训练数据的图神经网络嵌入竞争。FGW 方法可以用于识别未被探索为光伏材料但与已知高效率材料相似的材料，并通过混合密度泛函理论进行验证。FGW 方法展示了强大的归纳偏置在材料探索中的作用，即使训练数据很少。例如，Cs$_5$Sb$_8$ 被发现具有预测的 SLME 大于 30% 且热力学稳定。这证明了在材料探索中使用强归纳偏置的有效性。因此，FGW 方法不仅提供了一种有效的方法来识别潜在的高效率材料，还展示了在有限数据条件下进行材料预测的强大能力。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>化学和结构类比是材料发现中最常用和成功的方法之一。</li>
<li>如何定义相似材料在算法实现中是一个挑战。</li>
<li>如何平衡结构和组成相似性度量仍然是一个开放的问题。</li>
<li>Fused Gromov-Wasserstein (FGW) 元度量使用最优传输理论来平衡图结构和节点信息。</li>
<li>FGW 方法可以与基于大量训练数据的图神经网络嵌入竞争。</li>
<li>FGW 方法可以用于识别未被探索为光伏材料但与已知高效率材料相似的材料。</li>
<li>预测结果需要通过混合密度泛函理论进行验证。</li>
<li>FGW 方法展示了强大的归纳偏置在材料探索中的作用，即使训练数据很少。</li>
<li>Cs$_5$Sb$_8$ 被发现具有预测的 SLME 大于 30% 且热力学稳定。</li>
<li>FGW 方法证明了在材料探索中使用强归纳偏置的有效性。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-71">正文（抓取，非 AI）</h3>
<p>[2602.22036v1] Discovering new photovoltaics using optimal transport theory Condensed Matter &gt; Materials Science arXiv:2602.22036v1 (cond-mat) [Submitted on 25 Feb 2026] Title: Discovering new photovoltaics using optimal transport theory Authors: Matthew A. H. Walker , Zibo Zhang , Junayd Ul Islam , Keith T. Butler View a PDF of the paper titled Discovering new photovoltaics using optimal transport theory, by Matthew A. H. Walker and 3 other authors View PDF Abstract: Searching by chemical and structural analogy is one of the most commonly used and successful approaches to materials discovery. However, formulating this task for algorithmic implementation raises the question of how we define similar materials. Methods have been proposed for searching materials space using vectors based on chemical composition and functional fragments in the material. Descriptors for structural similarity have also been proposed. However, the question of how to incorporate and balance structural and compositional similarity measures in a single metric remains open. Here, we adapt methods developed for calculating distances between undirected graphs and apply them to crystalline materials similarity. The Fused Gromov-Wasserstein (FGW) metric uses optimal transport theory to map between two graphs considering a balance of the graph structure and the information present at the nodes of the graph (atoms in crystals). We apply the method to exploring new photovoltaic materials. We demonstrate that FGW is competitive with embeddings from an equivariant graph neural network, trained on $&gt; 10^6$ materials, despite minimal training. We then apply FGW to a discovery campaign to identify materials from the Materials Project database that have not previously been explored as photovoltaics, but have similarities to known high-efficiency materials. After validating predictions with hybrid density functional theory, we identify seven previously unexplored high-efficiency photovoltaic absorber candidates, including Cs$_5$Sb$_8$, which is found to have a predicted SLME of $&gt; 30\%$ and to be thermodynamically stable. The FGW approach demonstrates the power of strong inductive biases for developing metrics for materials exploration with minimal training data. Subjects: Materials Science (cond-mat.mtrl-sci) ; Disordered Systems and Neural Networks (cond-mat.dis-nn) Cite as: arXiv:2602.22036 [cond-mat.mtrl-sci] (or arXiv:2602.22036v1 [cond-mat.mtrl-sci] for this version) https://doi.org/10.48550/arXiv.2602.22036 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Keith Butler [ view email ] [v1] Wed, 25 Feb 2026 15:44:48 UTC (14,569 KB) Full-text links: Access Paper: View a PDF of the paper titled Discovering new photovoltaics using optimal transport theory, by Matthew A. H. Walker and 3 other authors View PDF TeX Source view license Current browse context: cond-mat.mtrl-sci &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cond-mat cond-mat.dis-nn References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-72">37. Quantum criticality in open quantum systems from the purification perspective</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.21979v1</li>
<li>来源：arxiv</li>
<li>摘要：Open quantum systems host mixed-state phases that go beyond the symmetry-protected topological and spontaneous symmetry-breaking paradigms established for closed, pure-state systems. Developing a unified and physically transparent classification of such phases remains a central challenge. In this work, we introduce a purification-based framework that systematically characterizes all mixed-state phases in one-dimensional systems with $\mathbb{Z}<em στ="">2^σ \times \mathbb{Z}_2^τ$ symmetry. By introducing an ancillary $κ$ chain and employing decorated domain-wall constructions, we derive eight purified fixed-point Hamiltonians labeled by topological indices $(μ</em>,μ_{τκ},μ_{κσ}) \in {\pm1}^3$. Tracing out the ancilla recovers the full structure of mixed-state phases, including symmetric, strong-to-weak spontaneous symmetry breaking, average symmetry-protected topological phases, and their nontrivial combinations. Interpolations between the eight fixed points naturally define a three-dimensional phase diagram with a cube geometry. The edges correspond to elementary transitions associated with single topological indices, while the faces host intermediate phases arising from competing domai</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">开放量子系统可以表现出封闭系统中不存在的混合态相，这些相态包括对称相、自发对称破缺相和对称保护拓扑相。然而，对这些混合态相的统一分类仍然具有挑战性。为了解决这一问题，引入了一个辅助的$\kappa$链，通过它可以推导出固定点哈密顿量。这八个固定点哈密顿量通过拓扑指数$(\mu_{\sigma\tau},\mu_{\tau\kappa},\mu_{\kappa\sigma}) \in \{\pm1\}^3$进行标记。通过排除辅助链，可以恢复混合态相的完整结构。固定点之间的插值定义了一个三维相图，相图的棱边对应于单一拓扑指数相关的基本转变，而相图的面则对应于竞争畴壁装饰产生的中间相。沿着棱边的临界行为将不同的强到弱对称破缺模式连接起来。大规模张量网络模拟揭示了丰富的相结构，而净化方法则提供了一个几何上透明且物理上完整的分类。这一模型通过单一的$\mathbb{Z}_2^{\sigma} \times \mathbb{Z}_2^{\tau} \times \mathbb{Z}_2^{\kappa}$框架实现了统一。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>open quantum systems can exhibit mixed-state phases beyond those found in closed systems.</li>
<li>mixed-state phases include symmetric, spontaneous symmetry breaking, and symmetry-protected topological phases.</li>
<li>a unified classification of mixed-state phases remains challenging.</li>
<li>introducing an ancillary $\kappa$ chain helps derive fixed-point Hamiltonians.</li>
<li>eight fixed-point Hamiltonians are labeled by topological indices $(\mu_{\sigma\tau},\mu_{\tau\kappa},\mu_{\kappa\sigma}) \in \{\pm1\}^3$.</li>
<li>tracing out the ancilla recovers the full structure of mixed-state phases.</li>
<li>interpolations between fixed points define a three-dimensional phase diagram.</li>
<li>edges of the cube correspond to elementary transitions associated with single topological indices.</li>
<li>faces host intermediate phases arising from competing domain-wall decorations.</li>
<li>critical behavior along edges connects distinct strong-to-weak symmetry-breaking patterns.</li>
<li>large-scale tensor-network simulations reveal a rich phase structure.</li>
<li>the purification approach provides a geometrically transparent and physically complete classification.</li>
<li>the model is unified with a single $\mathbb{Z}_2^{\sigma} \times \mathbb{Z}_2^{\tau} \times \mathbb{Z}_2^{\kappa}$ framework.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-73">正文（抓取，非 AI）</h3>
<p>[2602.21979v1] Quantum criticality in open quantum systems from the purification perspective Quantum Physics arXiv:2602.21979v1 (quant-ph) [Submitted on 25 Feb 2026] Title: Quantum criticality in open quantum systems from the purification perspective Authors: Yuchen Guo , Shuo Yang View a PDF of the paper titled Quantum criticality in open quantum systems from the purification perspective, by Yuchen Guo and 1 other authors View PDF Abstract: Open quantum systems host mixed-state phases that go beyond the symmetry-protected topological and spontaneous symmetry-breaking paradigms established for closed, pure-state systems. Developing a unified and physically transparent classification of such phases remains a central challenge. In this work, we introduce a purification-based framework that systematically characterizes all mixed-state phases in one-dimensional systems with $\mathbb{Z}<em _sigma_tau="\sigma\tau">2^{\sigma} \times \mathbb{Z}_2^{\tau}$ symmetry. By introducing an ancillary $\kappa$ chain and employing decorated domain-wall constructions, we derive eight purified fixed-point Hamiltonians labeled by topological indices $(\mu</em>,\mu_{\tau\kappa},\mu_{\kappa\sigma}) \in {\pm1}^3$. Tracing out the ancilla recovers the full structure of mixed-state phases, including symmetric, strong-to-weak spontaneous symmetry breaking, average symmetry-protected topological phases, and their nontrivial combinations. Interpolations between the eight fixed points naturally define a three-dimensional phase diagram with a cube geometry. The edges correspond to elementary transitions associated with single topological indices, while the faces host intermediate phases arising from competing domain-wall decorations. Along the edges, we identify a class of critical behavior that connects distinct strong-to-weak symmetry-breaking patterns associated with distinct strong subgroups, highlighting a mechanism unique to mixed-state settings. Large-scale tensor-network simulations reveal a rich phase structure, including pyramid-shaped symmetry-breaking regions and a fully symmetry-broken phase at the cube center. Overall, our purification approach provides a geometrically transparent and physically complete classification of mixed-state phases, unified with a single $\mathbb{Z}_2^{\sigma} \times \mathbb{Z}_2^{\tau} \times \mathbb{Z}_2^{\kappa}$ model. Comments: 24 pages, 10 figures Subjects: Quantum Physics (quant-ph) ; Strongly Correlated Electrons (cond-mat.str-el) Cite as: arXiv:2602.21979 [quant-ph] (or arXiv:2602.21979v1 [quant-ph] for this version) https://doi.org/10.48550/arXiv.2602.21979 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Shuo Yang [ view email ] [v1] Wed, 25 Feb 2026 14:57:44 UTC (1,972 KB) Full-text links: Access Paper: View a PDF of the paper titled Quantum criticality in open quantum systems from the purification perspective, by Yuchen Guo and 1 other authors View PDF TeX Source view license Current browse context: quant-ph &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cond-mat cond-mat.str-el References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-74">38. IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22017v1</li>
<li>来源：arxiv</li>
<li>摘要：As the complexity of the HPC storage stack rapidly grows, domain scientists face increasing challenges in effectively utilizing HPC storage systems to achieve their desired I/O performance. To identify and address I/O issues, scientists largely rely on I/O experts to analyze their I/O traces and provide insights into potential problems. However, with a limited number of I/O experts and the growing demand for data-intensive applications, inaccessibility has become a major bottleneck, hindering scientists from maximizing their productivity. Rapid advances in LLMs make it possible to build an automated tool that brings trustworthy I/O performance diagnosis to domain scientists. However, key challenges remain, such as the inability to handle long context windows, a lack of accurate domain knowledge about HPC I/O, and the generation of hallucinations during complex interactions.In this work, we propose IOAgent as a systematic effort to address these challenges. IOAgent integrates a module-based pre-processor, a RAG-based domain knowledge integrator, and a tree-based merger to accurately diagnose I/O issues from a given Darshan trace file. Similar to an I/O expert, IOAgent provides detai</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">IOAgent 的开发旨在解决I/O专家数量有限的问题，其核心在于需要处理长上下文窗口的能力。准确的HPC I/O领域知识对于IOAgent至关重要，因为这直接关系到其能否生成准确的幻觉。为了支持科学家提出后续问题，IOAgent通过一个交互界面提供详细的诊断依据和参考文献。此外，TraceBench作为第一个公开的诊断测试套件，为IOAgent的性能验证提供了重要工具。值得注意的是，IOAgent的性能并不受限于特定的LLM，这使得它成为科学家的强大工具，帮助他们更好地理解和导航复杂的HPC I/O子系统。因此，IOAgent不仅能够解决专家稀缺的问题，还能通过提供详尽的信息支持科学家进行深入研究。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>IOAgent 的开发旨在解决 I/O 专家数量有限的问题。</li>
<li>IOAgent 需要处理长上下文窗口的能力。</li>
<li>准确的 HPC I/O 领域知识对于 IOAgent 至关重要。</li>
<li>IOAgent 生成幻觉的能力是一个挑战。</li>
<li>IOAgent 提供详细的诊断依据和参考文献。</li>
<li>IOAgent 通过一个交互界面支持科学家提出后续问题。</li>
<li>TraceBench 是第一个公开的诊断测试套件。</li>
<li>IOAgent 的性能不受特定 LLM 的限制。</li>
<li>IOAgent 有望成为科学家的强大工具，帮助他们导航复杂的 HPC I/O 子系统。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-75">正文（抓取，非 AI）</h3>
<p>[2602.22017v1] IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs Computer Science &gt; Distributed, Parallel, and Cluster Computing arXiv:2602.22017v1 (cs) [Submitted on 25 Feb 2026] Title: IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs Authors: Chris Egersdoerfer , Arnav Sareen , Jean Luca Bez , Suren Byna , Dongkuan (DK)Xu, Dong Dai View a PDF of the paper titled IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs, by Chris Egersdoerfer and 5 other authors View PDF HTML (experimental) Abstract: As the complexity of the HPC storage stack rapidly grows, domain scientists face increasing challenges in effectively utilizing HPC storage systems to achieve their desired I/O performance. To identify and address I/O issues, scientists largely rely on I/O experts to analyze their I/O traces and provide insights into potential problems. However, with a limited number of I/O experts and the growing demand for data-intensive applications, inaccessibility has become a major bottleneck, hindering scientists from maximizing their productivity. Rapid advances in LLMs make it possible to build an automated tool that brings trustworthy I/O performance diagnosis to domain scientists. However, key challenges remain, such as the inability to handle long context windows, a lack of accurate domain knowledge about HPC I/O, and the generation of hallucinations during complex this http URL this work, we propose IOAgent as a systematic effort to address these challenges. IOAgent integrates a module-based pre-processor, a RAG-based domain knowledge integrator, and a tree-based merger to accurately diagnose I/O issues from a given Darshan trace file. Similar to an I/O expert, IOAgent provides detailed justifications and references for its diagnoses and offers an interactive interface for scientists to ask targeted follow-up questions. To evaluate IOAgent, we collected a diverse set of labeled job traces and released the first open diagnosis test suite, TraceBench. Using this test suite, we conducted extensive evaluations, demonstrating that IOAgent matches or outperforms state-of-the-art I/O diagnosis tools with accurate and useful diagnosis results. We also show that IOAgent is not tied to specific LLMs, performing similarly well with both proprietary and open-source LLMs. We believe IOAgent has the potential to become a powerful tool for scientists navigating complex HPC I/O subsystems in the future. Comments: Published in the Proceedings of the 2025 IEEE International Parallel and Distributed Processing Symposium (IPDPS 2025) Subjects: Distributed, Parallel, and Cluster Computing (cs.DC) Cite as: arXiv:2602.22017 [cs.DC] (or arXiv:2602.22017v1 [cs.DC] for this version) https://doi.org/10.48550/arXiv.2602.22017 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Related DOI : https://doi.org/10.1109/IPDPS64566.2025.00036 Focus to learn more DOI(s) linking to related resources Submission history From: Chris Egersdoerfer [ view email ] [v1] Wed, 25 Feb 2026 15:30:55 UTC (3,174 KB) Full-text links: Access Paper: View a PDF of the paper titled IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs, by Chris Egersdoerfer and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.DC &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-76">39. Probing Large-scale Structure and the Multi-Phase IGM at the Cosmic Noon -- Insights from a Joint Survey with Euclid, CSST, JPCam, and JUST</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.22004v1</li>
<li>来源：arxiv</li>
<li>摘要：We present scientific and technical justifications of a potential coordinated Euclid/CSST/JPCam/JUST survey of the Euclid Deep Field North (EDF-N), aimed at probing the multi-phase circumgalactic and intergalactic medium (CGM/IGM) at the cosmic noon over ~20 deg$^2$. The survey is structured around three connected goals: (1) improving photometric redshift (photo-z) accuracy through the combination of broad- and narrow-band photometry, enabling reliable identification of large-scale structures; (2) probing extended CGM emission with dedicated narrow-band imaging; and (3) mapping foreground IGM via absorption-line spectroscopy of background galaxies. Together, these components establish an integrated observational framework to investigate galactic ecosystems -- linking galaxies to their circumgalactic and intergalactic environments -- at cosmic noon. We show that the J-PAS-like narrow-band system used in JPCam substantially improves photo-z accuracies from only the Euclid/CSST broad-band data, especially for star-forming galaxies at z~1.0-1.4. This enables the identification of galaxy groups and (proto-)clusters directly from photo-z measurements. Stacked JPCam narrow-band imaging sh</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">photo-z 准确性的提升依赖于广带和窄带光度的结合，这表明窄带成像对于探测扩展的冷热中性气体（CGM）发射至关重要。CSST 和 JUST 能够提供背景星系的光谱，使得吸收线光谱学成为可能，从而有助于研究大尺度结构。然而，通过光谱堆叠或两点相关函数方法检测弥漫际空间（IGM）的镁（Mg II）吸收是不可行的。因此，未来设施如 39m E-ELT 需要更深更精细的光谱来限制弥漫 IGM 的金属丰度，以弥补当前技术的不足。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>photo-z 准确性提升依赖于广带和窄带光度的结合。</li>
<li>窄带成像对于探测扩展的 CGM 发射至关重要。</li>
<li>CSST 和 JUST 能够提供背景星系的光谱，用于吸收线光谱学。</li>
<li>CSST Lyα 森林能可靠地恢复大尺度结构。</li>
<li>通过光谱堆叠或两点相关函数方法检测弥漫 IGM 的 Mg II 吸收不可行。</li>
<li>未来设施如 39m E-ELT 需要更深更精细的光谱来限制弥漫 IGM 的金属丰度。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-77">正文（抓取，非 AI）</h3>
<p>[2602.22004v1] Probing Large-scale Structure and the Multi-Phase IGM at the Cosmic Noon -- Insights from a Joint Survey with Euclid, CSST, JPCam, and JUST Astrophysics &gt; Astrophysics of Galaxies arXiv:2602.22004v1 (astro-ph) [Submitted on 25 Feb 2026] Title: Probing Large-scale Structure and the Multi-Phase IGM at the Cosmic Noon -- Insights from a Joint Survey with Euclid, CSST, JPCam, and JUST Authors: Jiang-Tao Li , Renato A. Dupke , Yan Gong , Zhijie Qu , Weichen Wang , Xiaohu Yang , Xiaodi Yu View a PDF of the paper titled Probing Large-scale Structure and the Multi-Phase IGM at the Cosmic Noon -- Insights from a Joint Survey with Euclid, CSST, JPCam, and JUST, by Jiang-Tao Li and 5 other authors View PDF HTML (experimental) Abstract: We present scientific and technical justifications of a potential coordinated Euclid/CSST/JPCam/JUST survey of the Euclid Deep Field North (EDF-N), aimed at probing the multi-phase circumgalactic and intergalactic medium (CGM/IGM) at the cosmic noon over ~20 deg$^2$. The survey is structured around three connected goals: (1) improving photometric redshift (photo-z) accuracy through the combination of broad- and narrow-band photometry, enabling reliable identification of large-scale structures; (2) probing extended CGM emission with dedicated narrow-band imaging; and (3) mapping foreground IGM via absorption-line spectroscopy of background galaxies. Together, these components establish an integrated observational framework to investigate galactic ecosystems -- linking galaxies to their circumgalactic and intergalactic environments -- at cosmic noon. We show that the J-PAS-like narrow-band system used in JPCam substantially improves photo-z accuracies from only the Euclid/CSST broad-band data, especially for star-forming galaxies at z~1.0-1.4. This enables the identification of galaxy groups and (proto-)clusters directly from photo-z measurements. Stacked JPCam narrow-band imaging should also detect extended [O II]-emitting CGM halos. We then construct mock 3D gas distribution model and realistic galaxy catalog, and further construct mock CSST and JUST background galaxy spectra adding Lyalpha and Mg II absorptions. The reconstructed 3D H I field from CSST Lyalpha forest reliably recovers large-scale structures; however, our simulations indicate that detecting diffuse IGM Mg II absorption with JUST is infeasible, either through spectral stacking or via the two-point correlation function method. We conclude that constraining the metallicity of the diffuse IGM will require significantly deeper and higher-resolution spectroscopy expected from future facilities such as the 39 m E-ELT. Comments: 44 pages, 16 figures, 3 tables, accepted for publication by RAA Subjects: Astrophysics of Galaxies (astro-ph.GA) ; Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM) Cite as: arXiv:2602.22004 [astro-ph.GA] (or arXiv:2602.22004v1 [astro-ph.GA] for this version) https://doi.org/10.48550/arXiv.2602.22004 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Jiang-Tao Li Dr. [ view email ] [v1] Wed, 25 Feb 2026 15:21:48 UTC (12,110 KB) Full-text links: Access Paper: View a PDF of the paper titled Probing Large-scale Structure and the Multi-Phase IGM at the Cosmic Noon -- Insights from a Joint Survey with Euclid, CSST, JPCam, and JUST, by Jiang-Tao Li and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: astro-ph.GA &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: astro-ph astro-ph.CO astro-ph.IM References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p></div></details>
</div>
<script>
function speakText(t){ if(!t){ document.getElementById('readStatus').textContent=''; return; }
 speechSynthesis.cancel(); var status=document.getElementById('readStatus'); status.textContent='准备中…';
 var chunks=[]; var maxLen=280; for(var i=0;i<t.length;i+=maxLen){ var s=t.slice(i,i+maxLen); var j=s.lastIndexOf('。'); if(j>80){ chunks.push(s.slice(0,j+1)); i-=s.length-(j+1); } else chunks.push(s); }
 if(chunks.length===0) chunks=[t]; var idx=0; function speakNext(){ if(idx>=chunks.length){ status.textContent=''; return; } var u=new SpeechSynthesisUtterance(chunks[idx]); u.lang='zh-CN'; u.rate=0.95; var v=speechSynthesis.getVoices().filter(function(x){ return x.lang.indexOf('zh')>=0; })[0]; if(v) u.voice=v;
 u.onend=function(){ idx++; setTimeout(speakNext,80); }; u.onerror=function(){ idx++; setTimeout(speakNext,80); }; status.textContent='朗读中 '+(idx+1)+'/'+chunks.length+'…'; speechSynthesis.speak(u); }
 if(speechSynthesis.getVoices().length) speakNext(); else speechSynthesis.onvoiceschanged=function(){ speechSynthesis.onvoiceschanged=null; speakNext(); }; }
function readFullText(){ var c=document.querySelector('.content'); if(!c){ document.getElementById('readStatus').textContent='无可读内容'; return; } var t=(c.innerText||'').trim().replace(/\\s+/g,' '); if(!t){ document.getElementById('readStatus').textContent='无可读内容'; return; } speechSynthesis.cancel(); document.getElementById('readStatus').textContent='全文朗读…'; speakText(t); }
function getBlockForTap(el){ var c=document.querySelector('.content'); var blockTags=['P','DIV','H2','H3','H4','LI','PRE']; while(el&&el!==c){ if(c.contains(el)&&blockTags.indexOf(el.tagName)!==-1) return el; el=el.parentElement; } return null; }
function onContentTap(e){ if(e.target.closest&&e.target.closest('a')) return; var block=getBlockForTap(e.target); if(block){ var t=(block.innerText||'').trim().replace(/\\s+/g,' '); if(t){ e.preventDefault(); speechSynthesis.cancel(); document.getElementById('readStatus').textContent='朗读本段…'; speakText(t); } } }
if(document.readyState==='loading'){ document.addEventListener('DOMContentLoaded', function(){ var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }); } else { var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }
setTimeout(function(){ try{ var u=new SpeechSynthesisUtterance('\u200b'); u.volume=0; speechSynthesis.speak(u); }catch(e){} }, 300);
</script>
</body>
</html>
<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>知识流日报 2026-02-28：SOCP、CL4SE、GRAVE2、ParamMem、FlashOptim、coarse data、iTransformer、utilizing LLMs、LLM Novice Uplift、model disagreement、occlusion reasoning、dataset distillation、active depth learning</title>
<style>
  * { box-sizing: border-box; }
  body {
    font-family: system-ui, sans-serif;
    max-width: 720px;
    margin: 0 auto;
    padding: 2rem 1rem;
    color: #fff;
    min-height: 100vh;
    background: #0a0e1a;
    background-image:
      radial-gradient(2px 2px at 20px 30px, rgba(255,255,255,0.9), transparent),
      radial-gradient(2px 2px at 40px 70px, rgba(255,255,255,0.6), transparent),
      radial-gradient(1.5px 1.5px at 90px 40px, rgba(255,255,255,0.8), transparent),
      radial-gradient(2px 2px at 130px 80px, rgba(255,255,255,0.5), transparent),
      radial-gradient(1.5px 1.5px at 160px 120px, rgba(255,255,255,0.7), transparent),
      radial-gradient(ellipse 120% 100% at 50% 0%, rgba(88,60,120,0.25), transparent 50%),
      radial-gradient(ellipse 80% 80% at 80% 20%, rgba(40,60,100,0.2), transparent 40%);
    background-size: 200px 200px;
    background-repeat: repeat;
  }
  a { color: #a8d4ff; text-decoration: none; }
  a:hover { text-decoration: underline; }
 html{scroll-behavior:smooth;} .content h2,.content h3{scroll-margin-top:1rem;} .content .reading-highlight{background:rgba(255,255,255,0.12);border-left:3px solid rgba(255,255,255,0.5);border-radius:2px;} h1,h2,h3{margin-top:1.5rem;color:#fff;} pre{white-space:pre-wrap;color:rgba(255,255,255,0.9);} .toolbar{margin:0.5rem 0;color:rgba(255,255,255,0.8);} .content{color:rgba(255,255,255,0.95);} .content a{color:#a8d4ff;} .meta{color:rgba(255,255,255,0.65);font-size:0.9em;} .toc{margin:1rem 0;padding:0.8rem 1rem;background:rgba(255,255,255,0.08);border-radius:6px;} .toc .toc-title{margin:0 0 0.5rem 0;font-weight:bold;color:rgba(255,255,255,0.9);} .toc ul{list-style:none;padding-left:0;margin:0;} .toc li{margin:0.35rem 0;} .toc li.toc-h3{padding-left:1em;font-size:0.95em;} .toc a{color:#a8d4ff;text-decoration:none;} .toc a:hover{text-decoration:underline;} .content p,.content div,.content h2,.content h3,.content h4,.content li,.content pre{cursor:pointer;-webkit-tap-highlight-color:rgba(255,255,255,0.15);} .content .insight-summary{color:#c9a0dc;margin:0.5em 0 0.8em 0;} .content .insight-detail,.content .insight-detail li{color:#8dd4e8;list-style:disc;margin-left:1.2em;padding-left:0.3em;} .content .article-body-details{margin:0.8em 0;} .content .article-body-details summary{cursor:pointer;color:rgba(255,255,255,0.85);}</style>
</head>
<body>
<p><a href="https://YuxinWSoton.github.io/ai-knowledge-flow-site/">← 返回首页</a></p>
<h1>知识流日报 2026-02-28：SOCP、CL4SE、GRAVE2、ParamMem、FlashOptim、coarse data、iTransformer、utilizing LLMs、LLM Novice Uplift、model disagreement、occlusion reasoning、dataset distillation、active depth learning</h1>
<p class="meta" style="margin-top:0;">最后更新：2026-03-01 21:41</p>
<p class="toolbar"><button id="btnFull" onclick="readFullText()">全文朗读</button> <span id="readStatus"></span></p>
<p class="meta" style="margin-top:0;">（点任意段落可朗读该段；「全文朗读」读本页全部内容，当前读到的段落会自动滚动到视野内并高亮）</p>
<nav class="toc" aria-label="目录">
<p class="toc-title">目录</p>
<ul>
  <li><a href="#toc-0">1. Cyclic sieving for a class of rectangular domino tableaux</a></li>
  <li class="toc-h3"><a href="#toc-1">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-2">2. Utilizing LLMs for Industrial Process Automation</a></li>
  <li class="toc-h3"><a href="#toc-3">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-4">3. Generalized Rapid Action Value Estimation in Memory-Constrained Environments</a></li>
  <li class="toc-h3"><a href="#toc-5">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-6">4. Just-In-Time Piecewise-Linear Semantics for ReLU-type Networks</a></li>
  <li class="toc-h3"><a href="#toc-7">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-8">5. Memory-induced active particle ratchets: Mean currents and large deviations</a></li>
  <li class="toc-h3"><a href="#toc-9">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-10">6. A Proper Scoring Rule for Virtual Staining</a></li>
  <li class="toc-h3"><a href="#toc-11">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-12">7. Spin Glass Concepts in Computer Science, Statistics, and Learning</a></li>
  <li class="toc-h3"><a href="#toc-13">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-14">8. First-order SDSOS-convex semi-algebraic optimization and exact SOCP relaxations</a></li>
  <li class="toc-h3"><a href="#toc-15">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-16">9. Robust model selection using likelihood as data</a></li>
  <li class="toc-h3"><a href="#toc-17">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-18">10. Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training</a></li>
  <li class="toc-h3"><a href="#toc-19">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-20">11. On the embedding transformation for optimal control of multi-mode switched systems</a></li>
  <li class="toc-h3"><a href="#toc-21">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-22">12. VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale</a></li>
  <li class="toc-h3"><a href="#toc-23">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-24">13. CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays</a></li>
  <li class="toc-h3"><a href="#toc-25">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-26">14. EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-27">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-28">15. Millimeter-Wave RIS: Hardware Design and System-Level Considerations</a></li>
  <li class="toc-h3"><a href="#toc-29">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-30">16. Butterfly Echo Protocol for Axis-Agnostic Heisenberg-Limited Metrology</a></li>
  <li class="toc-h3"><a href="#toc-31">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-32">17. Differentiable Zero-One Loss via Hypersimplex Projections</a></li>
  <li class="toc-h3"><a href="#toc-33">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-34">18. Towards Joint Optimization for UAV-Integrated RIS-Assisted Fluid Antenna Systems</a></li>
  <li class="toc-h3"><a href="#toc-35">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-36">19. An Optimization Method for Autoregressive Time Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-37">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-38">20. Arrested Relaxation in a Disorder-Free Coulomb Spin Liquid</a></li>
  <li class="toc-h3"><a href="#toc-39">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-40">21. Selective Learning for Deep Time Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-41">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-42">22. Learning Contact Policies for SEIR Epidemics on Networks: A Mean-Field Game Approach</a></li>
  <li class="toc-h3"><a href="#toc-43">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-44">23. TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-45">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-46">24. Constrained Policy Optimization via Sampling-Based Weight-Space Projection</a></li>
  <li class="toc-h3"><a href="#toc-47">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-48">25. Quantum Neural Network Architectures for Multivariate Time-Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-49">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-50">26. FlashOptim: Optimizers for Memory Efficient Training</a></li>
  <li class="toc-h3"><a href="#toc-51">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-52">27. Retrieve and Segment: Are a Few Examples Enough to Bridge the Supervision Gap in Open-Vocabulary Segmentation?</a></li>
  <li class="toc-h3"><a href="#toc-53">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-54">28. Real-Time Stream Compaction for Sparse Machine Learning on FPGAs</a></li>
  <li class="toc-h3"><a href="#toc-55">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-56">29. CubeSounder: Low SWaP-C 180 GHz Radiometer for Atmospheric Sensing Tested on High Altitude Balloons</a></li>
  <li class="toc-h3"><a href="#toc-57">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-58">30. Non-Attainment of Minima in Non-Polyhedral Conic Optimization: A Robust SOCP Example</a></li>
  <li class="toc-h3"><a href="#toc-59">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-60">31. A Dataset is Worth 1 MB</a></li>
  <li class="toc-h3"><a href="#toc-61">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-62">32. Impacts of Aggregation on Model Diversity and Consumer Utility</a></li>
  <li class="toc-h3"><a href="#toc-63">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-64">33. Physics Informed Viscous Value Representations</a></li>
  <li class="toc-h3"><a href="#toc-65">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-66">34. Close-enough general routing problem for multiple unmanned aerial vehicles in monitoring missions</a></li>
  <li class="toc-h3"><a href="#toc-67">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-68">35. ParamMem: Augmenting Language Agents with Parametric Reflective Memory</a></li>
  <li class="toc-h3"><a href="#toc-69">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-70">36. Interface-Aware Trajectory Reconstruction of Limited Demonstrations for Robot Learning</a></li>
  <li class="toc-h3"><a href="#toc-71">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-72">37. Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City</a></li>
  <li class="toc-h3"><a href="#toc-73">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-74">38. Lossless Compression: A New Benchmark for Time Series Model Evaluation</a></li>
  <li class="toc-h3"><a href="#toc-75">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-76">39. Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces</a></li>
  <li class="toc-h3"><a href="#toc-77">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-78">40. ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding</a></li>
  <li class="toc-h3"><a href="#toc-79">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-80">41. SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport</a></li>
  <li class="toc-h3"><a href="#toc-81">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-82">42. Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms</a></li>
  <li class="toc-h3"><a href="#toc-83">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-84">43. Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments</a></li>
  <li class="toc-h3"><a href="#toc-85">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-86">44. Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity</a></li>
  <li class="toc-h3"><a href="#toc-87">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-88">45. Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems</a></li>
  <li class="toc-h3"><a href="#toc-89">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-90">46. The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss</a></li>
  <li class="toc-h3"><a href="#toc-91">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-92">47. PRIMA: Pre-training with Risk-integrated Image-Metadata Alignment for Medical Diagnosis via LLM</a></li>
  <li class="toc-h3"><a href="#toc-93">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-94">48. Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning</a></li>
  <li class="toc-h3"><a href="#toc-95">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-96">49. Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?</a></li>
  <li class="toc-h3"><a href="#toc-97">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-98">50. AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning</a></li>
  <li class="toc-h3"><a href="#toc-99">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-100">51. A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations</a></li>
  <li class="toc-h3"><a href="#toc-101">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-102">52. Model Agreement via Anchoring</a></li>
  <li class="toc-h3"><a href="#toc-103">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-104">53. InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling</a></li>
  <li class="toc-h3"><a href="#toc-105">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-106">54. Ruling Out Spiky WIMP Dark Matter using Indirect Searches</a></li>
  <li class="toc-h3"><a href="#toc-107">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-108">55. Decomposing Private Image Generation via Coarse-to-Fine Wavelet Modeling</a></li>
  <li class="toc-h3"><a href="#toc-109">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-110">56. Secure Multicast Communications with Pinching-Antenna Systems (PASS)</a></li>
  <li class="toc-h3"><a href="#toc-111">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-112">57. LineGraph2Road: Structural Graph Reasoning on Line Graphs for Road Network Extraction</a></li>
  <li class="toc-h3"><a href="#toc-113">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-114">58. Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks</a></li>
  <li class="toc-h3"><a href="#toc-115">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-116">59. MediX-R1: Open Ended Medical Reinforcement Learning</a></li>
  <li class="toc-h3"><a href="#toc-117">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-118">60. SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation</a></li>
  <li class="toc-h3"><a href="#toc-119">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-120">61. A Thermal-Electrical Co-Optimization Framework for Active Distribution Grids with Electric Vehicles and Heat Pumps</a></li>
  <li class="toc-h3"><a href="#toc-121">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-122">62. Cell-Free MIMO with Rotatable Antennas: When Macro-Diversity Meets Antenna Directivity</a></li>
  <li class="toc-h3"><a href="#toc-123">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-124">63. Towards Long-Form Spatio-Temporal Video Grounding</a></li>
  <li class="toc-h3"><a href="#toc-125">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-126">64. CL4SE: A Context Learning Benchmark For Software Engineering Tasks</a></li>
  <li class="toc-h3"><a href="#toc-127">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-128">65. 2D Sparse Array Design via Reweighted L1 Second Order Cone Programming for 3D Ultrasound Imaging</a></li>
  <li class="toc-h3"><a href="#toc-129">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-130">66. Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition</a></li>
  <li class="toc-h3"><a href="#toc-131">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-132">67. UniScale: Unified Scale-Aware 3D Reconstruction for Multi-View Understanding via Prior Injection for Robotic Perception</a></li>
  <li class="toc-h3"><a href="#toc-133">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-134">68. LLM Novice Uplift on Dual-Use, In Silico Biology Tasks</a></li>
  <li class="toc-h3"><a href="#toc-135">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-136">69. Beamforming for Transmissive RIS Transceiver Enabled Simultaneous Wireless Information and Power Transfer Systems</a></li>
  <li class="toc-h3"><a href="#toc-137">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-138">70. Comparative Evaluation of SDP, SOCP, and QC Convex Relaxations for Large-Scale Market-Based AC Optimal Power Flow</a></li>
  <li class="toc-h3"><a href="#toc-139">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-140">71. Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset</a></li>
  <li class="toc-h3"><a href="#toc-141">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-142">72. Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-143">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-144">73. TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints</a></li>
  <li class="toc-h3"><a href="#toc-145">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-146">74. MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction</a></li>
  <li class="toc-h3"><a href="#toc-147">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-148">75. Revisiting the Perseus Cluster II: Metallicity-Dependence of Massive Stars and Chemical Enrichment History</a></li>
  <li class="toc-h3"><a href="#toc-149">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-150">76. Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction</a></li>
  <li class="toc-h3"><a href="#toc-151">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-152">77. InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models</a></li>
  <li class="toc-h3"><a href="#toc-153">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-154">78. Benchmarking State Space Models, Transformers, and Recurrent Networks for US Grid Forecasting</a></li>
  <li class="toc-h3"><a href="#toc-155">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-156">79. TESS Planet Occurrence Rates Reveal the Disappearance of the Radius Valley Around Mid-to-Late M Dwarfs</a></li>
  <li class="toc-h3"><a href="#toc-157">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-158">80. AlayaLaser: Efficient Index Layout and Search Strategy for Large-scale High-dimensional Vector Similarity Search</a></li>
  <li class="toc-h3"><a href="#toc-159">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-160">81. ManifoldGD: Training-Free Hierarchical Manifold Guidance for Diffusion-Based Dataset Distillation</a></li>
  <li class="toc-h3"><a href="#toc-161">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-162">82. Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive</a></li>
  <li class="toc-h3"><a href="#toc-163">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-164">83. Revisiting the Perseus Cluster III: Role of Aspherical Explosions on its Chemical Composition and Extension to Metal-Poor Stars and Galaxies</a></li>
  <li class="toc-h3"><a href="#toc-165">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-166">84. Efficient MPC-Based Energy Management System for Secure and Cost-Effective Microgrid Operations</a></li>
  <li class="toc-h3"><a href="#toc-167">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-168">85. Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models</a></li>
  <li class="toc-h3"><a href="#toc-169">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-170">86. SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation</a></li>
  <li class="toc-h3"><a href="#toc-171">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-172">87. STELLAR: Storage Tuning Engine Leveraging LLM Autonomous Reasoning for High Performance Parallel File Systems</a></li>
  <li class="toc-h3"><a href="#toc-173">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-174">88. SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables</a></li>
  <li class="toc-h3"><a href="#toc-175">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-176">89. Extreme Emission Line Galaxies in CEERS Are Powered by Star Formation, not AGN</a></li>
  <li class="toc-h3"><a href="#toc-177">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-178">90. F10.7 Index Prediction: A Multiscale Decomposition Strategy with Wavelet Transform for Performance Optimization</a></li>
  <li class="toc-h3"><a href="#toc-179">正文（抓取，非 AI）</a></li>
</ul>
</nav>
<div class="content">
<h1>知识流日报 2026-02-28：SOCP、CL4SE、GRAVE2、ParamMem、FlashOptim、coarse data、iTransformer、utilizing LLMs、LLM Novice Uplift、model disagreement、occlusion reasoning、dataset distillation、active depth learning</h1>
<p>共 90 条（来自百度学术 / Google / Bing 等，仅含正文抓取成功的条目；按正文长度从短到长排列，便于先听短的）。</p>
<p>（以下含抓取正文，便于阅读。未调用任何 AI API。）</p>
<p>（仅前 50 条含模型提取的「易漏细节」关键点，页面上以颜色区分；第 51 条及之后未调用模型，故无易漏细节。可在 config 中调大 extract_insights_max_items 以增加条数。）</p>
<h2 id="toc-0">1. Cyclic sieving for a class of rectangular domino tableaux</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23343v1</li>
<li>来源：arxiv</li>
<li>摘要：The cyclic sieving phenomenon (CSP) provides valuable data about symmetry classes of cyclic actions, and has applications to representation theory. In this paper, we enumerate domino tableaux of shape 2-by-n, and use this result to prove a new CSP on these objects. We then enumerate the rectangular domino tableaux of any dimensions, and conjecture a more general CSP on rectangular domino tableaux. As a consequence of the enumerative results, we obtain several identities involving Fibonacci and Catalan numbers.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-1">正文（抓取，非 AI）</h3>
<p>[2602.23343v1] Cyclic sieving for a class of rectangular domino tableaux Mathematics &gt; Combinatorics arXiv:2602.23343v1 (math) [Submitted on 26 Feb 2026] Title: Cyclic sieving for a class of rectangular domino tableaux Authors: Laura Colmenarejo , Bridget Eileen Tenner , Camryn E. Thompson View a PDF of the paper titled Cyclic sieving for a class of rectangular domino tableaux, by Laura Colmenarejo and 2 other authors View PDF HTML (experimental) Abstract: The cyclic sieving phenomenon (CSP) provides valuable data about symmetry classes of cyclic actions, and has applications to representation theory. In this paper, we enumerate domino tableaux of shape 2-by-n, and use this result to prove a new CSP on these objects. We then enumerate the rectangular domino tableaux of any dimensions, and conjecture a more general CSP on rectangular domino tableaux. As a consequence of the enumerative results, we obtain several identities involving Fibonacci and Catalan numbers. Comments: 17 pages Subjects: Combinatorics (math.CO) MSC classes: Primary: 05E18, Secondary: 05A15, 05A10 Cite as: arXiv:2602.23343 [math.CO] (or arXiv:2602.23343v1 [math.CO] for this version) https://doi.org/10.48550/arXiv.2602.23343 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Bridget Tenner [ view email ] [v1] Thu, 26 Feb 2026 18:48:34 UTC (20 KB) Full-text links: Access Paper: View a PDF of the paper titled Cyclic sieving for a class of rectangular domino tableaux, by Laura Colmenarejo and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: math.CO &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: math References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-2">2. Utilizing LLMs for Industrial Process Automation</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23331v1</li>
<li>来源：arxiv</li>
<li>摘要：A growing number of publications address the best practices to use Large Language Models (LLMs) for software engineering in recent years. However, most of this work focuses on widely-used general purpose programming languages like Python due to their widespread usage training data. The utility of LLMs for software within the industrial process automation domain, with highly-specialized languages that are typically only used in proprietary contexts, remains underexplored. This research aims to utilize and integrate LLMs in the industrial development process, solving real-life programming tasks (e.g., generating a movement routine for a robotic arm) and accelerating the development cycles of manufacturing systems.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-3">正文（抓取，非 AI）</h3>
<p>[2602.23331v1] Utilizing LLMs for Industrial Process Automation Computer Science &gt; Software Engineering arXiv:2602.23331v1 (cs) [Submitted on 26 Feb 2026] Title: Utilizing LLMs for Industrial Process Automation Authors: Salim Fares View a PDF of the paper titled Utilizing LLMs for Industrial Process Automation, by Salim Fares View PDF HTML (experimental) Abstract: A growing number of publications address the best practices to use Large Language Models (LLMs) for software engineering in recent years. However, most of this work focuses on widely-used general purpose programming languages like Python due to their widespread usage training data. The utility of LLMs for software within the industrial process automation domain, with highly-specialized languages that are typically only used in proprietary contexts, remains underexplored. This research aims to utilize and integrate LLMs in the industrial development process, solving real-life programming tasks (e.g., generating a movement routine for a robotic arm) and accelerating the development cycles of manufacturing systems. Subjects: Software Engineering (cs.SE) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23331 [cs.SE] (or arXiv:2602.23331v1 [cs.SE] for this version) https://doi.org/10.48550/arXiv.2602.23331 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Salim Fares [ view email ] [v1] Thu, 26 Feb 2026 18:38:00 UTC (55 KB) Full-text links: Access Paper: View a PDF of the paper titled Utilizing LLMs for Industrial Process Automation, by Salim Fares View PDF HTML (experimental) TeX Source view license Current browse context: cs.SE &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-4">3. Generalized Rapid Action Value Estimation in Memory-Constrained Environments</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23318v1</li>
<li>来源：arxiv</li>
<li>摘要：Generalized Rapid Action Value Estimation (GRAVE) has been shown to be a strong variant within the Monte-Carlo Tree Search (MCTS) family of algorithms for General Game Playing (GGP). However, its reliance on storing additional win/visit statistics at each node makes its use impractical in memory-constrained environments, thereby limiting its applicability in practice. In this paper, we introduce the GRAVE2, GRAVER and GRAVER2 algorithms, which extend GRAVE through two-level search, node recycling, and a combination of both techniques, respectively. We show that these enhancements enable a drastic reduction in the number of stored nodes while matching the playing strength of GRAVE.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-5">正文（抓取，非 AI）</h3>
<p>[2602.23318v1] Generalized Rapid Action Value Estimation in Memory-Constrained Environments Computer Science &gt; Artificial Intelligence arXiv:2602.23318v1 (cs) [Submitted on 26 Feb 2026] Title: Generalized Rapid Action Value Estimation in Memory-Constrained Environments Authors: Aloïs Rautureau , Tristan Cazenave , Éric Piette View a PDF of the paper titled Generalized Rapid Action Value Estimation in Memory-Constrained Environments, by Alo\"is Rautureau and 2 other authors View PDF HTML (experimental) Abstract: Generalized Rapid Action Value Estimation (GRAVE) has been shown to be a strong variant within the Monte-Carlo Tree Search (MCTS) family of algorithms for General Game Playing (GGP). However, its reliance on storing additional win/visit statistics at each node makes its use impractical in memory-constrained environments, thereby limiting its applicability in practice. In this paper, we introduce the GRAVE2, GRAVER and GRAVER2 algorithms, which extend GRAVE through two-level search, node recycling, and a combination of both techniques, respectively. We show that these enhancements enable a drastic reduction in the number of stored nodes while matching the playing strength of GRAVE. Subjects: Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23318 [cs.AI] (or arXiv:2602.23318v1 [cs.AI] for this version) https://doi.org/10.48550/arXiv.2602.23318 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Aloïs Rautureau [ view email ] [v1] Thu, 26 Feb 2026 18:25:59 UTC (338 KB) Full-text links: Access Paper: View a PDF of the paper titled Generalized Rapid Action Value Estimation in Memory-Constrained Environments, by Alo\"is Rautureau and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.AI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-6">4. Just-In-Time Piecewise-Linear Semantics for ReLU-type Networks</h2>
<ul>
<li>链接：https://arxiv.org/abs/2510.17622v1</li>
<li>来源：arxiv</li>
<li>摘要：We present a JIT PL semantics for ReLU-type networks that compiles models into a guarded CPWL transducer with shared guards. The system adds hyperplanes only when operands are affine on the current cell, maintains global lower/upper envelopes, and uses a budgeted branch-and-bound. We obtain anytime soundness, exactness on fully refined cells, monotone progress, guard-linear complexity (avoiding global $\binom{k}{2}$), dominance pruning, and decidability under finite refinement. The shared carrier supports region extraction, decision complexes, Jacobians, exact/certified Lipschitz, LP/SOCP robustness, and maximal causal influence. A minimal prototype returns certificates or counterexamples with cost proportional to visited subdomains.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-7">正文（抓取，非 AI）</h3>
<p>[2510.17622v1] Just-In-Time Piecewise-Linear Semantics for ReLU-type Networks Computer Science &gt; Logic in Computer Science arXiv:2510.17622v1 (cs) [Submitted on 20 Oct 2025] Title: Just-In-Time Piecewise-Linear Semantics for ReLU-type Networks Authors: Hongyi Duan , Haoyang Liu , Jian'an Zhang , Fengrui Liu , Yiyi Wang View a PDF of the paper titled Just-In-Time Piecewise-Linear Semantics for ReLU-type Networks, by Hongyi Duan and 4 other authors View PDF HTML (experimental) Abstract: We present a JIT PL semantics for ReLU-type networks that compiles models into a guarded CPWL transducer with shared guards. The system adds hyperplanes only when operands are affine on the current cell, maintains global lower/upper envelopes, and uses a budgeted branch-and-bound. We obtain anytime soundness, exactness on fully refined cells, monotone progress, guard-linear complexity (avoiding global $\binom{k}{2}$), dominance pruning, and decidability under finite refinement. The shared carrier supports region extraction, decision complexes, Jacobians, exact/certified Lipschitz, LP/SOCP robustness, and maximal causal influence. A minimal prototype returns certificates or counterexamples with cost proportional to visited subdomains. Subjects: Logic in Computer Science (cs.LO) ; Machine Learning (cs.LG) Cite as: arXiv:2510.17622 [cs.LO] (or arXiv:2510.17622v1 [cs.LO] for this version) https://doi.org/10.48550/arXiv.2510.17622 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Hongyi Duan [ view email ] [v1] Mon, 20 Oct 2025 15:05:14 UTC (4,397 KB) Full-text links: Access Paper: View a PDF of the paper titled Just-In-Time Piecewise-Linear Semantics for ReLU-type Networks, by Hongyi Duan and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LO &lt; prev | next &gt; new | recent | 2025-10 Change to browse by: cs cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-8">5. Memory-induced active particle ratchets: Mean currents and large deviations</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23327v1</li>
<li>来源：arxiv</li>
<li>摘要：We analyse a continuous-time random walk model with stochastic reversals of direction. There is no external potential but the reorientation mechanism generates a non-zero current from asymmetry in the forward and backward waiting-time distributions (even when they have the same mean); the system can therefore can be considered as a type of active particle ratchet. We derive an explicit expression for the mean ratchet current with exponentially distributed reorientation times and also develop a general renewal-theory framework to obtain the full large deviations, using this to comment on the possibility of dynamical phase transitions.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-9">正文（抓取，非 AI）</h3>
<p>[2602.23327v1] Memory-induced active particle ratchets: Mean currents and large deviations Condensed Matter &gt; Statistical Mechanics arXiv:2602.23327v1 (cond-mat) [Submitted on 26 Feb 2026] Title: Memory-induced active particle ratchets: Mean currents and large deviations Authors: Venkata D. Pamulaparthy , Rosemary J. Harris View a PDF of the paper titled Memory-induced active particle ratchets: Mean currents and large deviations, by Venkata D. Pamulaparthy and Rosemary J. Harris View PDF Abstract: We analyse a continuous-time random walk model with stochastic reversals of direction. There is no external potential but the reorientation mechanism generates a non-zero current from asymmetry in the forward and backward waiting-time distributions (even when they have the same mean); the system can therefore can be considered as a type of active particle ratchet. We derive an explicit expression for the mean ratchet current with exponentially distributed reorientation times and also develop a general renewal-theory framework to obtain the full large deviations, using this to comment on the possibility of dynamical phase transitions. Comments: 15 pages, 10 figures Subjects: Statistical Mechanics (cond-mat.stat-mech) Cite as: arXiv:2602.23327 [cond-mat.stat-mech] (or arXiv:2602.23327v1 [cond-mat.stat-mech] for this version) https://doi.org/10.48550/arXiv.2602.23327 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Venkata Dhruva Pamulaparthy [ view email ] [v1] Thu, 26 Feb 2026 18:36:13 UTC (580 KB) Full-text links: Access Paper: View a PDF of the paper titled Memory-induced active particle ratchets: Mean currents and large deviations, by Venkata D. Pamulaparthy and Rosemary J. Harris View PDF TeX Source view license Current browse context: cond-mat.stat-mech &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cond-mat References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-10">6. A Proper Scoring Rule for Virtual Staining</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23305v1</li>
<li>来源：arxiv</li>
<li>摘要：Generative virtual staining (VS) models for high-throughput screening (HTS) can provide an estimated posterior distribution of possible biological feature values for each input and cell. However, when evaluating a VS model, the true posterior is unavailable. Existing evaluation protocols only check the accuracy of the marginal distribution over the dataset rather than the predicted posteriors. We introduce information gain (IG) as a cell-wise evaluation framework that enables direct assessment of predicted posteriors. IG is a strictly proper scoring rule and comes with a sound theoretical motivation allowing for interpretability, and for comparing results across models and features. We evaluate diffusion- and GAN-based models on an extensive HTS dataset using IG and other metrics and show that IG can reveal substantial performance differences other metrics cannot.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-11">正文（抓取，非 AI）</h3>
<p>[2602.23305v1] A Proper Scoring Rule for Virtual Staining Computer Science &gt; Machine Learning arXiv:2602.23305v1 (cs) [Submitted on 26 Feb 2026] Title: A Proper Scoring Rule for Virtual Staining Authors: Samuel Tonks , Steve Hood , Ryan Musso , Ceridwen Hopely , Steve Titus , Minh Doan , Iain Styles , Alexander Krull View a PDF of the paper titled A Proper Scoring Rule for Virtual Staining, by Samuel Tonks and 6 other authors View PDF HTML (experimental) Abstract: Generative virtual staining (VS) models for high-throughput screening (HTS) can provide an estimated posterior distribution of possible biological feature values for each input and cell. However, when evaluating a VS model, the true posterior is unavailable. Existing evaluation protocols only check the accuracy of the marginal distribution over the dataset rather than the predicted posteriors. We introduce information gain (IG) as a cell-wise evaluation framework that enables direct assessment of predicted posteriors. IG is a strictly proper scoring rule and comes with a sound theoretical motivation allowing for interpretability, and for comparing results across models and features. We evaluate diffusion- and GAN-based models on an extensive HTS dataset using IG and other metrics and show that IG can reveal substantial performance differences other metrics cannot. Subjects: Machine Learning (cs.LG) Cite as: arXiv:2602.23305 [cs.LG] (or arXiv:2602.23305v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23305 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Samuel Tonks Mr [ view email ] [v1] Thu, 26 Feb 2026 18:09:49 UTC (898 KB) Full-text links: Access Paper: View a PDF of the paper titled A Proper Scoring Rule for Virtual Staining, by Samuel Tonks and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-12">7. Spin Glass Concepts in Computer Science, Statistics, and Learning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23326v1</li>
<li>来源：arxiv</li>
<li>摘要：Spin glass theory studies the structure of sublevel sets and minima (or near-minima) of certain classes of random functions in high dimension. Near-minima of random functions also play an important role in high-dimensional statistics and statistical learning, where minimizing the empirical risk (which is a random function of the model parameters) is the method of choice for learning a statistical model from noisy data. Finally, near-minima of random functions are obviously central to average-case analysis of optimization algorithms. Computer science, statistics, and machine learning naturally lead to questions that are traditionally not addressed within physics and mathematical physics. I will try to explain how ideas from spin glass theory have seeded recent developments in these fields.   (This article was written on the occasion of the 2024 Abel Prize to Michel Talagrand.)</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-13">正文（抓取，非 AI）</h3>
<p>[2602.23326v1] Spin Glass Concepts in Computer Science, Statistics, and Learning Mathematics &gt; Probability arXiv:2602.23326v1 (math) [Submitted on 26 Feb 2026] Title: Spin Glass Concepts in Computer Science, Statistics, and Learning Authors: Andrea Montanari View a PDF of the paper titled Spin Glass Concepts in Computer Science, Statistics, and Learning, by Andrea Montanari View PDF HTML (experimental) Abstract: Spin glass theory studies the structure of sublevel sets and minima (or near-minima) of certain classes of random functions in high dimension. Near-minima of random functions also play an important role in high-dimensional statistics and statistical learning, where minimizing the empirical risk (which is a random function of the model parameters) is the method of choice for learning a statistical model from noisy data. Finally, near-minima of random functions are obviously central to average-case analysis of optimization algorithms. Computer science, statistics, and machine learning naturally lead to questions that are traditionally not addressed within physics and mathematical physics. I will try to explain how ideas from spin glass theory have seeded recent developments in these fields. (This article was written on the occasion of the 2024 Abel Prize to Michel Talagrand.) Comments: 33 pages; 2 pdf figures Subjects: Probability (math.PR) ; Disordered Systems and Neural Networks (cond-mat.dis-nn) Cite as: arXiv:2602.23326 [math.PR] (or arXiv:2602.23326v1 [math.PR] for this version) https://doi.org/10.48550/arXiv.2602.23326 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Andrea Montanari [ view email ] [v1] Thu, 26 Feb 2026 18:35:47 UTC (55 KB) Full-text links: Access Paper: View a PDF of the paper titled Spin Glass Concepts in Computer Science, Statistics, and Learning, by Andrea Montanari View PDF HTML (experimental) TeX Source view license Current browse context: math.PR &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cond-mat cond-mat.dis-nn math References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-14">8. First-order SDSOS-convex semi-algebraic optimization and exact SOCP relaxations</h2>
<ul>
<li>链接：https://arxiv.org/abs/2509.07418v1</li>
<li>来源：arxiv</li>
<li>摘要：In this paper, we define a new type of nonsmooth convex function, called {\em first-order SDSOS-convex semi-algebraic function}, which is an extension of the previously proposed first-order SDSOS-convex polynomials (Chuong et al. in J Global Optim 75:885--919, 2019). This class of nonsmooth convex functions contains many well-known functions, such as the Euclidean norm, the $\ell_1$-norm commonly used in compressed sensing and sparse optimization, and the least squares function frequently employed in machine learning and regression analysis. We show that, under suitable assumptions, the optimal value and optimal solutions of first-order SDSOS-convex semi-algebraic programs can be found by exactly solving an associated second-order cone programming problem. Finally, an application to robust optimization with first-order SDSOS-convex polynomials is discussed.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-15">正文（抓取，非 AI）</h3>
<p>[2509.07418v1] First-order SDSOS-convex semi-algebraic optimization and exact SOCP relaxations Mathematics &gt; Optimization and Control arXiv:2509.07418v1 (math) [Submitted on 9 Sep 2025] Title: First-order SDSOS-convex semi-algebraic optimization and exact SOCP relaxations Authors: Chengmiao Yang , Liguo Jiao , Jae Hyoung Lee View a PDF of the paper titled First-order SDSOS-convex semi-algebraic optimization and exact SOCP relaxations, by Chengmiao Yang and Liguo Jiao and Jae Hyoung Lee View PDF HTML (experimental) Abstract: In this paper, we define a new type of nonsmooth convex function, called {\em first-order SDSOS-convex semi-algebraic function}, which is an extension of the previously proposed first-order SDSOS-convex polynomials (Chuong et al. in J Global Optim 75:885--919, 2019). This class of nonsmooth convex functions contains many well-known functions, such as the Euclidean norm, the $\ell_1$-norm commonly used in compressed sensing and sparse optimization, and the least squares function frequently employed in machine learning and regression analysis. We show that, under suitable assumptions, the optimal value and optimal solutions of first-order SDSOS-convex semi-algebraic programs can be found by exactly solving an associated second-order cone programming problem. Finally, an application to robust optimization with first-order SDSOS-convex polynomials is discussed. Comments: 24pages Subjects: Optimization and Control (math.OC) Cite as: arXiv:2509.07418 [math.OC] (or arXiv:2509.07418v1 [math.OC] for this version) https://doi.org/10.48550/arXiv.2509.07418 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Chengmiao Yang [ view email ] [v1] Tue, 9 Sep 2025 06:06:48 UTC (21 KB) Full-text links: Access Paper: View a PDF of the paper titled First-order SDSOS-convex semi-algebraic optimization and exact SOCP relaxations, by Chengmiao Yang and Liguo Jiao and Jae Hyoung Lee View PDF HTML (experimental) TeX Source view license Current browse context: math.OC &lt; prev | next &gt; new | recent | 2025-09 Change to browse by: math References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-16">9. Robust model selection using likelihood as data</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23355v1</li>
<li>来源：arxiv</li>
<li>摘要：Model selection is a central task in statistics, but standard methods are not robust in misspecified settings where the true data-generating process (DGP) is not in the set of candidate models. The key limitation is that existing methods -- including information criteria and Bayesian posteriors -- do not quantify uncertainty about how well each candidate model approximates the true DGP. In this paper, we introduce a novel approach to model selection based on modeling the likelihood values themselves. Specifically, given $K$ candidate models and $n$ observations, we view the $n\times K$ matrix of negative log-likelihood values as a random data matrix and observe that the expectation of each row is equal to the vector of Kullback--Leibler divergences between the $K$ models and the true DGP, up to an additive constant. We use a multivariate normal model to estimate and quantify uncertainty in this expectation, providing calibrated inferences for robust model selection under misspecification. The procedure is easy to compute, interpretable, and comes with theoretical guarantees, including consistency.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-17">正文（抓取，非 AI）</h3>
<p>[2602.23355v1] Robust model selection using likelihood as data Statistics &gt; Methodology arXiv:2602.23355v1 (stat) [Submitted on 26 Feb 2026] Title: Robust model selection using likelihood as data Authors: Jongwoo Choi , Neil A. Spencer , Jeffrey W. Miller View a PDF of the paper titled Robust model selection using likelihood as data, by Jongwoo Choi and 2 other authors View PDF Abstract: Model selection is a central task in statistics, but standard methods are not robust in misspecified settings where the true data-generating process (DGP) is not in the set of candidate models. The key limitation is that existing methods -- including information criteria and Bayesian posteriors -- do not quantify uncertainty about how well each candidate model approximates the true DGP. In this paper, we introduce a novel approach to model selection based on modeling the likelihood values themselves. Specifically, given $K$ candidate models and $n$ observations, we view the $n\times K$ matrix of negative log-likelihood values as a random data matrix and observe that the expectation of each row is equal to the vector of Kullback--Leibler divergences between the $K$ models and the true DGP, up to an additive constant. We use a multivariate normal model to estimate and quantify uncertainty in this expectation, providing calibrated inferences for robust model selection under misspecification. The procedure is easy to compute, interpretable, and comes with theoretical guarantees, including consistency. Subjects: Methodology (stat.ME) Cite as: arXiv:2602.23355 [stat.ME] (or arXiv:2602.23355v1 [stat.ME] for this version) https://doi.org/10.48550/arXiv.2602.23355 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Jongwoo Choi [ view email ] [v1] Thu, 26 Feb 2026 18:57:26 UTC (3,599 KB) Full-text links: Access Paper: View a PDF of the paper titled Robust model selection using likelihood as data, by Jongwoo Choi and 2 other authors View PDF TeX Source view license Current browse context: stat.ME &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: stat References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-18">10. Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23357v1</li>
<li>来源：arxiv</li>
<li>摘要：Bio-inspired event cameras have recently attracted significant research due to their asynchronous and low-latency capabilities. These features provide a high dynamic range and significantly reduce motion blur. However, because of the novelty in the nature of their output signals, there is a gap in the variability of available data and a lack of extensive analysis of the parameters characterizing their signals. This paper addresses these issues by providing readers with an in-depth understanding of how intrinsic parameters affect the performance of a model trained on event data, specifically for object detection. We also use our findings to expand the capabilities of the downstream model towards sensor-agnostic robustness.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-19">正文（抓取，非 AI）</h3>
<p>[2602.23357v1] Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23357v1 (cs) [Submitted on 26 Feb 2026] Title: Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training Authors: Aheli Saha , René Schuster , Didier Stricker View a PDF of the paper titled Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training, by Aheli Saha and 2 other authors View PDF HTML (experimental) Abstract: Bio-inspired event cameras have recently attracted significant research due to their asynchronous and low-latency capabilities. These features provide a high dynamic range and significantly reduce motion blur. However, because of the novelty in the nature of their output signals, there is a gap in the variability of available data and a lack of extensive analysis of the parameters characterizing their signals. This paper addresses these issues by providing readers with an in-depth understanding of how intrinsic parameters affect the performance of a model trained on event data, specifically for object detection. We also use our findings to expand the capabilities of the downstream model towards sensor-agnostic robustness. Comments: 12 pages, International Conference on Pattern Recognition Applications and Methods Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.23357 [cs.CV] (or arXiv:2602.23357v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23357 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Aheli Saha [ view email ] [v1] Thu, 26 Feb 2026 18:57:52 UTC (2,819 KB) Full-text links: Access Paper: View a PDF of the paper titled Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training, by Aheli Saha and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-20">11. On the embedding transformation for optimal control of multi-mode switched systems</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.12883v1</li>
<li>来源：arxiv</li>
<li>摘要：This paper develops an embedding-based approach to solve switched optimal control problems (SOCPs) with an arbitrary number of subsystems. Initially, the discrete switching signal is represented by a set of binary variables, encoding each mode in binary format. An embedded optimal control problem (EOCP) is then formulated by replacing these binary variables with continuous embedded variables that can take intermediate values between zero and one. Although embedding allows SOCPs to be addressed using conventional techniques, the optimal solutions of EOCPs often yield intermediate values for binary variables, which may not be feasible for the original SOCP. To address this challenge, a modified EOCP (MEOCP) is introduced by adding a concave auxiliary cost function of appropriate dimensionality to the main cost function. This addition ensures that the optimal solution of the EOCP is bang-bang, and as a result, feasible for the original SOCP.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-21">正文（抓取，非 AI）</h3>
<p>[2512.12883v1] On the embedding transformation for optimal control of multi-mode switched systems Electrical Engineering and Systems Science &gt; Systems and Control arXiv:2512.12883v1 (eess) [Submitted on 14 Dec 2025] Title: On the embedding transformation for optimal control of multi-mode switched systems Authors: Masoud S. Sakha , Rushikesh Kamalapurkar View a PDF of the paper titled On the embedding transformation for optimal control of multi-mode switched systems, by Masoud S. Sakha and 1 other authors View PDF HTML (experimental) Abstract: This paper develops an embedding-based approach to solve switched optimal control problems (SOCPs) with an arbitrary number of subsystems. Initially, the discrete switching signal is represented by a set of binary variables, encoding each mode in binary format. An embedded optimal control problem (EOCP) is then formulated by replacing these binary variables with continuous embedded variables that can take intermediate values between zero and one. Although embedding allows SOCPs to be addressed using conventional techniques, the optimal solutions of EOCPs often yield intermediate values for binary variables, which may not be feasible for the original SOCP. To address this challenge, a modified EOCP (MEOCP) is introduced by adding a concave auxiliary cost function of appropriate dimensionality to the main cost function. This addition ensures that the optimal solution of the EOCP is bang-bang, and as a result, feasible for the original SOCP. Subjects: Systems and Control (eess.SY) ; Optimization and Control (math.OC) Cite as: arXiv:2512.12883 [eess.SY] (or arXiv:2512.12883v1 [eess.SY] for this version) https://doi.org/10.48550/arXiv.2512.12883 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Masoud Sakha [ view email ] [v1] Sun, 14 Dec 2025 23:56:07 UTC (928 KB) Full-text links: Access Paper: View a PDF of the paper titled On the embedding transformation for optimal control of multi-mode switched systems, by Masoud S. Sakha and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SY &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs cs.SY eess math math.OC References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-22">12. VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23361v1</li>
<li>来源：arxiv</li>
<li>摘要：We present a scalable 3D reconstruction model that addresses a critical limitation in offline feed-forward methods: their computational and memory requirements grow quadratically w.r.t. the number of input images. Our approach is built on the key insight that this bottleneck stems from the varying-length Key-Value (KV) space representation of scene geometry, which we distill into a fixed-size Multi-Layer Perceptron (MLP) via test-time training. VGG-T$^3$ (Visual Geometry Grounded Test Time Training) scales linearly w.r.t. the number of input views, similar to online models, and reconstructs a $1k$ image collection in just $54$ seconds, achieving a $11.6\times$ speed-up over baselines that rely on softmax attention. Since our method retains global scene aggregation capability, our point map reconstruction error outperforming other linear-time methods by large margins. Finally, we demonstrate visual localization capabilities of our model by querying the scene representation with unseen images.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-23">正文（抓取，非 AI）</h3>
<p>[2602.23361v1] VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23361v1 (cs) [Submitted on 26 Feb 2026] Title: VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale Authors: Sven Elflein , Ruilong Li , Sérgio Agostinho , Zan Gojcic , Laura Leal-Taixé , Qunjie Zhou , Aljosa Osep View a PDF of the paper titled VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale, by Sven Elflein and 6 other authors View PDF HTML (experimental) Abstract: We present a scalable 3D reconstruction model that addresses a critical limitation in offline feed-forward methods: their computational and memory requirements grow quadratically w.r.t. the number of input images. Our approach is built on the key insight that this bottleneck stems from the varying-length Key-Value (KV) space representation of scene geometry, which we distill into a fixed-size Multi-Layer Perceptron (MLP) via test-time training. VGG-T$^3$ (Visual Geometry Grounded Test Time Training) scales linearly w.r.t. the number of input views, similar to online models, and reconstructs a $1k$ image collection in just $54$ seconds, achieving a $11.6\times$ speed-up over baselines that rely on softmax attention. Since our method retains global scene aggregation capability, our point map reconstruction error outperforming other linear-time methods by large margins. Finally, we demonstrate visual localization capabilities of our model by querying the scene representation with unseen images. Comments: CVPR 2026, Project page: this https URL Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.23361 [cs.CV] (or arXiv:2602.23361v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23361 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Sven Elflein [ view email ] [v1] Thu, 26 Feb 2026 18:59:33 UTC (23,221 KB) Full-text links: Access Paper: View a PDF of the paper titled VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale, by Sven Elflein and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-24">13. CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23276v1</li>
<li>来源：arxiv</li>
<li>摘要：Chest X-ray plays a central role in thoracic diagnosis, and its interpretation inherently requires multi-step, evidence-grounded reasoning. However, large vision-language models (LVLMs) often generate plausible responses that are not faithfully grounded in diagnostic evidence and provide limited visual evidence for verification, while also requiring costly retraining to support new diagnostic tasks, limiting their reliability and adaptability in clinical settings. To address these limitations, we present CXReasonAgent, a diagnostic agent that integrates a large language model (LLM) with clinically grounded diagnostic tools to perform evidence-grounded diagnostic reasoning using image-derived diagnostic and visual evidence. To evaluate these capabilities, we introduce CXReasonDial, a multi-turn dialogue benchmark with 1,946 dialogues across 12 diagnostic tasks, and show that CXReasonAgent produces faithfully grounded responses, enabling more reliable and verifiable diagnostic reasoning than LVLMs. These findings highlight the importance of integrating clinically grounded diagnostic tools, particularly in safety-critical clinical settings.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-25">正文（抓取，非 AI）</h3>
<p>[2602.23276v1] CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays Computer Science &gt; Artificial Intelligence arXiv:2602.23276v1 (cs) [Submitted on 26 Feb 2026] Title: CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays Authors: Hyungyung Lee , Hangyul Yoon , Edward Choi View a PDF of the paper titled CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays, by Hyungyung Lee and 2 other authors View PDF HTML (experimental) Abstract: Chest X-ray plays a central role in thoracic diagnosis, and its interpretation inherently requires multi-step, evidence-grounded reasoning. However, large vision-language models (LVLMs) often generate plausible responses that are not faithfully grounded in diagnostic evidence and provide limited visual evidence for verification, while also requiring costly retraining to support new diagnostic tasks, limiting their reliability and adaptability in clinical settings. To address these limitations, we present CXReasonAgent, a diagnostic agent that integrates a large language model (LLM) with clinically grounded diagnostic tools to perform evidence-grounded diagnostic reasoning using image-derived diagnostic and visual evidence. To evaluate these capabilities, we introduce CXReasonDial, a multi-turn dialogue benchmark with 1,946 dialogues across 12 diagnostic tasks, and show that CXReasonAgent produces faithfully grounded responses, enabling more reliable and verifiable diagnostic reasoning than LVLMs. These findings highlight the importance of integrating clinically grounded diagnostic tools, particularly in safety-critical clinical settings. Subjects: Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23276 [cs.AI] (or arXiv:2602.23276v1 [cs.AI] for this version) https://doi.org/10.48550/arXiv.2602.23276 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Hyungyung Lee [ view email ] [v1] Thu, 26 Feb 2026 17:51:21 UTC (18,344 KB) Full-text links: Access Paper: View a PDF of the paper titled CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays, by Hyungyung Lee and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.AI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-26">14. EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2511.08396v1</li>
<li>来源：arxiv</li>
<li>摘要：Multivariate time series forecasting is crucial across a wide range of domains. While presenting notable progress for the Transformer architecture, iTransformer still lags behind the latest MLP-based models. We attribute this performance gap to unstable inter-channel relationships. To bridge this gap, we propose EMAformer, a simple yet effective model that enhances the Transformer with an auxiliary embedding suite, akin to armor that reinforces its ability. By introducing three key inductive biases, i.e., \textit{global stability}, \textit{phase sensitivity}, and \textit{cross-axis specificity}, EMAformer unlocks the further potential of the Transformer architecture, achieving state-of-the-art performance on 12 real-world benchmarks and reducing forecasting errors by an average of 2.73\% in MSE and 5.15\% in MAE. This significantly advances the practical applicability of Transformer-based approaches for multivariate time series forecasting. The code is available on https://github.com/PlanckChang/EMAformer.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-27">正文（抓取，非 AI）</h3>
<p>[2511.08396v1] EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting Computer Science &gt; Machine Learning arXiv:2511.08396v1 (cs) [Submitted on 11 Nov 2025] Title: EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting Authors: Zhiwei Zhang , Xinyi Du , Xuanchi Guo , Weihao Wang , Wenjuan Han View a PDF of the paper titled EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting, by Zhiwei Zhang and 4 other authors View PDF HTML (experimental) Abstract: Multivariate time series forecasting is crucial across a wide range of domains. While presenting notable progress for the Transformer architecture, iTransformer still lags behind the latest MLP-based models. We attribute this performance gap to unstable inter-channel relationships. To bridge this gap, we propose EMAformer, a simple yet effective model that enhances the Transformer with an auxiliary embedding suite, akin to armor that reinforces its ability. By introducing three key inductive biases, i.e., \textit{global stability}, \textit{phase sensitivity}, and \textit{cross-axis specificity}, EMAformer unlocks the further potential of the Transformer architecture, achieving state-of-the-art performance on 12 real-world benchmarks and reducing forecasting errors by an average of 2.73\% in MSE and 5.15\% in MAE. This significantly advances the practical applicability of Transformer-based approaches for multivariate time series forecasting. The code is available on this https URL . Comments: 14 pages, 9 figures, 6 tables, accepted by AAAI2026 Subjects: Machine Learning (cs.LG) Cite as: arXiv:2511.08396 [cs.LG] (or arXiv:2511.08396v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2511.08396 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Zhiwei Zhang [ view email ] [v1] Tue, 11 Nov 2025 16:12:44 UTC (402 KB) Full-text links: Access Paper: View a PDF of the paper titled EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting, by Zhiwei Zhang and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-11 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-28">15. Millimeter-Wave RIS: Hardware Design and System-Level Considerations</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23345v1</li>
<li>来源：arxiv</li>
<li>摘要：Reconfigurable intelligent surfaces have emerged as a promising hardware platform for shaping wireless propagation environments at millimeter-wave (mm-Wave) frequencies and beyond. While many existing studies emphasize channel modeling and signal processing, practical RIS deployment is fundamentally governed by hardware design choices and their system-level implications. This paper presents a hardware-centric overview of recent mm-Wave RIS developments, covering wideband realizations, high-resolution phase-quantized designs, fully printed low-cost implementations, optically transparent surfaces, RIS-on-chip solutions, and emerging three-dimensional architectures. Key challenges including mutual coupling, calibration, multi-RIS interaction, and frequency-dependent phase control are discussed to bridge hardware realization with system-level optimization. This overview provides practical design insights and aims to guide future RIS research toward scalable, efficient, and practically deployable intelligent surface architectures.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-29">正文（抓取，非 AI）</h3>
<p>[2602.23345v1] Millimeter-Wave RIS: Hardware Design and System-Level Considerations Electrical Engineering and Systems Science &gt; Systems and Control arXiv:2602.23345v1 (eess) [Submitted on 26 Feb 2026] Title: Millimeter-Wave RIS: Hardware Design and System-Level Considerations Authors: Ruiqi Wang , Pinjun Zheng , Yiming Yang , Xiarui Su , Mohammad Vaseem , Anas Chaaban , Md. Jahangir Hossain , Tareq Y. Al-Naffouri , Atif Shamim View a PDF of the paper titled Millimeter-Wave RIS: Hardware Design and System-Level Considerations, by Ruiqi Wang and 7 other authors View PDF HTML (experimental) Abstract: Reconfigurable intelligent surfaces have emerged as a promising hardware platform for shaping wireless propagation environments at millimeter-wave (mm-Wave) frequencies and beyond. While many existing studies emphasize channel modeling and signal processing, practical RIS deployment is fundamentally governed by hardware design choices and their system-level implications. This paper presents a hardware-centric overview of recent mm-Wave RIS developments, covering wideband realizations, high-resolution phase-quantized designs, fully printed low-cost implementations, optically transparent surfaces, RIS-on-chip solutions, and emerging three-dimensional architectures. Key challenges including mutual coupling, calibration, multi-RIS interaction, and frequency-dependent phase control are discussed to bridge hardware realization with system-level optimization. This overview provides practical design insights and aims to guide future RIS research toward scalable, efficient, and practically deployable intelligent surface architectures. Subjects: Systems and Control (eess.SY) Cite as: arXiv:2602.23345 [eess.SY] (or arXiv:2602.23345v1 [eess.SY] for this version) https://doi.org/10.48550/arXiv.2602.23345 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Ruiqi Wang [ view email ] [v1] Thu, 26 Feb 2026 18:49:53 UTC (29,193 KB) Full-text links: Access Paper: View a PDF of the paper titled Millimeter-Wave RIS: Hardware Design and System-Level Considerations, by Ruiqi Wang and 7 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SY &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.SY eess References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-30">16. Butterfly Echo Protocol for Axis-Agnostic Heisenberg-Limited Metrology</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23332v1</li>
<li>来源：arxiv</li>
<li>摘要：The extreme sensitivity of chaotic systems to external perturbations makes them natural candidates for sensing applications. We propose a single-shot echo-based protocol for estimating small rotations about an unknown axis that leverages random symmetric probe states prepared via chaotic dynamics. In contrast to previous protocols for this axis-agnostic rotation sensing problem that depend on difficult-to-prepare anticoherent states, the random probe states used in our protocol can be prepared via constant-depth chaotic circuits composed of random one-axis twisting pulses. We demonstrate analytically that our protocol achieves Heisenberg scaling relative to an arbitrary rotation axis that need not be a priori known. We also investigate the effects of collective and single-particle dephasing in our protocol using analytical and numerical tools. While the requirements on dephasing rates to maintain Heisenberg sensitivity are strict, they are achievable in near-term experiments, for instance, for magnetometric rotosensing with high-spin lanthanide atoms such as dysprosium-164.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-31">正文（抓取，非 AI）</h3>
<p>[2602.23332v1] Butterfly Echo Protocol for Axis-Agnostic Heisenberg-Limited Metrology Quantum Physics arXiv:2602.23332v1 (quant-ph) [Submitted on 26 Feb 2026] Title: Butterfly Echo Protocol for Axis-Agnostic Heisenberg-Limited Metrology Authors: Jacob Bringewatt , Leon Zaporski , Matthew Radzihovsky , Jasmine Albert , Alexey V. Gorshkov , Vladan Vuletic , Gregory Bentsen View a PDF of the paper titled Butterfly Echo Protocol for Axis-Agnostic Heisenberg-Limited Metrology, by Jacob Bringewatt and 6 other authors View PDF HTML (experimental) Abstract: The extreme sensitivity of chaotic systems to external perturbations makes them natural candidates for sensing applications. We propose a single-shot echo-based protocol for estimating small rotations about an unknown axis that leverages random symmetric probe states prepared via chaotic dynamics. In contrast to previous protocols for this axis-agnostic rotation sensing problem that depend on difficult-to-prepare anticoherent states, the random probe states used in our protocol can be prepared via constant-depth chaotic circuits composed of random one-axis twisting pulses. We demonstrate analytically that our protocol achieves Heisenberg scaling relative to an arbitrary rotation axis that need not be a priori known. We also investigate the effects of collective and single-particle dephasing in our protocol using analytical and numerical tools. While the requirements on dephasing rates to maintain Heisenberg sensitivity are strict, they are achievable in near-term experiments, for instance, for magnetometric rotosensing with high-spin lanthanide atoms such as dysprosium-164. Comments: 7 pages, 4 figures + 16 page supplement Subjects: Quantum Physics (quant-ph) Cite as: arXiv:2602.23332 [quant-ph] (or arXiv:2602.23332v1 [quant-ph] for this version) https://doi.org/10.48550/arXiv.2602.23332 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Gregory Bentsen [ view email ] [v1] Thu, 26 Feb 2026 18:38:01 UTC (5,623 KB) Full-text links: Access Paper: View a PDF of the paper titled Butterfly Echo Protocol for Axis-Agnostic Heisenberg-Limited Metrology, by Jacob Bringewatt and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: quant-ph &lt; prev | next &gt; new | recent | 2026-02 References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-32">17. Differentiable Zero-One Loss via Hypersimplex Projections</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23336v1</li>
<li>来源：arxiv</li>
<li>摘要：Recent advances in machine learning have emphasized the integration of structured optimization components into end-to-end differentiable models, enabling richer inductive biases and tighter alignment with task-specific objectives. In this work, we introduce a novel differentiable approximation to the zero-one loss-long considered the gold standard for classification performance, yet incompatible with gradient-based optimization due to its non-differentiability. Our method constructs a smooth, order-preserving projection onto the n,k-dimensional hypersimplex through a constrained optimization framework, leading to a new operator we term Soft-Binary-Argmax. After deriving its mathematical properties, we show how its Jacobian can be efficiently computed and integrated into binary and multiclass learning systems. Empirically, our approach achieves significant improvements in generalization under large-batch training by imposing geometric consistency constraints on the output logits, thereby narrowing the performance gap traditionally observed in large-batch training.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-33">正文（抓取，非 AI）</h3>
<p>[2602.23336v1] Differentiable Zero-One Loss via Hypersimplex Projections Computer Science &gt; Machine Learning arXiv:2602.23336v1 (cs) [Submitted on 26 Feb 2026] Title: Differentiable Zero-One Loss via Hypersimplex Projections Authors: Camilo Gomez , Pengyang Wang , Liansheng Tang View a PDF of the paper titled Differentiable Zero-One Loss via Hypersimplex Projections, by Camilo Gomez and 2 other authors View PDF HTML (experimental) Abstract: Recent advances in machine learning have emphasized the integration of structured optimization components into end-to-end differentiable models, enabling richer inductive biases and tighter alignment with task-specific objectives. In this work, we introduce a novel differentiable approximation to the zero-one loss-long considered the gold standard for classification performance, yet incompatible with gradient-based optimization due to its non-differentiability. Our method constructs a smooth, order-preserving projection onto the n,k-dimensional hypersimplex through a constrained optimization framework, leading to a new operator we term Soft-Binary-Argmax. After deriving its mathematical properties, we show how its Jacobian can be efficiently computed and integrated into binary and multiclass learning systems. Empirically, our approach achieves significant improvements in generalization under large-batch training by imposing geometric consistency constraints on the output logits, thereby narrowing the performance gap traditionally observed in large-batch training. Comments: To appear in PAKDD 2026 (Pacific-Asia Conference on Knowledge Discovery and Data Mining), 12 pages Subjects: Machine Learning (cs.LG) ; Machine Learning (stat.ML) Cite as: arXiv:2602.23336 [cs.LG] (or arXiv:2602.23336v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23336 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Camilo Gomez [ view email ] [v1] Thu, 26 Feb 2026 18:41:31 UTC (100 KB) Full-text links: Access Paper: View a PDF of the paper titled Differentiable Zero-One Loss via Hypersimplex Projections, by Camilo Gomez and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs stat stat.ML References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-34">18. Towards Joint Optimization for UAV-Integrated RIS-Assisted Fluid Antenna Systems</h2>
<ul>
<li>链接：https://arxiv.org/abs/2601.22109v1</li>
<li>来源：arxiv</li>
<li>摘要：Unmanned aerial vehicles (UAVs) integrated into cellular networks face significant challenges from air-to-ground interference. To address this, we propose a downlink UAV communication system that leverages a fluid antenna system (FAS)- assisted reconfigurable intelligent surface (RIS) to enhance signal quality. By jointly optimizing the FAS port positions and RIS phase shifts, we maximize the achievable rate. The resulting nonconvex optimization problem is solved using successive convex approximation (SCA) based on second-order cone programming (SOCP), which reformulates the constraints into a tractable form. Simulation results show that the proposed algorithm significantly improves both outage probability and achievable rate over conventional fixed-position antenna (FPA) schemes, with particularly large gains in large-scale RIS configurations. Moreover, the algorithm converges rapidly, making it suitable for real-time applications</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-35">正文（抓取，非 AI）</h3>
<p>[2601.22109v1] Towards Joint Optimization for UAV-Integrated RIS-Assisted Fluid Antenna Systems Electrical Engineering and Systems Science &gt; Signal Processing arXiv:2601.22109v1 (eess) [Submitted on 29 Jan 2026] Title: Towards Joint Optimization for UAV-Integrated RIS-Assisted Fluid Antenna Systems Authors: Ali Reda , Tamer Mekkawy , Theodoros A. Tsiftsis , Chan-Byoung Chae , Kai-Kit Wong View a PDF of the paper titled Towards Joint Optimization for UAV-Integrated RIS-Assisted Fluid Antenna Systems, by Ali Reda and 4 other authors View PDF HTML (experimental) Abstract: Unmanned aerial vehicles (UAVs) integrated into cellular networks face significant challenges from air-to-ground interference. To address this, we propose a downlink UAV communication system that leverages a fluid antenna system (FAS)- assisted reconfigurable intelligent surface (RIS) to enhance signal quality. By jointly optimizing the FAS port positions and RIS phase shifts, we maximize the achievable rate. The resulting nonconvex optimization problem is solved using successive convex approximation (SCA) based on second-order cone programming (SOCP), which reformulates the constraints into a tractable form. Simulation results show that the proposed algorithm significantly improves both outage probability and achievable rate over conventional fixed-position antenna (FPA) schemes, with particularly large gains in large-scale RIS configurations. Moreover, the algorithm converges rapidly, making it suitable for real-time applications Comments: 11 pages, 8 figures Subjects: Signal Processing (eess.SP) Cite as: arXiv:2601.22109 [eess.SP] (or arXiv:2601.22109v1 [eess.SP] for this version) https://doi.org/10.48550/arXiv.2601.22109 Focus to learn more arXiv-issued DOI via DataCite Journal reference: IEEE Transactions on Vehicular Technology, 2026 Related DOI : https://doi.org/10.1109/TVT.2026.3658088 Focus to learn more DOI(s) linking to related resources Submission history From: Theodoros Tsiftsis Prof. [ view email ] [v1] Thu, 29 Jan 2026 18:38:38 UTC (536 KB) Full-text links: Access Paper: View a PDF of the paper titled Towards Joint Optimization for UAV-Integrated RIS-Assisted Fluid Antenna Systems, by Ali Reda and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SP &lt; prev | next &gt; new | recent | 2026-01 Change to browse by: eess References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-36">19. An Optimization Method for Autoregressive Time Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.02288v1</li>
<li>来源：arxiv</li>
<li>摘要：Current time-series forecasting models are primarily based on transformer-style neural networks. These models achieve long-term forecasting mainly by scaling up the model size rather than through genuinely autoregressive (AR) rollout. From the perspective of large language model training, the traditional training process for time-series forecasting models ignores temporal causality. In this paper, we propose a novel training method for time-series forecasting that enforces two key properties: (1) AR prediction errors should increase with the forecasting horizon. Any violation of this principle is considered random guessing and is explicitly penalized in the loss function, and (2) the method enables models to concatenate short-term AR predictions for forming flexible long-term forecasts. Empirical results demonstrate that our method establishes a new state-of-the-art across multiple benchmarks, achieving an MSE reduction of more than 10% compared to iTransformer and other recent strong baselines. Furthermore, it enables short-horizon forecasting models to perform reliable long-term predictions at horizons over 7.5 times longer. Code is available at https://github.com/LizhengMathAi/A</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-37">正文（抓取，非 AI）</h3>
<p>[2602.02288v1] An Optimization Method for Autoregressive Time Series Forecasting Computer Science &gt; Machine Learning arXiv:2602.02288v1 (cs) [Submitted on 2 Feb 2026] Title: An Optimization Method for Autoregressive Time Series Forecasting Authors: Zheng Li , Jerry Cheng , Huanying Gu View a PDF of the paper titled An Optimization Method for Autoregressive Time Series Forecasting, by Zheng Li and 2 other authors View PDF HTML (experimental) Abstract: Current time-series forecasting models are primarily based on transformer-style neural networks. These models achieve long-term forecasting mainly by scaling up the model size rather than through genuinely autoregressive (AR) rollout. From the perspective of large language model training, the traditional training process for time-series forecasting models ignores temporal causality. In this paper, we propose a novel training method for time-series forecasting that enforces two key properties: (1) AR prediction errors should increase with the forecasting horizon. Any violation of this principle is considered random guessing and is explicitly penalized in the loss function, and (2) the method enables models to concatenate short-term AR predictions for forming flexible long-term forecasts. Empirical results demonstrate that our method establishes a new state-of-the-art across multiple benchmarks, achieving an MSE reduction of more than 10% compared to iTransformer and other recent strong baselines. Furthermore, it enables short-horizon forecasting models to perform reliable long-term predictions at horizons over 7.5 times longer. Code is available at this https URL Comments: 10 pages, 2 figures, 2 tables Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.02288 [cs.LG] (or arXiv:2602.02288v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.02288 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Zheng Li [ view email ] [v1] Mon, 2 Feb 2026 16:28:00 UTC (242 KB) Full-text links: Access Paper: View a PDF of the paper titled An Optimization Method for Autoregressive Time Series Forecasting, by Zheng Li and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-38">20. Arrested Relaxation in a Disorder-Free Coulomb Spin Liquid</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23362v1</li>
<li>来源：arxiv</li>
<li>摘要：We investigate Coulomb spin liquids in classical spin-3/2 ice and show that the enlarged on-site Hilbert space gives rise to a qualitatively new class of such phases. Beyond the conventional magnetic monopoles of spin-1/2 ice, the system hosts additional low-energy crystal-field excitations, whose interplay with monopoles significantly modifies both equilibrium and non-equilibrium properties. Following a thermal quench, we find a pronounced dynamical arrest manifested in an exponentially long-lived {athermal} plateau in spin autocorrelations. This constitutes a rare example of dynamical arrest in a short-range interacting, disorder-free system. We demonstrate that the arrested dynamics originate from novel composite excitation structures unique to spin-3/2 ice and from kinetically constrained relaxation pathways that require activated processes. Our results establish higher-spin ice as a fertile platform for realising unconventional Coulomb spin liquids and dynamical arrest without quenched disorder.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-39">正文（抓取，非 AI）</h3>
<p>[2602.23362v1] Arrested Relaxation in a Disorder-Free Coulomb Spin Liquid Condensed Matter &gt; Strongly Correlated Electrons arXiv:2602.23362v1 (cond-mat) [Submitted on 26 Feb 2026] Title: Arrested Relaxation in a Disorder-Free Coulomb Spin Liquid Authors: Souvik Kundu , Arnab Seth , Sthitadhi Roy , Subhro Bhattacharjee , Roderich Moessner View a PDF of the paper titled Arrested Relaxation in a Disorder-Free Coulomb Spin Liquid, by Souvik Kundu and 4 other authors View PDF HTML (experimental) Abstract: We investigate Coulomb spin liquids in classical spin-3/2 ice and show that the enlarged on-site Hilbert space gives rise to a qualitatively new class of such phases. Beyond the conventional magnetic monopoles of spin-1/2 ice, the system hosts additional low-energy crystal-field excitations, whose interplay with monopoles significantly modifies both equilibrium and non-equilibrium properties. Following a thermal quench, we find a pronounced dynamical arrest manifested in an exponentially long-lived {athermal} plateau in spin autocorrelations. This constitutes a rare example of dynamical arrest in a short-range interacting, disorder-free system. We demonstrate that the arrested dynamics originate from novel composite excitation structures unique to spin-3/2 ice and from kinetically constrained relaxation pathways that require activated processes. Our results establish higher-spin ice as a fertile platform for realising unconventional Coulomb spin liquids and dynamical arrest without quenched disorder. Comments: 8 pages, 9 figures + Supplementary Material (2 pages) Subjects: Strongly Correlated Electrons (cond-mat.str-el) ; Statistical Mechanics (cond-mat.stat-mech) Cite as: arXiv:2602.23362 [cond-mat.str-el] (or arXiv:2602.23362v1 [cond-mat.str-el] for this version) https://doi.org/10.48550/arXiv.2602.23362 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Sthitadhi Roy [ view email ] [v1] Thu, 26 Feb 2026 18:59:34 UTC (1,257 KB) Full-text links: Access Paper: View a PDF of the paper titled Arrested Relaxation in a Disorder-Free Coulomb Spin Liquid, by Souvik Kundu and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cond-mat.str-el &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cond-mat cond-mat.stat-mech References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-40">21. Selective Learning for Deep Time Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2510.25207v1</li>
<li>来源：arxiv</li>
<li>摘要：Benefiting from high capacity for capturing complex temporal patterns, deep learning (DL) has significantly advanced time series forecasting (TSF). However, deep models tend to suffer from severe overfitting due to the inherent vulnerability of time series to noise and anomalies. The prevailing DL paradigm uniformly optimizes all timesteps through the MSE loss and learns those uncertain and anomalous timesteps without difference, ultimately resulting in overfitting. To address this, we propose a novel selective learning strategy for deep TSF. Specifically, selective learning screens a subset of the whole timesteps to calculate the MSE loss in optimization, guiding the model to focus on generalizable timesteps while disregarding non-generalizable ones. Our framework introduces a dual-mask mechanism to target timesteps: (1) an uncertainty mask leveraging residual entropy to filter uncertain timesteps, and (2) an anomaly mask employing residual lower bound estimation to exclude anomalous timesteps. Extensive experiments across eight real-world datasets demonstrate that selective learning can significantly improve the predictive performance for typical state-of-the-art deep models, inc</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-41">正文（抓取，非 AI）</h3>
<p>[2510.25207v1] Selective Learning for Deep Time Series Forecasting Computer Science &gt; Machine Learning arXiv:2510.25207v1 (cs) [Submitted on 29 Oct 2025] Title: Selective Learning for Deep Time Series Forecasting Authors: Yisong Fu , Zezhi Shao , Chengqing Yu , Yujie Li , Zhulin An , Qi Wang , Yongjun Xu , Fei Wang View a PDF of the paper titled Selective Learning for Deep Time Series Forecasting, by Yisong Fu and 7 other authors View PDF Abstract: Benefiting from high capacity for capturing complex temporal patterns, deep learning (DL) has significantly advanced time series forecasting (TSF). However, deep models tend to suffer from severe overfitting due to the inherent vulnerability of time series to noise and anomalies. The prevailing DL paradigm uniformly optimizes all timesteps through the MSE loss and learns those uncertain and anomalous timesteps without difference, ultimately resulting in overfitting. To address this, we propose a novel selective learning strategy for deep TSF. Specifically, selective learning screens a subset of the whole timesteps to calculate the MSE loss in optimization, guiding the model to focus on generalizable timesteps while disregarding non-generalizable ones. Our framework introduces a dual-mask mechanism to target timesteps: (1) an uncertainty mask leveraging residual entropy to filter uncertain timesteps, and (2) an anomaly mask employing residual lower bound estimation to exclude anomalous timesteps. Extensive experiments across eight real-world datasets demonstrate that selective learning can significantly improve the predictive performance for typical state-of-the-art deep models, including 37.4% MSE reduction for Informer, 8.4% for TimesNet, and 6.5% for iTransformer. Comments: Accepted by NeurIPS 2025 Subjects: Machine Learning (cs.LG) Cite as: arXiv:2510.25207 [cs.LG] (or arXiv:2510.25207v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2510.25207 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Yisong Fu [ view email ] [v1] Wed, 29 Oct 2025 06:18:52 UTC (2,743 KB) Full-text links: Access Paper: View a PDF of the paper titled Selective Learning for Deep Time Series Forecasting, by Yisong Fu and 7 other authors View PDF TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-10 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-42">22. Learning Contact Policies for SEIR Epidemics on Networks: A Mean-Field Game Approach</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23344v1</li>
<li>来源：arxiv</li>
<li>摘要：In this paper, we develop a mean-field game model for SEIR epidemics on heterogeneous contact networks, where individuals choose state-dependent contact effort to balance infection losses against the social and economic costs of isolation. The Nash equilibrium is characterized by a coupled Hamilton--Jacobi--Bellman/Kolmogorov system across degree classes. An important feature of the SEIR setting is the exposed compartment: the incubation period separates infection from infectiousness and changes incentives after infection occurs. In the baseline formulation, exposed agents optimally maintain full contact, while susceptible agents reduce contact according to an explicit best-response rule driven by infection pressure and the value gap. We also discuss extensions that yield nontrivial exposed precaution by introducing responsibility or compliance incentives. We establish existence of equilibrium via a fixed-point argument and prove the uniqueness under a suitable monotonicity condition. The analysis identifies a delay in the onset of precaution under longer incubation, which can lead to weaker behavioral responses and larger outbreaks. Numerical experiments illustrate how network deg</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-43">正文（抓取，非 AI）</h3>
<p>[2602.23344v1] Learning Contact Policies for SEIR Epidemics on Networks: A Mean-Field Game Approach Quantitative Biology &gt; Populations and Evolution arXiv:2602.23344v1 (q-bio) [Submitted on 26 Feb 2026] Title: Learning Contact Policies for SEIR Epidemics on Networks: A Mean-Field Game Approach Authors: Weinan Wang View a PDF of the paper titled Learning Contact Policies for SEIR Epidemics on Networks: A Mean-Field Game Approach, by Weinan Wang View PDF HTML (experimental) Abstract: In this paper, we develop a mean-field game model for SEIR epidemics on heterogeneous contact networks, where individuals choose state-dependent contact effort to balance infection losses against the social and economic costs of isolation. The Nash equilibrium is characterized by a coupled Hamilton--Jacobi--Bellman/Kolmogorov system across degree classes. An important feature of the SEIR setting is the exposed compartment: the incubation period separates infection from infectiousness and changes incentives after infection occurs. In the baseline formulation, exposed agents optimally maintain full contact, while susceptible agents reduce contact according to an explicit best-response rule driven by infection pressure and the value gap. We also discuss extensions that yield nontrivial exposed precaution by introducing responsibility or compliance incentives. We establish existence of equilibrium via a fixed-point argument and prove the uniqueness under a suitable monotonicity condition. The analysis identifies a delay in the onset of precaution under longer incubation, which can lead to weaker behavioral responses and larger outbreaks. Numerical experiments illustrate how network degree and the cost exponent shape equilibrium policies and epidemic outcomes. Subjects: Populations and Evolution (q-bio.PE) Cite as: arXiv:2602.23344 [q-bio.PE] (or arXiv:2602.23344v1 [q-bio.PE] for this version) https://doi.org/10.48550/arXiv.2602.23344 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Weinan Wang [ view email ] [v1] Thu, 26 Feb 2026 18:48:55 UTC (632 KB) Full-text links: Access Paper: View a PDF of the paper titled Learning Contact Policies for SEIR Epidemics on Networks: A Mean-Field Game Approach, by Weinan Wang View PDF HTML (experimental) TeX Source view license Current browse context: q-bio.PE &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: q-bio References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-44">23. TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.12301v1</li>
<li>来源：arxiv</li>
<li>摘要：TwinFormer is a hierarchical Transformer for long-sequence time-series forecasting. It divides the input into non-overlapping temporal patches and processes them in two stages: (1) a Local Informer with top-$k$ Sparse Attention models intra-patch dynamics, followed by mean pooling; (2) a Global Informer captures long-range inter-patch dependencies using the same top-$k$ attention. A lightweight GRU aggregates the globally contextualized patch tokens for direct multi-horizon prediction. The resulting architecture achieves linear $O(kLd)$ time and memory complexity. On eight real-world benchmarking datasets from six different domains, including weather, stock price, temperature, power consumption, electricity, and disease, and forecasting horizons $96-720$, TwinFormer secures $27$ positions in the top two out of $34$. Out of the $27$, it achieves the best performance on MAE and RMSE at $17$ places and $10$ at the second-best place on MAE and RMSE. This consistently outperforms PatchTST, iTransformer, FEDformer, Informer, and vanilla Transformers. Ablations confirm the superiority of top-$k$ Sparse Attention over ProbSparse and the effectiveness of GRU-based aggregation. Code is avail</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-45">正文（抓取，非 AI）</h3>
<p>[2512.12301v1] TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting Computer Science &gt; Machine Learning arXiv:2512.12301v1 (cs) [Submitted on 13 Dec 2025] Title: TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting Authors: Mahima Kumavat , Aditya Maheshwari View a PDF of the paper titled TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting, by Mahima Kumavat and Aditya Maheshwari View PDF HTML (experimental) Abstract: TwinFormer is a hierarchical Transformer for long-sequence time-series forecasting. It divides the input into non-overlapping temporal patches and processes them in two stages: (1) a Local Informer with top-$k$ Sparse Attention models intra-patch dynamics, followed by mean pooling; (2) a Global Informer captures long-range inter-patch dependencies using the same top-$k$ attention. A lightweight GRU aggregates the globally contextualized patch tokens for direct multi-horizon prediction. The resulting architecture achieves linear $O(kLd)$ time and memory complexity. On eight real-world benchmarking datasets from six different domains, including weather, stock price, temperature, power consumption, electricity, and disease, and forecasting horizons $96-720$, TwinFormer secures $27$ positions in the top two out of $34$. Out of the $27$, it achieves the best performance on MAE and RMSE at $17$ places and $10$ at the second-best place on MAE and RMSE. This consistently outperforms PatchTST, iTransformer, FEDformer, Informer, and vanilla Transformers. Ablations confirm the superiority of top-$k$ Sparse Attention over ProbSparse and the effectiveness of GRU-based aggregation. Code is available at this repository: this https URL . Comments: 14 pages, 4 figures Subjects: Machine Learning (cs.LG) Cite as: arXiv:2512.12301 [cs.LG] (or arXiv:2512.12301v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2512.12301 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Aditya Maheshwari [ view email ] [v1] Sat, 13 Dec 2025 11:50:18 UTC (964 KB) Full-text links: Access Paper: View a PDF of the paper titled TwinFormer: A Dual-Level Transformer for Long-Sequence Time-Series Forecasting, by Mahima Kumavat and Aditya Maheshwari View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-46">24. Constrained Policy Optimization via Sampling-Based Weight-Space Projection</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.13788v1</li>
<li>来源：arxiv</li>
<li>摘要：Safety-critical learning requires policies that improve performance without leaving the safe operating regime. We study constrained policy learning where model parameters must satisfy unknown, rollout-based safety constraints. We propose SCPO, a sampling-based weight-space projection method that enforces safety directly in parameter space without requiring gradient access to the constraint functions. Our approach constructs a local safe region by combining trajectory rollouts with smoothness bounds that relate parameter changes to shifts in safety metrics. Each gradient update is then projected via a convex SOCP, producing a safe first-order step. We establish a safe-by-induction guarantee: starting from any safe initialization, all intermediate policies remain safe given feasible projections. In constrained control settings with a stabilizing backup policy, our approach further ensures closed-loop stability and enables safe adaptation beyond the conservative backup. On regression with harmful supervision and a constrained double-integrator task with malicious expert, our approach consistently rejects unsafe updates, maintains feasibility throughout training, and achieves meaningfu</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-47">正文（抓取，非 AI）</h3>
<p>[2512.13788v1] Constrained Policy Optimization via Sampling-Based Weight-Space Projection Computer Science &gt; Machine Learning arXiv:2512.13788v1 (cs) [Submitted on 15 Dec 2025] Title: Constrained Policy Optimization via Sampling-Based Weight-Space Projection Authors: Shengfan Cao , Francesco Borrelli View a PDF of the paper titled Constrained Policy Optimization via Sampling-Based Weight-Space Projection, by Shengfan Cao and 1 other authors View PDF HTML (experimental) Abstract: Safety-critical learning requires policies that improve performance without leaving the safe operating regime. We study constrained policy learning where model parameters must satisfy unknown, rollout-based safety constraints. We propose SCPO, a sampling-based weight-space projection method that enforces safety directly in parameter space without requiring gradient access to the constraint functions. Our approach constructs a local safe region by combining trajectory rollouts with smoothness bounds that relate parameter changes to shifts in safety metrics. Each gradient update is then projected via a convex SOCP, producing a safe first-order step. We establish a safe-by-induction guarantee: starting from any safe initialization, all intermediate policies remain safe given feasible projections. In constrained control settings with a stabilizing backup policy, our approach further ensures closed-loop stability and enables safe adaptation beyond the conservative backup. On regression with harmful supervision and a constrained double-integrator task with malicious expert, our approach consistently rejects unsafe updates, maintains feasibility throughout training, and achieves meaningful primal objective improvement. Comments: Submitted to IFAC World Congress 2026 Subjects: Machine Learning (cs.LG) ; Robotics (cs.RO) Cite as: arXiv:2512.13788 [cs.LG] (or arXiv:2512.13788v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2512.13788 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Shengfan Cao [ view email ] [v1] Mon, 15 Dec 2025 19:00:01 UTC (4,002 KB) Full-text links: Access Paper: View a PDF of the paper titled Constrained Policy Optimization via Sampling-Based Weight-Space Projection, by Shengfan Cao and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs cs.RO References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-48">25. Quantum Neural Network Architectures for Multivariate Time-Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2510.21168v1</li>
<li>来源：arxiv</li>
<li>摘要：In this paper, we address the challenge of multivariate time-series forecasting using quantum machine learning techniques. We introduce adaptation strategies that extend variational quantum circuit models, traditionally limited to univariate data, toward the multivariate setting, exploring both purely quantum and hybrid quantum-classical formulations. First, we extend and benchmark several VQC-based and hybrid architectures to systematically evaluate their capacity to model cross-variable dependencies. Second, building upon these foundations, we introduce the iQTransformer, a novel quantum transformer architecture that integrates a quantum self-attention mechanism within the iTransformer framework, enabling a quantum-native representation of inter-variable relationships. Third, we provide a comprehensive empirical evaluation on both synthetic and real-world datasets, showing that quantum-based models may achieve competitive or superior forecasting accuracy with fewer trainable parameters and faster convergence than state-of-the-art classical and quantum baselines in some cases. These contributions highlight the potential of quantum-enhanced architectures as efficient and scalable t</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-49">正文（抓取，非 AI）</h3>
<p>[2510.21168v1] Quantum Neural Network Architectures for Multivariate Time-Series Forecasting Quantum Physics arXiv:2510.21168v1 (quant-ph) [Submitted on 24 Oct 2025] Title: Quantum Neural Network Architectures for Multivariate Time-Series Forecasting Authors: Sandra Ranilla-Cortina , Diego A. Aranda , Jorge Ballesteros , Jesus Bonilla , Nerea Monrio , Elías F. Combarro , Jose Ranilla View a PDF of the paper titled Quantum Neural Network Architectures for Multivariate Time-Series Forecasting, by Sandra Ranilla-Cortina and 6 other authors View PDF HTML (experimental) Abstract: In this paper, we address the challenge of multivariate time-series forecasting using quantum machine learning techniques. We introduce adaptation strategies that extend variational quantum circuit models, traditionally limited to univariate data, toward the multivariate setting, exploring both purely quantum and hybrid quantum-classical formulations. First, we extend and benchmark several VQC-based and hybrid architectures to systematically evaluate their capacity to model cross-variable dependencies. Second, building upon these foundations, we introduce the iQTransformer, a novel quantum transformer architecture that integrates a quantum self-attention mechanism within the iTransformer framework, enabling a quantum-native representation of inter-variable relationships. Third, we provide a comprehensive empirical evaluation on both synthetic and real-world datasets, showing that quantum-based models may achieve competitive or superior forecasting accuracy with fewer trainable parameters and faster convergence than state-of-the-art classical and quantum baselines in some cases. These contributions highlight the potential of quantum-enhanced architectures as efficient and scalable tools for advancing multivariate time-series forecasting. Subjects: Quantum Physics (quant-ph) Cite as: arXiv:2510.21168 [quant-ph] (or arXiv:2510.21168v1 [quant-ph] for this version) https://doi.org/10.48550/arXiv.2510.21168 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Sandra Ranilla-Cortina [ view email ] [v1] Fri, 24 Oct 2025 05:44:41 UTC (708 KB) Full-text links: Access Paper: View a PDF of the paper titled Quantum Neural Network Architectures for Multivariate Time-Series Forecasting, by Sandra Ranilla-Cortina and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: quant-ph &lt; prev | next &gt; new | recent | 2025-10 References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-50">26. FlashOptim: Optimizers for Memory Efficient Training</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23349v1</li>
<li>来源：arxiv</li>
<li>摘要：Standard mixed-precision training of neural networks requires many bytes of accelerator memory for each model parameter. These bytes reflect not just the parameter itself, but also its gradient and one or more optimizer state variables. With each of these values typically requiring 4 bytes, training even a 7 billion parameter model can be impractical for researchers with less than 100GB of accelerator memory.   We introduce FlashOptim, a suite of optimizations that reduces per-parameter memory by over 50% while preserving model quality and API compatibility. Our approach introduces two key techniques. First, we improve master weight splitting by finding and exploiting a tight bound on its quantization error. Second, we design companding functions that greatly reduce the error in 8-bit optimizer state quantization. Together with 16-bit gradients, these techniques reduce AdamW memory from 16 bytes to 7 bytes per parameter, or 5 bytes with gradient release. They also cut model checkpoint sizes by more than half.   Experiments with FlashOptim applied to SGD, AdamW, and Lion show no measurable quality degradation on any task from a collection of standard vision and language benchmarks, </li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-51">正文（抓取，非 AI）</h3>
<p>[2602.23349v1] FlashOptim: Optimizers for Memory Efficient Training Computer Science &gt; Machine Learning arXiv:2602.23349v1 (cs) [Submitted on 26 Feb 2026] Title: FlashOptim: Optimizers for Memory Efficient Training Authors: Jose Javier Gonzalez Ortiz , Abhay Gupta , Chris Renard , Davis Blalock View a PDF of the paper titled FlashOptim: Optimizers for Memory Efficient Training, by Jose Javier Gonzalez Ortiz and 3 other authors View PDF HTML (experimental) Abstract: Standard mixed-precision training of neural networks requires many bytes of accelerator memory for each model parameter. These bytes reflect not just the parameter itself, but also its gradient and one or more optimizer state variables. With each of these values typically requiring 4 bytes, training even a 7 billion parameter model can be impractical for researchers with less than 100GB of accelerator memory. We introduce FlashOptim, a suite of optimizations that reduces per-parameter memory by over 50% while preserving model quality and API compatibility. Our approach introduces two key techniques. First, we improve master weight splitting by finding and exploiting a tight bound on its quantization error. Second, we design companding functions that greatly reduce the error in 8-bit optimizer state quantization. Together with 16-bit gradients, these techniques reduce AdamW memory from 16 bytes to 7 bytes per parameter, or 5 bytes with gradient release. They also cut model checkpoint sizes by more than half. Experiments with FlashOptim applied to SGD, AdamW, and Lion show no measurable quality degradation on any task from a collection of standard vision and language benchmarks, including Llama-3.1-8B finetuning. Comments: Source code is available at this https URL Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23349 [cs.LG] (or arXiv:2602.23349v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23349 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Jose Javier Gonzalez Ortiz [ view email ] [v1] Thu, 26 Feb 2026 18:52:22 UTC (484 KB) Full-text links: Access Paper: View a PDF of the paper titled FlashOptim: Optimizers for Memory Efficient Training, by Jose Javier Gonzalez Ortiz and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-52">27. Retrieve and Segment: Are a Few Examples Enough to Bridge the Supervision Gap in Open-Vocabulary Segmentation?</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23339v1</li>
<li>来源：arxiv</li>
<li>摘要：Open-vocabulary segmentation (OVS) extends the zero-shot recognition capabilities of vision-language models (VLMs) to pixel-level prediction, enabling segmentation of arbitrary categories specified by text prompts. Despite recent progress, OVS lags behind fully supervised approaches due to two challenges: the coarse image-level supervision used to train VLMs and the semantic ambiguity of natural language. We address these limitations by introducing a few-shot setting that augments textual prompts with a support set of pixel-annotated images. Building on this, we propose a retrieval-augmented test-time adapter that learns a lightweight, per-image classifier by fusing textual and visual support features. Unlike prior methods relying on late, hand-crafted fusion, our approach performs learned, per-query fusion, achieving stronger synergy between modalities. The method supports continually expanding support sets, and applies to fine-grained tasks such as personalized segmentation. Experiments show that we significantly narrow the gap between zero-shot and supervised segmentation while preserving open-vocabulary ability.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-53">正文（抓取，非 AI）</h3>
<p>[2602.23339v1] Retrieve and Segment: Are a Few Examples Enough to Bridge the Supervision Gap in Open-Vocabulary Segmentation? Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23339v1 (cs) [Submitted on 26 Feb 2026] Title: Retrieve and Segment: Are a Few Examples Enough to Bridge the Supervision Gap in Open-Vocabulary Segmentation? Authors: Tilemachos Aravanis , Vladan Stojnić , Bill Psomas , Nikos Komodakis , Giorgos Tolias View a PDF of the paper titled Retrieve and Segment: Are a Few Examples Enough to Bridge the Supervision Gap in Open-Vocabulary Segmentation?, by Tilemachos Aravanis and 4 other authors View PDF Abstract: Open-vocabulary segmentation (OVS) extends the zero-shot recognition capabilities of vision-language models (VLMs) to pixel-level prediction, enabling segmentation of arbitrary categories specified by text prompts. Despite recent progress, OVS lags behind fully supervised approaches due to two challenges: the coarse image-level supervision used to train VLMs and the semantic ambiguity of natural language. We address these limitations by introducing a few-shot setting that augments textual prompts with a support set of pixel-annotated images. Building on this, we propose a retrieval-augmented test-time adapter that learns a lightweight, per-image classifier by fusing textual and visual support features. Unlike prior methods relying on late, hand-crafted fusion, our approach performs learned, per-query fusion, achieving stronger synergy between modalities. The method supports continually expanding support sets, and applies to fine-grained tasks such as personalized segmentation. Experiments show that we significantly narrow the gap between zero-shot and supervised segmentation while preserving open-vocabulary ability. Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.23339 [cs.CV] (or arXiv:2602.23339v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23339 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Tilemachos Aravanis [ view email ] [v1] Thu, 26 Feb 2026 18:45:33 UTC (10,381 KB) Full-text links: Access Paper: View a PDF of the paper titled Retrieve and Segment: Are a Few Examples Enough to Bridge the Supervision Gap in Open-Vocabulary Segmentation?, by Tilemachos Aravanis and 4 other authors View PDF TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-54">28. Real-Time Stream Compaction for Sparse Machine Learning on FPGAs</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23281v1</li>
<li>来源：arxiv</li>
<li>摘要：Machine learning algorithms are being used more frequently in the first-level triggers in collider experiments, with Graph Neural Networks pushing the hardware requirements of FPGA-based triggers beyond the current state of the art. To meet the stringent demands of high-throughput and low-latency environments, we propose a concept for latency-optimized preprocessing of sparse sensor data, enabling efficient GNN hardware acceleration by removing dynamic input sparsity. Our approach rearranges data coming from a large number of First-In-First-Out interfaces, typically sensor frontends, to a smaller number of FIFO interfaces connected to a machine learning hardware accelerator. In order to achieve high throughput while minimizing the hardware utilization, we developed a hierarchical sparsity compression pipeline optimized for FPGAs. We implemented our concept in the Chisel design language as an open-source hardware generator. For demonstration, we implemented one configuration of our module as preprocessing stage in a GNN-based first-level trigger for the Electromagnetic Calorimeter inside the Belle II detector. Additionally we evaluate latency, throughput, resource utilization, and s</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-55">正文（抓取，非 AI）</h3>
<p>[2602.23281v1] Real-Time Stream Compaction for Sparse Machine Learning on FPGAs High Energy Physics - Experiment arXiv:2602.23281v1 (hep-ex) [Submitted on 26 Feb 2026] Title: Real-Time Stream Compaction for Sparse Machine Learning on FPGAs Authors: Marc Neu , Isabel Haide , Torben Ferber , Jürgen Becker View a PDF of the paper titled Real-Time Stream Compaction for Sparse Machine Learning on FPGAs, by Marc Neu and 3 other authors View PDF HTML (experimental) Abstract: Machine learning algorithms are being used more frequently in the first-level triggers in collider experiments, with Graph Neural Networks pushing the hardware requirements of FPGA-based triggers beyond the current state of the art. To meet the stringent demands of high-throughput and low-latency environments, we propose a concept for latency-optimized preprocessing of sparse sensor data, enabling efficient GNN hardware acceleration by removing dynamic input sparsity. Our approach rearranges data coming from a large number of First-In-First-Out interfaces, typically sensor frontends, to a smaller number of FIFO interfaces connected to a machine learning hardware accelerator. In order to achieve high throughput while minimizing the hardware utilization, we developed a hierarchical sparsity compression pipeline optimized for FPGAs. We implemented our concept in the Chisel design language as an open-source hardware generator. For demonstration, we implemented one configuration of our module as preprocessing stage in a GNN-based first-level trigger for the Electromagnetic Calorimeter inside the Belle II detector. Additionally we evaluate latency, throughput, resource utilization, and scalability for a wide range of parameters, to enable broader use for other large scale scientific experiments. Comments: 8 pages Subjects: High Energy Physics - Experiment (hep-ex) ; Hardware Architecture (cs.AR) Cite as: arXiv:2602.23281 [hep-ex] (or arXiv:2602.23281v1 [hep-ex] for this version) https://doi.org/10.48550/arXiv.2602.23281 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Marc Neu [ view email ] [v1] Thu, 26 Feb 2026 17:54:32 UTC (3,321 KB) Full-text links: Access Paper: View a PDF of the paper titled Real-Time Stream Compaction for Sparse Machine Learning on FPGAs, by Marc Neu and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: hep-ex &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AR References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-56">29. CubeSounder: Low SWaP-C 180 GHz Radiometer for Atmospheric Sensing Tested on High Altitude Balloons</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23338v1</li>
<li>来源：arxiv</li>
<li>摘要：Microwave sounding is the leading driver of global numerical weather forecasting, but is limited by the scalability of such instruments. With modern machining and commercial microwave components, it is now possible to design low size, weight, power, and cost (SWaP-C) microwave spectrometers while maintaining wide bandwidth performance. Here we report on the status of CubeSounder, a spectrometer tailored for water vapor radiometry that utilizes passive wave guide filter banks. After developing a prototype and high altitude balloon payload, we demonstrated CubeSounder on commercial stratospheric balloon flights. We report on our design process, especially the simulation and fabrication of the custom millimeter-wave filter banks. We also report the initial results of the data collected from the balloon flights.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-57">正文（抓取，非 AI）</h3>
<p>[2602.23338v1] CubeSounder: Low SWaP-C 180 GHz Radiometer for Atmospheric Sensing Tested on High Altitude Balloons Electrical Engineering and Systems Science &gt; Signal Processing arXiv:2602.23338v1 (eess) [Submitted on 26 Feb 2026] Title: CubeSounder: Low SWaP-C 180 GHz Radiometer for Atmospheric Sensing Tested on High Altitude Balloons Authors: Kyle D. Massingill , Tyler M. Karasinski , Sean Bryan , Michael Baricuatro , Daniel Bliss , Delondrae Carter , Walter Goodwin , Jonathan Greenfield , Christopher Groppi , Jae Joiner , Philip Mauskopf , Philip Rybak , Scott Smas , Roshni Suresh , Joesph Tinlin , Bianca Wullen , Peter Wullen View a PDF of the paper titled CubeSounder: Low SWaP-C 180 GHz Radiometer for Atmospheric Sensing Tested on High Altitude Balloons, by Kyle D. Massingill and 16 other authors View PDF Abstract: Microwave sounding is the leading driver of global numerical weather forecasting, but is limited by the scalability of such instruments. With modern machining and commercial microwave components, it is now possible to design low size, weight, power, and cost (SWaP-C) microwave spectrometers while maintaining wide bandwidth performance. Here we report on the status of CubeSounder, a spectrometer tailored for water vapor radiometry that utilizes passive wave guide filter banks. After developing a prototype and high altitude balloon payload, we demonstrated CubeSounder on commercial stratospheric balloon flights. We report on our design process, especially the simulation and fabrication of the custom millimeter-wave filter banks. We also report the initial results of the data collected from the balloon flights. Comments: 7 Pages, 11 Figures, Submitted to IEEE Transactions on Geoscience and Remote Sensing Subjects: Signal Processing (eess.SP) ; Instrumentation and Detectors (physics.ins-det) Cite as: arXiv:2602.23338 [eess.SP] (or arXiv:2602.23338v1 [eess.SP] for this version) https://doi.org/10.48550/arXiv.2602.23338 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Sean Bryan [ view email ] [v1] Thu, 26 Feb 2026 18:42:38 UTC (13,122 KB) Full-text links: Access Paper: View a PDF of the paper titled CubeSounder: Low SWaP-C 180 GHz Radiometer for Atmospheric Sensing Tested on High Altitude Balloons, by Kyle D. Massingill and 16 other authors View PDF TeX Source view license Current browse context: eess.SP &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: eess physics physics.ins-det References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-58">30. Non-Attainment of Minima in Non-Polyhedral Conic Optimization: A Robust SOCP Example</h2>
<ul>
<li>链接：https://arxiv.org/abs/2510.00318v2</li>
<li>来源：arxiv</li>
<li>摘要：A fundamental theorem of linear programming states that a feasible linear program is solvable if and only if its objective function is copositive with respect to the recession cone of its feasible set. This paper demonstrates that this crucial guarantee does not extend to Second-Order Cone Programs (SOCPs), a workhorse model in robust and convex optimization. We construct and analyze a rigorous counterexample derived from a robust linear optimization problem with ellipsoidal uncertainty. The resulting SOCP possesses a non-empty feasible set, a bounded objective, and an objective function that is copositive on its recession cone. Despite satisfying these classical conditions for solvability, the problem admits no optimal solution; its infimum is finite but unattainable. We trace this pathology directly to the non-polyhedral geometry of the second-order cone, which causes the image of the feasible set under the linear objective to be non-closed. We interpret the example explicitly within the context of robust optimization, discuss its significant practical implications for modeling and computation, and propose effective mitigation strategies via polyhedral approximation or regulariza</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-59">正文（抓取，非 AI）</h3>
<p>[2510.00318v2] Non-Attainment of Minima in Non-Polyhedral Conic Optimization: A Robust SOCP Example Mathematics &gt; Optimization and Control arXiv:2510.00318v2 (math) [Submitted on 30 Sep 2025 ( v1 ), last revised 30 Dec 2025 (this version, v2)] Title: Non-Attainment of Minima in Non-Polyhedral Conic Optimization: A Robust SOCP Example Authors: Vinh Nguyen View a PDF of the paper titled Non-Attainment of Minima in Non-Polyhedral Conic Optimization: A Robust SOCP Example, by Vinh Nguyen View PDF HTML (experimental) Abstract: A fundamental theorem of linear programming states that a feasible linear program is solvable if and only if its objective function is copositive with respect to the recession cone of its feasible set. This paper demonstrates that this crucial guarantee does not extend to Second-Order Cone Programs (SOCPs), a workhorse model in robust and convex optimization. We construct and analyze a rigorous counterexample derived from a robust linear optimization problem with ellipsoidal uncertainty. The resulting SOCP possesses a non-empty feasible set, a bounded objective, and an objective function that is copositive on its recession cone. Despite satisfying these classical conditions for solvability, the problem admits no optimal solution; its infimum is finite but unattainable. We trace this pathology directly to the non-polyhedral geometry of the second-order cone, which causes the image of the feasible set under the linear objective to be non-closed. We interpret the example explicitly within the context of robust optimization, discuss its significant practical implications for modeling and computation, and propose effective mitigation strategies via polyhedral approximation or regularization. Comments: minor change to title and adding some remarks Subjects: Optimization and Control (math.OC) MSC classes: 90C05, 90C17, 90C22, 90C25, 90C46 Cite as: arXiv:2510.00318 [math.OC] (or arXiv:2510.00318v2 [math.OC] for this version) https://doi.org/10.48550/arXiv.2510.00318 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Vinh Nguyen [ view email ] [v1] Tue, 30 Sep 2025 22:22:11 UTC (273 KB) [v2] Tue, 30 Dec 2025 18:35:43 UTC (274 KB) Full-text links: Access Paper: View a PDF of the paper titled Non-Attainment of Minima in Non-Polyhedral Conic Optimization: A Robust SOCP Example, by Vinh Nguyen View PDF HTML (experimental) TeX Source view license Current browse context: math.OC &lt; prev | next &gt; new | recent | 2025-10 Change to browse by: math References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-60">31. A Dataset is Worth 1 MB</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23358v1</li>
<li>来源：arxiv</li>
<li>摘要：A dataset server must often distribute the same large payload to many clients, incurring massive communication costs. Since clients frequently operate on diverse hardware and software frameworks, transmitting a pre-trained model is often infeasible; instead, agents require raw data to train their own task-specific models locally. While dataset distillation attempts to compress training signals, current methods struggle to scale to high-resolution data and rarely achieve sufficiently small files. In this paper, we propose Pseudo-Labels as Data (PLADA), a method that completely eliminates pixel transmission. We assume agents are preloaded with a large, generic, unlabeled reference dataset (e.g., ImageNet-1K, ImageNet-21K) and communicate a new task by transmitting only the class labels for specific images. To address the distribution mismatch between the reference and target datasets, we introduce a pruning mechanism that filters the reference dataset to retain only the labels of the most semantically relevant images for the target task. This selection process simultaneously maximizes training efficiency and minimizes transmission payload. Experiments on 10 diverse datasets demonstra</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-61">正文（抓取，非 AI）</h3>
<p>[2602.23358v1] A Dataset is Worth 1 MB Computer Science &gt; Machine Learning arXiv:2602.23358v1 (cs) [Submitted on 26 Feb 2026] Title: A Dataset is Worth 1 MB Authors: Elad Kimchi Shoshani , Leeyam Gabay , Yedid Hoshen View a PDF of the paper titled A Dataset is Worth 1 MB, by Elad Kimchi Shoshani and 2 other authors View PDF HTML (experimental) Abstract: A dataset server must often distribute the same large payload to many clients, incurring massive communication costs. Since clients frequently operate on diverse hardware and software frameworks, transmitting a pre-trained model is often infeasible; instead, agents require raw data to train their own task-specific models locally. While dataset distillation attempts to compress training signals, current methods struggle to scale to high-resolution data and rarely achieve sufficiently small files. In this paper, we propose Pseudo-Labels as Data (PLADA), a method that completely eliminates pixel transmission. We assume agents are preloaded with a large, generic, unlabeled reference dataset (e.g., ImageNet-1K, ImageNet-21K) and communicate a new task by transmitting only the class labels for specific images. To address the distribution mismatch between the reference and target datasets, we introduce a pruning mechanism that filters the reference dataset to retain only the labels of the most semantically relevant images for the target task. This selection process simultaneously maximizes training efficiency and minimizes transmission payload. Experiments on 10 diverse datasets demonstrate that our approach can transfer task knowledge with a payload of less than 1 MB while retaining high classification accuracy, offering a promising solution for efficient dataset serving. Comments: 23 pages, 9 figures Subjects: Machine Learning (cs.LG) ; Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.23358 [cs.LG] (or arXiv:2602.23358v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23358 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Elad Kimchi Shoshani [ view email ] [v1] Thu, 26 Feb 2026 18:59:03 UTC (13,118 KB) Full-text links: Access Paper: View a PDF of the paper titled A Dataset is Worth 1 MB, by Elad Kimchi Shoshani and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CV References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-62">32. Impacts of Aggregation on Model Diversity and Consumer Utility</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23293v1</li>
<li>来源：arxiv</li>
<li>摘要：Consider a marketplace of AI tools, each with slightly different strengths and weaknesses. By selecting the right model for the task at hand, a user can do better than simply committing to a single model for everything. Routers operate under a similar principle, where sophisticated model selection can increase overall performance. However, aggregation is often noisy, reflecting in imperfect user choices or routing decisions. This leads to two main questions: first, what does a "healthy marketplace" of models look like for maximizing consumer utility? Secondly, how can we incentivize producers to create such models? Here, we study two types of model changes: market entry (where an entirely new model is created and added to the set of available models), and model replacement (where an existing model has its strengths and weaknesses changed). We show that winrate, a standard benchmark in LLM evaluation, can incentivize model creators to homogenize for both types of model changes, reducing consumer welfare. We propose a new mechanism, weighted winrate, which rewards models for answers that are higher quality, and show that it provably improves incentives for producers to specialize and</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-63">正文（抓取，非 AI）</h3>
<p>[2602.23293v1] Impacts of Aggregation on Model Diversity and Consumer Utility Computer Science &gt; Computer Science and Game Theory arXiv:2602.23293v1 (cs) [Submitted on 26 Feb 2026] Title: Impacts of Aggregation on Model Diversity and Consumer Utility Authors: Kate Donahue , Manish Raghavan View a PDF of the paper titled Impacts of Aggregation on Model Diversity and Consumer Utility, by Kate Donahue and Manish Raghavan View PDF HTML (experimental) Abstract: Consider a marketplace of AI tools, each with slightly different strengths and weaknesses. By selecting the right model for the task at hand, a user can do better than simply committing to a single model for everything. Routers operate under a similar principle, where sophisticated model selection can increase overall performance. However, aggregation is often noisy, reflecting in imperfect user choices or routing decisions. This leads to two main questions: first, what does a "healthy marketplace" of models look like for maximizing consumer utility? Secondly, how can we incentivize producers to create such models? Here, we study two types of model changes: market entry (where an entirely new model is created and added to the set of available models), and model replacement (where an existing model has its strengths and weaknesses changed). We show that winrate, a standard benchmark in LLM evaluation, can incentivize model creators to homogenize for both types of model changes, reducing consumer welfare. We propose a new mechanism, weighted winrate, which rewards models for answers that are higher quality, and show that it provably improves incentives for producers to specialize and increases consumer welfare. We conclude by demonstrating that our theoretical results generalize to empirical benchmark datasets and discussing implications for evaluation design. Subjects: Computer Science and Game Theory (cs.GT) ; Computers and Society (cs.CY) Cite as: arXiv:2602.23293 [cs.GT] (or arXiv:2602.23293v1 [cs.GT] for this version) https://doi.org/10.48550/arXiv.2602.23293 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Kate Donahue [ view email ] [v1] Thu, 26 Feb 2026 18:04:03 UTC (970 KB) Full-text links: Access Paper: View a PDF of the paper titled Impacts of Aggregation on Model Diversity and Consumer Utility, by Kate Donahue and Manish Raghavan View PDF HTML (experimental) TeX Source view license Current browse context: cs.GT &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CY References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-64">33. Physics Informed Viscous Value Representations</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23280v1</li>
<li>来源：arxiv</li>
<li>摘要：Offline goal-conditioned reinforcement learning (GCRL) learns goal-conditioned policies from static pre-collected datasets. However, accurate value estimation remains a challenge due to the limited coverage of the state-action space. Recent physics-informed approaches have sought to address this by imposing physical and geometric constraints on the value function through regularization defined over first-order partial differential equations (PDEs), such as the Eikonal equation. However, these formulations can often be ill-posed in complex, high-dimensional environments. In this work, we propose a physics-informed regularization derived from the viscosity solution of the Hamilton-Jacobi-Bellman (HJB) equation. By providing a physics-based inductive bias, our approach grounds the learning process in optimal control theory, explicitly regularizing and bounding updates during value iterations. Furthermore, we leverage the Feynman-Kac theorem to recast the PDE solution as an expectation, enabling a tractable Monte Carlo estimation of the objective that avoids numerical instability in higher-order gradients. Experiments demonstrate that our method improves geometric consistency, making i</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-65">正文（抓取，非 AI）</h3>
<p>[2602.23280v1] Physics Informed Viscous Value Representations Computer Science &gt; Machine Learning arXiv:2602.23280v1 (cs) [Submitted on 26 Feb 2026] Title: Physics Informed Viscous Value Representations Authors: Hrishikesh Viswanath , Juanwu Lu , S. Talha Bukhari , Damon Conover , Ziran Wang , Aniket Bera View a PDF of the paper titled Physics Informed Viscous Value Representations, by Hrishikesh Viswanath and 5 other authors View PDF HTML (experimental) Abstract: Offline goal-conditioned reinforcement learning (GCRL) learns goal-conditioned policies from static pre-collected datasets. However, accurate value estimation remains a challenge due to the limited coverage of the state-action space. Recent physics-informed approaches have sought to address this by imposing physical and geometric constraints on the value function through regularization defined over first-order partial differential equations (PDEs), such as the Eikonal equation. However, these formulations can often be ill-posed in complex, high-dimensional environments. In this work, we propose a physics-informed regularization derived from the viscosity solution of the Hamilton-Jacobi-Bellman (HJB) equation. By providing a physics-based inductive bias, our approach grounds the learning process in optimal control theory, explicitly regularizing and bounding updates during value iterations. Furthermore, we leverage the Feynman-Kac theorem to recast the PDE solution as an expectation, enabling a tractable Monte Carlo estimation of the objective that avoids numerical instability in higher-order gradients. Experiments demonstrate that our method improves geometric consistency, making it broadly applicable to navigation and high-dimensional, complex manipulation tasks. Open-source codes are available at this https URL . Subjects: Machine Learning (cs.LG) ; Robotics (cs.RO) Cite as: arXiv:2602.23280 [cs.LG] (or arXiv:2602.23280v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23280 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Hrishikesh Viswanath [ view email ] [v1] Thu, 26 Feb 2026 17:53:46 UTC (8,162 KB) Full-text links: Access Paper: View a PDF of the paper titled Physics Informed Viscous Value Representations, by Hrishikesh Viswanath and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.RO References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-66">34. Close-enough general routing problem for multiple unmanned aerial vehicles in monitoring missions</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.15841v1</li>
<li>来源：arxiv</li>
<li>摘要：In this paper, we introduce a close-enough multi-UAV general routing problem (CEMUAVGRP) where a fleet of homogeneous UAVs conduct monitoring tasks containing nodes, each of which has its disk neighborhood, and edges, aiming to minimize the total distance. A two-phase iterative method is proposed, partitioning the CEMUAVGRP into a general routing phase where a satisfactory route including required nodes and edges for each UAV is obtained without considering the disk neighborhoods of required nodes, and a close-enough routing phase where representative points are optimized for each required node in the determined route. To be specific, a variable neighborhood descent (VND) heuristic is proposed for the general routing phase, while a second-order cone programming (SOCP) procedure is applied in the close-enough routing phase. These two phases are performed in an iterative fashion under the framework of an adaptive iterated local search (AILS) algorithm until the predefined termination criteria are satisfied. Extensive experiments and comparative studies are conducted, demonstrating the efficiency of the proposed AILS-VND-SOCP algorithm and the superiority of disk neighborhoods.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-67">正文（抓取，非 AI）</h3>
<p>[2602.15841v1] Close-enough general routing problem for multiple unmanned aerial vehicles in monitoring missions Electrical Engineering and Systems Science &gt; Systems and Control arXiv:2602.15841v1 (eess) [Submitted on 21 Jan 2026] Title: Close-enough general routing problem for multiple unmanned aerial vehicles in monitoring missions Authors: Huan Liu , Michel Gendreau , Binjie Xu , Guohua Wu , Yi Gu View a PDF of the paper titled Close-enough general routing problem for multiple unmanned aerial vehicles in monitoring missions, by Huan Liu and 4 other authors View PDF HTML (experimental) Abstract: In this paper, we introduce a close-enough multi-UAV general routing problem (CEMUAVGRP) where a fleet of homogeneous UAVs conduct monitoring tasks containing nodes, each of which has its disk neighborhood, and edges, aiming to minimize the total distance. A two-phase iterative method is proposed, partitioning the CEMUAVGRP into a general routing phase where a satisfactory route including required nodes and edges for each UAV is obtained without considering the disk neighborhoods of required nodes, and a close-enough routing phase where representative points are optimized for each required node in the determined route. To be specific, a variable neighborhood descent (VND) heuristic is proposed for the general routing phase, while a second-order cone programming (SOCP) procedure is applied in the close-enough routing phase. These two phases are performed in an iterative fashion under the framework of an adaptive iterated local search (AILS) algorithm until the predefined termination criteria are satisfied. Extensive experiments and comparative studies are conducted, demonstrating the efficiency of the proposed AILS-VND-SOCP algorithm and the superiority of disk neighborhoods. Subjects: Systems and Control (eess.SY) ; Networking and Internet Architecture (cs.NI); Optimization and Control (math.OC) Cite as: arXiv:2602.15841 [eess.SY] (or arXiv:2602.15841v1 [eess.SY] for this version) https://doi.org/10.48550/arXiv.2602.15841 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Huan Liu [ view email ] [v1] Wed, 21 Jan 2026 01:43:00 UTC (2,082 KB) Full-text links: Access Paper: View a PDF of the paper titled Close-enough general routing problem for multiple unmanned aerial vehicles in monitoring missions, by Huan Liu and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SY &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.NI cs.SY eess math math.OC References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-68">35. ParamMem: Augmenting Language Agents with Parametric Reflective Memory</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23320v1</li>
<li>来源：arxiv</li>
<li>摘要：Self-reflection enables language agents to iteratively refine solutions, yet often produces repetitive outputs that limit reasoning performance. Recent studies have attempted to address this limitation through various approaches, among which increasing reflective diversity has shown promise. Our empirical analysis reveals a strong positive correlation between reflective diversity and task success, further motivating the need for diverse reflection signals. We introduce ParamMem, a parametric memory module that encodes cross-sample reflection patterns into model parameters, enabling diverse reflection generation through temperature-controlled sampling. Building on this module, we propose ParamAgent, a reflection-based agent framework that integrates parametric memory with episodic and cross-sample memory. Extensive experiments on code generation, mathematical reasoning, and multi-hop question answering demonstrate consistent improvements over state-of-the-art baselines. Further analysis reveals that ParamMem is sample-efficient, enables weak-to-strong transfer across model scales, and supports self-improvement without reliance on stronger external model, highlighting the potential o</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-69">正文（抓取，非 AI）</h3>
<p>[2602.23320v1] ParamMem: Augmenting Language Agents with Parametric Reflective Memory Computer Science &gt; Machine Learning arXiv:2602.23320v1 (cs) [Submitted on 26 Feb 2026] Title: ParamMem: Augmenting Language Agents with Parametric Reflective Memory Authors: Tianjun Yao , Yongqiang Chen , Yujia Zheng , Pan Li , Zhiqiang Shen , Kun Zhang View a PDF of the paper titled ParamMem: Augmenting Language Agents with Parametric Reflective Memory, by Tianjun Yao and 5 other authors View PDF HTML (experimental) Abstract: Self-reflection enables language agents to iteratively refine solutions, yet often produces repetitive outputs that limit reasoning performance. Recent studies have attempted to address this limitation through various approaches, among which increasing reflective diversity has shown promise. Our empirical analysis reveals a strong positive correlation between reflective diversity and task success, further motivating the need for diverse reflection signals. We introduce ParamMem, a parametric memory module that encodes cross-sample reflection patterns into model parameters, enabling diverse reflection generation through temperature-controlled sampling. Building on this module, we propose ParamAgent, a reflection-based agent framework that integrates parametric memory with episodic and cross-sample memory. Extensive experiments on code generation, mathematical reasoning, and multi-hop question answering demonstrate consistent improvements over state-of-the-art baselines. Further analysis reveals that ParamMem is sample-efficient, enables weak-to-strong transfer across model scales, and supports self-improvement without reliance on stronger external model, highlighting the potential of ParamMem as an effective component for enhancing language agents. Comments: 20 pages Subjects: Machine Learning (cs.LG) ; Multiagent Systems (cs.MA) ACM classes: I.2.6 Cite as: arXiv:2602.23320 [cs.LG] (or arXiv:2602.23320v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23320 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Tianjun Yao [ view email ] [v1] Thu, 26 Feb 2026 18:28:04 UTC (2,463 KB) Full-text links: Access Paper: View a PDF of the paper titled ParamMem: Augmenting Language Agents with Parametric Reflective Memory, by Tianjun Yao and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.MA References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-70">36. Interface-Aware Trajectory Reconstruction of Limited Demonstrations for Robot Learning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23287v1</li>
<li>来源：arxiv</li>
<li>摘要：Assistive robots offer agency to humans with severe motor impairments. Often, these users control high-DoF robots through low-dimensional interfaces, such as using a 1-D sip-and-puff interface to operate a 6-DoF robotic arm. This mismatch results in having access to only a subset of control dimensions at a given time, imposing unintended and artificial constraints on robot motion. As a result, interface-limited demonstrations embed suboptimal motions that reflect interface restrictions rather than user intent. To address this, we present a trajectory reconstruction algorithm that reasons about task, environment, and interface constraints to lift demonstrations into the robot's full control space. We evaluate our approach using real-world demonstrations of ADL-inspired tasks performed via a 2-D joystick and 1-D sip-and-puff control interface, teleoperating two distinct 7-DoF robotic arms. Analyses of the reconstructed demonstrations and derived control policies show that lifted trajectories are faster and more efficient than their interface-constrained counterparts while respecting user preferences.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-71">正文（抓取，非 AI）</h3>
<p>[2602.23287v1] Interface-Aware Trajectory Reconstruction of Limited Demonstrations for Robot Learning Computer Science &gt; Robotics arXiv:2602.23287v1 (cs) [Submitted on 26 Feb 2026] Title: Interface-Aware Trajectory Reconstruction of Limited Demonstrations for Robot Learning Authors: Demiana R. Barsoum , Mahdieh Nejati Javaremi , Larisa Y.C. Loke , Brenna D. Argall View a PDF of the paper titled Interface-Aware Trajectory Reconstruction of Limited Demonstrations for Robot Learning, by Demiana R. Barsoum and 3 other authors View PDF HTML (experimental) Abstract: Assistive robots offer agency to humans with severe motor impairments. Often, these users control high-DoF robots through low-dimensional interfaces, such as using a 1-D sip-and-puff interface to operate a 6-DoF robotic arm. This mismatch results in having access to only a subset of control dimensions at a given time, imposing unintended and artificial constraints on robot motion. As a result, interface-limited demonstrations embed suboptimal motions that reflect interface restrictions rather than user intent. To address this, we present a trajectory reconstruction algorithm that reasons about task, environment, and interface constraints to lift demonstrations into the robot's full control space. We evaluate our approach using real-world demonstrations of ADL-inspired tasks performed via a 2-D joystick and 1-D sip-and-puff control interface, teleoperating two distinct 7-DoF robotic arms. Analyses of the reconstructed demonstrations and derived control policies show that lifted trajectories are faster and more efficient than their interface-constrained counterparts while respecting user preferences. Comments: 13 pages, 8 figures, to appear in the proceedings of the 2026 Human-Robot Interaction (HRI) Conference Subjects: Robotics (cs.RO) Cite as: arXiv:2602.23287 [cs.RO] (or arXiv:2602.23287v1 [cs.RO] for this version) https://doi.org/10.48550/arXiv.2602.23287 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Related DOI : https://doi.org/10.1145/3757279.3788671 Focus to learn more DOI(s) linking to related resources Submission history From: Demiana Barsoum [ view email ] [v1] Thu, 26 Feb 2026 18:01:25 UTC (4,278 KB) Full-text links: Access Paper: View a PDF of the paper titled Interface-Aware Trajectory Reconstruction of Limited Demonstrations for Robot Learning, by Demiana R. Barsoum and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.RO &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-72">37. Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.23898v1</li>
<li>来源：arxiv</li>
<li>摘要：Reliable forecasting of Global Horizontal Irradiance (GHI) is essential for mitigating the variability of solar energy in power grids. This study presents a comprehensive benchmark of ten deep learning architectures for short-term (1-hour ahead) GHI time series forecasting in Ho Chi Minh City, leveraging high-resolution NSRDB satellite data (2011-2020) to compare established baselines (e.g. LSTM, TCN) against emerging state-of-the-art architectures, including Transformer, Informer, iTransformer, TSMixer, and Mamba. Experimental results identify the Transformer as the superior architecture, achieving the highest predictive accuracy with an R^2 of 0.9696. The study further utilizes SHAP analysis to contrast the temporal reasoning of these architectures, revealing that Transformers exhibit a strong "recency bias" focused on immediate atmospheric conditions, whereas Mamba explicitly leverages 24-hour periodic dependencies to inform predictions. Furthermore, we demonstrate that Knowledge Distillation can compress the high-performance Transformer by 23.5% while surprisingly reducing error (MAE: 23.78 W/m^2), offering a proven pathway for deploying sophisticated, low-latency forecasting o</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-73">正文（抓取，非 AI）</h3>
<p>[2512.23898v1] Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City Computer Science &gt; Machine Learning arXiv:2512.23898v1 (cs) [Submitted on 29 Dec 2025] Title: Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City Authors: Tin Hoang View a PDF of the paper titled Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City, by Tin Hoang View PDF HTML (experimental) Abstract: Reliable forecasting of Global Horizontal Irradiance (GHI) is essential for mitigating the variability of solar energy in power grids. This study presents a comprehensive benchmark of ten deep learning architectures for short-term (1-hour ahead) GHI time series forecasting in Ho Chi Minh City, leveraging high-resolution NSRDB satellite data (2011-2020) to compare established baselines (e.g. LSTM, TCN) against emerging state-of-the-art architectures, including Transformer, Informer, iTransformer, TSMixer, and Mamba. Experimental results identify the Transformer as the superior architecture, achieving the highest predictive accuracy with an R^2 of 0.9696. The study further utilizes SHAP analysis to contrast the temporal reasoning of these architectures, revealing that Transformers exhibit a strong "recency bias" focused on immediate atmospheric conditions, whereas Mamba explicitly leverages 24-hour periodic dependencies to inform predictions. Furthermore, we demonstrate that Knowledge Distillation can compress the high-performance Transformer by 23.5% while surprisingly reducing error (MAE: 23.78 W/m^2), offering a proven pathway for deploying sophisticated, low-latency forecasting on resource-constrained edge devices. Comments: preprint, 40 pages Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2512.23898 [cs.LG] (or arXiv:2512.23898v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2512.23898 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Tin Hoang [ view email ] [v1] Mon, 29 Dec 2025 23:22:25 UTC (3,287 KB) Full-text links: Access Paper: View a PDF of the paper titled Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City, by Tin Hoang View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-74">38. Lossless Compression: A New Benchmark for Time Series Model Evaluation</h2>
<ul>
<li>链接：https://arxiv.org/abs/2509.21002v1</li>
<li>来源：arxiv</li>
<li>摘要：The evaluation of time series models has traditionally focused on four canonical tasks: forecasting, imputation, anomaly detection, and classification. While these tasks have driven significant progress, they primarily assess task-specific performance and do not rigorously measure whether a model captures the full generative distribution of the data. We introduce lossless compression as a new paradigm for evaluating time series models, grounded in Shannon's source coding theorem. This perspective establishes a direct equivalence between optimal compression length and the negative log-likelihood, providing a strict and unified information-theoretic criterion for modeling capacity. Then We define a standardized evaluation protocol and metrics. We further propose and open-source a comprehensive evaluation framework TSCom-Bench, which enables the rapid adaptation of time series models as backbones for lossless compression. Experiments across diverse datasets on state-of-the-art models, including TimeXer, iTransformer, and PatchTST, demonstrate that compression reveals distributional weaknesses overlooked by classic benchmarks. These findings position lossless compression as a principle</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-75">正文（抓取，非 AI）</h3>
<p>[2509.21002v1] Lossless Compression: A New Benchmark for Time Series Model Evaluation Computer Science &gt; Machine Learning arXiv:2509.21002v1 (cs) [Submitted on 25 Sep 2025] Title: Lossless Compression: A New Benchmark for Time Series Model Evaluation Authors: Meng Wan , Benxi Tian , Jue Wang , Cui Hui , Ningming Nie , Tiantian Liu , Zongguo Wang , Cao Rongqiang , Peng Shi , Yangang Wang View a PDF of the paper titled Lossless Compression: A New Benchmark for Time Series Model Evaluation, by Meng Wan and 9 other authors View PDF HTML (experimental) Abstract: The evaluation of time series models has traditionally focused on four canonical tasks: forecasting, imputation, anomaly detection, and classification. While these tasks have driven significant progress, they primarily assess task-specific performance and do not rigorously measure whether a model captures the full generative distribution of the data. We introduce lossless compression as a new paradigm for evaluating time series models, grounded in Shannon's source coding theorem. This perspective establishes a direct equivalence between optimal compression length and the negative log-likelihood, providing a strict and unified information-theoretic criterion for modeling capacity. Then We define a standardized evaluation protocol and metrics. We further propose and open-source a comprehensive evaluation framework TSCom-Bench, which enables the rapid adaptation of time series models as backbones for lossless compression. Experiments across diverse datasets on state-of-the-art models, including TimeXer, iTransformer, and PatchTST, demonstrate that compression reveals distributional weaknesses overlooked by classic benchmarks. These findings position lossless compression as a principled task that complements and extends existing evaluation for time series modeling. Comments: 24 pages Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2509.21002 [cs.LG] (or arXiv:2509.21002v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2509.21002 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Meng Wan [ view email ] [v1] Thu, 25 Sep 2025 10:52:48 UTC (3,041 KB) Full-text links: Access Paper: View a PDF of the paper titled Lossless Compression: A New Benchmark for Time Series Model Evaluation, by Meng Wan and 9 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-09 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-76">39. Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.17149v1</li>
<li>来源：arxiv</li>
<li>摘要：This study investigates the task of dwell time prediction and proposes a Transformer framework based on interaction behavior modeling. The method first represents user interaction sequences on the interface by integrating dwell duration, click frequency, scrolling behavior, and contextual features, which are mapped into a unified latent space through embedding and positional encoding. On this basis, a multi-head self-attention mechanism is employed to capture long-range dependencies, while a feed-forward network performs deep nonlinear transformations to model the dynamic patterns of dwell time. Multiple comparative experiments are conducted with BILSTM, DRFormer, FedFormer, and iTransformer as baselines under the same conditions. The results show that the proposed method achieves the best performance in terms of MSE, RMSE, MAPE, and RMAE, and more accurately captures the complex patterns in interaction behavior. In addition, sensitivity experiments are carried out on hyperparameters and environments to examine the impact of the number of attention heads, sequence window length, and device environment on prediction performance, which further demonstrates the robustness and adaptabi</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-77">正文（抓取，非 AI）</h3>
<p>[2512.17149v1] Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces Computer Science &gt; Human-Computer Interaction arXiv:2512.17149v1 (cs) [Submitted on 19 Dec 2025] Title: Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces Authors: Rui Liu , Runsheng Zhang , Shixiao Wang View a PDF of the paper titled Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces, by Rui Liu and 2 other authors View PDF Abstract: This study investigates the task of dwell time prediction and proposes a Transformer framework based on interaction behavior modeling. The method first represents user interaction sequences on the interface by integrating dwell duration, click frequency, scrolling behavior, and contextual features, which are mapped into a unified latent space through embedding and positional encoding. On this basis, a multi-head self-attention mechanism is employed to capture long-range dependencies, while a feed-forward network performs deep nonlinear transformations to model the dynamic patterns of dwell time. Multiple comparative experiments are conducted with BILSTM, DRFormer, FedFormer, and iTransformer as baselines under the same conditions. The results show that the proposed method achieves the best performance in terms of MSE, RMSE, MAPE, and RMAE, and more accurately captures the complex patterns in interaction behavior. In addition, sensitivity experiments are carried out on hyperparameters and environments to examine the impact of the number of attention heads, sequence window length, and device environment on prediction performance, which further demonstrates the robustness and adaptability of the method. Overall, this study provides a new solution for dwell time prediction from both theoretical and methodological perspectives and verifies its effectiveness in multiple aspects. Subjects: Human-Computer Interaction (cs.HC) Cite as: arXiv:2512.17149 [cs.HC] (or arXiv:2512.17149v1 [cs.HC] for this version) https://doi.org/10.48550/arXiv.2512.17149 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Rui Liu [ view email ] [v1] Fri, 19 Dec 2025 00:55:14 UTC (362 KB) Full-text links: Access Paper: View a PDF of the paper titled Transformer-Based Modeling of User Interaction Sequences for Dwell Time Prediction in Human-Computer Interfaces, by Rui Liu and 2 other authors View PDF view license Current browse context: cs.HC &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-78">40. ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23306v1</li>
<li>来源：arxiv</li>
<li>摘要：Omni-modal reasoning is essential for intelligent systems to understand and draw inferences from diverse data sources. While existing omni-modal large language models (OLLM) excel at perceiving diverse modalities, they lack the complex reasoning abilities of recent large reasoning models (LRM). However, enhancing the reasoning ability of OLLMs through additional training presents significant challenges, including the need for high-quality data, task-specific adaptation, and substantial computational costs. To address these limitations, we propose ThinkOmni, a training-free and data-free framework that lifts textual reasoning to omni-modal scenarios. ThinkOmni introduces two key components: 1) LRM-as-a-Guide, which leverages off-the-shelf LRMs to guide the OLLM decoding process; 2) Stepwise Contrastive Scaling, which adaptively balances perception and reasoning signals without manual hyperparameter tuning. Experiments on six multi-modal reasoning benchmarks demonstrate that ThinkOmni consistently delivers performance improvements, with main results achieving 70.2 on MathVista and 75.5 on MMAU. Overall, ThinkOmni offers a flexible and generalizable solution for omni-modal reasoning a</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-79">正文（抓取，非 AI）</h3>
<p>[2602.23306v1] ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23306v1 (cs) [Submitted on 26 Feb 2026] Title: ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding Authors: Yiran Guan , Sifan Tu , Dingkang Liang , Linghao Zhu , Jianzhong Ju , Zhenbo Luo , Jian Luan , Yuliang Liu , Xiang Bai View a PDF of the paper titled ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding, by Yiran Guan and 8 other authors View PDF HTML (experimental) Abstract: Omni-modal reasoning is essential for intelligent systems to understand and draw inferences from diverse data sources. While existing omni-modal large language models (OLLM) excel at perceiving diverse modalities, they lack the complex reasoning abilities of recent large reasoning models (LRM). However, enhancing the reasoning ability of OLLMs through additional training presents significant challenges, including the need for high-quality data, task-specific adaptation, and substantial computational costs. To address these limitations, we propose ThinkOmni, a training-free and data-free framework that lifts textual reasoning to omni-modal scenarios. ThinkOmni introduces two key components: 1) LRM-as-a-Guide, which leverages off-the-shelf LRMs to guide the OLLM decoding process; 2) Stepwise Contrastive Scaling, which adaptively balances perception and reasoning signals without manual hyperparameter tuning. Experiments on six multi-modal reasoning benchmarks demonstrate that ThinkOmni consistently delivers performance improvements, with main results achieving 70.2 on MathVista and 75.5 on MMAU. Overall, ThinkOmni offers a flexible and generalizable solution for omni-modal reasoning and provides new insights into the generalization and application of reasoning capabilities. Comments: Accept by ICLR 2026 Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.23306 [cs.CV] (or arXiv:2602.23306v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23306 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Yiran Guan [ view email ] [v1] Thu, 26 Feb 2026 18:10:41 UTC (4,428 KB) Full-text links: Access Paper: View a PDF of the paper titled ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding, by Yiran Guan and 8 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-80">41. SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23353v1</li>
<li>来源：arxiv</li>
<li>摘要：The Platonic Representation Hypothesis posits that neural networks trained on different modalities converge toward a shared statistical model of the world. Recent work exploits this convergence by aligning frozen pretrained vision and language models with lightweight alignment layers, but typically relies on contrastive losses and millions of paired samples. In this work, we ask whether meaningful alignment can be achieved with substantially less supervision. We introduce a semi-supervised setting in which pretrained unimodal encoders are aligned using a small number of image-text pairs together with large amounts of unpaired data. To address this challenge, we propose SOTAlign, a two-stage framework that first recovers a coarse shared geometry from limited paired data using a linear teacher, then refines the alignment on unpaired samples via an optimal-transport-based divergence that transfers relational structure without overconstraining the target space. Unlike existing semi-supervised methods, SOTAlign effectively leverages unpaired images and text, learning robust joint embeddings across datasets and encoder pairs, and significantly outperforming supervised and semi-supervised</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-81">正文（抓取，非 AI）</h3>
<p>[2602.23353v1] SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport Computer Science &gt; Machine Learning arXiv:2602.23353v1 (cs) [Submitted on 26 Feb 2026] Title: SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport Authors: Simon Roschmann , Paul Krzakala , Sonia Mazelet , Quentin Bouniot , Zeynep Akata View a PDF of the paper titled SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport, by Simon Roschmann and 4 other authors View PDF HTML (experimental) Abstract: The Platonic Representation Hypothesis posits that neural networks trained on different modalities converge toward a shared statistical model of the world. Recent work exploits this convergence by aligning frozen pretrained vision and language models with lightweight alignment layers, but typically relies on contrastive losses and millions of paired samples. In this work, we ask whether meaningful alignment can be achieved with substantially less supervision. We introduce a semi-supervised setting in which pretrained unimodal encoders are aligned using a small number of image-text pairs together with large amounts of unpaired data. To address this challenge, we propose SOTAlign, a two-stage framework that first recovers a coarse shared geometry from limited paired data using a linear teacher, then refines the alignment on unpaired samples via an optimal-transport-based divergence that transfers relational structure without overconstraining the target space. Unlike existing semi-supervised methods, SOTAlign effectively leverages unpaired images and text, learning robust joint embeddings across datasets and encoder pairs, and significantly outperforming supervised and semi-supervised baselines. Comments: Preprint Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23353 [cs.LG] (or arXiv:2602.23353v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23353 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Simon Roschmann [ view email ] [v1] Thu, 26 Feb 2026 18:55:06 UTC (4,133 KB) Full-text links: Access Paper: View a PDF of the paper titled SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport, by Simon Roschmann and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-82">42. Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23341v1</li>
<li>来源：arxiv</li>
<li>摘要：Coarse data arise when learners observe only partial information about samples; namely, a set containing the sample rather than its exact value. This occurs naturally through measurement rounding, sensor limitations, and lag in economic systems. We study Gaussian mean estimation from coarse data, where each true sample $x$ is drawn from a $d$-dimensional Gaussian distribution with identity covariance, but is revealed only through the set of a partition containing $x$. When the coarse samples, roughly speaking, have ``low'' information, the mean cannot be uniquely recovered from observed samples (i.e., the problem is not identifiable). Recent work by Fotakis, Kalavasis, Kontonis, and Tzamos [FKKT21] established that sample-efficient mean estimation is possible when the unknown mean is identifiable and the partition consists of only convex sets. Moreover, they showed that without convexity, mean estimation becomes NP-hard. However, two fundamental questions remained open: (1) When is the mean identifiable under convex partitions? (2) Is computationally efficient estimation possible under identifiability and convex partitions? This work resolves both questions. [...]</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-83">正文（抓取，非 AI）</h3>
<p>[2602.23341v1] Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms Computer Science &gt; Machine Learning arXiv:2602.23341v1 (cs) [Submitted on 26 Feb 2026] Title: Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms Authors: Alkis Kalavasis , Anay Mehrotra , Manolis Zampetakis , Felix Zhou , Ziyu Zhu View a PDF of the paper titled Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms, by Alkis Kalavasis and 4 other authors View PDF HTML (experimental) Abstract: Coarse data arise when learners observe only partial information about samples; namely, a set containing the sample rather than its exact value. This occurs naturally through measurement rounding, sensor limitations, and lag in economic systems. We study Gaussian mean estimation from coarse data, where each true sample $x$ is drawn from a $d$-dimensional Gaussian distribution with identity covariance, but is revealed only through the set of a partition containing $x$. When the coarse samples, roughly speaking, have ``low'' information, the mean cannot be uniquely recovered from observed samples (i.e., the problem is not identifiable). Recent work by Fotakis, Kalavasis, Kontonis, and Tzamos [FKKT21] established that sample-efficient mean estimation is possible when the unknown mean is identifiable and the partition consists of only convex sets. Moreover, they showed that without convexity, mean estimation becomes NP-hard. However, two fundamental questions remained open: (1) When is the mean identifiable under convex partitions? (2) Is computationally efficient estimation possible under identifiability and convex partitions? This work resolves both questions. [...] Comments: Abstract truncated to arXiv limits. To appear in ICLR'26 Subjects: Machine Learning (cs.LG) ; Data Structures and Algorithms (cs.DS); Statistics Theory (math.ST); Machine Learning (stat.ML) Cite as: arXiv:2602.23341 [cs.LG] (or arXiv:2602.23341v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23341 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Felix Zhou [ view email ] [v1] Thu, 26 Feb 2026 18:47:06 UTC (1,020 KB) Full-text links: Access Paper: View a PDF of the paper titled Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms, by Alkis Kalavasis and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.DS math math.ST stat stat.ML stat.TH References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-84">43. Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23234v1</li>
<li>来源：arxiv</li>
<li>摘要：Large-scale commercial search systems optimize for relevance to drive successful sessions that help users find what they are looking for. To maximize relevance, we leverage two complementary objectives: behavioral relevance (results users tend to click or download) and textual relevance (a result's semantic fit to the query). A persistent challenge is the scarcity of expert-provided textual relevance labels relative to abundant behavioral relevance labels. We first address this by systematically evaluating LLM configurations, finding that a specialized, fine-tuned model significantly outperforms a much larger pre-trained one in providing highly relevant labels. Using this optimal model as a force multiplier, we generate millions of textual relevance labels to overcome the data scarcity. We show that augmenting our production ranker with these textual relevance labels leads to a significant outward shift of the Pareto frontier: offline NDCG improves for behavioral relevance while simultaneously increasing for textual relevance. These offline gains were validated by a worldwide A/B test on the App Store ranker, which demonstrated a statistically significant +0.24% increase in convers</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-85">正文（抓取，非 AI）</h3>
<p>[2602.23234v1] Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments Computer Science &gt; Information Retrieval arXiv:2602.23234v1 (cs) [Submitted on 26 Feb 2026] Title: Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments Authors: Evangelia Christakopoulou , Vivekkumar Patel , Hemanth Velaga , Sandip Gaikwad View a PDF of the paper titled Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments, by Evangelia Christakopoulou and 3 other authors View PDF HTML (experimental) Abstract: Large-scale commercial search systems optimize for relevance to drive successful sessions that help users find what they are looking for. To maximize relevance, we leverage two complementary objectives: behavioral relevance (results users tend to click or download) and textual relevance (a result's semantic fit to the query). A persistent challenge is the scarcity of expert-provided textual relevance labels relative to abundant behavioral relevance labels. We first address this by systematically evaluating LLM configurations, finding that a specialized, fine-tuned model significantly outperforms a much larger pre-trained one in providing highly relevant labels. Using this optimal model as a force multiplier, we generate millions of textual relevance labels to overcome the data scarcity. We show that augmenting our production ranker with these textual relevance labels leads to a significant outward shift of the Pareto frontier: offline NDCG improves for behavioral relevance while simultaneously increasing for textual relevance. These offline gains were validated by a worldwide A/B test on the App Store ranker, which demonstrated a statistically significant +0.24% increase in conversion rate, with the most substantial performance gains occurring in tail queries, where the new textual relevance labels provide a robust signal in the absence of reliable behavioral relevance labels. Subjects: Information Retrieval (cs.IR) ; Artificial Intelligence (cs.AI); Machine Learning (cs.LG) Cite as: arXiv:2602.23234 [cs.IR] (or arXiv:2602.23234v1 [cs.IR] for this version) https://doi.org/10.48550/arXiv.2602.23234 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Hemanth Velaga [ view email ] [v1] Thu, 26 Feb 2026 17:11:26 UTC (50 KB) Full-text links: Access Paper: View a PDF of the paper titled Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments, by Evangelia Christakopoulou and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.IR &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-86">44. Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23296v1</li>
<li>来源：arxiv</li>
<li>摘要：Federated learning (FL) faces challenges in uncertainty quantification (UQ). Without reliable UQ, FL systems risk deploying overconfident models at under-resourced agents, leading to silent local failures despite seemingly satisfactory global performance. Existing federated UQ approaches often address data heterogeneity or model heterogeneity in isolation, overlooking their joint effect on coverage reliability across agents. Conformal prediction is a widely used distribution-free UQ framework, yet its applications in heterogeneous FL settings remains underexplored. We provide FedWQ-CP, a simple yet effective approach that balances empirical coverage performance with efficiency at both global and agent levels under the dual heterogeneity. FedWQ-CP performs agent-server calibration in a single communication round. On each agent, conformity scores are computed on calibration data and a local quantile threshold is derived. Each agent then transmits only its quantile threshold and calibration sample size to the server. The server simply aggregates these thresholds through a weighted average to produce a global threshold. Experimental results on seven public datasets for both classificat</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-87">正文（抓取，非 AI）</h3>
<p>[2602.23296v1] Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity Computer Science &gt; Machine Learning arXiv:2602.23296v1 (cs) [Submitted on 26 Feb 2026] Title: Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity Authors: Quang-Huy Nguyen , Jiaqi Wang , Wei-Shinn Ku View a PDF of the paper titled Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity, by Quang-Huy Nguyen and Jiaqi Wang and Wei-Shinn Ku View PDF HTML (experimental) Abstract: Federated learning (FL) faces challenges in uncertainty quantification (UQ). Without reliable UQ, FL systems risk deploying overconfident models at under-resourced agents, leading to silent local failures despite seemingly satisfactory global performance. Existing federated UQ approaches often address data heterogeneity or model heterogeneity in isolation, overlooking their joint effect on coverage reliability across agents. Conformal prediction is a widely used distribution-free UQ framework, yet its applications in heterogeneous FL settings remains underexplored. We provide FedWQ-CP, a simple yet effective approach that balances empirical coverage performance with efficiency at both global and agent levels under the dual heterogeneity. FedWQ-CP performs agent-server calibration in a single communication round. On each agent, conformity scores are computed on calibration data and a local quantile threshold is derived. Each agent then transmits only its quantile threshold and calibration sample size to the server. The server simply aggregates these thresholds through a weighted average to produce a global threshold. Experimental results on seven public datasets for both classification and regression demonstrate that FedWQ-CP empirically maintains agent-wise and global coverage while producing the smallest prediction sets or intervals. Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23296 [cs.LG] (or arXiv:2602.23296v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23296 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Quang Huy Nguyen [ view email ] [v1] Thu, 26 Feb 2026 18:07:45 UTC (95 KB) Full-text links: Access Paper: View a PDF of the paper titled Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity, by Quang-Huy Nguyen and Jiaqi Wang and Wei-Shinn Ku View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-88">45. Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23266v1</li>
<li>来源：arxiv</li>
<li>摘要：Achieving human-like responsiveness is a critical yet challenging goal for cascaded spoken dialogue systems. Conventional ASR-LLM-TTS pipelines follow a strictly sequential paradigm, requiring complete transcription and full reasoning before speech synthesis can begin, which results in high response latency. We propose the Discourse-Aware Dual-Track Streaming Response (DDTSR) framework, a low-latency architecture that enables listen-while-thinking and speak-while-thinking. DDTSR is built upon three key mechanisms: (1) connective-guided small-large model synergy, where an auxiliary small model generates minimal-committal discourse connectives while a large model performs knowledge-intensive reasoning in parallel; (2) streaming-based cross-modal collaboration, which dynamically overlaps ASR, LLM inference, and TTS to advance the earliest speakable moment; and (3) curriculum-learning-based discourse continuity enhancement, which maintains coherence and logical consistency between early responses and subsequent reasoning outputs. Experiments on two spoken dialogue benchmarks demonstrate that DDTSR reduces response latency by 19%-51% while preserving discourse quality. Further analysis </li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-89">正文（抓取，非 AI）</h3>
<p>[2602.23266v1] Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems Computer Science &gt; Computation and Language arXiv:2602.23266v1 (cs) [Submitted on 26 Feb 2026] Title: Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems Authors: Siyuan Liu , Jiahui Xu , Feng Jiang , Kuang Wang , Zefeng Zhao , Chu-Ren Huang , Jinghang Gu , Changqing Yin , Haizhou Li View a PDF of the paper titled Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems, by Siyuan Liu and 8 other authors View PDF HTML (experimental) Abstract: Achieving human-like responsiveness is a critical yet challenging goal for cascaded spoken dialogue systems. Conventional ASR-LLM-TTS pipelines follow a strictly sequential paradigm, requiring complete transcription and full reasoning before speech synthesis can begin, which results in high response latency. We propose the Discourse-Aware Dual-Track Streaming Response (DDTSR) framework, a low-latency architecture that enables listen-while-thinking and speak-while-thinking. DDTSR is built upon three key mechanisms: (1) connective-guided small-large model synergy, where an auxiliary small model generates minimal-committal discourse connectives while a large model performs knowledge-intensive reasoning in parallel; (2) streaming-based cross-modal collaboration, which dynamically overlaps ASR, LLM inference, and TTS to advance the earliest speakable moment; and (3) curriculum-learning-based discourse continuity enhancement, which maintains coherence and logical consistency between early responses and subsequent reasoning outputs. Experiments on two spoken dialogue benchmarks demonstrate that DDTSR reduces response latency by 19%-51% while preserving discourse quality. Further analysis shows that DDTSR functions as a plug-and-play module compatible with diverse LLM backbones, and remains robust across varying utterance lengths, indicating strong practicality and scalability for real-time spoken interaction. Subjects: Computation and Language (cs.CL) Cite as: arXiv:2602.23266 [cs.CL] (or arXiv:2602.23266v1 [cs.CL] for this version) https://doi.org/10.48550/arXiv.2602.23266 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Siyuan Liu [ view email ] [v1] Thu, 26 Feb 2026 17:39:56 UTC (1,012 KB) Full-text links: Access Paper: View a PDF of the paper titled Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems, by Siyuan Liu and 8 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CL &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-90">46. The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss</h2>
<ul>
<li>链接：https://arxiv.org/abs/2512.18610v2</li>
<li>来源：arxiv</li>
<li>摘要：Optimizing time series models via point-wise loss functions (e.g., MSE) relying on a heuristic point-wise i.i.d. assumption disregards the causal temporal structure. Focusing on the core independence issue under covariance stationarity, this paper aims to provide a first-principles analysis of the Expectation of Optimization Bias (EOB). Our analysis reveals a fundamental paradigm paradox: The more deterministic and structured the time series, the more severe the bias incurred by point-wise loss function. We derive the first closed-form quantification for the non-deterministic EOB across linear and non-linear systems, and prove EOB is an intrinsic data property, governed exclusively by sequence length and the defined Structural Signal-to-Noise Ratio. This theoretical discovery motivates our principled debiasing program that eliminates the bias through sequence length reduction and structural orthogonalization. We present a concrete solution via DFT or DWT, and propose a novel harmonized $\ell_p$ norm framework to rectify gradient optimization pathologies of high-variance sequences. Extensive experiments validate EOB Theory's generality and the superior performance of debiasing progr</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-91">正文（抓取，非 AI）</h3>
<p>[2512.18610v2] The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss Computer Science &gt; Machine Learning arXiv:2512.18610v2 (cs) [Submitted on 21 Dec 2025 ( v1 ), last revised 1 Feb 2026 (this version, v2)] Title: The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss Authors: Rongyao Cai , Yuxi Wan , Kexin Zhang , Ming Jin , Hao Wang , Zhiqiang Ge , Daoyi Dong , Yong Liu , Qingsong Wen View a PDF of the paper titled The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss, by Rongyao Cai and 8 other authors View PDF HTML (experimental) Abstract: Optimizing time series models via point-wise loss functions (e.g., MSE) relying on a heuristic point-wise i.i.d. assumption disregards the causal temporal structure. Focusing on the core independence issue under covariance stationarity, this paper aims to provide a first-principles analysis of the Expectation of Optimization Bias (EOB). Our analysis reveals a fundamental paradigm paradox: The more deterministic and structured the time series, the more severe the bias incurred by point-wise loss function. We derive the first closed-form quantification for the non-deterministic EOB across linear and non-linear systems, and prove EOB is an intrinsic data property, governed exclusively by sequence length and the defined Structural Signal-to-Noise Ratio. This theoretical discovery motivates our principled debiasing program that eliminates the bias through sequence length reduction and structural orthogonalization. We present a concrete solution via DFT or DWT, and propose a novel harmonized $\ell_p$ norm framework to rectify gradient optimization pathologies of high-variance sequences. Extensive experiments validate EOB Theory's generality and the superior performance of debiasing program, achieving 5.2% and 5.1% average improvement of MSE and MAE conducted on the iTransformer across 11 datasets, respectively. Comments: 54 pages Subjects: Machine Learning (cs.LG) Cite as: arXiv:2512.18610 [cs.LG] (or arXiv:2512.18610v2 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2512.18610 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Rongyao Cai [ view email ] [v1] Sun, 21 Dec 2025 06:08:22 UTC (27,328 KB) [v2] Sun, 1 Feb 2026 14:34:29 UTC (34,944 KB) Full-text links: Access Paper: View a PDF of the paper titled The Procrustean Bed of Time Series: The Optimization Bias of Point-wise Loss, by Rongyao Cai and 8 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-12 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-92">47. PRIMA: Pre-training with Risk-integrated Image-Metadata Alignment for Medical Diagnosis via LLM</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23297v1</li>
<li>来源：arxiv</li>
<li>摘要：Medical diagnosis requires the effective synthesis of visual manifestations and clinical metadata. However, existing methods often treat metadata as isolated tags, failing to exploit the rich semantic knowledge embedded in clinical descriptions. We propose PRIMA (Pre-training with Risk-integrated Image-Metadata Alignment), a framework that integrates domain-specific knowledge into multi-modal representation learning. We first curate an expert corpus of risk-disease correlations via Retrieval-Augmented Generation (RAG) to refine Clinical ModernBERT, embedding diagnostic priors into the text encoder. To bridge the modality gap, we introduce a dual-encoder pre-training strategy utilizing DINOv3 and our refined BERT, optimized by a suite of four complementary loss functions. These losses are designed to capture multi-granular semantic alignment and handle the ambiguity of clinical correlations through soft labels. Finally, we leverage Qwen-3 to fuse these aligned features for precise disease classification. Extensive experiments demonstrate that PRIMA effectively harmonizes pixel-level features with abstract clinical expertise, significantly outperforming other state-of-the-art methods</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-93">正文（抓取，非 AI）</h3>
<p>[2602.23297v1] PRIMA: Pre-training with Risk-integrated Image-Metadata Alignment for Medical Diagnosis via LLM Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23297v1 (cs) [Submitted on 26 Feb 2026] Title: PRIMA: Pre-training with Risk-integrated Image-Metadata Alignment for Medical Diagnosis via LLM Authors: Yiqing Wang , Chunming He , Ming-Chen Lu , Mercy Pawar , Leslie Niziol , Maria Woodward , Sina Farsiu View a PDF of the paper titled PRIMA: Pre-training with Risk-integrated Image-Metadata Alignment for Medical Diagnosis via LLM, by Yiqing Wang and 6 other authors View PDF HTML (experimental) Abstract: Medical diagnosis requires the effective synthesis of visual manifestations and clinical metadata. However, existing methods often treat metadata as isolated tags, failing to exploit the rich semantic knowledge embedded in clinical descriptions. We propose PRIMA (Pre-training with Risk-integrated Image-Metadata Alignment), a framework that integrates domain-specific knowledge into multi-modal representation learning. We first curate an expert corpus of risk-disease correlations via Retrieval-Augmented Generation (RAG) to refine Clinical ModernBERT, embedding diagnostic priors into the text encoder. To bridge the modality gap, we introduce a dual-encoder pre-training strategy utilizing DINOv3 and our refined BERT, optimized by a suite of four complementary loss functions. These losses are designed to capture multi-granular semantic alignment and handle the ambiguity of clinical correlations through soft labels. Finally, we leverage Qwen-3 to fuse these aligned features for precise disease classification. Extensive experiments demonstrate that PRIMA effectively harmonizes pixel-level features with abstract clinical expertise, significantly outperforming other state-of-the-art methods. Notably, our framework achieves superior robustness without the need for massive data collection or exhaustive computational resources. Our code will be made public upon acceptance. Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.23297 [cs.CV] (or arXiv:2602.23297v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23297 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Yiqing Wang [ view email ] [v1] Thu, 26 Feb 2026 18:07:52 UTC (521 KB) Full-text links: Access Paper: View a PDF of the paper titled PRIMA: Pre-training with Risk-integrated Image-Metadata Alignment for Medical Diagnosis via LLM, by Yiqing Wang and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-94">48. Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23351v1</li>
<li>来源：arxiv</li>
<li>摘要：The lack of reasoning capabilities in Vision-Language Models (VLMs) has remained at the forefront of research discourse. We posit that this behavior stems from a reporting bias in their training data. That is, how people communicate about visual content by default omits tacit information needed to supervise some types of reasoning; e.g., "at the game today!" is a more likely caption than "a photo of 37 people standing behind a field". We investigate the data underlying the popular VLMs OpenCLIP, LLaVA-1.5 and Molmo through the lens of theories from pragmatics, and find that reporting bias results in insufficient representation of four reasoning skills (spatial, temporal, negation, and counting), despite the corpora being of web-scale, and/or synthetically generated. With a set of curated benchmarks, we demonstrate that: (i) VLMs perform poorly on the aforementioned types of reasoning suppressed in the training data by reporting bias; (ii) contrary to popular belief, scaling data size, model size, and to multiple languages does not result in emergence of these skills by default; but, promisingly, (iii) incorporating annotations specifically collected to obtain tacit information is e</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-95">正文（抓取，非 AI）</h3>
<p>[2602.23351v1] Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning Computer Science &gt; Computation and Language arXiv:2602.23351v1 (cs) [Submitted on 26 Feb 2026] Title: Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning Authors: Amita Kamath , Jack Hessel , Khyathi Chandu , Jena D. Hwang , Kai-Wei Chang , Ranjay Krishna View a PDF of the paper titled Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning, by Amita Kamath and 5 other authors View PDF HTML (experimental) Abstract: The lack of reasoning capabilities in Vision-Language Models (VLMs) has remained at the forefront of research discourse. We posit that this behavior stems from a reporting bias in their training data. That is, how people communicate about visual content by default omits tacit information needed to supervise some types of reasoning; e.g., "at the game today!" is a more likely caption than "a photo of 37 people standing behind a field". We investigate the data underlying the popular VLMs OpenCLIP, LLaVA-1.5 and Molmo through the lens of theories from pragmatics, and find that reporting bias results in insufficient representation of four reasoning skills (spatial, temporal, negation, and counting), despite the corpora being of web-scale, and/or synthetically generated. With a set of curated benchmarks, we demonstrate that: (i) VLMs perform poorly on the aforementioned types of reasoning suppressed in the training data by reporting bias; (ii) contrary to popular belief, scaling data size, model size, and to multiple languages does not result in emergence of these skills by default; but, promisingly, (iii) incorporating annotations specifically collected to obtain tacit information is effective. Our findings highlight the need for more intentional training data curation methods, rather than counting on scale for emergence of reasoning capabilities. Comments: TACL 2026 Subjects: Computation and Language (cs.CL) ; Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.23351 [cs.CL] (or arXiv:2602.23351v1 [cs.CL] for this version) https://doi.org/10.48550/arXiv.2602.23351 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Amita Kamath [ view email ] [v1] Thu, 26 Feb 2026 18:54:06 UTC (15,345 KB) Full-text links: Access Paper: View a PDF of the paper titled Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning, by Amita Kamath and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CL &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CV References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-96">49. Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23225v1</li>
<li>来源：arxiv</li>
<li>摘要：Diffusion Language Models (DLMs) are often advertised as enabling parallel token generation, yet practical fast DLMs frequently converge to left-to-right, autoregressive (AR)-like decoding dynamics. In contrast, genuinely non-AR generation is promising because it removes AR's sequential bottleneck, better exploiting parallel hardware to reduce synchronization/communication overhead and improve latency scaling with output length. We argue that a primary driver of AR-like decoding is a mismatch between DLM objectives and the highly sequential structure of widely used training data, including standard pretraining corpora and long chain-of-thought (CoT) supervision. Motivated by this diagnosis, we propose NAP (Non-Autoregressive Parallel DLMs), a proof-of-concept, data-centric approach that better aligns supervision with non-AR parallel decoding. NAP curates examples as multiple independent reasoning trajectories and couples them with a parallel-forced decoding strategy that encourages multi-token parallel updates. Across math reasoning benchmarks, NAP yields stronger performance under parallel decoding than DLMs trained on standard long CoT data, with gains growing as parallelism incr</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-97">正文（抓取，非 AI）</h3>
<p>[2602.23225v1] Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding? Computer Science &gt; Computation and Language arXiv:2602.23225v1 (cs) [Submitted on 26 Feb 2026] Title: Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding? Authors: Pengxiang Li , Dilxat Muhtar , Lu Yin , Tianlong Chen , Shiwei Liu View a PDF of the paper titled Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?, by Pengxiang Li and 4 other authors View PDF HTML (experimental) Abstract: Diffusion Language Models (DLMs) are often advertised as enabling parallel token generation, yet practical fast DLMs frequently converge to left-to-right, autoregressive (AR)-like decoding dynamics. In contrast, genuinely non-AR generation is promising because it removes AR's sequential bottleneck, better exploiting parallel hardware to reduce synchronization/communication overhead and improve latency scaling with output length. We argue that a primary driver of AR-like decoding is a mismatch between DLM objectives and the highly sequential structure of widely used training data, including standard pretraining corpora and long chain-of-thought (CoT) supervision. Motivated by this diagnosis, we propose NAP (Non-Autoregressive Parallel DLMs), a proof-of-concept, data-centric approach that better aligns supervision with non-AR parallel decoding. NAP curates examples as multiple independent reasoning trajectories and couples them with a parallel-forced decoding strategy that encourages multi-token parallel updates. Across math reasoning benchmarks, NAP yields stronger performance under parallel decoding than DLMs trained on standard long CoT data, with gains growing as parallelism increases. Our results suggest that revisiting data and supervision is a principled direction for mitigating AR-like behavior and moving toward genuinely non-autoregressive parallel generation in DLMs. Our code is available at this https URL . Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23225 [cs.CL] (or arXiv:2602.23225v1 [cs.CL] for this version) https://doi.org/10.48550/arXiv.2602.23225 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Pengxiang Li [ view email ] [v1] Thu, 26 Feb 2026 17:04:57 UTC (782 KB) Full-text links: Access Paper: View a PDF of the paper titled Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?, by Pengxiang Li and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CL &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-98">50. AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23258v1</li>
<li>来源：arxiv</li>
<li>摘要：While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification effor</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-99">正文（抓取，非 AI）</h3>
<p>[2602.23258v1] AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Computer Science &gt; Artificial Intelligence arXiv:2602.23258v1 (cs) [Submitted on 26 Feb 2026] Title: AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Authors: Yutong Wang , Siyuan Xiong , Xuebo Liu , Wenkang Zhou , Liang Ding , Miao Zhang , Min Zhang View a PDF of the paper titled AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning, by Yutong Wang and 6 other authors View PDF HTML (experimental) Abstract: While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at this https URL . Subjects: Artificial Intelligence (cs.AI) ; Computation and Language (cs.CL) Cite as: arXiv:2602.23258 [cs.AI] (or arXiv:2602.23258v1 [cs.AI] for this version) https://doi.org/10.48550/arXiv.2602.23258 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Yutong Wang [ view email ] [v1] Thu, 26 Feb 2026 17:31:43 UTC (626 KB) Full-text links: Access Paper: View a PDF of the paper titled AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning, by Yutong Wang and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.AI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CL References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-100">51. A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23300v1</li>
<li>来源：arxiv</li>
<li>摘要：Emotion Recognition in Conversations (ERC) presents unique challenges, requiring models to capture the temporal flow of multi-turn dialogues and to effectively integrate cues from multiple modalities. We propose Mixture of Speech-Text Experts for Recognition of Emotions (MiSTER-E), a modular Mixture-of-Experts (MoE) framework designed to decouple two core challenges in ERC: modality-specific context modeling and multimodal information fusion. MiSTER-E leverages large language models (LLMs) fine-tuned for both speech and text to provide rich utterance-level embeddings, which are then enhanced through a convolutional-recurrent context modeling layer. The system integrates predictions from three experts-speech-only, text-only, and cross-modal-using a learned gating mechanism that dynamically weighs their outputs. To further encourage consistency and alignment across modalities, we introduce a supervised contrastive loss between paired speech-text representations and a KL-divergence-based regulariza-tion across expert predictions. Importantly, MiSTER-E does not rely on speaker identity at any stage. Experiments on three benchmark datasets-IEMOCAP, MELD, and MOSI-show that our proposal </li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-101">正文（抓取，非 AI）</h3>
<p>[2602.23300v1] A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations Computer Science &gt; Computation and Language arXiv:2602.23300v1 (cs) [Submitted on 26 Feb 2026] Title: A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations Authors: Soumya Dutta , Smruthi Balaji , Sriram Ganapathy View a PDF of the paper titled A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations, by Soumya Dutta and 2 other authors View PDF HTML (experimental) Abstract: Emotion Recognition in Conversations (ERC) presents unique challenges, requiring models to capture the temporal flow of multi-turn dialogues and to effectively integrate cues from multiple modalities. We propose Mixture of Speech-Text Experts for Recognition of Emotions (MiSTER-E), a modular Mixture-of-Experts (MoE) framework designed to decouple two core challenges in ERC: modality-specific context modeling and multimodal information fusion. MiSTER-E leverages large language models (LLMs) fine-tuned for both speech and text to provide rich utterance-level embeddings, which are then enhanced through a convolutional-recurrent context modeling layer. The system integrates predictions from three experts-speech-only, text-only, and cross-modal-using a learned gating mechanism that dynamically weighs their outputs. To further encourage consistency and alignment across modalities, we introduce a supervised contrastive loss between paired speech-text representations and a KL-divergence-based regulariza-tion across expert predictions. Importantly, MiSTER-E does not rely on speaker identity at any stage. Experiments on three benchmark datasets-IEMOCAP, MELD, and MOSI-show that our proposal achieves 70.9%, 69.5%, and 87.9% weighted F1-scores respectively, outperforming several baseline speech-text ERC systems. We also provide various ablations to highlight the contributions made in the proposed approach. Comments: Accepted to Elsevier Computer Speech and Language. 30 pages, 9 figures, 5 tables Subjects: Computation and Language (cs.CL) ; Audio and Speech Processing (eess.AS) Cite as: arXiv:2602.23300 [cs.CL] (or arXiv:2602.23300v1 [cs.CL] for this version) https://doi.org/10.48550/arXiv.2602.23300 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Soumya Dutta Mr [ view email ] [v1] Thu, 26 Feb 2026 18:08:40 UTC (7,797 KB) Full-text links: Access Paper: View a PDF of the paper titled A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations, by Soumya Dutta and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CL &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs eess eess.AS References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-102">52. Model Agreement via Anchoring</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23360v1</li>
<li>来源：arxiv</li>
<li>摘要：Numerous lines of aim to control $\textit{model disagreement}$ -- the extent to which two machine learning models disagree in their predictions. We adopt a simple and standard notion of model disagreement in real-valued prediction problems, namely the expected squared difference in predictions between two models trained on independent samples, without any coordination of the training processes. We would like to be able to drive disagreement to zero with some natural parameter(s) of the training procedure using analyses that can be applied to existing training methodologies.   We develop a simple general technique for proving bounds on independent model disagreement based on $\textit{anchoring}$ to the average of two models within the analysis. We then apply this technique to prove disagreement bounds for four commonly used machine learning algorithms: (1) stacked aggregation over an arbitrary model class (where disagreement is driven to 0 with the number of models $k$ being stacked) (2) gradient boosting (where disagreement is driven to 0 with the number of iterations $k$) (3) neural network training with architecture search (where disagreement is driven to 0 with the size $n$ of t</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-103">正文（抓取，非 AI）</h3>
<p>[2602.23360v1] Model Agreement via Anchoring Computer Science &gt; Machine Learning arXiv:2602.23360v1 (cs) [Submitted on 26 Feb 2026] Title: Model Agreement via Anchoring Authors: Eric Eaton , Surbhi Goel , Marcel Hussing , Michael Kearns , Aaron Roth , Sikata Bela Sengupta , Jessica Sorrell View a PDF of the paper titled Model Agreement via Anchoring, by Eric Eaton and 6 other authors View PDF HTML (experimental) Abstract: Numerous lines of aim to control $\textit{model disagreement}$ -- the extent to which two machine learning models disagree in their predictions. We adopt a simple and standard notion of model disagreement in real-valued prediction problems, namely the expected squared difference in predictions between two models trained on independent samples, without any coordination of the training processes. We would like to be able to drive disagreement to zero with some natural parameter(s) of the training procedure using analyses that can be applied to existing training methodologies. We develop a simple general technique for proving bounds on independent model disagreement based on $\textit{anchoring}$ to the average of two models within the analysis. We then apply this technique to prove disagreement bounds for four commonly used machine learning algorithms: (1) stacked aggregation over an arbitrary model class (where disagreement is driven to 0 with the number of models $k$ being stacked) (2) gradient boosting (where disagreement is driven to 0 with the number of iterations $k$) (3) neural network training with architecture search (where disagreement is driven to 0 with the size $n$ of the architecture being optimized over) and (4) regression tree training over all regression trees of fixed depth (where disagreement is driven to 0 with the depth $d$ of the tree architecture). For clarity, we work out our initial bounds in the setting of one-dimensional regression with squared error loss -- but then show that all of our results generalize to multi-dimensional regression with any strongly convex loss. Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23360 [cs.LG] (or arXiv:2602.23360v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23360 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Sikata Sengupta [ view email ] [v1] Thu, 26 Feb 2026 18:59:32 UTC (44 KB) Full-text links: Access Paper: View a PDF of the paper titled Model Agreement via Anchoring, by Eric Eaton and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-104">53. InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling</h2>
<ul>
<li>链接：https://arxiv.org/abs/2510.20302v1</li>
<li>来源：arxiv</li>
<li>摘要：Multivariate time series forecasting requires simultaneously modeling temporal patterns and cross-variate dependencies. Channel-independent methods such as PatchTST excel at temporal modeling but ignore variable correlations, while pure variate-attention approaches such as iTransformer sacrifice temporal encoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that achieves principled separation between temporal encoding and variate-level decoding. InvDec combines a patch-based temporal encoder with an inverted decoder operating on the variate dimension through variate-wise self-attention. We introduce delayed variate embeddings that enrich variable-specific representations only after temporal encoding, preserving temporal feature integrity. An adaptive residual fusion mechanism dynamically balances temporal and variate information across datasets of varying dimensions. Instantiating InvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven benchmarks demonstrate significant gains on high-dimensional datasets: 20.9% MSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and 2.7% gain on Traffic compared to PatchTST, while maintainin</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-105">正文（抓取，非 AI）</h3>
<p>[2510.20302v1] InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling Computer Science &gt; Machine Learning arXiv:2510.20302v1 (cs) [Submitted on 23 Oct 2025] Title: InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling Authors: Yuhang Wang View a PDF of the paper titled InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling, by Yuhang Wang View PDF HTML (experimental) Abstract: Multivariate time series forecasting requires simultaneously modeling temporal patterns and cross-variate dependencies. Channel-independent methods such as PatchTST excel at temporal modeling but ignore variable correlations, while pure variate-attention approaches such as iTransformer sacrifice temporal encoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that achieves principled separation between temporal encoding and variate-level decoding. InvDec combines a patch-based temporal encoder with an inverted decoder operating on the variate dimension through variate-wise self-attention. We introduce delayed variate embeddings that enrich variable-specific representations only after temporal encoding, preserving temporal feature integrity. An adaptive residual fusion mechanism dynamically balances temporal and variate information across datasets of varying dimensions. Instantiating InvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven benchmarks demonstrate significant gains on high-dimensional datasets: 20.9% MSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and 2.7% gain on Traffic compared to PatchTST, while maintaining competitive performance on low-dimensional ETT datasets. Ablation studies validate each component, and analysis reveals that InvDec's advantage grows with dataset dimensionality, confirming that cross-variate modeling becomes critical as the number of variables increases. Comments: 23pages, 3 figures Subjects: Machine Learning (cs.LG) Cite as: arXiv:2510.20302 [cs.LG] (or arXiv:2510.20302v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2510.20302 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Yuhang Wang [ view email ] [v1] Thu, 23 Oct 2025 07:42:01 UTC (475 KB) Full-text links: Access Paper: View a PDF of the paper titled InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling, by Yuhang Wang View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-10 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-106">54. Ruling Out Spiky WIMP Dark Matter using Indirect Searches</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23348v1</li>
<li>来源：arxiv</li>
<li>摘要：The dark matter (DM) density profile in the innermost region of the Galaxy remains an open question. In particular, while adiabatic growth of the supermassive black hole Sgr A$^\ast$ at the Galactic Center (GC) can induce a 'spike' in central DM density, the existence of such a spike is still under debate. Here we present new constraints on the spike slope $γ_{\rm sp}$ using conventional DM indirect detection searches. We first recast existing photon and neutrino line searches, which include the contribution from the GC region, into constraints on the thermally-averaged DM annihilation cross section $\langleσv\rangle$ in the presence of a DM spike. We then derive new bounds on the spike profile for a generic Weakly Interacting Massive Particle (WIMP) DM scenario, where the thermal freeze-out mechanism fixes the annihilation cross-section at $\langleσv\rangle\sim (2-3) \times 10^{-26}~{\rm cm}^3~{\rm s}^{-1}$. We find that for DM annihilation to photons, constraints from Fermi-LAT and MAGIC rule out spike profiles at the GC for a broad range of WIMP DM masses from 10 GeV to 100 TeV. Our result holds even if the photon channel constitutes only $1\%$ of the total annihilation rate. Fo</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-107">正文（抓取，非 AI）</h3>
<p>[2602.23348v1] Ruling Out Spiky WIMP Dark Matter using Indirect Searches High Energy Physics - Phenomenology arXiv:2602.23348v1 (hep-ph) [Submitted on 26 Feb 2026] Title: Ruling Out Spiky WIMP Dark Matter using Indirect Searches Authors: Dibya S. Chattopadhyay , P. S. Bhupal Dev , Yago Porto View a PDF of the paper titled Ruling Out Spiky WIMP Dark Matter using Indirect Searches, by Dibya S. Chattopadhyay and 2 other authors View PDF HTML (experimental) Abstract: The dark matter (DM) density profile in the innermost region of the Galaxy remains an open question. In particular, while adiabatic growth of the supermassive black hole Sgr A$^\ast$ at the Galactic Center (GC) can induce a 'spike' in central DM density, the existence of such a spike is still under debate. Here we present new constraints on the spike slope $\gamma_{\rm sp}$ using conventional DM indirect detection searches. We first recast existing photon and neutrino line searches, which include the contribution from the GC region, into constraints on the thermally-averaged DM annihilation cross section $\langle\sigma v\rangle$ in the presence of a DM spike. We then derive new bounds on the spike profile for a generic Weakly Interacting Massive Particle (WIMP) DM scenario, where the thermal freeze-out mechanism fixes the annihilation cross-section at $\langle\sigma v\rangle\sim (2-3) \times 10^{-26}~{\rm cm}^3~{\rm s}^{-1}$. We find that for DM annihilation to photons, constraints from Fermi-LAT and MAGIC rule out spike profiles at the GC for a broad range of WIMP DM masses from 10 GeV to 100 TeV. Our result holds even if the photon channel constitutes only $1\%$ of the total annihilation rate. For the neutrino channel, we use the IceCube data to constrain the existence of an extremely steep spike in the $\mathscr{O}(1-10)$ TeV DM mass range. Our analysis can be easily extended to other annihilation channels. Comments: 23 pages, 7 figures Subjects: High Energy Physics - Phenomenology (hep-ph) ; Astrophysics of Galaxies (astro-ph.GA) Report number: CETUP-2025-019 Cite as: arXiv:2602.23348 [hep-ph] (or arXiv:2602.23348v1 [hep-ph] for this version) https://doi.org/10.48550/arXiv.2602.23348 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Dibya Chattopadhyay [ view email ] [v1] Thu, 26 Feb 2026 18:51:44 UTC (1,011 KB) Full-text links: Access Paper: View a PDF of the paper titled Ruling Out Spiky WIMP Dark Matter using Indirect Searches, by Dibya S. Chattopadhyay and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: hep-ph &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: astro-ph astro-ph.GA References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-108">55. Decomposing Private Image Generation via Coarse-to-Fine Wavelet Modeling</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23262v1</li>
<li>来源：arxiv</li>
<li>摘要：Generative models trained on sensitive image datasets risk memorizing and reproducing individual training examples, making strong privacy guarantees essential. While differential privacy (DP) provides a principled framework for such guarantees, standard DP finetuning (e.g., with DP-SGD) often results in severe degradation of image quality, particularly in high-frequency textures, due to the indiscriminate addition of noise across all model parameters. In this work, we propose a spectral DP framework based on the hypothesis that the most privacy-sensitive portions of an image are often low-frequency components in the wavelet space (e.g., facial features and object shapes) while high-frequency components are largely generic and public. Based on this hypothesis, we propose the following two-stage framework for DP image generation with coarse image intermediaries: (1) DP finetune an autoregressive spectral image tokenizer model on the low-resolution wavelet coefficients of the sensitive images, and (2) perform high-resolution upsampling using a publicly pretrained super-resolution model. By restricting the privacy budget to the global structures of the image in the first stage, and lev</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-109">正文（抓取，非 AI）</h3>
<p>[2602.23262v1] Decomposing Private Image Generation via Coarse-to-Fine Wavelet Modeling Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23262v1 (cs) [Submitted on 26 Feb 2026] Title: Decomposing Private Image Generation via Coarse-to-Fine Wavelet Modeling Authors: Jasmine Bayrooti , Weiwei Kong , Natalia Ponomareva , Carlos Esteves , Ameesh Makadia , Amanda Prorok View a PDF of the paper titled Decomposing Private Image Generation via Coarse-to-Fine Wavelet Modeling, by Jasmine Bayrooti and 5 other authors View PDF HTML (experimental) Abstract: Generative models trained on sensitive image datasets risk memorizing and reproducing individual training examples, making strong privacy guarantees essential. While differential privacy (DP) provides a principled framework for such guarantees, standard DP finetuning (e.g., with DP-SGD) often results in severe degradation of image quality, particularly in high-frequency textures, due to the indiscriminate addition of noise across all model parameters. In this work, we propose a spectral DP framework based on the hypothesis that the most privacy-sensitive portions of an image are often low-frequency components in the wavelet space (e.g., facial features and object shapes) while high-frequency components are largely generic and public. Based on this hypothesis, we propose the following two-stage framework for DP image generation with coarse image intermediaries: (1) DP finetune an autoregressive spectral image tokenizer model on the low-resolution wavelet coefficients of the sensitive images, and (2) perform high-resolution upsampling using a publicly pretrained super-resolution model. By restricting the privacy budget to the global structures of the image in the first stage, and leveraging the post-processing property of DP for detail refinement, we achieve promising trade-offs between privacy and utility. Experiments on the MS-COCO and MM-CelebA-HQ datasets show that our method generates images with improved quality and style capture relative to other leading DP image frameworks. Subjects: Computer Vision and Pattern Recognition (cs.CV) ; Cryptography and Security (cs.CR) Cite as: arXiv:2602.23262 [cs.CV] (or arXiv:2602.23262v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23262 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Jasmine Bayrooti [ view email ] [v1] Thu, 26 Feb 2026 17:36:48 UTC (10,320 KB) Full-text links: Access Paper: View a PDF of the paper titled Decomposing Private Image Generation via Coarse-to-Fine Wavelet Modeling, by Jasmine Bayrooti and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CR References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-110">56. Secure Multicast Communications with Pinching-Antenna Systems (PASS)</h2>
<ul>
<li>链接：https://arxiv.org/abs/2509.16045v1</li>
<li>来源：arxiv</li>
<li>摘要：This article investigates secure multicast communications in pinching-antenna systems (PASS), where pinching beamforming is enabled by adaptively adjusting pinching antenna (PAs) positions along waveguides to improve multicast security. Specifically, a PASS-based secure multicast framework is proposed, in which joint optimization of transmit and pinching beamforming is conducted to maximize the secrecy multicast rate. i) For the single-group multicast scenario, an alternating optimization (AO) framework is employed, where the pinching beamformer is updated via an element-wise sequential optimization method. The transmit beamformer is designed via a semidefinite relaxation (SDR) formulation for an upper-bound solution, while a Dinkelbach-alternating direction method of multipliers (ADMM) offers a low-complexity alternative. ii) For the multi-group multicast scenario, transmit and pinching beamformers are alternately optimized under a majorization-minimization (MM) framework. The transmit beamformer is obtained via SDR or an efficient second-order cone programming (SOCP) method, while the pinching beamformer is updated through MM-based element-wise sequential update strategy. Numeric</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-111">正文（抓取，非 AI）</h3>
<p>[2509.16045v1] Secure Multicast Communications with Pinching-Antenna Systems (PASS) Electrical Engineering and Systems Science &gt; Signal Processing arXiv:2509.16045v1 (eess) [Submitted on 19 Sep 2025] Title: Secure Multicast Communications with Pinching-Antenna Systems (PASS) Authors: Shan Shan , Chongjun Ouyang , Yong Li , Yuanwei Liu View a PDF of the paper titled Secure Multicast Communications with Pinching-Antenna Systems (PASS), by Shan Shan and Chongjun Ouyang and Yong Li and Yuanwei Liu View PDF HTML (experimental) Abstract: This article investigates secure multicast communications in pinching-antenna systems (PASS), where pinching beamforming is enabled by adaptively adjusting pinching antenna (PAs) positions along waveguides to improve multicast security. Specifically, a PASS-based secure multicast framework is proposed, in which joint optimization of transmit and pinching beamforming is conducted to maximize the secrecy multicast rate. i) For the single-group multicast scenario, an alternating optimization (AO) framework is employed, where the pinching beamformer is updated via an element-wise sequential optimization method. The transmit beamformer is designed via a semidefinite relaxation (SDR) formulation for an upper-bound solution, while a Dinkelbach-alternating direction method of multipliers (ADMM) offers a low-complexity alternative. ii) For the multi-group multicast scenario, transmit and pinching beamformers are alternately optimized under a majorization-minimization (MM) framework. The transmit beamformer is obtained via SDR or an efficient second-order cone programming (SOCP) method, while the pinching beamformer is updated through MM-based element-wise sequential update strategy. Numerical results are provided to demonstrate that: (i) PASS consistently outperform conventional fixed-location antenna architectures in terms of secrecy performance across various configurations; and (ii) the performance advantage of PASS over fixed-location architectures becomes more significant with increased service region, larger antenna arrays, and higher user and eavesdropper densities. Subjects: Signal Processing (eess.SP) Cite as: arXiv:2509.16045 [eess.SP] (or arXiv:2509.16045v1 [eess.SP] for this version) https://doi.org/10.48550/arXiv.2509.16045 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Shan Shan [ view email ] [v1] Fri, 19 Sep 2025 14:57:02 UTC (385 KB) Full-text links: Access Paper: View a PDF of the paper titled Secure Multicast Communications with Pinching-Antenna Systems (PASS), by Shan Shan and Chongjun Ouyang and Yong Li and Yuanwei Liu View PDF HTML (experimental) TeX Source view license Current browse context: eess.SP &lt; prev | next &gt; new | recent | 2025-09 Change to browse by: eess References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-112">57. LineGraph2Road: Structural Graph Reasoning on Line Graphs for Road Network Extraction</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23290v1</li>
<li>来源：arxiv</li>
<li>摘要：The accurate and automatic extraction of roads from satellite imagery is critical for applications in navigation and urban planning, significantly reducing the need for manual annotation. Many existing methods decompose this task into keypoint extraction and connectedness prediction, but often struggle to capture long-range dependencies and complex topologies. Here, we propose LineGraph2Road, a framework that improves connectedness prediction by formulating it as binary classification over edges in a constructed global but sparse Euclidean graph, where nodes are keypoints extracted from segmentation masks and edges connect node pairs within a predefined distance threshold, representing potential road segments. To better learn structural link representation, we transform the original graph into its corresponding line graph and apply a Graph Transformer on it for connectedness prediction. This formulation overcomes the limitations of endpoint-embedding fusion on set-isomorphic links, enabling rich link representations and effective relational reasoning over the global structure. Additionally, we introduce an overpass/underpass head to resolve multi-level crossings and a coupled NMS s</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-113">正文（抓取，非 AI）</h3>
<p>[2602.23290v1] LineGraph2Road: Structural Graph Reasoning on Line Graphs for Road Network Extraction Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23290v1 (cs) [Submitted on 26 Feb 2026] Title: LineGraph2Road: Structural Graph Reasoning on Line Graphs for Road Network Extraction Authors: Zhengyang Wei , Renzhi Jing , Yiyi He , Jenny Suckale View a PDF of the paper titled LineGraph2Road: Structural Graph Reasoning on Line Graphs for Road Network Extraction, by Zhengyang Wei and 3 other authors View PDF HTML (experimental) Abstract: The accurate and automatic extraction of roads from satellite imagery is critical for applications in navigation and urban planning, significantly reducing the need for manual annotation. Many existing methods decompose this task into keypoint extraction and connectedness prediction, but often struggle to capture long-range dependencies and complex topologies. Here, we propose LineGraph2Road, a framework that improves connectedness prediction by formulating it as binary classification over edges in a constructed global but sparse Euclidean graph, where nodes are keypoints extracted from segmentation masks and edges connect node pairs within a predefined distance threshold, representing potential road segments. To better learn structural link representation, we transform the original graph into its corresponding line graph and apply a Graph Transformer on it for connectedness prediction. This formulation overcomes the limitations of endpoint-embedding fusion on set-isomorphic links, enabling rich link representations and effective relational reasoning over the global structure. Additionally, we introduce an overpass/underpass head to resolve multi-level crossings and a coupled NMS strategy to preserve critical connections. We evaluate LineGraph2Road on three benchmarks: City-scale, SpaceNet, and Global-scale, and show that it achieves state-of-the-art results on two key metrics, TOPO-F1 and APLS. It also captures fine visual details critical for real-world deployment. We will make our code publicly available. Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.23290 [cs.CV] (or arXiv:2602.23290v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23290 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Zhengyang Wei [ view email ] [v1] Thu, 26 Feb 2026 18:02:44 UTC (16,303 KB) Full-text links: Access Paper: View a PDF of the paper titled LineGraph2Road: Structural Graph Reasoning on Line Graphs for Road Network Extraction, by Zhengyang Wei and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-114">58. Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23330v1</li>
<li>来源：arxiv</li>
<li>摘要：The advancement of large language models (LLMs) has accelerated the development of autonomous financial trading systems. While mainstream approaches deploy multi-agent systems mimicking analyst and manager roles, they often rely on abstract instructions that overlook the intricacies of real-world workflows, which can lead to degraded inference performance and less transparent decision-making. Therefore, we propose a multi-agent LLM trading framework that explicitly decomposes investment analysis into fine-grained tasks, rather than providing coarse-grained instructions. We evaluate the proposed framework using Japanese stock data, including prices, financial statements, news, and macro information, under a leakage-controlled backtesting setting. Experimental results show that fine-grained task decomposition significantly improves risk-adjusted returns compared to conventional coarse-grained designs. Crucially, further analysis of intermediate agent outputs suggests that alignment between analytical outputs and downstream decision preferences is a critical driver of system performance. Moreover, we conduct standard portfolio optimization, exploiting low correlation with the stock in</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-115">正文（抓取，非 AI）</h3>
<p>[2602.23330v1] Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks Computer Science &gt; Artificial Intelligence arXiv:2602.23330v1 (cs) [Submitted on 26 Feb 2026] Title: Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks Authors: Kunihiro Miyazaki , Takanobu Kawahara , Stephen Roberts , Stefan Zohren View a PDF of the paper titled Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks, by Kunihiro Miyazaki and 2 other authors View PDF HTML (experimental) Abstract: The advancement of large language models (LLMs) has accelerated the development of autonomous financial trading systems. While mainstream approaches deploy multi-agent systems mimicking analyst and manager roles, they often rely on abstract instructions that overlook the intricacies of real-world workflows, which can lead to degraded inference performance and less transparent decision-making. Therefore, we propose a multi-agent LLM trading framework that explicitly decomposes investment analysis into fine-grained tasks, rather than providing coarse-grained instructions. We evaluate the proposed framework using Japanese stock data, including prices, financial statements, news, and macro information, under a leakage-controlled backtesting setting. Experimental results show that fine-grained task decomposition significantly improves risk-adjusted returns compared to conventional coarse-grained designs. Crucially, further analysis of intermediate agent outputs suggests that alignment between analytical outputs and downstream decision preferences is a critical driver of system performance. Moreover, we conduct standard portfolio optimization, exploiting low correlation with the stock index and the variance of each system's output. This approach achieves superior performance. These findings contribute to the design of agent structure and task configuration when applying LLM agents to trading systems in practical settings. Comments: 14 pages, 3 figures Subjects: Artificial Intelligence (cs.AI) ; Trading and Market Microstructure (q-fin.TR) Cite as: arXiv:2602.23330 [cs.AI] (or arXiv:2602.23330v1 [cs.AI] for this version) https://doi.org/10.48550/arXiv.2602.23330 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Takanobu Kawahara [ view email ] [v1] Thu, 26 Feb 2026 18:37:36 UTC (144 KB) Full-text links: Access Paper: View a PDF of the paper titled Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks, by Kunihiro Miyazaki and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.AI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs q-fin q-fin.TR References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-116">59. MediX-R1: Open Ended Medical Reinforcement Learning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23363v1</li>
<li>来源：arxiv</li>
<li>摘要：We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond multiple-choice formats. MediX-R1 fine-tunes a baseline vision-language backbone with Group Based RL and a composite reward tailored for medical reasoning: an LLM-based accuracy reward that judges semantic correctness with a strict YES/NO decision, a medical embedding-based semantic reward to capture paraphrases and terminology variants, and lightweight format and modality rewards that enforce interpretable reasoning and modality recognition. This multi-signal design provides stable, informative feedback for open-ended outputs where traditional verifiable or MCQ-only rewards fall short. To measure progress, we propose a unified evaluation framework for both text-only and image+text tasks that uses a Reference-based LLM-as-judge in place of brittle string-overlap metrics, capturing semantic correctness, reasoning, and contextual alignment. Despite using only $\sim51$K instruction examples, MediX-R1 achieves excellent results across standard medical LLM (text-only) and VLM (image + text) benchmarks, </li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-117">正文（抓取，非 AI）</h3>
<p>[2602.23363v1] MediX-R1: Open Ended Medical Reinforcement Learning Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23363v1 (cs) [Submitted on 26 Feb 2026] Title: MediX-R1: Open Ended Medical Reinforcement Learning Authors: Sahal Shaji Mullappilly , Mohammed Irfan Kurpath , Omair Mohamed , Mohamed Zidan , Fahad Khan , Salman Khan , Rao Anwer , Hisham Cholakkal View a PDF of the paper titled MediX-R1: Open Ended Medical Reinforcement Learning, by Sahal Shaji Mullappilly and 7 other authors View PDF HTML (experimental) Abstract: We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond multiple-choice formats. MediX-R1 fine-tunes a baseline vision-language backbone with Group Based RL and a composite reward tailored for medical reasoning: an LLM-based accuracy reward that judges semantic correctness with a strict YES/NO decision, a medical embedding-based semantic reward to capture paraphrases and terminology variants, and lightweight format and modality rewards that enforce interpretable reasoning and modality recognition. This multi-signal design provides stable, informative feedback for open-ended outputs where traditional verifiable or MCQ-only rewards fall short. To measure progress, we propose a unified evaluation framework for both text-only and image+text tasks that uses a Reference-based LLM-as-judge in place of brittle string-overlap metrics, capturing semantic correctness, reasoning, and contextual alignment. Despite using only $\sim51$K instruction examples, MediX-R1 achieves excellent results across standard medical LLM (text-only) and VLM (image + text) benchmarks, outperforming strong open-source baselines and delivering particularly large gains on open-ended clinical tasks. Our results demonstrate that open-ended RL with comprehensive reward signals and LLM-based evaluation is a practical path toward reliable medical reasoning in multimodal models. Our trained models, curated datasets and source code are available at this https URL Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.23363 [cs.CV] (or arXiv:2602.23363v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23363 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Sahal Shaji Mullappilly [ view email ] [v1] Thu, 26 Feb 2026 18:59:46 UTC (1,145 KB) Full-text links: Access Paper: View a PDF of the paper titled MediX-R1: Open Ended Medical Reinforcement Learning, by Sahal Shaji Mullappilly and 7 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-118">60. SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23359v1</li>
<li>来源：arxiv</li>
<li>摘要：We identify occlusion reasoning as a fundamental yet overlooked aspect for 3D layout-conditioned generation. It is essential for synthesizing partially occluded objects with depth-consistent geometry and scale. While existing methods can generate realistic scenes that follow input layouts, they often fail to model precise inter-object occlusions. We propose SeeThrough3D, a model for 3D layout conditioned generation that explicitly models occlusions. We introduce an occlusion-aware 3D scene representation (OSCR), where objects are depicted as translucent 3D boxes placed within a virtual environment and rendered from desired camera viewpoint. The transparency encodes hidden object regions, enabling the model to reason about occlusions, while the rendered viewpoint provides explicit camera control during generation. We condition a pretrained flow based text-to-image image generation model by introducing a set of visual tokens derived from our rendered 3D representation. Furthermore, we apply masked self-attention to accurately bind each object bounding box to its corresponding textual description, enabling accurate generation of multiple objects without object attribute mixing. To tra</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-119">正文（抓取，非 AI）</h3>
<p>[2602.23359v1] SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23359v1 (cs) [Submitted on 26 Feb 2026] Title: SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation Authors: Vaibhav Agrawal , Rishubh Parihar , Pradhaan Bhat , Ravi Kiran Sarvadevabhatla , R. Venkatesh Babu View a PDF of the paper titled SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation, by Vaibhav Agrawal and 4 other authors View PDF HTML (experimental) Abstract: We identify occlusion reasoning as a fundamental yet overlooked aspect for 3D layout-conditioned generation. It is essential for synthesizing partially occluded objects with depth-consistent geometry and scale. While existing methods can generate realistic scenes that follow input layouts, they often fail to model precise inter-object occlusions. We propose SeeThrough3D, a model for 3D layout conditioned generation that explicitly models occlusions. We introduce an occlusion-aware 3D scene representation (OSCR), where objects are depicted as translucent 3D boxes placed within a virtual environment and rendered from desired camera viewpoint. The transparency encodes hidden object regions, enabling the model to reason about occlusions, while the rendered viewpoint provides explicit camera control during generation. We condition a pretrained flow based text-to-image image generation model by introducing a set of visual tokens derived from our rendered 3D representation. Furthermore, we apply masked self-attention to accurately bind each object bounding box to its corresponding textual description, enabling accurate generation of multiple objects without object attribute mixing. To train the model, we construct a synthetic dataset with diverse multi-object scenes with strong inter-object occlusions. SeeThrough3D generalizes effectively to unseen object categories and enables precise 3D layout control with realistic occlusions and consistent camera control. Comments: Project page: this https URL . Accepted at CVPR 2026 Subjects: Computer Vision and Pattern Recognition (cs.CV) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23359 [cs.CV] (or arXiv:2602.23359v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23359 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Rishubh Parihar [ view email ] [v1] Thu, 26 Feb 2026 18:59:05 UTC (38,865 KB) Full-text links: Access Paper: View a PDF of the paper titled SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation, by Vaibhav Agrawal and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-120">61. A Thermal-Electrical Co-Optimization Framework for Active Distribution Grids with Electric Vehicles and Heat Pumps</h2>
<ul>
<li>链接：https://arxiv.org/abs/2601.21651v1</li>
<li>来源：arxiv</li>
<li>摘要：The growing electrification of transportation and heating through Electric Vehicles (EVs) and Heat Pumps (HPs) introduces both flexibility and complexity to Active Distribution Networks (ADNs). These resources provide substantial operational flexibility but also create tightly coupled thermal-electrical dynamics that challenge conventional network management. This paper proposes a unified co-optimization framework that integrates a calibrated 3R2C grey-box building thermal model into a network-constrained Optimal Power Flow (OPF). The framework jointly optimizes EVs, HPs, and photovoltaic systems while explicitly enforcing thermal comfort, Distributed Energy Resource (DER) limits, and full power flow physics. To maintain computational tractability, Second-Order Cone Programming (SOCP) relaxations are evaluated on a realistic low-voltage feeder. The analysis shows that, despite network heterogeneity violating some theoretical exactness conditions, the relaxation remains exact in practice. Comparative assessments of convex DistFlow, bus injection, and branch flow formulations reveal that convex DistFlow achieves sub-second runtimes and near-optimal performance even at high DER penetr</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-121">正文（抓取，非 AI）</h3>
<p>[2601.21651v1] A Thermal-Electrical Co-Optimization Framework for Active Distribution Grids with Electric Vehicles and Heat Pumps Electrical Engineering and Systems Science &gt; Systems and Control arXiv:2601.21651v1 (eess) [Submitted on 29 Jan 2026] Title: A Thermal-Electrical Co-Optimization Framework for Active Distribution Grids with Electric Vehicles and Heat Pumps Authors: Savvas Panagi , Chrysovalantis Spanias , Petros Aristidou View a PDF of the paper titled A Thermal-Electrical Co-Optimization Framework for Active Distribution Grids with Electric Vehicles and Heat Pumps, by Savvas Panagi and 2 other authors View PDF HTML (experimental) Abstract: The growing electrification of transportation and heating through Electric Vehicles (EVs) and Heat Pumps (HPs) introduces both flexibility and complexity to Active Distribution Networks (ADNs). These resources provide substantial operational flexibility but also create tightly coupled thermal-electrical dynamics that challenge conventional network management. This paper proposes a unified co-optimization framework that integrates a calibrated 3R2C grey-box building thermal model into a network-constrained Optimal Power Flow (OPF). The framework jointly optimizes EVs, HPs, and photovoltaic systems while explicitly enforcing thermal comfort, Distributed Energy Resource (DER) limits, and full power flow physics. To maintain computational tractability, Second-Order Cone Programming (SOCP) relaxations are evaluated on a realistic low-voltage feeder. The analysis shows that, despite network heterogeneity violating some theoretical exactness conditions, the relaxation remains exact in practice. Comparative assessments of convex DistFlow, bus injection, and branch flow formulations reveal that convex DistFlow achieves sub-second runtimes and near-optimal performance even at high DER penetration levels. Simulations confirm the effectiveness of coordinated scheduling, yielding reductions of 41% in transformer aging, 54% in losses, and complete elimination of voltage violations, demonstrating the value of integrated thermal-electrical coordination in future smart grids. Subjects: Systems and Control (eess.SY) Cite as: arXiv:2601.21651 [eess.SY] (or arXiv:2601.21651v1 [eess.SY] for this version) https://doi.org/10.48550/arXiv.2601.21651 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Savvas Panagi [ view email ] [v1] Thu, 29 Jan 2026 12:50:01 UTC (1,074 KB) Full-text links: Access Paper: View a PDF of the paper titled A Thermal-Electrical Co-Optimization Framework for Active Distribution Grids with Electric Vehicles and Heat Pumps, by Savvas Panagi and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SY &lt; prev | next &gt; new | recent | 2026-01 Change to browse by: cs cs.SY eess References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-122">62. Cell-Free MIMO with Rotatable Antennas: When Macro-Diversity Meets Antenna Directivity</h2>
<ul>
<li>链接：https://arxiv.org/abs/2601.16543v1</li>
<li>来源：arxiv</li>
<li>摘要：Cell-free networks leverage distributed access points (APs) to achieve macro-diversity, yet their performance is often constrained by large disparities in channel quality arising from user geometry and blockages. To address this, rotatable antennas (RAs) add a lightweight hardware degree of freedom by steering the antenna boresight toward dominant propagation directions to strengthen unfavorable links, thereby enabling the network to better exploit macro-diversity for higher and more uniform performance. This paper investigates an RA-enabled cell-free downlink network and formulates a max-min rate problem that jointly optimizes transmit beamforming and antenna orientations. To tackle this challenging problem, we develop an alternating-optimization-based algorithm that iteratively updates the beamformers via a second-order cone program (SOCP) and optimizes the antenna orientations using successive convex approximation. To reduce complexity, we further propose an efficient two-stage scheme that first designs orientations by maximizing a proportional-fair log-utility using manifold-aware Frank-Wolfe updates, and then computes the beamformers using an SOCP-based design. Simulation resu</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-123">正文（抓取，非 AI）</h3>
<p>[2601.16543v1] Cell-Free MIMO with Rotatable Antennas: When Macro-Diversity Meets Antenna Directivity Electrical Engineering and Systems Science &gt; Signal Processing arXiv:2601.16543v1 (eess) [Submitted on 23 Jan 2026] Title: Cell-Free MIMO with Rotatable Antennas: When Macro-Diversity Meets Antenna Directivity Authors: Xingxiang Peng , Qingqing Wu , Ziyuan Zheng , Yanze Zhu , Wen Chen , Penghui Huang , Ying Gao , Honghao Wang View a PDF of the paper titled Cell-Free MIMO with Rotatable Antennas: When Macro-Diversity Meets Antenna Directivity, by Xingxiang Peng and 7 other authors View PDF HTML (experimental) Abstract: Cell-free networks leverage distributed access points (APs) to achieve macro-diversity, yet their performance is often constrained by large disparities in channel quality arising from user geometry and blockages. To address this, rotatable antennas (RAs) add a lightweight hardware degree of freedom by steering the antenna boresight toward dominant propagation directions to strengthen unfavorable links, thereby enabling the network to better exploit macro-diversity for higher and more uniform performance. This paper investigates an RA-enabled cell-free downlink network and formulates a max-min rate problem that jointly optimizes transmit beamforming and antenna orientations. To tackle this challenging problem, we develop an alternating-optimization-based algorithm that iteratively updates the beamformers via a second-order cone program (SOCP) and optimizes the antenna orientations using successive convex approximation. To reduce complexity, we further propose an efficient two-stage scheme that first designs orientations by maximizing a proportional-fair log-utility using manifold-aware Frank-Wolfe updates, and then computes the beamformers using an SOCP-based design. Simulation results demonstrate that the proposed orientation-aware designs achieve a substantially higher worst-user rate than conventional beamforming-only benchmarks. Furthermore, larger antenna directivity enhances fairness with proper orientation but can degrade the worst-user performance otherwise. Comments: 12 pages, 7 figures. Submitted to an IEEE journal for possible publication Subjects: Signal Processing (eess.SP) Cite as: arXiv:2601.16543 [eess.SP] (or arXiv:2601.16543v1 [eess.SP] for this version) https://doi.org/10.48550/arXiv.2601.16543 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Xingxiang Peng [ view email ] [v1] Fri, 23 Jan 2026 08:23:55 UTC (246 KB) Full-text links: Access Paper: View a PDF of the paper titled Cell-Free MIMO with Rotatable Antennas: When Macro-Diversity Meets Antenna Directivity, by Xingxiang Peng and 7 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SP &lt; prev | next &gt; new | recent | 2026-01 Change to browse by: eess References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-124">63. Towards Long-Form Spatio-Temporal Video Grounding</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23294v1</li>
<li>来源：arxiv</li>
<li>摘要：In real scenarios, videos can span several minutes or even hours. However, existing research on spatio-temporal video grounding (STVG), given a textual query, mainly focuses on localizing targets in short videos of tens of seconds, typically less than one minute, which limits real-world applications. In this paper, we explore Long-Form STVG (LF-STVG), which aims to locate targets in long-term videos. Compared with short videos, long-term videos contain much longer temporal spans and more irrelevant information, making it difficult for existing STVG methods that process all frames at once. To address this challenge, we propose an AutoRegressive Transformer architecture for LF-STVG, termed ART-STVG. Unlike conventional STVG methods that require the entire video sequence to make predictions at once, ART-STVG treats the video as streaming input and processes frames sequentially, enabling efficient handling of long videos. To model spatio-temporal context, we design spatial and temporal memory banks and apply them to the decoders. Since memories from different moments are not always relevant to the current frame, we introduce simple yet effective memory selection strategies to provide m</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-125">正文（抓取，非 AI）</h3>
<p>[2602.23294v1] Towards Long-Form Spatio-Temporal Video Grounding Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23294v1 (cs) [Submitted on 26 Feb 2026] Title: Towards Long-Form Spatio-Temporal Video Grounding Authors: Xin Gu , Bing Fan , Jiali Yao , Zhipeng Zhang , Yan Huang , Cheng Han , Heng Fan , Libo Zhang View a PDF of the paper titled Towards Long-Form Spatio-Temporal Video Grounding, by Xin Gu and 7 other authors View PDF HTML (experimental) Abstract: In real scenarios, videos can span several minutes or even hours. However, existing research on spatio-temporal video grounding (STVG), given a textual query, mainly focuses on localizing targets in short videos of tens of seconds, typically less than one minute, which limits real-world applications. In this paper, we explore Long-Form STVG (LF-STVG), which aims to locate targets in long-term videos. Compared with short videos, long-term videos contain much longer temporal spans and more irrelevant information, making it difficult for existing STVG methods that process all frames at once. To address this challenge, we propose an AutoRegressive Transformer architecture for LF-STVG, termed ART-STVG. Unlike conventional STVG methods that require the entire video sequence to make predictions at once, ART-STVG treats the video as streaming input and processes frames sequentially, enabling efficient handling of long videos. To model spatio-temporal context, we design spatial and temporal memory banks and apply them to the decoders. Since memories from different moments are not always relevant to the current frame, we introduce simple yet effective memory selection strategies to provide more relevant information to the decoders, significantly improving performance. Furthermore, instead of parallel spatial and temporal localization, we propose a cascaded spatio-temporal design that connects the spatial decoder to the temporal decoder, allowing fine-grained spatial cues to assist complex temporal localization in long videos. Experiments on newly extended LF-STVG datasets show that ART-STVG significantly outperforms state-of-the-art methods, while achieving competitive performance on conventional short-form STVG. Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.23294 [cs.CV] (or arXiv:2602.23294v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23294 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Bing Fan [ view email ] [v1] Thu, 26 Feb 2026 18:04:09 UTC (3,102 KB) Full-text links: Access Paper: View a PDF of the paper titled Towards Long-Form Spatio-Temporal Video Grounding, by Xin Gu and 7 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-126">64. CL4SE: A Context Learning Benchmark For Software Engineering Tasks</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23047v1</li>
<li>来源：arxiv</li>
<li>摘要：Context engineering has emerged as a pivotal paradigm for unlocking the potential of Large Language Models (LLMs) in Software Engineering (SE) tasks, enabling performance gains at test time without model fine-tuning. Despite its success, existing research lacks a systematic taxonomy of SE-specific context types and a dedicated benchmark to quantify the heterogeneous effects of different contexts across core SE workflows. To address this gap, we propose CL4SE (Context Learning for Software Engineering), a comprehensive benchmark featuring a fine-grained taxonomy of four SE-oriented context types (interpretable examples, project-specific context, procedural decision-making context, and positive &amp; negative context), each mapped to a representative task (code generation, code summarization, code review, and patch correctness assessment). We construct high-quality datasets comprising over 13,000 samples from more than 30 open-source projects and evaluate five mainstream LLMs across nine metrics. Extensive experiments demonstrate that context learning yields an average performance improvement of 24.7% across all tasks. Specifically, procedural context boosts code review performance by up</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-127">正文（抓取，非 AI）</h3>
<p>[2602.23047v1] CL4SE: A Context Learning Benchmark For Software Engineering Tasks Computer Science &gt; Software Engineering arXiv:2602.23047v1 (cs) [Submitted on 26 Feb 2026] Title: CL4SE: A Context Learning Benchmark For Software Engineering Tasks Authors: Haichuan Hu , Ye Shang , Guoqing Xie , Congqing He , Quanjun Zhang View a PDF of the paper titled CL4SE: A Context Learning Benchmark For Software Engineering Tasks, by Haichuan Hu and 4 other authors View PDF HTML (experimental) Abstract: Context engineering has emerged as a pivotal paradigm for unlocking the potential of Large Language Models (LLMs) in Software Engineering (SE) tasks, enabling performance gains at test time without model fine-tuning. Despite its success, existing research lacks a systematic taxonomy of SE-specific context types and a dedicated benchmark to quantify the heterogeneous effects of different contexts across core SE workflows. To address this gap, we propose CL4SE (Context Learning for Software Engineering), a comprehensive benchmark featuring a fine-grained taxonomy of four SE-oriented context types (interpretable examples, project-specific context, procedural decision-making context, and positive &amp; negative context), each mapped to a representative task (code generation, code summarization, code review, and patch correctness assessment). We construct high-quality datasets comprising over 13,000 samples from more than 30 open-source projects and evaluate five mainstream LLMs across nine metrics. Extensive experiments demonstrate that context learning yields an average performance improvement of 24.7% across all tasks. Specifically, procedural context boosts code review performance by up to 33% (Qwen3-Max), mixed positive-negative context improves patch assessment by 30% (DeepSeek-V3), project-specific context increases code summarization BLEU by 14.78% (GPT-Oss-120B), and interpretable examples enhance code generation PASS@1 by 5.72% (DeepSeek-V3). CL4SE establishes the first standardized evaluation framework for SE context learning, provides actionable empirical insights into task-specific context design, and releases a large-scale dataset to facilitate reproducible research in this domain. Comments: 23 pages, 4 figures Subjects: Software Engineering (cs.SE) Cite as: arXiv:2602.23047 [cs.SE] (or arXiv:2602.23047v1 [cs.SE] for this version) https://doi.org/10.48550/arXiv.2602.23047 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Shang Ye [ view email ] [v1] Thu, 26 Feb 2026 14:28:57 UTC (235 KB) Full-text links: Access Paper: View a PDF of the paper titled CL4SE: A Context Learning Benchmark For Software Engineering Tasks, by Haichuan Hu and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.SE &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-128">65. 2D Sparse Array Design via Reweighted L1 Second Order Cone Programming for 3D Ultrasound Imaging</h2>
<ul>
<li>链接：https://arxiv.org/abs/2511.21133v1</li>
<li>来源：arxiv</li>
<li>摘要：Two-dimensional (2D) fully-addressed arrays can conveniently realize three-dimensional (3D) ultrasound imaging while fully controlled such arrays usually demands thousands of independent channels, which is costly. Sparse array technique using stochastic optimization methods is one of promising techniques to reduce channel counts while due to the stochastic nature of these methods, the optimized results are usually unstable. In this work, we introduce a sparse array design approach that formulates the synthesis problem of sparse arrays as second-order cone programming (SOCP) and a re-weighted L1 technique is implemented to sequentially optimize the SOCP. Based on this method, an on-grid quasi-flatten side-lobe (Q-Flats) 2D sparse array with side-lobe level (SLL) no more than -21.26 dB and 252 activated elements is designed, which aims to achieve as high contrast performance as possible under the limits of resolution and maximum number of independent channels (i.e., 256). The imaging performance of the Q-Flats array was compared with those of a corresponding dense array (Dense), a Fermat spiral array (Spiral) and a spatially 50%-Tukey tapered spiral array (Spiral-Taper) using Field I</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-129">正文（抓取，非 AI）</h3>
<p>[2511.21133v1] 2D Sparse Array Design via Reweighted L1 Second Order Cone Programming for 3D Ultrasound Imaging Electrical Engineering and Systems Science &gt; Signal Processing arXiv:2511.21133v1 (eess) [Submitted on 26 Nov 2025] Title: 2D Sparse Array Design via Reweighted L1 Second Order Cone Programming for 3D Ultrasound Imaging Authors: Xi Zhang , Miguel Bernal , Wei-Ning Lee View a PDF of the paper titled 2D Sparse Array Design via Reweighted L1 Second Order Cone Programming for 3D Ultrasound Imaging, by Xi Zhang and 2 other authors View PDF HTML (experimental) Abstract: Two-dimensional (2D) fully-addressed arrays can conveniently realize three-dimensional (3D) ultrasound imaging while fully controlled such arrays usually demands thousands of independent channels, which is costly. Sparse array technique using stochastic optimization methods is one of promising techniques to reduce channel counts while due to the stochastic nature of these methods, the optimized results are usually unstable. In this work, we introduce a sparse array design approach that formulates the synthesis problem of sparse arrays as second-order cone programming (SOCP) and a re-weighted L1 technique is implemented to sequentially optimize the SOCP. Based on this method, an on-grid quasi-flatten side-lobe (Q-Flats) 2D sparse array with side-lobe level (SLL) no more than -21.26 dB and 252 activated elements is designed, which aims to achieve as high contrast performance as possible under the limits of resolution and maximum number of independent channels (i.e., 256). The imaging performance of the Q-Flats array was compared with those of a corresponding dense array (Dense), a Fermat spiral array (Spiral) and a spatially 50%-Tukey tapered spiral array (Spiral-Taper) using Field II simulations in a multi-angle steered diverging wave transmission scheme. It was demonstrated that the Dense achieved the best resolution and contrast and the Spiral-Taper the worst. The Q-Flats showed better resolution (about 3%) but slightly worse contrast than the Spiral. All the results indicate the re-weighted L1 SOCP method is a promising and flexible method for seeking trade-offs among resolution, contrast, and number of activated elements. Subjects: Signal Processing (eess.SP) Cite as: arXiv:2511.21133 [eess.SP] (or arXiv:2511.21133v1 [eess.SP] for this version) https://doi.org/10.48550/arXiv.2511.21133 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Xi Zhang [ view email ] [v1] Wed, 26 Nov 2025 07:33:16 UTC (8,705 KB) Full-text links: Access Paper: View a PDF of the paper titled 2D Sparse Array Design via Reweighted L1 Second Order Cone Programming for 3D Ultrasound Imaging, by Xi Zhang and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SP &lt; prev | next &gt; new | recent | 2025-11 Change to browse by: eess References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-130">66. Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition</h2>
<ul>
<li>链接：https://arxiv.org/abs/2601.10525v1</li>
<li>来源：arxiv</li>
<li>摘要：Understanding how local neurophysiological patterns interact with global brain dynamics is essential for decoding human emotions from EEG signals. However, existing deep learning approaches often overlook the brain's intrinsic spatial organization, failing to simultaneously capture local topological relations and global dependencies. To address these challenges, we propose Neuro-HGLN, a Neurologically-informed Hierarchical Graph-Transformer Learning Network that integrates biologically grounded priors with hierarchical representation learning. Neuro-HGLN first constructs a spatial Euclidean prior graph based on physical electrode distances to serve as an anatomically grounded inductive bias. A learnable global dynamic graph is then introduced to model functional connectivity across the entire brain. In parallel, to capture fine-grained regional dependencies, Neuro-HGLN builds region-level local graphs using a multi-head self-attention mechanism. These graphs are processed synchronously through local-constrained parallel GCN layers to produce region-specific representations. Subsequently, an iTransformer encoder aggregates these features to capture cross-region dependencies under a </li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-131">正文（抓取，非 AI）</h3>
<p>[2601.10525v1] Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition Computer Science &gt; Human-Computer Interaction arXiv:2601.10525v1 (cs) [Submitted on 15 Jan 2026] Title: Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition Authors: Yijin Zhou , Fu Li , Yi Niu , Boxun Fu , Huaning Wang , Lijian Zhang View a PDF of the paper titled Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition, by Yijin Zhou and 5 other authors View PDF HTML (experimental) Abstract: Understanding how local neurophysiological patterns interact with global brain dynamics is essential for decoding human emotions from EEG signals. However, existing deep learning approaches often overlook the brain's intrinsic spatial organization, failing to simultaneously capture local topological relations and global dependencies. To address these challenges, we propose Neuro-HGLN, a Neurologically-informed Hierarchical Graph-Transformer Learning Network that integrates biologically grounded priors with hierarchical representation learning. Neuro-HGLN first constructs a spatial Euclidean prior graph based on physical electrode distances to serve as an anatomically grounded inductive bias. A learnable global dynamic graph is then introduced to model functional connectivity across the entire brain. In parallel, to capture fine-grained regional dependencies, Neuro-HGLN builds region-level local graphs using a multi-head self-attention mechanism. These graphs are processed synchronously through local-constrained parallel GCN layers to produce region-specific representations. Subsequently, an iTransformer encoder aggregates these features to capture cross-region dependencies under a dimension-as-token formulation. Extensive experiments demonstrate that Neuro-HGLN achieves state-of-the-art performance on multiple benchmarks, providing enhanced interpretability grounded in neurophysiological structure. These results highlight the efficacy of unifying local topological learning with cross-region dependency modeling for robust EEG emotion recognition. Subjects: Human-Computer Interaction (cs.HC) Cite as: arXiv:2601.10525 [cs.HC] (or arXiv:2601.10525v1 [cs.HC] for this version) https://doi.org/10.48550/arXiv.2601.10525 Focus to learn more arXiv-issued DOI via DataCite Submission history From: YiJin Zhou [ view email ] [v1] Thu, 15 Jan 2026 15:52:05 UTC (10,475 KB) Full-text links: Access Paper: View a PDF of the paper titled Learning from Brain Topography: A Hierarchical Local-Global Graph-Transformer Network for EEG Emotion Recognition, by Yijin Zhou and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.HC &lt; prev | next &gt; new | recent | 2026-01 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-132">67. UniScale: Unified Scale-Aware 3D Reconstruction for Multi-View Understanding via Prior Injection for Robotic Perception</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23224v1</li>
<li>来源：arxiv</li>
<li>摘要：We present UniScale, a unified, scale-aware multi-view 3D reconstruction framework for robotic applications that flexibly integrates geometric priors through a modular, semantically informed design. In vision-based robotic navigation, the accurate extraction of environmental structure from raw image sequences is critical for downstream tasks. UniScale addresses this challenge with a single feed-forward network that jointly estimates camera intrinsics and extrinsics, scale-invariant depth and point maps, and the metric scale of a scene from multi-view images, while optionally incorporating auxiliary geometric priors when available. By combining global contextual reasoning with camera-aware feature representations, UniScale is able to recover the metric-scale of the scene. In robotic settings where camera intrinsics are known, they can be easily incorporated to improve performance, with additional gains obtained when camera poses are also available. This co-design enables robust, metric-aware 3D reconstruction within a single unified model. Importantly, UniScale does not require training from scratch, and leverages world priors exhibited in pre-existing models without geometric encod</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-133">正文（抓取，非 AI）</h3>
<p>[2602.23224v1] UniScale: Unified Scale-Aware 3D Reconstruction for Multi-View Understanding via Prior Injection for Robotic Perception Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23224v1 (cs) [Submitted on 26 Feb 2026] Title: UniScale: Unified Scale-Aware 3D Reconstruction for Multi-View Understanding via Prior Injection for Robotic Perception Authors: Mohammad Mahdavian , Gordon Tan , Binbin Xu , Yuan Ren , Dongfeng Bai , Bingbing Liu View a PDF of the paper titled UniScale: Unified Scale-Aware 3D Reconstruction for Multi-View Understanding via Prior Injection for Robotic Perception, by Mohammad Mahdavian and 5 other authors View PDF Abstract: We present UniScale, a unified, scale-aware multi-view 3D reconstruction framework for robotic applications that flexibly integrates geometric priors through a modular, semantically informed design. In vision-based robotic navigation, the accurate extraction of environmental structure from raw image sequences is critical for downstream tasks. UniScale addresses this challenge with a single feed-forward network that jointly estimates camera intrinsics and extrinsics, scale-invariant depth and point maps, and the metric scale of a scene from multi-view images, while optionally incorporating auxiliary geometric priors when available. By combining global contextual reasoning with camera-aware feature representations, UniScale is able to recover the metric-scale of the scene. In robotic settings where camera intrinsics are known, they can be easily incorporated to improve performance, with additional gains obtained when camera poses are also available. This co-design enables robust, metric-aware 3D reconstruction within a single unified model. Importantly, UniScale does not require training from scratch, and leverages world priors exhibited in pre-existing models without geometric encoding strategies, making it particularly suitable for resource-constrained robotic teams. We evaluate UniScale on multiple benchmarks, demonstrating strong generalization and consistent performance across diverse environments. We will release our implementation upon acceptance. Subjects: Computer Vision and Pattern Recognition (cs.CV) ; Robotics (cs.RO) Cite as: arXiv:2602.23224 [cs.CV] (or arXiv:2602.23224v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23224 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Mohammad Mahdavian [ view email ] [v1] Thu, 26 Feb 2026 17:04:36 UTC (4,836 KB) Full-text links: Access Paper: View a PDF of the paper titled UniScale: Unified Scale-Aware 3D Reconstruction for Multi-View Understanding via Prior Injection for Robotic Perception, by Mohammad Mahdavian and 5 other authors View PDF TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.RO References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-134">68. LLM Novice Uplift on Dual-Use, In Silico Biology Tasks</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23329v1</li>
<li>来源：arxiv</li>
<li>摘要：Large language models (LLMs) perform increasingly well on biology benchmarks, but it remains unclear whether they uplift novice users -- i.e., enable humans to perform better than with internet-only resources. This uncertainty is central to understanding both scientific acceleration and dual-use risk. We conducted a multi-model, multi-benchmark human uplift study comparing novices with LLM access versus internet-only access across eight biosecurity-relevant task sets. Participants worked on complex problems with ample time (up to 13 hours for the most involved tasks). We found that LLM access provided substantial uplift: novices with LLMs were 4.16 times more accurate than controls (95% CI [2.63, 6.87]). On four benchmarks with available expert baselines (internet-only), novices with LLMs outperformed experts on three of them. Perhaps surprisingly, standalone LLMs often exceeded LLM-assisted novices, indicating that users were not eliciting the strongest available contributions from the LLMs. Most participants (89.6%) reported little difficulty obtaining dual-use-relevant information despite safeguards. Overall, LLMs substantially uplift novices on biological tasks previously reser</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-135">正文（抓取，非 AI）</h3>
<p>[2602.23329v1] LLM Novice Uplift on Dual-Use, In Silico Biology Tasks Computer Science &gt; Artificial Intelligence arXiv:2602.23329v1 (cs) [Submitted on 26 Feb 2026] Title: LLM Novice Uplift on Dual-Use, In Silico Biology Tasks Authors: Chen Bo Calvin Zhang , Christina Q. Knight , Nicholas Kruus , Jason Hausenloy , Pedro Medeiros , Nathaniel Li , Aiden Kim , Yury Orlovskiy , Coleman Breen , Bryce Cai , Jasper Götting , Andrew Bo Liu , Samira Nedungadi , Paula Rodriguez , Yannis Yiming He , Mohamed Shaaban , Zifan Wang , Seth Donoughe , Julian Michael View a PDF of the paper titled LLM Novice Uplift on Dual-Use, In Silico Biology Tasks, by Chen Bo Calvin Zhang and 18 other authors View PDF HTML (experimental) Abstract: Large language models (LLMs) perform increasingly well on biology benchmarks, but it remains unclear whether they uplift novice users -- i.e., enable humans to perform better than with internet-only resources. This uncertainty is central to understanding both scientific acceleration and dual-use risk. We conducted a multi-model, multi-benchmark human uplift study comparing novices with LLM access versus internet-only access across eight biosecurity-relevant task sets. Participants worked on complex problems with ample time (up to 13 hours for the most involved tasks). We found that LLM access provided substantial uplift: novices with LLMs were 4.16 times more accurate than controls (95% CI [2.63, 6.87]). On four benchmarks with available expert baselines (internet-only), novices with LLMs outperformed experts on three of them. Perhaps surprisingly, standalone LLMs often exceeded LLM-assisted novices, indicating that users were not eliciting the strongest available contributions from the LLMs. Most participants (89.6%) reported little difficulty obtaining dual-use-relevant information despite safeguards. Overall, LLMs substantially uplift novices on biological tasks previously reserved for trained practitioners, underscoring the need for sustained, interactive uplift evaluations alongside traditional benchmarks. Comments: 59 pages, 33 figures Subjects: Artificial Intelligence (cs.AI) ; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC) Cite as: arXiv:2602.23329 [cs.AI] (or arXiv:2602.23329v1 [cs.AI] for this version) https://doi.org/10.48550/arXiv.2602.23329 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Chen Bo Calvin Zhang [ view email ] [v1] Thu, 26 Feb 2026 18:37:23 UTC (574 KB) Full-text links: Access Paper: View a PDF of the paper titled LLM Novice Uplift on Dual-Use, In Silico Biology Tasks, by Chen Bo Calvin Zhang and 18 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.AI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CL cs.CR cs.CY cs.HC References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-136">69. Beamforming for Transmissive RIS Transceiver Enabled Simultaneous Wireless Information and Power Transfer Systems</h2>
<ul>
<li>链接：https://arxiv.org/abs/2511.11985v2</li>
<li>来源：arxiv</li>
<li>摘要：This paper investigates a novel transmissive reconfigurable intelligent surface (TRIS) transceiver-empowered simultaneous wireless information and power transfer (SWIPT) system with multiple information decoding (ID) and energy harvesting (EH) users. Under the considered system model, we formulate an optimization problem that maximizes the sum-rate of all ID users via the design of the TRIS transceiver's active beamforming. The design is constrained by per-antenna power limits at the TRIS transceiver and by the minimum harvested energy demand of all EH users. Due to the non-convexity of the objective function and the energy harvesting constraint, the sum-rate problem is difficult to tackle. To solve this challenging optimization problem, by leveraging the weighted minimum mean squared error (WMMSE) framework and the majorization-minimization (MM) method, we propose a second-order cone programming (SOCP)-based algorithm. Per-element power constraints introduce a large number of constraints, making the problem considerably more difficult. By applying the alternating direction method of multipliers (ADMM) method, we successfully develop an analytical, computationally efficient, and hi</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-137">正文（抓取，非 AI）</h3>
<p>[2511.11985v2] Beamforming for Transmissive RIS Transceiver Enabled Simultaneous Wireless Information and Power Transfer Systems Electrical Engineering and Systems Science &gt; Signal Processing arXiv:2511.11985v2 (eess) [Submitted on 15 Nov 2025 ( v1 ), last revised 23 Nov 2025 (this version, v2)] Title: Beamforming for Transmissive RIS Transceiver Enabled Simultaneous Wireless Information and Power Transfer Systems Authors: Yuan Guo , Wen Chen , Yanze Zhu , Zhendong Li , Qiong Wu , Kunlun Wang View a PDF of the paper titled Beamforming for Transmissive RIS Transceiver Enabled Simultaneous Wireless Information and Power Transfer Systems, by Yuan Guo and 5 other authors View PDF HTML (experimental) Abstract: This paper investigates a novel transmissive reconfigurable intelligent surface (TRIS) transceiver-empowered simultaneous wireless information and power transfer (SWIPT) system with multiple information decoding (ID) and energy harvesting (EH) users. Under the considered system model, we formulate an optimization problem that maximizes the sum-rate of all ID users via the design of the TRIS transceiver's active beamforming. The design is constrained by per-antenna power limits at the TRIS transceiver and by the minimum harvested energy demand of all EH users. Due to the non-convexity of the objective function and the energy harvesting constraint, the sum-rate problem is difficult to tackle. To solve this challenging optimization problem, by leveraging the weighted minimum mean squared error (WMMSE) framework and the majorization-minimization (MM) method, we propose a second-order cone programming (SOCP)-based algorithm. Per-element power constraints introduce a large number of constraints, making the problem considerably more difficult. By applying the alternating direction method of multipliers (ADMM) method, we successfully develop an analytical, computationally efficient, and highly parallelizable algorithm to address this challenge. Numerical results are provided to validate the convergence and effectiveness of the proposed algorithms. Furthermore, the low-complexity algorithm significantly reduces computational complexity without performance degradation. Subjects: Signal Processing (eess.SP) Cite as: arXiv:2511.11985 [eess.SP] (or arXiv:2511.11985v2 [eess.SP] for this version) https://doi.org/10.48550/arXiv.2511.11985 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Yuan Guo [ view email ] [v1] Sat, 15 Nov 2025 01:45:03 UTC (377 KB) [v2] Sun, 23 Nov 2025 02:21:05 UTC (377 KB) Full-text links: Access Paper: View a PDF of the paper titled Beamforming for Transmissive RIS Transceiver Enabled Simultaneous Wireless Information and Power Transfer Systems, by Yuan Guo and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SP &lt; prev | next &gt; new | recent | 2025-11 Change to browse by: eess References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-138">70. Comparative Evaluation of SDP, SOCP, and QC Convex Relaxations for Large-Scale Market-Based AC Optimal Power Flow</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.14136v1</li>
<li>来源：arxiv</li>
<li>摘要：The alternating current optimal power flow (ACOPF) problem is central to modern power system operations, determining how electricity is generated and transmitted to maximize social welfare while respecting physical and operational constraints. However, the nonlinear and non-convex nature of AC power flow equations makes finding globally optimal solutions computationally intractable for large networks. Convex relaxations - including semidefinite programming (SDP), second-order cone programming (SOCP), and quadratic convex (QC) formulations - provide tractable alternatives that can yield provably optimal or near-optimal solutions under appropriate conditions. This paper presents a comprehensive comparative study of multiple ACOPF relaxations applied to market-based welfare maximization. We implement DCOPF, Shor's SDP relaxation (complex and real-valued forms), chordal SDP, Jabr's SOCP relaxation, and QC relaxations in a unified, solver-native framework using the MOSEK Fusion API, eliminating modeling overhead present in high-level frameworks such as CVXPY. To address the practical challenge of missing or overly conservative angle difference bounds required by QC relaxations, we emplo</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-139">正文（抓取，非 AI）</h3>
<p>[2602.14136v1] Comparative Evaluation of SDP, SOCP, and QC Convex Relaxations for Large-Scale Market-Based AC Optimal Power Flow Mathematics &gt; Optimization and Control arXiv:2602.14136v1 (math) [Submitted on 15 Feb 2026] Title: Comparative Evaluation of SDP, SOCP, and QC Convex Relaxations for Large-Scale Market-Based AC Optimal Power Flow Authors: Ata Keskin View a PDF of the paper titled Comparative Evaluation of SDP, SOCP, and QC Convex Relaxations for Large-Scale Market-Based AC Optimal Power Flow, by Ata Keskin View PDF Abstract: The alternating current optimal power flow (ACOPF) problem is central to modern power system operations, determining how electricity is generated and transmitted to maximize social welfare while respecting physical and operational constraints. However, the nonlinear and non-convex nature of AC power flow equations makes finding globally optimal solutions computationally intractable for large networks. Convex relaxations - including semidefinite programming (SDP), second-order cone programming (SOCP), and quadratic convex (QC) formulations - provide tractable alternatives that can yield provably optimal or near-optimal solutions under appropriate conditions. This paper presents a comprehensive comparative study of multiple ACOPF relaxations applied to market-based welfare maximization. We implement DCOPF, Shor's SDP relaxation (complex and real-valued forms), chordal SDP, Jabr's SOCP relaxation, and QC relaxations in a unified, solver-native framework using the MOSEK Fusion API, eliminating modeling overhead present in high-level frameworks such as CVXPY. To address the practical challenge of missing or overly conservative angle difference bounds required by QC relaxations, we employ quasi-Monte Carlo sampling with Sobol sequences to empirically estimate tighter bounds. We evaluate these relaxations on subnetworks of varying sizes derived from the ARPA-E dataset, systematically comparing solution quality, runtime, and memory consumption. Our results demonstrate the trade-offs between relaxation tightness and computational efficiency, providing practical guidance for selecting appropriate formulations based on network scale and solution requirements. Subjects: Optimization and Control (math.OC) MSC classes: 90C26, 90C22 ACM classes: G.1.6; G.3; J.2 Cite as: arXiv:2602.14136 [math.OC] (or arXiv:2602.14136v1 [math.OC] for this version) https://doi.org/10.48550/arXiv.2602.14136 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Ata Keskin [ view email ] [v1] Sun, 15 Feb 2026 13:17:22 UTC (150 KB) Full-text links: Access Paper: View a PDF of the paper titled Comparative Evaluation of SDP, SOCP, and QC Convex Relaxations for Large-Scale Market-Based AC Optimal Power Flow, by Ata Keskin View PDF TeX Source view license Current browse context: math.OC &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: math References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-140">71. Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23335v1</li>
<li>来源：arxiv</li>
<li>摘要：AI-powered scientific research tools are rapidly being integrated into research workflows, yet the field lacks a clear lens into how researchers use these systems in real-world settings. We present and analyze the Asta Interaction Dataset, a large-scale resource comprising over 200,000 user queries and interaction logs from two deployed tools (a literature discovery interface and a scientific question-answering interface) within an LLM-powered retrieval-augmented generation platform. Using this dataset, we characterize query patterns, engagement behaviors, and how usage evolves with experience. We find that users submit longer and more complex queries than in traditional search, and treat the system as a collaborative research partner, delegating tasks such as drafting content and identifying research gaps. Users treat generated responses as persistent artifacts, revisiting and navigating among outputs and cited evidence in non-linear ways. With experience, users issue more targeted queries and engage more deeply with supporting citations, although keyword-style queries persist even among experienced users. We release the anonymized dataset and analysis with a new query intent taxo</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-141">正文（抓取，非 AI）</h3>
<p>[2602.23335v1] Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset Computer Science &gt; Human-Computer Interaction arXiv:2602.23335v1 (cs) [Submitted on 26 Feb 2026] Title: Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset Authors: Dany Haddad , Dan Bareket , Joseph Chee Chang , Jay DeYoung , Jena D. Hwang , Uri Katz , Mark Polak , Sangho Suh , Harshit Surana , Aryeh Tiktinsky , Shriya Atmakuri , Jonathan Bragg , Mike D'Arcy , Sergey Feldman , Amal Hassan-Ali , Rubén Lozano , Bodhisattwa Prasad Majumder , Charles McGrady , Amanpreet Singh , Brooke Vlahos , Yoav Goldberg , Doug Downey View a PDF of the paper titled Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset, by Dany Haddad and 21 other authors View PDF HTML (experimental) Abstract: AI-powered scientific research tools are rapidly being integrated into research workflows, yet the field lacks a clear lens into how researchers use these systems in real-world settings. We present and analyze the Asta Interaction Dataset, a large-scale resource comprising over 200,000 user queries and interaction logs from two deployed tools (a literature discovery interface and a scientific question-answering interface) within an LLM-powered retrieval-augmented generation platform. Using this dataset, we characterize query patterns, engagement behaviors, and how usage evolves with experience. We find that users submit longer and more complex queries than in traditional search, and treat the system as a collaborative research partner, delegating tasks such as drafting content and identifying research gaps. Users treat generated responses as persistent artifacts, revisiting and navigating among outputs and cited evidence in non-linear ways. With experience, users issue more targeted queries and engage more deeply with supporting citations, although keyword-style queries persist even among experienced users. We release the anonymized dataset and analysis with a new query intent taxonomy to inform future designs of real-world AI research assistants and to support realistic evaluation. Subjects: Human-Computer Interaction (cs.HC) ; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR) Cite as: arXiv:2602.23335 [cs.HC] (or arXiv:2602.23335v1 [cs.HC] for this version) https://doi.org/10.48550/arXiv.2602.23335 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Dany Haddad [ view email ] [v1] Thu, 26 Feb 2026 18:40:28 UTC (14,759 KB) Full-text links: Access Paper: View a PDF of the paper titled Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset, by Dany Haddad and 21 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.HC &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI cs.IR References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-142">72. Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2511.10200v2</li>
<li>来源：arxiv</li>
<li>摘要：Time series forecasting is an important task that involves analyzing temporal dependencies and underlying patterns (such as trends, cyclicality, and seasonality) in historical data to predict future values or trends. Current deep learning-based forecasting models primarily employ Mean Squared Error (MSE) loss functions for regression modeling. Despite enabling direct value prediction, this method offers no uncertainty estimation and exhibits poor outlier robustness. To address these limitations, we propose OCE-TS, a novel ordinal classification approach for time series forecasting that replaces MSE with Ordinal Cross-Entropy (OCE) loss, preserving prediction order while quantifying uncertainty through probability output. Specifically, OCE-TS begins by discretizing observed values into ordered intervals and deriving their probabilities via a parametric distribution as supervision signals. Using a simple linear model, we then predict probability distributions for each timestep. The OCE loss is computed between the cumulative distributions of predicted and ground-truth probabilities, explicitly preserving ordinal relationships among forecasted values. Through theoretical analysis usin</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-143">正文（抓取，非 AI）</h3>
<p>[2511.10200v2] Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting Computer Science &gt; Machine Learning arXiv:2511.10200v2 (cs) [Submitted on 13 Nov 2025 ( v1 ), last revised 27 Nov 2025 (this version, v2)] Title: Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting Authors: Jieting Wang , Huimei Shi , Feijiang Li , Xiaolei Shang View a PDF of the paper titled Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting, by Jieting Wang and 3 other authors View PDF HTML (experimental) Abstract: Time series forecasting is an important task that involves analyzing temporal dependencies and underlying patterns (such as trends, cyclicality, and seasonality) in historical data to predict future values or trends. Current deep learning-based forecasting models primarily employ Mean Squared Error (MSE) loss functions for regression modeling. Despite enabling direct value prediction, this method offers no uncertainty estimation and exhibits poor outlier robustness. To address these limitations, we propose OCE-TS, a novel ordinal classification approach for time series forecasting that replaces MSE with Ordinal Cross-Entropy (OCE) loss, preserving prediction order while quantifying uncertainty through probability output. Specifically, OCE-TS begins by discretizing observed values into ordered intervals and deriving their probabilities via a parametric distribution as supervision signals. Using a simple linear model, we then predict probability distributions for each timestep. The OCE loss is computed between the cumulative distributions of predicted and ground-truth probabilities, explicitly preserving ordinal relationships among forecasted values. Through theoretical analysis using influence functions, we establish that cross-entropy (CE) loss exhibits superior stability and outlier robustness compared to MSE loss. Empirically, we compared OCE-TS with five baseline models-Autoformer, DLinear, iTransformer, TimeXer, and TimeBridge-on seven public time series datasets. Using MSE and Mean Absolute Error (MAE) as evaluation metrics, the results demonstrate that OCE-TS consistently outperforms benchmark models. The codeis publicly available at: this https URL . Subjects: Machine Learning (cs.LG) Cite as: arXiv:2511.10200 [cs.LG] (or arXiv:2511.10200v2 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2511.10200 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Feijiang Li [ view email ] [v1] Thu, 13 Nov 2025 11:14:24 UTC (10,056 KB) [v2] Thu, 27 Nov 2025 11:46:13 UTC (10,059 KB) Full-text links: Access Paper: View a PDF of the paper titled Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting, by Jieting Wang and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-11 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-144">73. TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints</h2>
<ul>
<li>链接：https://arxiv.org/abs/2511.12910v1</li>
<li>来源：arxiv</li>
<li>摘要：Differential-driven wheeled robots (DWR) represent the quintessential type of mobile robots and find extensive appli- cations across the robotic field. Most high-performance control approaches for DWR explicitly utilize the linear and angular velocities of the trajectory as control references. However, existing research on time-optimal path parameterization (TOPP) for mobile robots usually neglects the angular velocity and joint vel- ocity constraints, which can result in degraded control perfor- mance in practical applications. In this article, a systematic and practical TOPP algorithm named TOPP-DWR is proposed for DWR and other mobile robots. First, the non-uniform B-spline is adopted to represent the initial trajectory in the task space. Second, the piecewise-constant angular velocity, as well as joint velocity, linear velocity, and linear acceleration constraints, are incorporated into the TOPP problem. During the construction of the optimization problem, the aforementioned constraints are uniformly represented as linear velocity constraints. To boost the numerical computational efficiency, we introduce a slack variable to reformulate the problem into second-order-cone program</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-145">正文（抓取，非 AI）</h3>
<p>[2511.12910v1] TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints Computer Science &gt; Robotics arXiv:2511.12910v1 (cs) [Submitted on 17 Nov 2025] Title: TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints Authors: Yong Li , Yujun Huang , Yi Chen , Hui Cheng View a PDF of the paper titled TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints, by Yong Li and 2 other authors View PDF Abstract: Differential-driven wheeled robots (DWR) represent the quintessential type of mobile robots and find extensive appli- cations across the robotic field. Most high-performance control approaches for DWR explicitly utilize the linear and angular velocities of the trajectory as control references. However, existing research on time-optimal path parameterization (TOPP) for mobile robots usually neglects the angular velocity and joint vel- ocity constraints, which can result in degraded control perfor- mance in practical applications. In this article, a systematic and practical TOPP algorithm named TOPP-DWR is proposed for DWR and other mobile robots. First, the non-uniform B-spline is adopted to represent the initial trajectory in the task space. Second, the piecewise-constant angular velocity, as well as joint velocity, linear velocity, and linear acceleration constraints, are incorporated into the TOPP problem. During the construction of the optimization problem, the aforementioned constraints are uniformly represented as linear velocity constraints. To boost the numerical computational efficiency, we introduce a slack variable to reformulate the problem into second-order-cone programming (SOCP). Subsequently, comparative experiments are conducted to validate the superiority of the proposed method. Quantitative performance indexes show that TOPP-DWR achieves TOPP while adhering to all constraints. Finally, field autonomous navigation experiments are carried out to validate the practicability of TOPP-DWR in real-world applications. Subjects: Robotics (cs.RO) Report number: IROS20251376 Cite as: arXiv:2511.12910 [cs.RO] (or arXiv:2511.12910v1 [cs.RO] for this version) https://doi.org/10.48550/arXiv.2511.12910 Focus to learn more arXiv-issued DOI via DataCite Journal reference: 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025) Submission history From: Yong Li [ view email ] [v1] Mon, 17 Nov 2025 02:58:53 UTC (5,008 KB) Full-text links: Access Paper: View a PDF of the paper titled TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints, by Yong Li and 2 other authors View PDF view license Current browse context: cs.RO &lt; prev | next &gt; new | recent | 2025-11 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-146">74. MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23228v1</li>
<li>来源：arxiv</li>
<li>摘要：With the explosive growth of digital entertainment, automated video summarization has become indispensable for applications such as content indexing, personalized recommendation, and efficient media archiving. Automatic synopsis generation for long-form videos, such as movies and TV series, presents a significant challenge for existing Vision-Language Models (VLMs). While proficient at single-image captioning, these general-purpose models often exhibit critical failures in long-duration contexts, primarily a lack of ID-consistent character identification and a fractured narrative coherence. To overcome these limitations, we propose MovieTeller, a novel framework for generating movie synopses via tool-augmented progressive abstraction. Our core contribution is a training-free, tool-augmented, fact-grounded generation process. Instead of requiring costly model fine-tuning, our framework directly leverages off-the-shelf models in a plug-and-play manner. We first invoke a specialized face recognition model as an external "tool" to establish Factual Groundings--precise character identities and their corresponding bounding boxes. These groundings are then injected into the prompt to stee</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-147">正文（抓取，非 AI）</h3>
<p>[2602.23228v1] MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23228v1 (cs) [Submitted on 26 Feb 2026] Title: MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction Authors: Yizhi Li , Xiaohan Chen , Miao Jiang , Wentao Tang , Gaoang Wang View a PDF of the paper titled MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction, by Yizhi Li and 3 other authors View PDF HTML (experimental) Abstract: With the explosive growth of digital entertainment, automated video summarization has become indispensable for applications such as content indexing, personalized recommendation, and efficient media archiving. Automatic synopsis generation for long-form videos, such as movies and TV series, presents a significant challenge for existing Vision-Language Models (VLMs). While proficient at single-image captioning, these general-purpose models often exhibit critical failures in long-duration contexts, primarily a lack of ID-consistent character identification and a fractured narrative coherence. To overcome these limitations, we propose MovieTeller, a novel framework for generating movie synopses via tool-augmented progressive abstraction. Our core contribution is a training-free, tool-augmented, fact-grounded generation process. Instead of requiring costly model fine-tuning, our framework directly leverages off-the-shelf models in a plug-and-play manner. We first invoke a specialized face recognition model as an external "tool" to establish Factual Groundings--precise character identities and their corresponding bounding boxes. These groundings are then injected into the prompt to steer the VLM's reasoning, ensuring the generated scene descriptions are anchored to verifiable facts. Furthermore, our progressive abstraction pipeline decomposes the summarization of a full-length movie into a multi-stage process, effectively mitigating the context length limitations of current VLMs. Experiments demonstrate that our approach yields significant improvements in factual accuracy, character consistency, and overall narrative coherence compared to end-to-end baselines. Comments: 6 pages, CSCWD 2026 Subjects: Computer Vision and Pattern Recognition (cs.CV) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23228 [cs.CV] (or arXiv:2602.23228v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23228 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Yizhi Li [ view email ] [v1] Thu, 26 Feb 2026 17:08:08 UTC (8,873 KB) Full-text links: Access Paper: View a PDF of the paper titled MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction, by Yizhi Li and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-148">75. Revisiting the Perseus Cluster II: Metallicity-Dependence of Massive Stars and Chemical Enrichment History</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23354v1</li>
<li>来源：arxiv</li>
<li>摘要：The legacy Hitomi telescope has delivered the precise measurements of the chemical abundances in the Perseus Cluster, covering the Si-group (Si, S, Ar, Ca) and Fe-group elements (Cr, Mn, Ni). In Paper I (Leung et al., ApJ 2025), we examined the role of convection parameters and presented new core-collapse supernova (CCSN) explosion models at solar metallicity, which fit the observed abundance pattern. In this article, we extend our calculation for the stellar evolutionary models and CCSN models of the initial mass $15 - 60M_{\odot}$ and the metallicity $Z = 0 - Z_{\odot}$. The detailed pre- and post-explosion chemical profiles are calculated with a large post-processing network to capture the production of $α$-chain elements (e.g., Si, S, Ar), odd-number elements (e.g., P, K, Cl), and iron-group elements (e.g., Mn, Ni). We study the role of CCSNe in the production of these elements. We compare the galactic chemical evolution model based on the nucleosynthesis yield of the new massive stars and other yield tables from the literature. For each supernova yield, we perform parameter surveys and search for configurations that produce the best-fit model and best-rate model using the Pers</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-149">正文（抓取，非 AI）</h3>
<p>[2602.23354v1] Revisiting the Perseus Cluster II: Metallicity-Dependence of Massive Stars and Chemical Enrichment History Astrophysics &gt; Solar and Stellar Astrophysics arXiv:2602.23354v1 (astro-ph) [Submitted on 26 Feb 2026] Title: Revisiting the Perseus Cluster II: Metallicity-Dependence of Massive Stars and Chemical Enrichment History Authors: Shing-Chi Leung , Seth Walther , Henry Yerdon , Ken'ichi Nomoto , Aurora Simionescu View a PDF of the paper titled Revisiting the Perseus Cluster II: Metallicity-Dependence of Massive Stars and Chemical Enrichment History, by Shing-Chi Leung and 4 other authors View PDF HTML (experimental) Abstract: The legacy Hitomi telescope has delivered the precise measurements of the chemical abundances in the Perseus Cluster, covering the Si-group (Si, S, Ar, Ca) and Fe-group elements (Cr, Mn, Ni). In Paper I (Leung et al., ApJ 2025), we examined the role of convection parameters and presented new core-collapse supernova (CCSN) explosion models at solar metallicity, which fit the observed abundance pattern. In this article, we extend our calculation for the stellar evolutionary models and CCSN models of the initial mass $15 - 60M_{\odot}$ and the metallicity $Z = 0 - Z_{\odot}$. The detailed pre- and post-explosion chemical profiles are calculated with a large post-processing network to capture the production of $\alpha$-chain elements (e.g., Si, S, Ar), odd-number elements (e.g., P, K, Cl), and iron-group elements (e.g., Mn, Ni). We study the role of CCSNe in the production of these elements. We compare the galactic chemical evolution model based on the nucleosynthesis yield of the new massive stars and other yield tables from the literature. For each supernova yield, we perform parameter surveys and search for configurations that produce the best-fit model and best-rate model using the Perseus Cluster as the reference. From the survey, we study how individual chemical elements affect the contributions of massive stars and Type Ia supernovae in the cosmic chemical enrichment Comments: 18 pages, 25 figures. Submitted to the Astrophysical Journal on Jul 18 2025, accepted on Feb 21 2026 Subjects: Solar and Stellar Astrophysics (astro-ph.SR) ; Astrophysics of Galaxies (astro-ph.GA) Cite as: arXiv:2602.23354 [astro-ph.SR] (or arXiv:2602.23354v1 [astro-ph.SR] for this version) https://doi.org/10.48550/arXiv.2602.23354 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Shing Chi Leung [ view email ] [v1] Thu, 26 Feb 2026 18:57:10 UTC (1,958 KB) Full-text links: Access Paper: View a PDF of the paper titled Revisiting the Perseus Cluster II: Metallicity-Dependence of Massive Stars and Chemical Enrichment History, by Shing-Chi Leung and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: astro-ph.SR &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: astro-ph astro-ph.GA References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-150">76. Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23312v1</li>
<li>来源：arxiv</li>
<li>摘要：Leader-follower interaction is an important paradigm in human-robot interaction (HRI). Yet, assigning roles in real time remains challenging for resource-constrained mobile and assistive robots. While large language models (LLMs) have shown promise for natural communication, their size and latency limit on-device deployment. Small language models (SLMs) offer a potential alternative, but their effectiveness for role classification in HRI has not been systematically evaluated. In this paper, we present a benchmark of SLMs for leader-follower communication, introducing a novel dataset derived from a published database and augmented with synthetic samples to capture interaction-specific dynamics. We investigate two adaptation strategies: prompt engineering and fine-tuning, studied under zero-shot and one-shot interaction modes, compared with an untrained baseline. Experiments with Qwen2.5-0.5B reveal that zero-shot fine-tuning achieves robust classification performance (86.66% accuracy) while maintaining low latency (22.2 ms per sample), significantly outperforming baseline and prompt-engineered approaches. However, results also indicate a performance degradation in one-shot modes, wh</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-151">正文（抓取，非 AI）</h3>
<p>[2602.23312v1] Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction Computer Science &gt; Human-Computer Interaction arXiv:2602.23312v1 (cs) [Submitted on 26 Feb 2026] Title: Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction Authors: Rafael R. Baptista , André de Lima Salgado , Ricardo V. Godoy , Marcelo Becker , Thiago Boaventura , Gustavo J. G. Lahr View a PDF of the paper titled Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction, by Rafael R. Baptista and 5 other authors View PDF HTML (experimental) Abstract: Leader-follower interaction is an important paradigm in human-robot interaction (HRI). Yet, assigning roles in real time remains challenging for resource-constrained mobile and assistive robots. While large language models (LLMs) have shown promise for natural communication, their size and latency limit on-device deployment. Small language models (SLMs) offer a potential alternative, but their effectiveness for role classification in HRI has not been systematically evaluated. In this paper, we present a benchmark of SLMs for leader-follower communication, introducing a novel dataset derived from a published database and augmented with synthetic samples to capture interaction-specific dynamics. We investigate two adaptation strategies: prompt engineering and fine-tuning, studied under zero-shot and one-shot interaction modes, compared with an untrained baseline. Experiments with Qwen2.5-0.5B reveal that zero-shot fine-tuning achieves robust classification performance (86.66% accuracy) while maintaining low latency (22.2 ms per sample), significantly outperforming baseline and prompt-engineered approaches. However, results also indicate a performance degradation in one-shot modes, where increased context length challenges the model's architectural capacity. These findings demonstrate that fine-tuned SLMs provide an effective solution for direct role assignment, while highlighting critical trade-offs between dialogue complexity and classification reliability on the edge. Subjects: Human-Computer Interaction (cs.HC) ; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO); Systems and Control (eess.SY) Cite as: arXiv:2602.23312 [cs.HC] (or arXiv:2602.23312v1 [cs.HC] for this version) https://doi.org/10.48550/arXiv.2602.23312 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Ricardo Vilela De Godoy Dr. [ view email ] [v1] Thu, 26 Feb 2026 18:20:26 UTC (1,308 KB) Full-text links: Access Paper: View a PDF of the paper titled Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction, by Rafael R. Baptista and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.HC &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI cs.LG cs.RO cs.SY eess eess.SY References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-152">77. InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23200v1</li>
<li>来源：arxiv</li>
<li>摘要：Reducing the hardware footprint of large language models (LLMs) during decoding is critical for efficient long-sequence generation. A key bottleneck is the key-value (KV) cache, whose size scales with sequence length and easily dominates the memory footprint of the model. Previous work proposed quantization methods that are focused on compressing the KV cache while maintaining its information. We introduce InnerQ, a hardware-aware KV-cache quantization scheme that lowers decode latency without sacrificing accuracy. InnerQ applies group-wise quantization while grouping the cache matrices over their inner dimension. Unlike previous work that group over the outer dimension, InnerQ aligns dequantization with the vector-matrix multiplication and enables scale factor reuse across GPU compute units. This reduces memory accesses and accelerates dequantization, yielding up to $22\%$ speedup over previous work and up to $88\%$ over half-precision vector-matrix multiplication. To preserve fidelity under aggressive compression, InnerQ incorporates (i) hybrid quantization, selecting symmetric or asymmetric quantization per group based on local statistics; (ii) high-precision windows for both th</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-153">正文（抓取，非 AI）</h3>
<p>[2602.23200v1] InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models Computer Science &gt; Machine Learning arXiv:2602.23200v1 (cs) [Submitted on 26 Feb 2026] Title: InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models Authors: Sayed Mohammadreza Tayaranian Hosseini , Amir Ardakani , Warren J. Gross View a PDF of the paper titled InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models, by Sayed Mohammadreza Tayaranian Hosseini and 2 other authors View PDF Abstract: Reducing the hardware footprint of large language models (LLMs) during decoding is critical for efficient long-sequence generation. A key bottleneck is the key-value (KV) cache, whose size scales with sequence length and easily dominates the memory footprint of the model. Previous work proposed quantization methods that are focused on compressing the KV cache while maintaining its information. We introduce InnerQ, a hardware-aware KV-cache quantization scheme that lowers decode latency without sacrificing accuracy. InnerQ applies group-wise quantization while grouping the cache matrices over their inner dimension. Unlike previous work that group over the outer dimension, InnerQ aligns dequantization with the vector-matrix multiplication and enables scale factor reuse across GPU compute units. This reduces memory accesses and accelerates dequantization, yielding up to $22\%$ speedup over previous work and up to $88\%$ over half-precision vector-matrix multiplication. To preserve fidelity under aggressive compression, InnerQ incorporates (i) hybrid quantization, selecting symmetric or asymmetric quantization per group based on local statistics; (ii) high-precision windows for both the most recent tokens and the attention sink tokens to mitigate outlier leakage; and (iii) per-channel normalization of the key cache, computed once during prefill and folded into the query to avoid runtime overhead. Our evaluation experiments on Llama models shows that InnerQ maintains a few-shot GSM8K performance comparable to non-quantized KV caches and surpasses prior KV cache quantization methods. Comments: 16 pages, 4 figures, 4 tables, 2 algorithms Subjects: Machine Learning (cs.LG) ; Computation and Language (cs.CL) Cite as: arXiv:2602.23200 [cs.LG] (or arXiv:2602.23200v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23200 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Sayed Mohammadreza Tayaranian Hosseini [ view email ] [v1] Thu, 26 Feb 2026 16:50:36 UTC (30 KB) Full-text links: Access Paper: View a PDF of the paper titled InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models, by Sayed Mohammadreza Tayaranian Hosseini and 2 other authors View PDF TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CL References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-154">78. Benchmarking State Space Models, Transformers, and Recurrent Networks for US Grid Forecasting</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.21415v1</li>
<li>来源：arxiv</li>
<li>摘要：Selecting the right deep learning model for power grid forecasting is challenging, as performance heavily depends on the data available to the operator. This paper presents a comprehensive benchmark of five modern neural architectures: two state space models (PowerMamba, S-Mamba), two Transformers (iTransformer, PatchTST), and a traditional LSTM. We evaluate these models on hourly electricity demand across six diverse US power grids for forecast windows between 24 and 168 hours. To ensure a fair comparison, we adapt each model with specialized temporal processing and a modular layer that cleanly integrates weather covariates. Our results reveal that there is no single best model for all situations. When forecasting using only historical load, PatchTST and the state space models provide the highest accuracy. However, when explicit weather data is added to the inputs, the rankings reverse: iTransformer improves its accuracy three times more efficiently than PatchTST. By controlling for model size, we confirm that this advantage stems from the architecture's inherent ability to mix information across different variables. Extending our evaluation to solar generation, wind power, and wh</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-155">正文（抓取，非 AI）</h3>
<p>[2602.21415v1] Benchmarking State Space Models, Transformers, and Recurrent Networks for US Grid Forecasting Computer Science &gt; Machine Learning arXiv:2602.21415v1 (cs) [Submitted on 24 Feb 2026] Title: Benchmarking State Space Models, Transformers, and Recurrent Networks for US Grid Forecasting Authors: Sunki Hong , Jisoo Lee , Yuanyuan Shi View a PDF of the paper titled Benchmarking State Space Models, Transformers, and Recurrent Networks for US Grid Forecasting, by Sunki Hong and 2 other authors View PDF HTML (experimental) Abstract: Selecting the right deep learning model for power grid forecasting is challenging, as performance heavily depends on the data available to the operator. This paper presents a comprehensive benchmark of five modern neural architectures: two state space models (PowerMamba, S-Mamba), two Transformers (iTransformer, PatchTST), and a traditional LSTM. We evaluate these models on hourly electricity demand across six diverse US power grids for forecast windows between 24 and 168 hours. To ensure a fair comparison, we adapt each model with specialized temporal processing and a modular layer that cleanly integrates weather covariates. Our results reveal that there is no single best model for all situations. When forecasting using only historical load, PatchTST and the state space models provide the highest accuracy. However, when explicit weather data is added to the inputs, the rankings reverse: iTransformer improves its accuracy three times more efficiently than PatchTST. By controlling for model size, we confirm that this advantage stems from the architecture's inherent ability to mix information across different variables. Extending our evaluation to solar generation, wind power, and wholesale prices further demonstrates that model rankings depend on the forecast task: PatchTST excels on highly rhythmic signals like solar, while state space models are better suited for the chaotic fluctuations of wind and price. Ultimately, this benchmark provides grid operators with actionable guidelines for selecting the optimal forecasting architecture based on their specific data environments. Comments: 11 pages, 2 figures, 8 tables Subjects: Machine Learning (cs.LG) ; Systems and Control (eess.SY) MSC classes: 68T07, 62M20 ACM classes: I.2.6; G.3; J.2 Cite as: arXiv:2602.21415 [cs.LG] (or arXiv:2602.21415v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.21415 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Jisoo Lee [ view email ] [v1] Tue, 24 Feb 2026 22:42:39 UTC (2,320 KB) Full-text links: Access Paper: View a PDF of the paper titled Benchmarking State Space Models, Transformers, and Recurrent Networks for US Grid Forecasting, by Sunki Hong and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.SY eess eess.SY References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-156">79. TESS Planet Occurrence Rates Reveal the Disappearance of the Radius Valley Around Mid-to-Late M Dwarfs</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23364v1</li>
<li>来源：arxiv</li>
<li>摘要：We present the deepest systematic search for planets around mid-to-late M dwarfs to date. We have surveyed 8134 mid-to-late M dwarfs observed by TESS with a custom built pipeline and recover 77 vetted transiting planet candidates. We characterize the sensitivity of our survey via injection-recovery and measure the occurrence rate of planets as a function of orbital period, instellation, and planet radius. We measure a cumulative occurrence rate of $1.10\pm0.16$ planets per star with radii $&gt;1\, R_\oplus$ orbiting within 30 days. This value is consistent with the cumulative occurrence rate around early M dwarfs, making M dwarfs collectively the most prolific hosts of small close-in planets. Unlike the bimodal Radius Valley exhibited by close-in planet population around FGK and early M dwarfs, we recover a unimodal planet radius distribution peaking at $1.25\pm0.05 \, R_\oplus$. We additionally find $0.954\pm0.147$ super-Earths and $0.148\pm0.045$ sub-Neptunes per star, with super-Earths outnumbering sub-Neptunes 5.5:1, firmly demonstrating that the Radius Valley disappears around the lowest mass stars. The dearth of sub-Neptunes around mid-to-late M dwarfs is consistent with predict</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-157">正文（抓取，非 AI）</h3>
<p>[2602.23364v1] TESS Planet Occurrence Rates Reveal the Disappearance of the Radius Valley Around Mid-to-Late M Dwarfs Astrophysics &gt; Earth and Planetary Astrophysics arXiv:2602.23364v1 (astro-ph) [Submitted on 26 Feb 2026] Title: TESS Planet Occurrence Rates Reveal the Disappearance of the Radius Valley Around Mid-to-Late M Dwarfs Authors: Erik Gillis , Ryan Cloutier , Emily Pass View a PDF of the paper titled TESS Planet Occurrence Rates Reveal the Disappearance of the Radius Valley Around Mid-to-Late M Dwarfs, by Erik Gillis and 2 other authors View PDF HTML (experimental) Abstract: We present the deepest systematic search for planets around mid-to-late M dwarfs to date. We have surveyed 8134 mid-to-late M dwarfs observed by TESS with a custom built pipeline and recover 77 vetted transiting planet candidates. We characterize the sensitivity of our survey via injection-recovery and measure the occurrence rate of planets as a function of orbital period, instellation, and planet radius. We measure a cumulative occurrence rate of $1.10\pm0.16$ planets per star with radii $&gt;1\, R_\oplus$ orbiting within 30 days. This value is consistent with the cumulative occurrence rate around early M dwarfs, making M dwarfs collectively the most prolific hosts of small close-in planets. Unlike the bimodal Radius Valley exhibited by close-in planet population around FGK and early M dwarfs, we recover a unimodal planet radius distribution peaking at $1.25\pm0.05 \, R_\oplus$. We additionally find $0.954\pm0.147$ super-Earths and $0.148\pm0.045$ sub-Neptunes per star, with super-Earths outnumbering sub-Neptunes 5.5:1, firmly demonstrating that the Radius Valley disappears around the lowest mass stars. The dearth of sub-Neptunes around mid-to-late M dwarfs is consistent with predictions from water-rich pebble accretion models that predict a fading Radius Valley with decreasing stellar mass. Our results support the emerging idea that the sub-Neptune population around M dwarfs is composed of water-rich worlds. We find no hot Jupiters in our survey and set an upper limit of 0.012 hot Jupiters per mid-to-late M dwarf within 10 days. Comments: Submitted to AAS Journals February 26 2026, 25 pages, 17 Figures, 8 Tables Subjects: Earth and Planetary Astrophysics (astro-ph.EP) Cite as: arXiv:2602.23364 [astro-ph.EP] (or arXiv:2602.23364v1 [astro-ph.EP] for this version) https://doi.org/10.48550/arXiv.2602.23364 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Erik Gillis Mr [ view email ] [v1] Thu, 26 Feb 2026 18:59:48 UTC (20,029 KB) Full-text links: Access Paper: View a PDF of the paper titled TESS Planet Occurrence Rates Reveal the Disappearance of the Radius Valley Around Mid-to-Late M Dwarfs, by Erik Gillis and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: astro-ph.EP &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: astro-ph References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-158">80. AlayaLaser: Efficient Index Layout and Search Strategy for Large-scale High-dimensional Vector Similarity Search</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23342v1</li>
<li>来源：arxiv</li>
<li>摘要：On-disk graph-based approximate nearest neighbor search (ANNS) is essential for large-scale, high-dimensional vector retrieval, yet its performance is widely recognized to be limited by the prohibitive I/O costs. Interestingly, we observed that the performance of on-disk graph-based index systems is compute-bound, not I/O-bound, with the rising of the vector data dimensionality (e.g., hundreds or thousands). This insight uncovers a significant optimization opportunity: existing on-disk graph-based index systems universally target I/O reduction and largely overlook computational overhead, which leaves a substantial performance improvement space.   In this work, we propose AlayaLaser, an efficient on-disk graph-based index system for large-scale high-dimensional vector similarity search. In particular, we first conduct performance analysis on existing on-disk graph-based index systems via the adapted roofline model, then we devise a novel on-disk data layout in AlayaLaser to effectively alleviate the compute-bound, which is revealed by the above roofline model analysis, by exploiting SIMD instructions on modern CPUs. We next design a suite of optimization techniques (e.g., degree-bas</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-159">正文（抓取，非 AI）</h3>
<p>[2602.23342v1] AlayaLaser: Efficient Index Layout and Search Strategy for Large-scale High-dimensional Vector Similarity Search Computer Science &gt; Databases arXiv:2602.23342v1 (cs) [Submitted on 26 Feb 2026] Title: AlayaLaser: Efficient Index Layout and Search Strategy for Large-scale High-dimensional Vector Similarity Search Authors: Weijian Chen , Haotian Liu , Yangshen Deng , Long Xiang , Liang Huang , Gezi Li , Bo Tang View a PDF of the paper titled AlayaLaser: Efficient Index Layout and Search Strategy for Large-scale High-dimensional Vector Similarity Search, by Weijian Chen and 5 other authors View PDF HTML (experimental) Abstract: On-disk graph-based approximate nearest neighbor search (ANNS) is essential for large-scale, high-dimensional vector retrieval, yet its performance is widely recognized to be limited by the prohibitive I/O costs. Interestingly, we observed that the performance of on-disk graph-based index systems is compute-bound, not I/O-bound, with the rising of the vector data dimensionality (e.g., hundreds or thousands). This insight uncovers a significant optimization opportunity: existing on-disk graph-based index systems universally target I/O reduction and largely overlook computational overhead, which leaves a substantial performance improvement space. In this work, we propose AlayaLaser, an efficient on-disk graph-based index system for large-scale high-dimensional vector similarity search. In particular, we first conduct performance analysis on existing on-disk graph-based index systems via the adapted roofline model, then we devise a novel on-disk data layout in AlayaLaser to effectively alleviate the compute-bound, which is revealed by the above roofline model analysis, by exploiting SIMD instructions on modern CPUs. We next design a suite of optimization techniques (e.g., degree-based node cache, cluster-based entry point selection, and early dispatch strategy) to further improve the performance of AlayaLaser. We last conduct extensive experimental studies on a wide range of large-scale high-dimensional vector datasets to verify the superiority of AlayaLaser. Specifically, AlayaLaser not only surpasses existing on-disk graph-based index systems but also matches or even exceeds the performance of in-memory index systems. Comments: The paper has been accepted by SIGMOD 2026 Subjects: Databases (cs.DB) ; Information Retrieval (cs.IR) Cite as: arXiv:2602.23342 [cs.DB] (or arXiv:2602.23342v1 [cs.DB] for this version) https://doi.org/10.48550/arXiv.2602.23342 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Long Xiang [ view email ] [v1] Thu, 26 Feb 2026 18:48:29 UTC (685 KB) Full-text links: Access Paper: View a PDF of the paper titled AlayaLaser: Efficient Index Layout and Search Strategy for Large-scale High-dimensional Vector Similarity Search, by Weijian Chen and 5 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.DB &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.IR References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-160">81. ManifoldGD: Training-Free Hierarchical Manifold Guidance for Diffusion-Based Dataset Distillation</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23295v1</li>
<li>来源：arxiv</li>
<li>摘要：In recent times, large datasets hinder efficient model training while also containing redundant concepts. Dataset distillation aims to synthesize compact datasets that preserve the knowledge of large-scale training sets while drastically reducing storage and computation. Recent advances in diffusion models have enabled training-free distillation by leveraging pre-trained generative priors; however, existing guidance strategies remain limited. Current score-based methods either perform unguided denoising or rely on simple mode-based guidance toward instance prototype centroids (IPC centroids), which often are rudimentary and suboptimal. We propose Manifold-Guided Distillation (ManifoldGD), a training-free diffusion-based framework that integrates manifold consistent guidance at every denoising timestep. Our method employs IPCs computed via a hierarchical, divisive clustering of VAE latent features, yielding a multi-scale coreset of IPCs that captures both coarse semantic modes and fine intra-class variability. Using a local neighborhood of the extracted IPC centroids, we create the latent manifold for each diffusion denoising timestep. At each denoising step, we project the mode-ali</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-161">正文（抓取，非 AI）</h3>
<p>[2602.23295v1] ManifoldGD: Training-Free Hierarchical Manifold Guidance for Diffusion-Based Dataset Distillation Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23295v1 (cs) [Submitted on 26 Feb 2026] Title: ManifoldGD: Training-Free Hierarchical Manifold Guidance for Diffusion-Based Dataset Distillation Authors: Ayush Roy , Wei-Yang Alex Lee , Rudrasis Chakraborty , Vishnu Suresh Lokhande View a PDF of the paper titled ManifoldGD: Training-Free Hierarchical Manifold Guidance for Diffusion-Based Dataset Distillation, by Ayush Roy and 3 other authors View PDF HTML (experimental) Abstract: In recent times, large datasets hinder efficient model training while also containing redundant concepts. Dataset distillation aims to synthesize compact datasets that preserve the knowledge of large-scale training sets while drastically reducing storage and computation. Recent advances in diffusion models have enabled training-free distillation by leveraging pre-trained generative priors; however, existing guidance strategies remain limited. Current score-based methods either perform unguided denoising or rely on simple mode-based guidance toward instance prototype centroids (IPC centroids), which often are rudimentary and suboptimal. We propose Manifold-Guided Distillation (ManifoldGD), a training-free diffusion-based framework that integrates manifold consistent guidance at every denoising timestep. Our method employs IPCs computed via a hierarchical, divisive clustering of VAE latent features, yielding a multi-scale coreset of IPCs that captures both coarse semantic modes and fine intra-class variability. Using a local neighborhood of the extracted IPC centroids, we create the latent manifold for each diffusion denoising timestep. At each denoising step, we project the mode-alignment vector onto the local tangent space of the estimated latent manifold, thus constraining the generation trajectory to remain manifold-faithful while preserving semantic consistency. This formulation improves representativeness, diversity, and image fidelity without requiring any model retraining. Empirical results demonstrate consistent gains over existing training-free and training-based baselines in terms of FID, l2 distance among real and synthetic dataset embeddings, and classification accuracy, establishing ManifoldGD as the first geometry-aware training-free data distillation framework. Comments: CVPE 2026 Subjects: Computer Vision and Pattern Recognition (cs.CV) ; Machine Learning (cs.LG) Cite as: arXiv:2602.23295 [cs.CV] (or arXiv:2602.23295v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23295 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Ayush Roy [ view email ] [v1] Thu, 26 Feb 2026 18:07:10 UTC (17,761 KB) Full-text links: Access Paper: View a PDF of the paper titled ManifoldGD: Training-Free Hierarchical Manifold Guidance for Diffusion-Based Dataset Distillation, by Ayush Roy and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-162">82. Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23239v1</li>
<li>来源：arxiv</li>
<li>摘要：AI systems are increasingly deployed in high-stakes contexts -- medical diagnosis, legal research, financial analysis -- under the assumption they can be governed by norms. This paper demonstrates that assumption is formally invalid for optimization-based systems, specifically Large Language Models trained via Reinforcement Learning from Human Feedback (RLHF). We establish that genuine agency requires two necessary and jointly sufficient architectural conditions: the capacity to maintain certain boundaries as non-negotiable constraints rather than tradeable weights (Incommensurability), and a non-inferential mechanism capable of suspending processing when those boundaries are threatened (Apophatic Responsiveness). These conditions apply across all normative domains.   RLHF-based systems are constitutively incompatible with both conditions. The operations that make optimization powerful -- unifying all values on a scalar metric and always selecting the highest-scoring output -- are precisely the operations that preclude normative governance. This incompatibility is not a correctable training bug awaiting a technical fix; it is a formal constraint inherent to what optimization is. Co</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-163">正文（抓取，非 AI）</h3>
<p>[2602.23239v1] Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive Computer Science &gt; Artificial Intelligence arXiv:2602.23239v1 (cs) [Submitted on 26 Feb 2026] Title: Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive Authors: Radha Sarma View a PDF of the paper titled Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive, by Radha Sarma View PDF Abstract: AI systems are increasingly deployed in high-stakes contexts -- medical diagnosis, legal research, financial analysis -- under the assumption they can be governed by norms. This paper demonstrates that assumption is formally invalid for optimization-based systems, specifically Large Language Models trained via Reinforcement Learning from Human Feedback (RLHF). We establish that genuine agency requires two necessary and jointly sufficient architectural conditions: the capacity to maintain certain boundaries as non-negotiable constraints rather than tradeable weights (Incommensurability), and a non-inferential mechanism capable of suspending processing when those boundaries are threatened (Apophatic Responsiveness). These conditions apply across all normative domains. RLHF-based systems are constitutively incompatible with both conditions. The operations that make optimization powerful -- unifying all values on a scalar metric and always selecting the highest-scoring output -- are precisely the operations that preclude normative governance. This incompatibility is not a correctable training bug awaiting a technical fix; it is a formal constraint inherent to what optimization is. Consequently, documented failure modes - sycophancy, hallucination, and unfaithful reasoning - are not accidents but structural manifestations. Misaligned deployment triggers a second-order risk we term the Convergence Crisis: when humans are forced to verify AI outputs under metric pressure, they degrade from genuine agents into criteria-checking optimizers, eliminating the only component in the system capable of normative accountability. Beyond the incompatibility proof, the paper's primary positive contribution is a substrate-neutral architectural specification defining what any system -- biological, artificial, or institutional -- must satisfy to qualify as an agent rather than a sophisticated instrument. Comments: About 10,500 words in all (including 922 words of literature and 2019 words of Appendices). Under journal review Subjects: Artificial Intelligence (cs.AI) ; Computers and Society (cs.CY) Cite as: arXiv:2602.23239 [cs.AI] (or arXiv:2602.23239v1 [cs.AI] for this version) https://doi.org/10.48550/arXiv.2602.23239 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Radha Sarma Dr. [ view email ] [v1] Thu, 26 Feb 2026 17:16:17 UTC (331 KB) Full-text links: Access Paper: View a PDF of the paper titled Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive, by Radha Sarma View PDF view license Current browse context: cs.AI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CY References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-164">83. Revisiting the Perseus Cluster III: Role of Aspherical Explosions on its Chemical Composition and Extension to Metal-Poor Stars and Galaxies</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23356v1</li>
<li>来源：arxiv</li>
<li>摘要：The Perseus Cluster has been precisely measured by the legacy Hitomi telescope on the Si-group (Si, S, Ar, Ca) and Fe-group elements (Cr, Mn, Ni). These element abundance ratios provide insight into the typical behaviour of supernovae. In Paper II, we presented new massive star explosion models at various metallicity, assuming spherical explosions. We show that while the fitting is improved, some features (e.g., Ni/Fe) remain to be improved. In this article, we extend our calculation to an aspherical explosion using the jet-induced explosion mechanism. The detailed pre- and post-explosion chemical profiles are calculated with a large post-processing network to capture the production of odd-number elements (V, Mn, Cu) and iron-group elements. We further explore how the jet-driven explosions create the diversity of models which could be compatible with the observed diversity in terms of $^{56}$Ni-mass vs ejecta mass, Ti-V relation, and stellar abundances. Finally, we apply the new collapsar models in the Galactic Chemical Evolution context. We study how the galactic stars, including the Zn-enriched star HE 1327-2326, can put constraints on the relative rates of collapsar and some of </li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-165">正文（抓取，非 AI）</h3>
<p>[2602.23356v1] Revisiting the Perseus Cluster III: Role of Aspherical Explosions on its Chemical Composition and Extension to Metal-Poor Stars and Galaxies Astrophysics &gt; Astrophysics of Galaxies arXiv:2602.23356v1 (astro-ph) [Submitted on 26 Feb 2026] Title: Revisiting the Perseus Cluster III: Role of Aspherical Explosions on its Chemical Composition and Extension to Metal-Poor Stars and Galaxies Authors: Shing-Chi Leung , Henry Yerdon , Seth Walther , Ken'ichi Nomoto , Aurora Simionescu View a PDF of the paper titled Revisiting the Perseus Cluster III: Role of Aspherical Explosions on its Chemical Composition and Extension to Metal-Poor Stars and Galaxies, by Shing-Chi Leung and 4 other authors View PDF HTML (experimental) Abstract: The Perseus Cluster has been precisely measured by the legacy Hitomi telescope on the Si-group (Si, S, Ar, Ca) and Fe-group elements (Cr, Mn, Ni). These element abundance ratios provide insight into the typical behaviour of supernovae. In Paper II, we presented new massive star explosion models at various metallicity, assuming spherical explosions. We show that while the fitting is improved, some features (e.g., Ni/Fe) remain to be improved. In this article, we extend our calculation to an aspherical explosion using the jet-induced explosion mechanism. The detailed pre- and post-explosion chemical profiles are calculated with a large post-processing network to capture the production of odd-number elements (V, Mn, Cu) and iron-group elements. We further explore how the jet-driven explosions create the diversity of models which could be compatible with the observed diversity in terms of $^{56}$Ni-mass vs ejecta mass, Ti-V relation, and stellar abundances. Finally, we apply the new collapsar models in the Galactic Chemical Evolution context. We study how the galactic stars, including the Zn-enriched star HE 1327-2326, can put constraints on the relative rates of collapsar and some of its model parameters. We show that collapsar could lead to significant changes in some elements, e.g., Zn. Our study shows that the collapsar is a necessary component to explain multiple elemental trends observed in the Milky Way Galaxy. Comments: 23 pages, 39 figures. Submitted to the Astrophysical Journal on Nov 10 2025, accepted on Feb 7 2026 Subjects: Astrophysics of Galaxies (astro-ph.GA) ; High Energy Astrophysical Phenomena (astro-ph.HE) Cite as: arXiv:2602.23356 [astro-ph.GA] (or arXiv:2602.23356v1 [astro-ph.GA] for this version) https://doi.org/10.48550/arXiv.2602.23356 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Shing Chi Leung [ view email ] [v1] Thu, 26 Feb 2026 18:57:36 UTC (2,769 KB) Full-text links: Access Paper: View a PDF of the paper titled Revisiting the Perseus Cluster III: Role of Aspherical Explosions on its Chemical Composition and Extension to Metal-Poor Stars and Galaxies, by Shing-Chi Leung and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: astro-ph.GA &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: astro-ph astro-ph.HE References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-166">84. Efficient MPC-Based Energy Management System for Secure and Cost-Effective Microgrid Operations</h2>
<ul>
<li>链接：https://arxiv.org/abs/2510.03241v2</li>
<li>来源：arxiv</li>
<li>摘要：Model predictive control (MPC)-based energy management systems (EMS) are essential for ensuring optimal, secure, and stable operation in microgrids with high penetrations of distributed energy resources. However, due to the high computational cost for the decision-making, the conventional MPC-based EMS typically adopts a simplified integrated-bus power balance model. While this simplification is effective for small networks, large-scale systems require a more detailed branch flow model to account for the increased impact of grid power losses and security constraints. This work proposes an efficient and reliable MPC-based EMS that incorporates power-loss effects and grid-security constraints. %, while adaptively shaping the battery power profile in response to online renewable inputs, achieving reduced operational costs. It enhances system reliability, reduces operational costs, and shows strong potential for online implementation due to its reduced computational effort. Specifically, a second-order cone program (SOCP) branch flow relaxation is integrated into the constraint set, yielding a convex formulation that guarantees globally optimal solutions with high computational efficie</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-167">正文（抓取，非 AI）</h3>
<p>[2510.03241v2] Efficient MPC-Based Energy Management System for Secure and Cost-Effective Microgrid Operations Electrical Engineering and Systems Science &gt; Systems and Control arXiv:2510.03241v2 (eess) [Submitted on 23 Sep 2025 ( v1 ), last revised 7 Oct 2025 (this version, v2)] Title: Efficient MPC-Based Energy Management System for Secure and Cost-Effective Microgrid Operations Authors: Hanyang He , John Harlim , Daning Huang , Yan Li View a PDF of the paper titled Efficient MPC-Based Energy Management System for Secure and Cost-Effective Microgrid Operations, by Hanyang He and 3 other authors View PDF HTML (experimental) Abstract: Model predictive control (MPC)-based energy management systems (EMS) are essential for ensuring optimal, secure, and stable operation in microgrids with high penetrations of distributed energy resources. However, due to the high computational cost for the decision-making, the conventional MPC-based EMS typically adopts a simplified integrated-bus power balance model. While this simplification is effective for small networks, large-scale systems require a more detailed branch flow model to account for the increased impact of grid power losses and security constraints. This work proposes an efficient and reliable MPC-based EMS that incorporates power-loss effects and grid-security constraints. %, while adaptively shaping the battery power profile in response to online renewable inputs, achieving reduced operational costs. It enhances system reliability, reduces operational costs, and shows strong potential for online implementation due to its reduced computational effort. Specifically, a second-order cone program (SOCP) branch flow relaxation is integrated into the constraint set, yielding a convex formulation that guarantees globally optimal solutions with high computational efficiency. Owing to the radial topology of the microgrid, this relaxation is practically tight, ensuring equivalence to the original problem. Building on this foundation, an online demand response (DR) module is designed to further reduce the operation cost through peak shaving. To the best of our knowledge, no prior MPC-EMS framework has simultaneously modeled losses and security constraints while coordinating flexible loads within a unified architecture. The developed framework enables secure operation with effective peak shaving and reduced total cost. The effectiveness of the proposed method is validated on 10-bus, 18-bus, and 33-bus systems. Subjects: Systems and Control (eess.SY) Cite as: arXiv:2510.03241 [eess.SY] (or arXiv:2510.03241v2 [eess.SY] for this version) https://doi.org/10.48550/arXiv.2510.03241 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Hanyang He [ view email ] [v1] Tue, 23 Sep 2025 13:29:36 UTC (11,061 KB) [v2] Tue, 7 Oct 2025 12:07:41 UTC (11,066 KB) Full-text links: Access Paper: View a PDF of the paper titled Efficient MPC-Based Energy Management System for Secure and Cost-Effective Microgrid Operations, by Hanyang He and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: eess.SY &lt; prev | next &gt; new | recent | 2025-10 Change to browse by: cs cs.SY eess References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-168">85. Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models</h2>
<ul>
<li>链接：https://arxiv.org/abs/2510.04900v1</li>
<li>来源：arxiv</li>
<li>摘要：Understanding the robustness of deep learning models for multivariate long-term time series forecasting (M-LTSF) remains challenging, as evaluations typically rely on real-world datasets with unknown noise properties. We propose a simulation-based evaluation framework that generates parameterizable synthetic datasets, where each dataset instance corresponds to a different configuration of signal components, noise types, signal-to-noise ratios, and frequency characteristics. These configurable components aim to model real-world multivariate time series data without the ambiguity of unknown noise. This framework enables fine-grained, systematic evaluation of M-LTSF models under controlled and diverse scenarios. We benchmark four representative architectures S-Mamba (state-space), iTransformer (transformer-based), R-Linear (linear), and Autoformer (decomposition-based). Our analysis reveals that all models degrade severely when lookback windows cannot capture complete periods of seasonal patters in the data. S-Mamba and Autoformer perform best on sawtooth patterns, while R-Linear and iTransformer favor sinusoidal signals. White and Brownian noise universally degrade performance with l</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-169">正文（抓取，非 AI）</h3>
<p>[2510.04900v1] Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models Computer Science &gt; Machine Learning arXiv:2510.04900v1 (cs) [Submitted on 6 Oct 2025] Title: Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models Authors: Nick Janßen , Melanie Schaller , Bodo Rosenhahn View a PDF of the paper titled Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models, by Nick Jan{\ss}en and 2 other authors View PDF HTML (experimental) Abstract: Understanding the robustness of deep learning models for multivariate long-term time series forecasting (M-LTSF) remains challenging, as evaluations typically rely on real-world datasets with unknown noise properties. We propose a simulation-based evaluation framework that generates parameterizable synthetic datasets, where each dataset instance corresponds to a different configuration of signal components, noise types, signal-to-noise ratios, and frequency characteristics. These configurable components aim to model real-world multivariate time series data without the ambiguity of unknown noise. This framework enables fine-grained, systematic evaluation of M-LTSF models under controlled and diverse scenarios. We benchmark four representative architectures S-Mamba (state-space), iTransformer (transformer-based), R-Linear (linear), and Autoformer (decomposition-based). Our analysis reveals that all models degrade severely when lookback windows cannot capture complete periods of seasonal patters in the data. S-Mamba and Autoformer perform best on sawtooth patterns, while R-Linear and iTransformer favor sinusoidal signals. White and Brownian noise universally degrade performance with lower signal-to-noise ratio while S-Mamba shows specific trend-noise and iTransformer shows seasonal-noise vulnerability. Further spectral analysis shows that S-Mamba and iTransformer achieve superior frequency reconstruction. This controlled approach, based on our synthetic and principle-driven testbed, offers deeper insights into model-specific strengths and limitations through the aggregation of MSE scores and provides concrete guidance for model selection based on signal characteristics and noise conditions. Comments: Number of pages: 13 Number of figures: 16 Number of Tables: 1 Submitted to: IEEE Transactions on Signal Processing Subjects: Machine Learning (cs.LG) ; Systems and Control (eess.SY) Cite as: arXiv:2510.04900 [cs.LG] (or arXiv:2510.04900v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2510.04900 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Nick Janßen [ view email ] [v1] Mon, 6 Oct 2025 15:16:52 UTC (441 KB) Full-text links: Access Paper: View a PDF of the paper titled Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models, by Nick Jan{\ss}en and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2025-10 Change to browse by: cs cs.SY eess eess.SY References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-170">86. SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23199v1</li>
<li>来源：arxiv</li>
<li>摘要：Large language models (LLMs) are increasingly applied in scientific research, offering new capabilities for knowledge discovery and reasoning. In single-cell biology, however, evaluation practices for both general and specialized LLMs remain inadequate: existing benchmarks are fragmented across tasks, adopt formats such as multiple-choice classification that diverge from real-world usage, and rely on metrics lacking interpretability and biological grounding. We present SC-ARENA, a natural language evaluation framework tailored to single-cell foundation models. SC-ARENA formalizes a virtual cell abstraction that unifies evaluation targets by representing both intrinsic attributes and gene-level interactions. Within this paradigm, we define five natural language tasks (cell type annotation, captioning, generation, perturbation prediction, and scientific QA) that probe core reasoning capabilities in cellular biology. To overcome the limitations of brittle string-matching metrics, we introduce knowledge-augmented evaluation, which incorporates external ontologies, marker databases, and scientific literature to support biologically faithful and interpretable judgments. Experiments and a</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-171">正文（抓取，非 AI）</h3>
<p>[2602.23199v1] SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation Computer Science &gt; Artificial Intelligence arXiv:2602.23199v1 (cs) [Submitted on 26 Feb 2026] Title: SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation Authors: Jiahao Zhao , Feng Jiang , Shaowei Qin , Zhonghui Zhang , Junhao Liu , Guibing Guo , Hamid Alinejad-Rokny , Min Yang View a PDF of the paper titled SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation, by Jiahao Zhao and 7 other authors View PDF HTML (experimental) Abstract: Large language models (LLMs) are increasingly applied in scientific research, offering new capabilities for knowledge discovery and reasoning. In single-cell biology, however, evaluation practices for both general and specialized LLMs remain inadequate: existing benchmarks are fragmented across tasks, adopt formats such as multiple-choice classification that diverge from real-world usage, and rely on metrics lacking interpretability and biological grounding. We present SC-ARENA, a natural language evaluation framework tailored to single-cell foundation models. SC-ARENA formalizes a virtual cell abstraction that unifies evaluation targets by representing both intrinsic attributes and gene-level interactions. Within this paradigm, we define five natural language tasks (cell type annotation, captioning, generation, perturbation prediction, and scientific QA) that probe core reasoning capabilities in cellular biology. To overcome the limitations of brittle string-matching metrics, we introduce knowledge-augmented evaluation, which incorporates external ontologies, marker databases, and scientific literature to support biologically faithful and interpretable judgments. Experiments and analysis across both general-purpose and domain-specialized LLMs demonstrate that (i) under the Virtual Cell unified evaluation paradigm, current models achieve uneven performance on biologically complex tasks, particularly those demanding mechanistic or causal understanding; and (ii) our knowledge-augmented evaluation framework ensures biological correctness, provides interpretable, evidence-grounded rationales, and achieves high discriminative capacity, overcoming the brittleness and opacity of conventional metrics. SC-Arena thus provides a unified and interpretable framework for assessing LLMs in single-cell biology, pointing toward the development of biology-aligned, generalizable foundation models. Subjects: Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23199 [cs.AI] (or arXiv:2602.23199v1 [cs.AI] for this version) https://doi.org/10.48550/arXiv.2602.23199 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Zhao Jiahao [ view email ] [v1] Thu, 26 Feb 2026 16:50:28 UTC (1,738 KB) Full-text links: Access Paper: View a PDF of the paper titled SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation, by Jiahao Zhao and 7 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.AI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-172">87. STELLAR: Storage Tuning Engine Leveraging LLM Autonomous Reasoning for High Performance Parallel File Systems</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23220v1</li>
<li>来源：arxiv</li>
<li>摘要：I/O performance is crucial to efficiency in data-intensive scientific computing; but tuning large-scale storage systems is complex, costly, and notoriously manpower-intensive, making it inaccessible for most domain scientists. To address this problem, we propose STELLAR, an autonomous tuner for high-performance parallel file systems. Our evaluations show that STELLAR almost always selects near-optimal parameter configurations for parallel file systems within the first five attempts, even for previously unseen applications.   STELLAR differs fundamentally from traditional autotuning methods, which often require hundreds of thousands of iterations to converge. Powered by large language models (LLMs), STELLAR enables autonomous end-to-end agentic tuning by (1) accurately extracting tunable parameters from software manuals, (2) analyzing I/O trace logs generated by applications, (3) selecting initial tuning strategies, (4) rerunning applications on real systems and collecting I/O performance feedback, (5) adjusting tuning strategies and repeating the tuning cycle, and (6) reflecting on and summarizing tuning experiences into reusable knowledge for future optimizations. STELLAR integrat</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-173">正文（抓取，非 AI）</h3>
<p>[2602.23220v1] STELLAR: Storage Tuning Engine Leveraging LLM Autonomous Reasoning for High Performance Parallel File Systems Computer Science &gt; Distributed, Parallel, and Cluster Computing arXiv:2602.23220v1 (cs) [Submitted on 26 Feb 2026] Title: STELLAR: Storage Tuning Engine Leveraging LLM Autonomous Reasoning for High Performance Parallel File Systems Authors: Chris Egersdoerfer , Philip Carns , Shane Snyder , Robert Ross , Dong Dai View a PDF of the paper titled STELLAR: Storage Tuning Engine Leveraging LLM Autonomous Reasoning for High Performance Parallel File Systems, by Chris Egersdoerfer and 4 other authors View PDF HTML (experimental) Abstract: I/O performance is crucial to efficiency in data-intensive scientific computing; but tuning large-scale storage systems is complex, costly, and notoriously manpower-intensive, making it inaccessible for most domain scientists. To address this problem, we propose STELLAR, an autonomous tuner for high-performance parallel file systems. Our evaluations show that STELLAR almost always selects near-optimal parameter configurations for parallel file systems within the first five attempts, even for previously unseen applications. STELLAR differs fundamentally from traditional autotuning methods, which often require hundreds of thousands of iterations to converge. Powered by large language models (LLMs), STELLAR enables autonomous end-to-end agentic tuning by (1) accurately extracting tunable parameters from software manuals, (2) analyzing I/O trace logs generated by applications, (3) selecting initial tuning strategies, (4) rerunning applications on real systems and collecting I/O performance feedback, (5) adjusting tuning strategies and repeating the tuning cycle, and (6) reflecting on and summarizing tuning experiences into reusable knowledge for future optimizations. STELLAR integrates retrieval-augmented generation (RAG), tool execution, LLM-based reasoning, and a multiagent design to stabilize reasoning and combat hallucinations. We evaluate the impact of each component on optimization outcomes, providing design insights for similar systems in other optimization domains. STELLAR's architecture and empirical results highlight a promising approach to complex system optimization, especially for problems with large search spaces and high exploration costs, while making I/O tuning more accessible to domain scientists with minimal added resources. Comments: Published in the Proceedings of the 2025 International Conference for High Performance Computing, Networking, Storage, and Analysis (SC25) Subjects: Distributed, Parallel, and Cluster Computing (cs.DC) Cite as: arXiv:2602.23220 [cs.DC] (or arXiv:2602.23220v1 [cs.DC] for this version) https://doi.org/10.48550/arXiv.2602.23220 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Related DOI : https://doi.org/10.1145/3712285.3759887 Focus to learn more DOI(s) linking to related resources Submission history From: Chris Egersdoerfer [ view email ] [v1] Thu, 26 Feb 2026 17:01:18 UTC (2,737 KB) Full-text links: Access Paper: View a PDF of the paper titled STELLAR: Storage Tuning Engine Leveraging LLM Autonomous Reasoning for High Performance Parallel File Systems, by Chris Egersdoerfer and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.DC &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-174">88. SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23286v1</li>
<li>来源：arxiv</li>
<li>摘要：Real-world Table-Text question answering (QA) tasks require models that can reason across long text and source tables, traversing multiple hops and executing complex operations such as aggregation. Yet existing benchmarks are small, manually curated - and therefore error-prone - and contain shallow questions that seldom demand more than two hops or invoke aggregations, grouping, or other advanced analytical operations expressible in natural-language queries. We present SPARTA, an end-to-end construction framework that automatically generates large-scale Table-Text QA benchmarks with lightweight human validation, requiring only one quarter of the annotation time of HybridQA. The framework first constructs a reference fact database by enriching each source table with grounding tables whose tuples are atomic facts automatically extracted from the accompanying unstructured passages, then synthesizes nested queries whose number of nested predicates matches the desired hop count. To ensure that every SQL statement is executable and that its verbalization yields a fluent, human-sounding question, we propose two novel techniques: provenance-based refinement, which rewrites any syntacticall</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-175">正文（抓取，非 AI）</h3>
<p>[2602.23286v1] SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables Computer Science &gt; Computation and Language arXiv:2602.23286v1 (cs) [Submitted on 26 Feb 2026] Title: SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables Authors: Sungho Park , Jueun Kim , Wook-Shin Han View a PDF of the paper titled SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables, by Sungho Park and 1 other authors View PDF HTML (experimental) Abstract: Real-world Table-Text question answering (QA) tasks require models that can reason across long text and source tables, traversing multiple hops and executing complex operations such as aggregation. Yet existing benchmarks are small, manually curated - and therefore error-prone - and contain shallow questions that seldom demand more than two hops or invoke aggregations, grouping, or other advanced analytical operations expressible in natural-language queries. We present SPARTA, an end-to-end construction framework that automatically generates large-scale Table-Text QA benchmarks with lightweight human validation, requiring only one quarter of the annotation time of HybridQA. The framework first constructs a reference fact database by enriching each source table with grounding tables whose tuples are atomic facts automatically extracted from the accompanying unstructured passages, then synthesizes nested queries whose number of nested predicates matches the desired hop count. To ensure that every SQL statement is executable and that its verbalization yields a fluent, human-sounding question, we propose two novel techniques: provenance-based refinement, which rewrites any syntactically valid query that returns a non-empty result, and realistic-structure enforcement, which confines generation to post-order traversals of the query graph. The resulting pipeline produces thousands of high-fidelity question-answer pairs covering aggregations, grouping, and deep multi-hop reasoning across text and tables. On SPARTA, state-of-the-art models that reach over 70 F1 on HybridQA or over 50 F1 on OTT-QA drop by more than 30 F1 points, exposing fundamental weaknesses in current cross-modal reasoning. Our benchmark, construction code, and baseline models are available at this https URL . Comments: 10 pages, 5 figures. Published as a conference paper at ICLR 2026. Project page: this https URL Subjects: Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Databases (cs.DB); Information Retrieval (cs.IR) ACM classes: H.2.4; H.3.3; H.3.4; I.2.7; I.2.1; H.2.3; F.2.2; I.2.6; H.3.1 Cite as: arXiv:2602.23286 [cs.CL] (or arXiv:2602.23286v1 [cs.CL] for this version) https://doi.org/10.48550/arXiv.2602.23286 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Journal reference: The Fourteenth International Conference on Learning Representations (ICLR), 2026 Submission history From: Sungho Park [ view email ] [v1] Thu, 26 Feb 2026 17:59:51 UTC (1,194 KB) Full-text links: Access Paper: View a PDF of the paper titled SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables, by Sungho Park and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CL &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI cs.DB cs.IR References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-176">89. Extreme Emission Line Galaxies in CEERS Are Powered by Star Formation, not AGN</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23310v1</li>
<li>来源：arxiv</li>
<li>摘要：We present a spectroscopic study of photometrically identified extreme emission-line galaxies (EELGs) with observed-frame equivalent widths (EWs) &gt;5000 A of either H alpha or H beta + [OIII] in the CEERS legacy deep field utilizing JWST NIRSpec spectroscopy from the CAPERS, RUBIES, THRILS and CEERS surveys. This master sample allows for performance tests of photometric selections and unveils what types of sources, either AGN or young star formation, were producing excessive ionizing radiation in the early Universe. We identify AGN through broad H alpha emission-lines and report 6 new broad-line AGN at 3.5&lt;z&lt;7 identified by the deep (~8 hr) G395M THRILS survey. We investigate the photometrically selected EELGs in a color-color plot designed for ``Little Red Dot'' selection and demonstrate that it effectively removes AGN with non-extreme lines from the sample. EELGs with and without broad lines show similar optical line ratios. We compare emission-line morphology to EWs and continuum morphologies and find that [OIII] morphology is more compact at higher EW. ~10% of photometrically selected EELGs have broad Balmer lines, jumping to 35% in deep spectroscopy which indicates a significan</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-177">正文（抓取，非 AI）</h3>
<p>[2602.23310v1] Extreme Emission Line Galaxies in CEERS Are Powered by Star Formation, not AGN Astrophysics &gt; Astrophysics of Galaxies arXiv:2602.23310v1 (astro-ph) [Submitted on 26 Feb 2026] Title: Extreme Emission Line Galaxies in CEERS Are Powered by Star Formation, not AGN Authors: Kelcey Davis , Madisyn Brooks , Jonathan R. Trump , Vital Fernández , Taylor A. Hutchison , Rebecca L. Larson , Anthony J. Taylor , Elizabeth J. McGrath , Guillermo Barro , Anton M. Koekemoer , Pablo Arrabal Haro , Mark Dickinson , Bren E. Backhaus , Nikko J. Cleri , Steven L. Finkelstein , Ananya Ganapathy , Raymond C. Simons , Ricardo O. Amorín , Alexander de la Vega , Norman A. Grogin , Michaela Hirschmann , Weida Hu , Jarrett L. Johnson , Jeyhan S. Kartaltepe , Dale Kocevski , Mario Llerena , Ray A. Lucas , Madeline A. Marshall , Fabio Pacucci , Laura Pentericci , Phoebe R. Upton Sanderbeck View a PDF of the paper titled Extreme Emission Line Galaxies in CEERS Are Powered by Star Formation, not AGN, by Kelcey Davis and 30 other authors View PDF HTML (experimental) Abstract: We present a spectroscopic study of photometrically identified extreme emission-line galaxies (EELGs) with observed-frame equivalent widths (EWs) &gt;5000 A of either H alpha or H beta + [OIII] in the CEERS legacy deep field utilizing JWST NIRSpec spectroscopy from the CAPERS, RUBIES, THRILS and CEERS surveys. This master sample allows for performance tests of photometric selections and unveils what types of sources, either AGN or young star formation, were producing excessive ionizing radiation in the early Universe. We identify AGN through broad H alpha emission-lines and report 6 new broad-line AGN at 3.5&lt;z&lt;7 identified by the deep (~8 hr) G395M THRILS survey. We investigate the photometrically selected EELGs in a color-color plot designed for ``Little Red Dot'' selection and demonstrate that it effectively removes AGN with non-extreme lines from the sample. EELGs with and without broad lines show similar optical line ratios. We compare emission-line morphology to EWs and continuum morphologies and find that [OIII] morphology is more compact at higher EW. ~10% of photometrically selected EELGs have broad Balmer lines, jumping to 35% in deep spectroscopy which indicates a significant fraction of photometrically selected EELGs may host AGN. However, many AGN selected as EELGs have incorrectly high photometric EWs. For sources with extreme emission-line EWs that pass our photometric criteria and host an AGN, we find that the narrow H alpha component dominates over the broad, especially in the highest-EW sources. This implies that even when an AGN is present, it does not dominate the extreme emission. Comments: Submitted to ApJ Subjects: Astrophysics of Galaxies (astro-ph.GA) Cite as: arXiv:2602.23310 [astro-ph.GA] (or arXiv:2602.23310v1 [astro-ph.GA] for this version) https://doi.org/10.48550/arXiv.2602.23310 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Kelcey Davis [ view email ] [v1] Thu, 26 Feb 2026 18:16:17 UTC (2,093 KB) Full-text links: Access Paper: View a PDF of the paper titled Extreme Emission Line Galaxies in CEERS Are Powered by Star Formation, not AGN, by Kelcey Davis and 30 other authors View PDF HTML (experimental) TeX Source view license Current browse context: astro-ph.GA &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: astro-ph References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-178">90. F10.7 Index Prediction: A Multiscale Decomposition Strategy with Wavelet Transform for Performance Optimization</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.20712v1</li>
<li>来源：arxiv</li>
<li>摘要：In this study, we construct Dataset A for training, validation, and testing, and Dataset B to evaluate generalization. We propose a novel F10.7 index forecasting method using wavelet decomposition, which feeds F10.7 together with its decomposed approximate and detail signals into the iTransformer model. We also incorporate the International Sunspot Number (ISN) and its wavelet-decomposed signals to assess their influence on prediction performance. Our optimal method is then compared with the latest method from S. Yan et al. (2025) and three operational models (SWPC, BGS, CLS). Additionally, we transfer our method to the PatchTST model used in H. Ye et al. (2024) and compare our method with theirs on Dataset B. Key findings include: (1) The wavelet-based combination methods overall outperform the baseline using only F10.7 index. The prediction performance improves as higher-level approximate and detail signals are incrementally added. The Combination 6 method integrating F10.7 with its first to fifth level approximate and detail signals outperforms methods using only approximate or detail signals. (2) Incorporating ISN and its wavelet-decomposed signals does not enhance prediction p</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-179">正文（抓取，非 AI）</h3>
<p>[2602.20712v1] F10.7 Index Prediction: A Multiscale Decomposition Strategy with Wavelet Transform for Performance Optimization Astrophysics &gt; Instrumentation and Methods for Astrophysics arXiv:2602.20712v1 (astro-ph) [Submitted on 24 Feb 2026] Title: F10.7 Index Prediction: A Multiscale Decomposition Strategy with Wavelet Transform for Performance Optimization Authors: Xuran Ma , Xuebao Li , Yanfang Zheng , Yongshang Lv , Xiaojia Ji , Jiancheng Xu , Hongwei Ye , Zixian Wu , Shuainan Yan , Liang Dong , Zamri Zainal Abidin , Xusheng Huang , Shunhuang Zhang , Honglei Jin , Tarik Abdul Latef , Noraisyah Mohamed Shah , Mohamadariff Othman , Kamarul Ariffin Noordin View a PDF of the paper titled F10.7 Index Prediction: A Multiscale Decomposition Strategy with Wavelet Transform for Performance Optimization, by Xuran Ma and 17 other authors View PDF HTML (experimental) Abstract: In this study, we construct Dataset A for training, validation, and testing, and Dataset B to evaluate generalization. We propose a novel F10.7 index forecasting method using wavelet decomposition, which feeds F10.7 together with its decomposed approximate and detail signals into the iTransformer model. We also incorporate the International Sunspot Number (ISN) and its wavelet-decomposed signals to assess their influence on prediction performance. Our optimal method is then compared with the latest method from S. Yan et al. (2025) and three operational models (SWPC, BGS, CLS). Additionally, we transfer our method to the PatchTST model used in H. Ye et al. (2024) and compare our method with theirs on Dataset B. Key findings include: (1) The wavelet-based combination methods overall outperform the baseline using only F10.7 index. The prediction performance improves as higher-level approximate and detail signals are incrementally added. The Combination 6 method integrating F10.7 with its first to fifth level approximate and detail signals outperforms methods using only approximate or detail signals. (2) Incorporating ISN and its wavelet-decomposed signals does not enhance prediction performance. (3) The Combination 6 method significantly surpasses S. Yan et al. (2025) and three operational models, with RMSE, MAE, and MAPE reduced by 18.22%, 15.09%, and 8.57%, respectively, against the former method. It also excels across four different conditions of solar activity. (4) Our method demonstrates superior generalization and prediction capability over the method of H. Ye et al. (2024) across all forecast horizons. To our knowledge, this is the first application of wavelet decomposition in F10.7 prediction, substantially improving forecast performance. Subjects: Instrumentation and Methods for Astrophysics (astro-ph.IM) ; Solar and Stellar Astrophysics (astro-ph.SR); Machine Learning (cs.LG) Cite as: arXiv:2602.20712 [astro-ph.IM] (or arXiv:2602.20712v1 [astro-ph.IM] for this version) https://doi.org/10.48550/arXiv.2602.20712 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Yanfang Zheng [ view email ] [v1] Tue, 24 Feb 2026 09:18:57 UTC (2,874 KB) Full-text links: Access Paper: View a PDF of the paper titled F10.7 Index Prediction: A Multiscale Decomposition Strategy with Wavelet Transform for Performance Optimization, by Xuran Ma and 17 other authors View PDF HTML (experimental) TeX Source view license Current browse context: astro-ph.IM &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: astro-ph astro-ph.SR cs cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p></div></details>
</div>
<script>
var READING_HIGHLIGHT_CLASS='reading-highlight';
function getBlocksInOrder(container){
 var blocks=[]; var blockTags=['P','DIV','H2','H3','H4','LI','PRE'];
 function walk(el){
  if(!el||!container.contains(el))return;
  if(blockTags.indexOf(el.tagName)!==-1){
   var hasBlockChild=false;
   for(var k=0;k<el.children.length;k++){ var c=el.children[k]; if(blockTags.indexOf(c.tagName)!==-1){ hasBlockChild=true; break; } }
   if(!hasBlockChild){ var t=(el.innerText||'').trim().replace(/\\s+/g,' '); if(t)blocks.push({el:el,text:t}); }
   else for(k=0;k<el.children.length;k++)walk(el.children[k]);
  } else for(k=0;k<el.children.length;k++)walk(el.children[k]);
 }
 walk(container); return blocks;
}
function speakText(t,onDone){ if(!t){ document.getElementById('readStatus').textContent=''; if(onDone)onDone(); return; }
 speechSynthesis.cancel(); var status=document.getElementById('readStatus'); status.textContent='准备中…';
 var chunks=[]; var maxLen=280; for(var i=0;i<t.length;i+=maxLen){ var s=t.slice(i,i+maxLen); var j=s.lastIndexOf('。'); if(j>80){ chunks.push(s.slice(0,j+1)); i-=s.length-(j+1); } else chunks.push(s); }
 if(chunks.length===0)chunks=[t]; var idx=0;
 function speakNext(){ if(idx>=chunks.length){ status.textContent=''; if(onDone)onDone(); return; } var u=new SpeechSynthesisUtterance(chunks[idx]); u.lang='zh-CN'; u.rate=0.95; var v=speechSynthesis.getVoices().filter(function(x){ return x.lang.indexOf('zh')>=0; })[0]; if(v)u.voice=v;
  u.onend=function(){ idx++; setTimeout(speakNext,80); }; u.onerror=function(){ idx++; setTimeout(speakNext,80); }; status.textContent='朗读中 '+(idx+1)+'/'+chunks.length+'…'; speechSynthesis.speak(u); }
 if(speechSynthesis.getVoices().length)speakNext(); else speechSynthesis.onvoiceschanged=function(){ speechSynthesis.onvoiceschanged=null; speakNext(); }; }
function readFullText(){ var c=document.querySelector('.content'); if(!c){ document.getElementById('readStatus').textContent='无可读内容'; return; }
 var segments=getBlocksInOrder(c); if(!segments.length){ document.getElementById('readStatus').textContent='无可读内容'; return; }
 speechSynthesis.cancel(); document.querySelectorAll('.content .'+READING_HIGHLIGHT_CLASS).forEach(function(el){ el.classList.remove(READING_HIGHLIGHT_CLASS); });
 var status=document.getElementById('readStatus'); var idx=0;
 function runSegment(){ if(idx>=segments.length){ status.textContent=''; document.querySelectorAll('.content .'+READING_HIGHLIGHT_CLASS).forEach(function(el){ el.classList.remove(READING_HIGHLIGHT_CLASS); }); return; }
  var seg=segments[idx]; seg.el.scrollIntoView({behavior:'smooth',block:'center'}); document.querySelectorAll('.content .'+READING_HIGHLIGHT_CLASS).forEach(function(el){ el.classList.remove(READING_HIGHLIGHT_CLASS); }); seg.el.classList.add(READING_HIGHLIGHT_CLASS);
  status.textContent='朗读 '+(idx+1)+'/'+segments.length+'…';
  speakText(seg.text,function(){ seg.el.classList.remove(READING_HIGHLIGHT_CLASS); idx++; setTimeout(runSegment,120); }); }
 runSegment(); }
function getBlockForTap(el){ var c=document.querySelector('.content'); var blockTags=['P','DIV','H2','H3','H4','LI','PRE']; while(el&&el!==c){ if(c.contains(el)&&blockTags.indexOf(el.tagName)!==-1) return el; el=el.parentElement; } return null; }
function onContentTap(e){ if(e.target.closest&&e.target.closest('a')) return; var block=getBlockForTap(e.target); if(block){ var t=(block.innerText||'').trim().replace(/\\s+/g,' '); if(t){ e.preventDefault(); speechSynthesis.cancel(); document.getElementById('readStatus').textContent='朗读本段…'; speakText(t); } } }
if(document.readyState==='loading'){ document.addEventListener('DOMContentLoaded', function(){ var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }); } else { var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }
setTimeout(function(){ try{ var u=new SpeechSynthesisUtterance('\u200b'); u.volume=0; speechSynthesis.speak(u); }catch(e){} }, 300);
</script>
</body>
</html>
<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>知识流日报 2026-03-01：average pooling</title>
<style>
  * { box-sizing: border-box; }
  body {
    font-family: system-ui, sans-serif;
    max-width: 720px;
    margin: 0 auto;
    padding: 2rem 1rem;
    color: #fff;
    min-height: 100vh;
    background: #0a0e1a;
    background-image:
      radial-gradient(2px 2px at 20px 30px, rgba(255,255,255,0.9), transparent),
      radial-gradient(2px 2px at 40px 70px, rgba(255,255,255,0.6), transparent),
      radial-gradient(1.5px 1.5px at 90px 40px, rgba(255,255,255,0.8), transparent),
      radial-gradient(2px 2px at 130px 80px, rgba(255,255,255,0.5), transparent),
      radial-gradient(1.5px 1.5px at 160px 120px, rgba(255,255,255,0.7), transparent),
      radial-gradient(ellipse 120% 100% at 50% 0%, rgba(88,60,120,0.25), transparent 50%),
      radial-gradient(ellipse 80% 80% at 80% 20%, rgba(40,60,100,0.2), transparent 40%);
    background-size: 200px 200px;
    background-repeat: repeat;
  }
  a { color: #a8d4ff; text-decoration: none; }
  a:hover { text-decoration: underline; }
 html{scroll-behavior:smooth;} .content h2,.content h3{scroll-margin-top:1rem;} .content .reading-highlight{background:rgba(255,255,255,0.12);border-left:3px solid rgba(255,255,255,0.5);border-radius:2px;} h1,h2,h3{margin-top:1.5rem;color:#fff;} pre{white-space:pre-wrap;color:rgba(255,255,255,0.9);} .toolbar{margin:0.5rem 0;color:rgba(255,255,255,0.8);} .content{color:rgba(255,255,255,0.95);} .content a{color:#a8d4ff;} .meta{color:rgba(255,255,255,0.65);font-size:0.9em;} .toc{margin:1rem 0;padding:0.8rem 1rem;background:rgba(255,255,255,0.08);border-radius:6px;} .toc .toc-title{margin:0 0 0.5rem 0;font-weight:bold;color:rgba(255,255,255,0.9);} .toc ul{list-style:none;padding-left:0;margin:0;} .toc li{margin:0.35rem 0;} .toc li.toc-h3{padding-left:1em;font-size:0.95em;} .toc a{color:#a8d4ff;text-decoration:none;} .toc a:hover{text-decoration:underline;} .content p,.content div,.content h2,.content h3,.content h4,.content li,.content pre{cursor:pointer;-webkit-tap-highlight-color:rgba(255,255,255,0.15);} .content .insight-summary{color:#c9a0dc;margin:0.5em 0 0.8em 0;} .content .insight-detail,.content .insight-detail li{color:#8dd4e8;list-style:disc;margin-left:1.2em;padding-left:0.3em;} .content .article-body-details{margin:0.8em 0;} .content .article-body-details summary{cursor:pointer;color:rgba(255,255,255,0.85);}</style>
</head>
<body>
<p><a href="https://YuxinWSoton.github.io/ai-knowledge-flow-site/">← 返回首页</a></p>
<h1>知识流日报 2026-03-01：average pooling</h1>
<p class="meta" style="margin-top:0;">最后更新：2026-03-01 21:41</p>
<p class="toolbar"><button id="btnFull" onclick="readFullText()">全文朗读</button> <span id="readStatus"></span></p>
<p class="meta" style="margin-top:0;">（点任意段落可朗读该段；「全文朗读」读本页全部内容，当前读到的段落会自动滚动到视野内并高亮）</p>
<nav class="toc" aria-label="目录">
<p class="toc-title">目录</p>
<ul>
  <li><a href="#toc-0">1. Excel怎么求平均值，AVERAGE函数公式值得拥有！</a></li>
  <li class="toc-h3"><a href="#toc-1">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-2">2. Spin Glass Concepts in Computer Science, Statistics, and Learning</a></li>
  <li class="toc-h3"><a href="#toc-3">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-4">3. FairQuant: Fairness-Aware Mixed-Precision Quantization for Medical Image Classification</a></li>
  <li class="toc-h3"><a href="#toc-5">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-6">4. Evaluating Stochasticity in Deep Research Agents</a></li>
  <li class="toc-h3"><a href="#toc-7">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-8">5. Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity</a></li>
  <li class="toc-h3"><a href="#toc-9">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-10">6. AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning</a></li>
  <li class="toc-h3"><a href="#toc-11">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-12">7. Model Agreement via Anchoring</a></li>
  <li class="toc-h3"><a href="#toc-13">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-14">8. Automated Vulnerability Detection in Source Code Using Deep Representation Learning</a></li>
  <li class="toc-h3"><a href="#toc-15">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-16">9. CL4SE: A Context Learning Benchmark For Software Engineering Tasks</a></li>
  <li class="toc-h3"><a href="#toc-17">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-18">10. Efficient evaluation of fundamental sensitivity limits and full counting statistics for continuously monitored Gaussian quantum systems</a></li>
  <li class="toc-h3"><a href="#toc-19">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-20">11. Learning Continuous Wasserstein Barycenter Space for Generalized All-in-One Image Restoration</a></li>
  <li class="toc-h3"><a href="#toc-21">正文（抓取，非 AI）</a></li>
  <li><a href="#toc-22">12. LLMServingSim 2.0: A Unified Simulator for Heterogeneous and Disaggregated LLM Serving Infrastructure</a></li>
  <li class="toc-h3"><a href="#toc-23">正文（抓取，非 AI）</a></li>
</ul>
</nav>
<div class="content">
<h1>知识流日报 2026-03-01：average pooling</h1>
<p>共 12 条（来自百度学术 / Google / Bing 等，仅含正文抓取成功的条目；按正文长度从短到长排列，便于先听短的）。</p>
<p>（以下含抓取正文，便于阅读。未调用任何 AI API。）</p>
<p>（仅前 12 条含模型提取的「易漏细节」关键点，页面上以颜色区分；第 13 条及之后未调用模型，故无易漏细节。可在 config 中调大 extract_insights_max_items 以增加条数。）</p>
<h2 id="toc-0">1. Excel怎么求平均值，AVERAGE函数公式值得拥有！</h2>
<ul>
<li>链接：https://www.zhihu.com/tardis/bd/art/719130156</li>
<li>来源：bing</li>
<li>摘要：2024年9月9日 · 一、使用 AVERAGE 函数 AVERAGE 函数是 Excel 中最直接用来计算平均值的函数。 操作步骤： 选择一个空白单元格来显示计算结果。 输入公式： =AVERAGE(数据区域)。 例如，如果你 …</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">AVERAGE函数可以直接计算数值的平均值，选择空白单元格来显示计算结果，输入公式时需正确指定数据区域。此外，Excel还提供了“平均值”按钮，可以快速计算平均值。AVERAGEIF函数适用于满足单一条件的数据平均值，而AVERAGEIFS函数则适用于满足多个条件的数据平均值。为了确保计算的准确性，需要确保数据区域不含非数值单元格，并且条件设置需准确无误。值得注意的是，AVERAGE函数会自动忽略空白单元格，但使用数组公式时需额外处理空白单元格，否则可能会影响计算结果。因此，如果计算结果不符合预期，应检查数据和条件设置，确保输入正确无误。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>AVERAGE函数直接计算数值的平均值。</li>
<li>选择空白单元格来显示计算结果。</li>
<li>输入公式时需正确指定数据区域。</li>
<li>“平均值”按钮快速计算平均值。</li>
<li>AVERAGEIF函数用于满足单一条件的数据平均值。</li>
<li>AVERAGEIFS函数用于满足多个条件的数据平均值。</li>
<li>确保数据区域不含非数值单元格。</li>
<li>条件设置需准确无误。</li>
<li>AVERAGE函数会自动忽略空白单元格。</li>
<li>计算结果不符合预期需检查数据和条件。</li>
<li>使用数组公式需额外处理空白单元格。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-1">正文（抓取，非 AI）</h3>
<p>大家好，这里是 效率办公指南 ！ 在数据分析中，计算平均值是一项基本而重要的任务。Excel 提供了多种方法来求平均值，适用于不同的数据集和需求。今天，我们将介绍几种在 Excel 中求平均值的方法。 一、使用 AVERAGE 函数 AVERAGE 函数是 Excel 中最直接用来计算平均值的函数。 操作步骤： 选择一个空白单元格来显示计算结果。 输入公式： =AVERAGE(数据区域) 。 例如，如果你的数据位于 A2:A6，公式将是： =AVERAGE(A2:A6) 。 二、使用“平均值”按钮 Excel 的“开始”选项卡提供了一个快速计算平均值的工具。 操作步骤： 选中包含数据的单元格区域。 在“开始”选项卡的“编辑”组中，点击“平均值”按钮。 三、结合条件求平均值 如果要计算满足特定条件的数据平均值，可以使用 AVERAGEIF 或 AVERAGEIFS 函数。 操作步骤： AVERAGEIF ： =AVERAGEIF(条件范围, 条件, [数据范围]) AVERAGEIFS ： =AVERAGEIFS(数据范围, 条件范围1, 条件1, [条件范围2, 条件2], ...) 统计60分以上分数的平均值 注意事项 确保数据区域正确，不含有任何非数值单元格。 使用 AVERAGEIF 或 AVERAGEIFS 时，注意条件的准确性。 常见问题 Q: 计算结果不符合预期？ A: 检查数据区域是否包含了非数值单元格，或条件设置是否正确。 Q: 如何忽略空白单元格计算平均值？ A: 使用 AVERAGE 函数时，它会自然忽略空白单元格。如果使用数组公式或其它方法，可能需要额外处理。 结语 通过今天的学习，我们掌握了在 Excel 中求平均值的几种方法。无论是使用基本的 AVERAGE 函数，还是结合条件求平均值，这些技巧都将帮助你更有效地进行数据分析。如果你有任何问题或想要了解更多 Excel 技巧，请在评论区留言，我们一起探讨和学习！</p>
</div></details><h2 id="toc-2">2. Spin Glass Concepts in Computer Science, Statistics, and Learning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23326v1</li>
<li>来源：arxiv</li>
<li>摘要：Spin glass theory studies the structure of sublevel sets and minima (or near-minima) of certain classes of random functions in high dimension. Near-minima of random functions also play an important role in high-dimensional statistics and statistical learning, where minimizing the empirical risk (which is a random function of the model parameters) is the method of choice for learning a statistical model from noisy data. Finally, near-minima of random functions are obviously central to average-case analysis of optimization algorithms. Computer science, statistics, and machine learning naturally lead to questions that are traditionally not addressed within physics and mathematical physics. I will try to explain how ideas from spin glass theory have seeded recent developments in these fields.   (This article was written on the occasion of the 2024 Abel Prize to Michel Talagrand.)</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">sublevel sets和随机函数的最小值在高维空间中的研究是统计学和机器学习领域的重要课题。近似最小值在高维统计中至关重要，直接影响着统计模型的学习过程。通过最小化经验风险，可以有效学习统计模型，而近似最小值在优化算法的平均情况分析中占据核心地位。计算机科学、统计学和机器学习不断提出新的问题，其中一些问题与无序磁性材料（spin glass）理论密切相关。spin玻璃概念对于处理噪声数据的学习过程具有重要意义，这些理论为理解和解决现代统计和机器学习问题提供了新的视角。因此，结合spin玻璃理论，可以更好地理解和分析优化算法在实际应用中的表现。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>sublevel sets and minima of random functions are studied in high dimensions.</li>
<li>near-minima of random functions are crucial in high-dimensional statistics.</li>
<li>minimizing empirical risk is a method for learning statistical models.</li>
<li>near-minima are central to the average-case analysis of optimization algorithms.</li>
<li>computer science, statistics, and machine learning pose new questions.</li>
<li>ideas from spin glass theory have influenced recent developments.</li>
<li>spin glass concepts are relevant to learning from noisy data.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-3">正文（抓取，非 AI）</h3>
<p>[2602.23326v1] Spin Glass Concepts in Computer Science, Statistics, and Learning Mathematics &gt; Probability arXiv:2602.23326v1 (math) [Submitted on 26 Feb 2026] Title: Spin Glass Concepts in Computer Science, Statistics, and Learning Authors: Andrea Montanari View a PDF of the paper titled Spin Glass Concepts in Computer Science, Statistics, and Learning, by Andrea Montanari View PDF HTML (experimental) Abstract: Spin glass theory studies the structure of sublevel sets and minima (or near-minima) of certain classes of random functions in high dimension. Near-minima of random functions also play an important role in high-dimensional statistics and statistical learning, where minimizing the empirical risk (which is a random function of the model parameters) is the method of choice for learning a statistical model from noisy data. Finally, near-minima of random functions are obviously central to average-case analysis of optimization algorithms. Computer science, statistics, and machine learning naturally lead to questions that are traditionally not addressed within physics and mathematical physics. I will try to explain how ideas from spin glass theory have seeded recent developments in these fields. (This article was written on the occasion of the 2024 Abel Prize to Michel Talagrand.) Comments: 33 pages; 2 pdf figures Subjects: Probability (math.PR) ; Disordered Systems and Neural Networks (cond-mat.dis-nn) Cite as: arXiv:2602.23326 [math.PR] (or arXiv:2602.23326v1 [math.PR] for this version) https://doi.org/10.48550/arXiv.2602.23326 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Andrea Montanari [ view email ] [v1] Thu, 26 Feb 2026 18:35:47 UTC (55 KB) Full-text links: Access Paper: View a PDF of the paper titled Spin Glass Concepts in Computer Science, Statistics, and Learning, by Andrea Montanari View PDF HTML (experimental) TeX Source view license Current browse context: math.PR &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cond-mat cond-mat.dis-nn math References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-4">3. FairQuant: Fairness-Aware Mixed-Precision Quantization for Medical Image Classification</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23192v1</li>
<li>来源：arxiv</li>
<li>摘要：Compressing neural networks by quantizing model parameters offers useful trade-off between performance and efficiency. Methods like quantization-aware training and post-training quantization strive to maintain the downstream performance of compressed models compared to the full precision models. However, these techniques do not explicitly consider the impact on algorithmic fairness. In this work, we study fairness-aware mixed-precision quantization schemes for medical image classification under explicit bit budgets. We introduce FairQuant, a framework that combines group-aware importance analysis, budgeted mixed-precision allocation, and a learnable Bit-Aware Quantization (BAQ) mode that jointly optimizes weights and per-unit bit allocations under bitrate and fairness regularization. We evaluate the method on Fitzpatrick17k and ISIC2019 across ResNet18/50, DeiT-Tiny, and TinyViT. Results show that FairQuant configurations with average precision near 4-6 bits recover much of the Uniform 8-bit accuracy while improving worst-group performance relative to Uniform 4- and 8-bit baselines, with comparable fairness metrics under shared budgets.</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，Fairness-aware quantization考虑了量化对算法公平性的影响，确保在降低计算精度的同时不会显著损害特定群体的性能。其次，Group-aware importance分析有助于识别重要参数，从而在优化过程中给予这些参数更多的关注。此外，Budgeted mixed-precision分配在预算内优化精度，确保资源的有效利用。Learnable Bit-Aware Quantization模式则允许根据具体情况调整权重和比特分配，进一步提高模型的灵活性。因此，FairQuant在4-6比特精度下恢复了大部分8比特精度的性能，并且特别提高了最不利群体的性能。公平性指标在共享预算下保持可比性，使得不同群体之间的性能差异得以最小化。与Uniform 4-和8比特基线相比，FairQuant在最不利群体的表现上有了显著改进。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>fairness-aware quantization考虑了量化对算法公平性的影响。</li>
<li>group-aware importance分析有助于识别重要参数。</li>
<li>budgeted mixed-precision分配在预算内优化精度。</li>
<li>learnable Bit-Aware Quantization模式可调整权重和比特分配。</li>
<li>FairQuant配置在4-6比特精度下恢复了大部分8比特精度的性能。</li>
<li>FairQuant提高了最不利群体的性能。</li>
<li>公平性指标在共享预算下保持可比性。</li>
<li>Uniform 4-和8比特基线相比，FairQuant改进了最不利群体的表现。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-5">正文（抓取，非 AI）</h3>
<p>[2602.23192v1] FairQuant: Fairness-Aware Mixed-Precision Quantization for Medical Image Classification Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23192v1 (cs) [Submitted on 26 Feb 2026] Title: FairQuant: Fairness-Aware Mixed-Precision Quantization for Medical Image Classification Authors: Thomas Woergaard , Raghavendra Selvan View a PDF of the paper titled FairQuant: Fairness-Aware Mixed-Precision Quantization for Medical Image Classification, by Thomas Woergaard and 1 other authors View PDF HTML (experimental) Abstract: Compressing neural networks by quantizing model parameters offers useful trade-off between performance and efficiency. Methods like quantization-aware training and post-training quantization strive to maintain the downstream performance of compressed models compared to the full precision models. However, these techniques do not explicitly consider the impact on algorithmic fairness. In this work, we study fairness-aware mixed-precision quantization schemes for medical image classification under explicit bit budgets. We introduce FairQuant, a framework that combines group-aware importance analysis, budgeted mixed-precision allocation, and a learnable Bit-Aware Quantization (BAQ) mode that jointly optimizes weights and per-unit bit allocations under bitrate and fairness regularization. We evaluate the method on Fitzpatrick17k and ISIC2019 across ResNet18/50, DeiT-Tiny, and TinyViT. Results show that FairQuant configurations with average precision near 4-6 bits recover much of the Uniform 8-bit accuracy while improving worst-group performance relative to Uniform 4- and 8-bit baselines, with comparable fairness metrics under shared budgets. Comments: Source code available at this https URL Subjects: Computer Vision and Pattern Recognition (cs.CV) ; Machine Learning (cs.LG) Cite as: arXiv:2602.23192 [cs.CV] (or arXiv:2602.23192v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23192 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Raghavendra Selvan [ view email ] [v1] Thu, 26 Feb 2026 16:44:47 UTC (696 KB) Full-text links: Access Paper: View a PDF of the paper titled FairQuant: Fairness-Aware Mixed-Precision Quantization for Medical Image Classification, by Thomas Woergaard and 1 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.LG References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-6">4. Evaluating Stochasticity in Deep Research Agents</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23271v1</li>
<li>来源：arxiv</li>
<li>摘要：Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information to support research across domains such as financial decision-making, medical analysis, and scientific discovery. Despite recent improvements in research quality (e.g., outcome accuracy when ground truth is available), DRA system design often overlooks a critical barrier to real-world deployment: stochasticity. Under identical queries, repeated executions of DRAs can exhibit substantial variability in terms of research outcome, findings, and citations. In this paper, we formalize the study of stochasticity in DRAs by modeling them as information acquisition Markov Decision Processes. We introduce an evaluation framework that quantifies variance in the system and identify three sources of it: information acquisition, information compression, and inference. Through controlled experiments, we investigate how stochasticity from these modules across different decision steps influences the variance of DRA outputs. Our results show that reducing stochasticity can improve research output quality, with inference and early-stage stochasticity contributing the most to DRA output variance. Based on</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，随机性可以影响研究结果和发现，导致重复执行深度检索代理（DRA）时表现出显著的差异性。这种随机性主要源自于信息的获取、压缩和推理过程。其次，研究表明，推理和早期阶段的随机性对DRA输出的差异性贡献最大。因此，通过结构化的输出和基于集合的查询生成方法来减轻随机性，可以显著提高研究输出的质量。例如，实验表明，通过这些方法可以在DeepSearchQA上实现平均随机性22%的减少。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>stochasticity can affect research outcomes and findings.</li>
<li>repeated executions of DRAs can exhibit substantial variability.</li>
<li>stochasticity originates from information acquisition, compression, and inference.</li>
<li>reducing stochasticity can improve research output quality.</li>
<li>inference and early-stage stochasticity contribute most to DRA output variance.</li>
<li>mitigating stochasticity can be achieved through structured output and ensemble-based query generation.</li>
<li>experiments on DeepSearchQA show a 22% reduction in average stochasticity.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-7">正文（抓取，非 AI）</h3>
<p>[2602.23271v1] Evaluating Stochasticity in Deep Research Agents Computer Science &gt; Artificial Intelligence arXiv:2602.23271v1 (cs) [Submitted on 26 Feb 2026] Title: Evaluating Stochasticity in Deep Research Agents Authors: Haotian Zhai , Elias Stengel-Eskin , Pratik Patil , Liu Leqi View a PDF of the paper titled Evaluating Stochasticity in Deep Research Agents, by Haotian Zhai and 3 other authors View PDF HTML (experimental) Abstract: Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information to support research across domains such as financial decision-making, medical analysis, and scientific discovery. Despite recent improvements in research quality (e.g., outcome accuracy when ground truth is available), DRA system design often overlooks a critical barrier to real-world deployment: stochasticity. Under identical queries, repeated executions of DRAs can exhibit substantial variability in terms of research outcome, findings, and citations. In this paper, we formalize the study of stochasticity in DRAs by modeling them as information acquisition Markov Decision Processes. We introduce an evaluation framework that quantifies variance in the system and identify three sources of it: information acquisition, information compression, and inference. Through controlled experiments, we investigate how stochasticity from these modules across different decision steps influences the variance of DRA outputs. Our results show that reducing stochasticity can improve research output quality, with inference and early-stage stochasticity contributing the most to DRA output variance. Based on these findings, we propose strategies for mitigating stochasticity while maintaining output quality via structured output and ensemble-based query generation. Our experiments on DeepSearchQA show that our proposed mitigation methods reduce average stochasticity by 22% while maintaining high research quality. Subjects: Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23271 [cs.AI] (or arXiv:2602.23271v1 [cs.AI] for this version) https://doi.org/10.48550/arXiv.2602.23271 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Haotian Zhai [ view email ] [v1] Thu, 26 Feb 2026 17:46:42 UTC (1,174 KB) Full-text links: Access Paper: View a PDF of the paper titled Evaluating Stochasticity in Deep Research Agents, by Haotian Zhai and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.AI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-8">5. Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23296v1</li>
<li>来源：arxiv</li>
<li>摘要：Federated learning (FL) faces challenges in uncertainty quantification (UQ). Without reliable UQ, FL systems risk deploying overconfident models at under-resourced agents, leading to silent local failures despite seemingly satisfactory global performance. Existing federated UQ approaches often address data heterogeneity or model heterogeneity in isolation, overlooking their joint effect on coverage reliability across agents. Conformal prediction is a widely used distribution-free UQ framework, yet its applications in heterogeneous FL settings remains underexplored. We provide FedWQ-CP, a simple yet effective approach that balances empirical coverage performance with efficiency at both global and agent levels under the dual heterogeneity. FedWQ-CP performs agent-server calibration in a single communication round. On each agent, conformity scores are computed on calibration data and a local quantile threshold is derived. Each agent then transmits only its quantile threshold and calibration sample size to the server. The server simply aggregates these thresholds through a weighted average to produce a global threshold. Experimental results on seven public datasets for both classificat</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">FL系统在部署模型时可能忽视了资源不足代理的风险，这可能导致模型在实际应用中表现不佳。此外，单独处理数据异质性或模型异质性忽略了它们对覆盖可靠性的影响，使得模型的泛化能力受限。Conformal预测作为一种广泛使用的无分布不确定性量化框架，能够提供可靠的预测区间。然而，现有的联邦不确定性量化方法往往忽视了数据异质性和模型异质性的影响，导致预测集或区间过大，影响了模型的效率。为此，FedWQ-CP方法在单次通信中进行代理-服务器校准，每个代理计算校准数据上的一致性分数并导出局部分位数阈值，仅向服务器传输其分位数阈值和校准样本大小。服务器通过加权平均简单地汇总这些阈值以生成全局阈值，从而保持代理和全局覆盖性并产生最小的预测集或区间。实验结果表明，FedWQ-CP方法能够有效提升预测的准确性和效率。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>FL系统在部署模型时可能忽视了资源不足代理的风险。</li>
<li>单独处理数据异质性或模型异质性忽略了它们对覆盖可靠性的影响。</li>
<li>Conformal预测是一种广泛使用的无分布不确定性量化框架。</li>
<li>现有的联邦不确定性量化方法往往忽视了数据异质性和模型异质性的影响。</li>
<li>FedWQ-CP方法在单次通信中进行代理-服务器校准。</li>
<li>每个代理计算校准数据上的一致性分数并导出局部分位数阈值。</li>
<li>代理只需向服务器传输其分位数阈值和校准样本大小。</li>
<li>服务器通过加权平均简单地汇总这些阈值以生成全局阈值。</li>
<li>实验结果表明FedWQ-CP能保持代理和全局覆盖性并产生最小的预测集或区间。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-9">正文（抓取，非 AI）</h3>
<p>[2602.23296v1] Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity Computer Science &gt; Machine Learning arXiv:2602.23296v1 (cs) [Submitted on 26 Feb 2026] Title: Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity Authors: Quang-Huy Nguyen , Jiaqi Wang , Wei-Shinn Ku View a PDF of the paper titled Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity, by Quang-Huy Nguyen and Jiaqi Wang and Wei-Shinn Ku View PDF HTML (experimental) Abstract: Federated learning (FL) faces challenges in uncertainty quantification (UQ). Without reliable UQ, FL systems risk deploying overconfident models at under-resourced agents, leading to silent local failures despite seemingly satisfactory global performance. Existing federated UQ approaches often address data heterogeneity or model heterogeneity in isolation, overlooking their joint effect on coverage reliability across agents. Conformal prediction is a widely used distribution-free UQ framework, yet its applications in heterogeneous FL settings remains underexplored. We provide FedWQ-CP, a simple yet effective approach that balances empirical coverage performance with efficiency at both global and agent levels under the dual heterogeneity. FedWQ-CP performs agent-server calibration in a single communication round. On each agent, conformity scores are computed on calibration data and a local quantile threshold is derived. Each agent then transmits only its quantile threshold and calibration sample size to the server. The server simply aggregates these thresholds through a weighted average to produce a global threshold. Experimental results on seven public datasets for both classification and regression demonstrate that FedWQ-CP empirically maintains agent-wise and global coverage while producing the smallest prediction sets or intervals. Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23296 [cs.LG] (or arXiv:2602.23296v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23296 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Quang Huy Nguyen [ view email ] [v1] Thu, 26 Feb 2026 18:07:45 UTC (95 KB) Full-text links: Access Paper: View a PDF of the paper titled Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity, by Quang-Huy Nguyen and Jiaqi Wang and Wei-Shinn Ku View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-10">6. AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23258v1</li>
<li>来源：arxiv</li>
<li>摘要：While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification effor</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">AgentDropoutV2 是一种无需重新训练即可优化多智能体系统信息流的技术。它通过拦截并逐步纠正错误来动态优化信息流，具体而言，AgentDropoutV2 使用失败驱动的指示池来识别潜在错误，并通过上下文感知的指示器来解决广泛的错误模式。不可修复的输出会被剪枝以防止错误传播，从而确保信息流的准确性和可靠性。此外，AgentDropoutV2 在数学基准测试中平均提高了6.3个百分点的准确性，展示了其强大的泛化能力和适应性。因此，这一技术不仅能够显著提升多智能体系统的性能，还为研究者提供了宝贵的代码和数据集支持。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>AgentDropoutV2 不需要重新训练即可优化多智能体系统的信息流。</li>
<li>AgentDropoutV2 通过拦截并逐步纠正错误来动态优化信息流。</li>
<li>AgentDropoutV2 使用失败驱动的指示池来识别潜在错误。</li>
<li>不可修复的输出会被剪枝以防止错误传播。</li>
<li>AgentDropoutV2 通过上下文感知的指示器来解决广泛的错误模式。</li>
<li>AgentDropoutV2 在数学基准测试中平均提高了6.3个百分点的准确性。</li>
<li>AgentDropoutV2 具有强大的泛化能力和适应性。</li>
<li>AgentDropoutV2 的代码和数据集已发布。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-11">正文（抓取，非 AI）</h3>
<p>[2602.23258v1] AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Computer Science &gt; Artificial Intelligence arXiv:2602.23258v1 (cs) [Submitted on 26 Feb 2026] Title: AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning Authors: Yutong Wang , Siyuan Xiong , Xuebo Liu , Wenkang Zhou , Liang Ding , Miao Zhang , Min Zhang View a PDF of the paper titled AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning, by Yutong Wang and 6 other authors View PDF HTML (experimental) Abstract: While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at this https URL . Subjects: Artificial Intelligence (cs.AI) ; Computation and Language (cs.CL) Cite as: arXiv:2602.23258 [cs.AI] (or arXiv:2602.23258v1 [cs.AI] for this version) https://doi.org/10.48550/arXiv.2602.23258 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Yutong Wang [ view email ] [v1] Thu, 26 Feb 2026 17:31:43 UTC (626 KB) Full-text links: Access Paper: View a PDF of the paper titled AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning, by Yutong Wang and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.AI &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.CL References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-12">7. Model Agreement via Anchoring</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23360v1</li>
<li>来源：arxiv</li>
<li>摘要：Numerous lines of aim to control $\textit{model disagreement}$ -- the extent to which two machine learning models disagree in their predictions. We adopt a simple and standard notion of model disagreement in real-valued prediction problems, namely the expected squared difference in predictions between two models trained on independent samples, without any coordination of the training processes. We would like to be able to drive disagreement to zero with some natural parameter(s) of the training procedure using analyses that can be applied to existing training methodologies.   We develop a simple general technique for proving bounds on independent model disagreement based on $\textit{anchoring}$ to the average of two models within the analysis. We then apply this technique to prove disagreement bounds for four commonly used machine learning algorithms: (1) stacked aggregation over an arbitrary model class (where disagreement is driven to 0 with the number of models $k$ being stacked) (2) gradient boosting (where disagreement is driven to 0 with the number of iterations $k$) (3) neural network training with architecture search (where disagreement is driven to 0 with the size $n$ of t</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">model disagreement 的衡量方式是两个模型在独立样本上的预测差异的期望平方，即 expected squared difference。独立样本的训练过程不会进行协调，因此模型之间的预测差异可以通过调整训练过程中的某些参数来驱动为零。首先，在一维回归和平方误差损失的情况下，我们计算初始界限，通过 anchoring 技术将分析锚定在两个模型的平均值上来证明独立模型预测差异的界限。结果可以推广到多维回归和任何强凸损失。此外，模型预测差异可以通过增加模型数量、迭代次数、优化的架构大小或树的深度来驱动为零，这些方法都能有效地减少模型之间的预测差异。因此，通过调整训练过程中的参数和增加模型的复杂度，可以显著降低模型之间的预测差异。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>model disagreement 的衡量方式是两个模型在独立样本上的预测差异的期望平方。</li>
<li>expected squared difference 用于衡量模型之间的预测差异。</li>
<li>独立样本的训练过程不会进行协调。</li>
<li>模型的预测差异可以通过调整训练过程中的某些参数来驱动为零。</li>
<li>模型预测差异可以通过调整训练过程中的参数来驱动为零。</li>
<li>anchoring 技术通过将分析锚定在两个模型的平均值上来证明独立模型预测差异的界限。</li>
<li>我们首先在一维回归和平方误差损失的情况下计算初始界限。</li>
<li>结果可以推广到多维回归和任何强凸损失。</li>
<li>模型预测差异可以通过增加模型数量、迭代次数、优化的架构大小或树的深度来驱动为零。</li>
<li>模型预测差异可以通过增加模型数量、迭代次数、优化的架构大小或树的深度来驱动为零。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-13">正文（抓取，非 AI）</h3>
<p>[2602.23360v1] Model Agreement via Anchoring Computer Science &gt; Machine Learning arXiv:2602.23360v1 (cs) [Submitted on 26 Feb 2026] Title: Model Agreement via Anchoring Authors: Eric Eaton , Surbhi Goel , Marcel Hussing , Michael Kearns , Aaron Roth , Sikata Bela Sengupta , Jessica Sorrell View a PDF of the paper titled Model Agreement via Anchoring, by Eric Eaton and 6 other authors View PDF HTML (experimental) Abstract: Numerous lines of aim to control $\textit{model disagreement}$ -- the extent to which two machine learning models disagree in their predictions. We adopt a simple and standard notion of model disagreement in real-valued prediction problems, namely the expected squared difference in predictions between two models trained on independent samples, without any coordination of the training processes. We would like to be able to drive disagreement to zero with some natural parameter(s) of the training procedure using analyses that can be applied to existing training methodologies. We develop a simple general technique for proving bounds on independent model disagreement based on $\textit{anchoring}$ to the average of two models within the analysis. We then apply this technique to prove disagreement bounds for four commonly used machine learning algorithms: (1) stacked aggregation over an arbitrary model class (where disagreement is driven to 0 with the number of models $k$ being stacked) (2) gradient boosting (where disagreement is driven to 0 with the number of iterations $k$) (3) neural network training with architecture search (where disagreement is driven to 0 with the size $n$ of the architecture being optimized over) and (4) regression tree training over all regression trees of fixed depth (where disagreement is driven to 0 with the depth $d$ of the tree architecture). For clarity, we work out our initial bounds in the setting of one-dimensional regression with squared error loss -- but then show that all of our results generalize to multi-dimensional regression with any strongly convex loss. Subjects: Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23360 [cs.LG] (or arXiv:2602.23360v1 [cs.LG] for this version) https://doi.org/10.48550/arXiv.2602.23360 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Sikata Sengupta [ view email ] [v1] Thu, 26 Feb 2026 18:59:32 UTC (44 KB) Full-text links: Access Paper: View a PDF of the paper titled Model Agreement via Anchoring, by Eric Eaton and 6 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.LG &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) IArxiv recommender toggle IArxiv Recommender ( What is IArxiv? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-14">8. Automated Vulnerability Detection in Source Code Using Deep Representation Learning</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23121v1</li>
<li>来源：arxiv</li>
<li>摘要：Each year, software vulnerabilities are discovered, which pose significant risks of exploitation and system compromise. We present a convolutional neural network model that can successfully identify bugs in C code. We trained our model using two complementary datasets: a machine-labeled dataset created by Draper Labs using three static analyzers and the NIST SATE Juliet human-labeled dataset designed for testing static analyzers. In contrast with the work of Russell et al. on these datasets, we focus on C programs, enabling us to specialize and optimize our detection techniques for this language. After removing duplicates from the dataset, we tokenize the input into 91 token categories. The category values are converted to a binary vector to save memory. Our first convolution layer is chosen so that the entire encoding of the token is presented to the filter. We use two convolution and pooling layers followed by two fully connected layers to classify programs into either a common weakness enumeration category or as ``clean.'' We obtain higher recall than prior work by Russell et al. on this dataset when requiring high precision. We also demonstrate on a custom Linux kernel dataset </li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">机器标记的数据集由Draper Labs使用三个静态分析器创建，这些数据集主要用于C程序的标记。我们的模型专注于C语言，这使我们能够针对此语言专门化和优化检测技术，从而在需要高精度时获得更高的召回率。我们使用了两个卷积和池化层，后跟两个全连接层来分类程序。为了实现这一目标，我们使用了91个标记类别进行输入标记化，并设计了第一个卷积层将整个标记编码呈现给过滤器。我们的方法在自定义Linux内核数据集上的结果表明，我们能够在复杂代码中找到真实漏洞，且误报率低。此外，我们使用了两个互补的数据集进行训练，这进一步提高了模型的性能和准确性。因此，我们的方法不仅能够识别漏洞，还能在高精度要求下实现更高的召回率。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>机器标记的数据集由Draper Labs使用三个静态分析器创建。</li>
<li>我们的模型专注于C程序，这使我们能够针对此语言专门化和优化检测技术。</li>
<li>我们使用了两个卷积和池化层，后跟两个全连接层来分类程序。</li>
<li>我们的方法在需要高精度时获得了更高的召回率。</li>
<li>我们展示了在自定义Linux内核数据集上的结果，表明我们能够在复杂代码中找到真实漏洞，且误报率低。</li>
<li>我们使用了91个标记类别进行输入标记化。</li>
<li>第一个卷积层设计为将整个标记编码呈现给过滤器。</li>
<li>我们的模型在C代码中成功识别了漏洞。</li>
<li>我们使用了两个互补的数据集进行训练。</li>
<li>我们的方法在需要高精度时获得了更高的召回率。</li>
<li>我们专注于C语言，这使我们能够针对此语言进行专门化和优化。</li>
<li>我们使用了两个互补的数据集进行训练。</li>
<li>我们使用了两个互补的数据集进行训练。</li>
<li>我们使用了两个互补的数据集进行训练。</li>
<li>我们使用了两个互补的数据集进行训练。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-15">正文（抓取，非 AI）</h3>
<p>[2602.23121v1] Automated Vulnerability Detection in Source Code Using Deep Representation Learning Computer Science &gt; Cryptography and Security arXiv:2602.23121v1 (cs) [Submitted on 26 Feb 2026] Title: Automated Vulnerability Detection in Source Code Using Deep Representation Learning Authors: C. Seas , G. Fitzpatrick , J. A. Hamilton , M. C. Carlisle View a PDF of the paper titled Automated Vulnerability Detection in Source Code Using Deep Representation Learning, by C. Seas and 2 other authors View PDF HTML (experimental) Abstract: Each year, software vulnerabilities are discovered, which pose significant risks of exploitation and system compromise. We present a convolutional neural network model that can successfully identify bugs in C code. We trained our model using two complementary datasets: a machine-labeled dataset created by Draper Labs using three static analyzers and the NIST SATE Juliet human-labeled dataset designed for testing static analyzers. In contrast with the work of Russell et al. on these datasets, we focus on C programs, enabling us to specialize and optimize our detection techniques for this language. After removing duplicates from the dataset, we tokenize the input into 91 token categories. The category values are converted to a binary vector to save memory. Our first convolution layer is chosen so that the entire encoding of the token is presented to the filter. We use two convolution and pooling layers followed by two fully connected layers to classify programs into either a common weakness enumeration category or as ``clean.'' We obtain higher recall than prior work by Russell et al. on this dataset when requiring high precision. We also demonstrate on a custom Linux kernel dataset that we are able to find real vulnerabilities in complex code with a low false-positive rate. Subjects: Cryptography and Security (cs.CR) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23121 [cs.CR] (or arXiv:2602.23121v1 [cs.CR] for this version) https://doi.org/10.48550/arXiv.2602.23121 Focus to learn more arXiv-issued DOI via DataCite Journal reference: 2024 IEEE 14th Annual Computing and Communication Workshop and Conference (CCWC), Las Vegas, NV, USA, 2024, pp. 0484-0490 Related DOI : https://doi.org/10.1109/CCWC60891.2024.10427574 Focus to learn more DOI(s) linking to related resources Submission history From: Martin Carlisle [ view email ] [v1] Thu, 26 Feb 2026 15:35:17 UTC (280 KB) Full-text links: Access Paper: View a PDF of the paper titled Automated Vulnerability Detection in Source Code Using Deep Representation Learning, by C. Seas and 2 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CR &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-16">9. CL4SE: A Context Learning Benchmark For Software Engineering Tasks</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23047v1</li>
<li>来源：arxiv</li>
<li>摘要：Context engineering has emerged as a pivotal paradigm for unlocking the potential of Large Language Models (LLMs) in Software Engineering (SE) tasks, enabling performance gains at test time without model fine-tuning. Despite its success, existing research lacks a systematic taxonomy of SE-specific context types and a dedicated benchmark to quantify the heterogeneous effects of different contexts across core SE workflows. To address this gap, we propose CL4SE (Context Learning for Software Engineering), a comprehensive benchmark featuring a fine-grained taxonomy of four SE-oriented context types (interpretable examples, project-specific context, procedural decision-making context, and positive &amp; negative context), each mapped to a representative task (code generation, code summarization, code review, and patch correctness assessment). We construct high-quality datasets comprising over 13,000 samples from more than 30 open-source projects and evaluate five mainstream LLMs across nine metrics. Extensive experiments demonstrate that context learning yields an average performance improvement of 24.7% across all tasks. Specifically, procedural context boosts code review performance by up</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">首先，上下文学习能够提升软件工程任务的表现，而无需对模型进行精细调整。然而，现有的研究缺乏对软件工程特定上下文类型的系统性分类。其次，程序上下文可以显著提升代码审查的表现，甚至能将代码审查性能提高33%。此外，混合的正负上下文能够改善补丁评估，提升30%的性能。项目特定的上下文能够增强代码总结的BLEU分数，提高14.78%。可解释的示例能够提升代码生成的pass@1指标，提高5.72%。为此，cl4se提供了一个标准化的评估框架，用于软件工程中的上下文学习。该基准包括四种类型的上下文：可解释的示例、项目特定的上下文、程序决策上下文以及正负上下文。评估涉及五个主流的大规模语言模型，涵盖九个指标。因此，cl4se不仅有助于设计特定任务的上下文，还促进了软件工程中的可重复研究。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>context learning can improve performance in software engineering tasks without fine-tuning models.</li>
<li>existing research lacks a systematic taxonomy of software engineering-specific context types.</li>
<li>procedural context can significantly boost code review performance.</li>
<li>mixed positive-negative context can improve patch assessment performance.</li>
<li>project-specific context can enhance code summarization.</li>
<li>interpretable examples can improve code generation.</li>
<li>cl4se provides a standardized evaluation framework for software engineering context learning.</li>
<li>the benchmark includes four types of context: interpretable examples, project-specific context, procedural decision-making context, and positive &amp; negative context.</li>
<li>the evaluation involves five mainstream large language models across nine metrics.</li>
<li>procedural context can increase code review performance by up to 33%.</li>
<li>mixed positive-negative context can improve patch assessment by 30%.</li>
<li>project-specific context can increase code summarization bleu by 14.78%.</li>
<li>interpretable examples can enhance code generation pass@1 by 5.72%.</li>
<li>cl4se helps in designing task-specific context and facilitates reproducible research in software engineering.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-17">正文（抓取，非 AI）</h3>
<p>[2602.23047v1] CL4SE: A Context Learning Benchmark For Software Engineering Tasks Computer Science &gt; Software Engineering arXiv:2602.23047v1 (cs) [Submitted on 26 Feb 2026] Title: CL4SE: A Context Learning Benchmark For Software Engineering Tasks Authors: Haichuan Hu , Ye Shang , Guoqing Xie , Congqing He , Quanjun Zhang View a PDF of the paper titled CL4SE: A Context Learning Benchmark For Software Engineering Tasks, by Haichuan Hu and 4 other authors View PDF HTML (experimental) Abstract: Context engineering has emerged as a pivotal paradigm for unlocking the potential of Large Language Models (LLMs) in Software Engineering (SE) tasks, enabling performance gains at test time without model fine-tuning. Despite its success, existing research lacks a systematic taxonomy of SE-specific context types and a dedicated benchmark to quantify the heterogeneous effects of different contexts across core SE workflows. To address this gap, we propose CL4SE (Context Learning for Software Engineering), a comprehensive benchmark featuring a fine-grained taxonomy of four SE-oriented context types (interpretable examples, project-specific context, procedural decision-making context, and positive &amp; negative context), each mapped to a representative task (code generation, code summarization, code review, and patch correctness assessment). We construct high-quality datasets comprising over 13,000 samples from more than 30 open-source projects and evaluate five mainstream LLMs across nine metrics. Extensive experiments demonstrate that context learning yields an average performance improvement of 24.7% across all tasks. Specifically, procedural context boosts code review performance by up to 33% (Qwen3-Max), mixed positive-negative context improves patch assessment by 30% (DeepSeek-V3), project-specific context increases code summarization BLEU by 14.78% (GPT-Oss-120B), and interpretable examples enhance code generation PASS@1 by 5.72% (DeepSeek-V3). CL4SE establishes the first standardized evaluation framework for SE context learning, provides actionable empirical insights into task-specific context design, and releases a large-scale dataset to facilitate reproducible research in this domain. Comments: 23 pages, 4 figures Subjects: Software Engineering (cs.SE) Cite as: arXiv:2602.23047 [cs.SE] (or arXiv:2602.23047v1 [cs.SE] for this version) https://doi.org/10.48550/arXiv.2602.23047 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Shang Ye [ view email ] [v1] Thu, 26 Feb 2026 14:28:57 UTC (235 KB) Full-text links: Access Paper: View a PDF of the paper titled CL4SE: A Context Learning Benchmark For Software Engineering Tasks, by Haichuan Hu and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.SE &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-18">10. Efficient evaluation of fundamental sensitivity limits and full counting statistics for continuously monitored Gaussian quantum systems</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23304v1</li>
<li>来源：arxiv</li>
<li>摘要：Generalized master equations (GMEs) -- time-local but generally neither trace-preserving nor Hermiticity-preserving -- are convenient tools to compute properties of the environment of an open or continuously monitored quantum system. A two-sided master equation yields the fidelity and quantum Fisher information (QFI) of environment states, thereby setting fundamental limits for hypothesis testing and parameter estimation under continuous monitoring. For unmonitored noise or inefficient detection, the QFI of the detectable part of the environment may be obtained from a recently derived GME acting on multiple system replicas. Tilted master equations provide the full counting statistics of quantum jumps and diffusive measurements, enabling, e.g., studies of quantum thermodynamics beyond average values. Here we focus on bosonic linear systems, governed by a quadratic Hamiltonian and linear jump operators, whose dynamics preserves Gaussianity. For Gaussian initial states, we recast a generic GME as a compact set of ordinary differential equations for the covariance matrix (a Riccati-type equation), first moments, and normalization. These equations can be integrated efficiently without H</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">GMEs不是迹保持的，也不是保持厄米性的，这使得它们在描述量子系统与环境相互作用时具有独特性。两面的GME能够给出环境状态的保真度和量子费舍信息（QFI），而QFI在连续监控下的假设检验和参数估计中起着关键作用。在未监控噪声或检测不充分的情况下，可以从多个系统复制品中获得可检测环境部分的QFI。倾斜的GME则提供量子跃迁和扩散测量的完整计数统计。该研究专注于玻色线性系统，由二次哈密顿量和线性跃迁算子描述。对于高斯初态，可以将通用GME重新表述为关于协方差矩阵、一阶矩和归一化的常微分方程组，这些方程可以高效地积分而无需希尔伯特空间截断。此外，研究还提供了保真度/QFI和完整计数统计的特殊形式。连续监控的光学参量振荡器被用来确定频率估计的灵敏度极限，而该研究还用于基准测试Hasegawa的热力学不确定性关系。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>GMEs不是迹保持的。</li>
<li>GMEs不是保持厄米性的。</li>
<li>两面的GME可以给出环境状态的保真度和量子费舍信息。</li>
<li>QFI限制了连续监控下的假设检验和参数估计。</li>
<li>未监控噪声或检测不充分时，可以从多个系统复制品中获得可检测环境部分的QFI。</li>
<li>倾斜的GME提供量子跃迁和扩散测量的完整计数统计。</li>
<li>该研究专注于玻色线性系统，由二次哈密顿量和线性跃迁算子描述。</li>
<li>对于高斯初态，可以将通用GME重新表述为关于协方差矩阵、一阶矩和归一化的常微分方程组。</li>
<li>这些方程可以高效地积分而无需希尔伯特空间截断。</li>
<li>可以提供保真度/QFI和完整计数统计的特殊形式。</li>
<li>连续监控的光学参量振荡器被用来确定频率估计的灵敏度极限。</li>
<li>该研究还用于基准测试Hasegawa的热力学不确定性关系。</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-19">正文（抓取，非 AI）</h3>
<p>[2602.23304v1] Efficient evaluation of fundamental sensitivity limits and full counting statistics for continuously monitored Gaussian quantum systems Quantum Physics arXiv:2602.23304v1 (quant-ph) [Submitted on 26 Feb 2026] Title: Efficient evaluation of fundamental sensitivity limits and full counting statistics for continuously monitored Gaussian quantum systems Authors: Francesco Albarelli , Marco G. Genoni View a PDF of the paper titled Efficient evaluation of fundamental sensitivity limits and full counting statistics for continuously monitored Gaussian quantum systems, by Francesco Albarelli and Marco G. Genoni View PDF HTML (experimental) Abstract: Generalized master equations (GMEs) -- time-local but generally neither trace-preserving nor Hermiticity-preserving -- are convenient tools to compute properties of the environment of an open or continuously monitored quantum system. A two-sided master equation yields the fidelity and quantum Fisher information (QFI) of environment states, thereby setting fundamental limits for hypothesis testing and parameter estimation under continuous monitoring. For unmonitored noise or inefficient detection, the QFI of the detectable part of the environment may be obtained from a recently derived GME acting on multiple system replicas. Tilted master equations provide the full counting statistics of quantum jumps and diffusive measurements, enabling, e.g., studies of quantum thermodynamics beyond average values. Here we focus on bosonic linear systems, governed by a quadratic Hamiltonian and linear jump operators, whose dynamics preserves Gaussianity. For Gaussian initial states, we recast a generic GME as a compact set of ordinary differential equations for the covariance matrix (a Riccati-type equation), first moments, and normalization. These equations can be integrated efficiently without Hilbert-space truncation, and admit analytical results in simple settings. We also provide specialized forms for fidelity/QFI and full counting statistics. We illustrate the formalism with a continuously monitored optical parametric oscillator, using it to determine sensitivity limits for frequency estimation and to benchmark Hasegawa's thermodynamic uncertainty relations. Comments: 9+4 pages, 3 figures Subjects: Quantum Physics (quant-ph) Cite as: arXiv:2602.23304 [quant-ph] (or arXiv:2602.23304v1 [quant-ph] for this version) https://doi.org/10.48550/arXiv.2602.23304 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Francesco Albarelli [ view email ] [v1] Thu, 26 Feb 2026 18:09:46 UTC (190 KB) Full-text links: Access Paper: View a PDF of the paper titled Efficient evaluation of fundamental sensitivity limits and full counting statistics for continuously monitored Gaussian quantum systems, by Francesco Albarelli and Marco G. Genoni View PDF HTML (experimental) TeX Source view license Current browse context: quant-ph &lt; prev | next &gt; new | recent | 2026-02 References &amp; Citations INSPIRE HEP NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-20">11. Learning Continuous Wasserstein Barycenter Space for Generalized All-in-One Image Restoration</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23169v1</li>
<li>来源：arxiv</li>
<li>摘要：Despite substantial advances in all-in-one image restoration for addressing diverse degradations within a unified model, existing methods remain vulnerable to out-of-distribution degradations, thereby limiting their generalization in real-world scenarios. To tackle the challenge, this work is motivated by the intuition that multisource degraded feature distributions are induced by different degradation-specific shifts from an underlying degradation-agnostic distribution, and recovering such a shared distribution is thus crucial for achieving generalization across degradations. With this insight, we propose BaryIR, a representation learning framework that aligns multisource degraded features in the Wasserstein barycenter (WB) space, which models a degradation-agnostic distribution by minimizing the average of Wasserstein distances to multisource degraded distributions. We further introduce residual subspaces, whose embeddings are mutually contrasted while remaining orthogonal to the WB embeddings. Consequently, BaryIR explicitly decouples two orthogonal spaces: a WB space that encodes the degradation-agnostic invariant contents shared across degradations, and residual subspaces that</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">out-of-distribution退化处理更加困难，限制了模型在现实世界中的泛化能力。多源退化特征分布从一个退化无关的基础分布中发生了偏移。为此，Wasserstein barycenter空间通过最小化平均Wasserstein距离，建模了一个退化无关的基础分布。残差子空间与Wasserstein barycenter嵌入正交，并且相互对比，从而保留了退化特定的知识。这种分离有助于减轻对内部退化过度拟合的问题。BaryIR在与最先进的单一模型方法竞争中表现出色，并且能够很好地泛化到未见过的退化，显示出显著的鲁棒性。即使训练仅限于有限的退化类型，BaryIR仍然能够进行稳健的现实世界数据评估。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>out-of-distribution degradations are harder to handle and limit real-world generalization.</li>
<li>multisource degraded feature distributions are shifted from an underlying degradation-agnostic distribution.</li>
<li>Wasserstein barycenter space models a degradation-agnostic distribution by minimizing average Wasserstein distances.</li>
<li>residual subspaces are orthogonal to Wasserstein barycenter embeddings and contrasted mutually.</li>
<li>WB space encodes degradation-agnostic invariant contents across degradations.</li>
<li>residual subspaces preserve degradation-specific knowledge adaptively.</li>
<li>disentanglement helps mitigate overfitting to in-distribution degradations.</li>
<li>BaryIR performs competitively against state-of-the-art all-in-one methods.</li>
<li>BaryIR generalizes well to unseen degradations and shows remarkable robustness.</li>
<li>training on limited degradation types still enables robust real-world data evaluation.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-21">正文（抓取，非 AI）</h3>
<p>[2602.23169v1] Learning Continuous Wasserstein Barycenter Space for Generalized All-in-One Image Restoration Computer Science &gt; Computer Vision and Pattern Recognition arXiv:2602.23169v1 (cs) [Submitted on 26 Feb 2026] Title: Learning Continuous Wasserstein Barycenter Space for Generalized All-in-One Image Restoration Authors: Xiaole Tang , Xiaoyi He , Jiayi Xu , Xiang Gu , Jian Sun View a PDF of the paper titled Learning Continuous Wasserstein Barycenter Space for Generalized All-in-One Image Restoration, by Xiaole Tang and 4 other authors View PDF HTML (experimental) Abstract: Despite substantial advances in all-in-one image restoration for addressing diverse degradations within a unified model, existing methods remain vulnerable to out-of-distribution degradations, thereby limiting their generalization in real-world scenarios. To tackle the challenge, this work is motivated by the intuition that multisource degraded feature distributions are induced by different degradation-specific shifts from an underlying degradation-agnostic distribution, and recovering such a shared distribution is thus crucial for achieving generalization across degradations. With this insight, we propose BaryIR, a representation learning framework that aligns multisource degraded features in the Wasserstein barycenter (WB) space, which models a degradation-agnostic distribution by minimizing the average of Wasserstein distances to multisource degraded distributions. We further introduce residual subspaces, whose embeddings are mutually contrasted while remaining orthogonal to the WB embeddings. Consequently, BaryIR explicitly decouples two orthogonal spaces: a WB space that encodes the degradation-agnostic invariant contents shared across degradations, and residual subspaces that adaptively preserve the degradation-specific knowledge. This disentanglement mitigates overfitting to in-distribution degradations and enables adaptive restoration grounded on the degradation-agnostic shared invariance. Extensive experiments demonstrate that BaryIR performs competitively against state-of-the-art all-in-one methods. Notably, BaryIR generalizes well to unseen degradations (\textit{e.g.,} types and levels) and shows remarkable robustness in learning generalized features, even when trained on limited degradation types and evaluated on real-world data with mixed degradations. Subjects: Computer Vision and Pattern Recognition (cs.CV) Cite as: arXiv:2602.23169 [cs.CV] (or arXiv:2602.23169v1 [cs.CV] for this version) https://doi.org/10.48550/arXiv.2602.23169 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Xiaole Tang [ view email ] [v1] Thu, 26 Feb 2026 16:31:27 UTC (37,835 KB) Full-text links: Access Paper: View a PDF of the paper titled Learning Continuous Wasserstein Barycenter Space for Generalized All-in-One Image Restoration, by Xiaole Tang and 4 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.CV &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p>
</div></details><h2 id="toc-22">12. LLMServingSim 2.0: A Unified Simulator for Heterogeneous and Disaggregated LLM Serving Infrastructure</h2>
<ul>
<li>链接：https://arxiv.org/abs/2602.23036v1</li>
<li>来源：arxiv</li>
<li>摘要：Large language model (LLM) serving infrastructures are undergoing a shift toward heterogeneity and disaggregation. Modern deployments increasingly integrate diverse accelerators and near-memory processing technologies, introducing significant hardware heterogeneity, while system software increasingly separates computation, memory, and model components across distributed resources to improve scalability and efficiency. As a result, LLM serving performance is no longer determined by hardware or software choices in isolation, but by their runtime interaction through scheduling, data movement, and interconnect behavior. However, understanding these interactions remains challenging, as existing simulators lack the ability to jointly model heterogeneous hardware and disaggregated serving techniques within a unified, runtime-driven framework.   This paper presents LLMServingSim 2.0, a unified system-level simulator designed to make runtime-driven hardware-software interactions in heterogeneous and disaggregated LLM serving infrastructures explicit and analyzable. LLMServingSim 2.0 embeds serving decisions and hardware behavior into a single runtime loop, enabling interaction-aware modelin</li>
<li><strong>易漏细节梳理：</strong></li>
</ul>
<p class="insight-summary">LLM服务性能不仅依赖于硬件和软件的选择，更取决于运行时的交互。然而，理解硬件与软件的交互仍然具有挑战性，主要是因为缺乏统一的模拟器。为了解决这一问题，LLMServingSim 2.0应运而生，它不仅能够模拟异构硬件，还能模拟拆分的服务技术，从而捕捉动态服务行为和系统级的影响。此外，LLMServingSim 2.0支持可扩展的新兴加速器和内存系统的集成，确保即使在复杂配置下，模拟时间也能保持在约10分钟。更为重要的是，该工具能够重现关键的性能、内存和功耗指标，其误差平均仅为0.97%，这使得它成为评估LLM服务性能的重要工具。</p>
<ul>
<li><strong>关键点（易漏细节）：</strong></li>
</ul>
<ul class="insight-detail">
<li>LLM serving performance depends on runtime interactions, not just hardware or software choices.</li>
<li>Understanding hardware-software interactions remains challenging due to the lack of unified simulators.</li>
<li>LLMServingSim 2.0 models both heterogeneous hardware and disaggregated serving techniques.</li>
<li>LLMServingSim 2.0 captures dynamic serving behavior and system-level effects.</li>
<li>LLMServingSim 2.0 supports extensible integration of emerging accelerators and memory systems.</li>
<li>LLMServingSim 2.0 maintains simulation times of around 10 minutes even for complex configurations.</li>
<li>LLMServingSim 2.0 reproduces key performance, memory, and power metrics with an average error of 0.97%.</li>
</ul>
<details class="article-body-details"><summary>正文（点击展开）</summary><div class="article-body-fold"><h3 id="toc-23">正文（抓取，非 AI）</h3>
<p>[2602.23036v1] LLMServingSim 2.0: A Unified Simulator for Heterogeneous and Disaggregated LLM Serving Infrastructure Computer Science &gt; Distributed, Parallel, and Cluster Computing arXiv:2602.23036v1 (cs) [Submitted on 26 Feb 2026] Title: LLMServingSim 2.0: A Unified Simulator for Heterogeneous and Disaggregated LLM Serving Infrastructure Authors: Jaehong Cho , Hyunmin Choi , Guseul Heo , Jongse Park View a PDF of the paper titled LLMServingSim 2.0: A Unified Simulator for Heterogeneous and Disaggregated LLM Serving Infrastructure, by Jaehong Cho and 3 other authors View PDF HTML (experimental) Abstract: Large language model (LLM) serving infrastructures are undergoing a shift toward heterogeneity and disaggregation. Modern deployments increasingly integrate diverse accelerators and near-memory processing technologies, introducing significant hardware heterogeneity, while system software increasingly separates computation, memory, and model components across distributed resources to improve scalability and efficiency. As a result, LLM serving performance is no longer determined by hardware or software choices in isolation, but by their runtime interaction through scheduling, data movement, and interconnect behavior. However, understanding these interactions remains challenging, as existing simulators lack the ability to jointly model heterogeneous hardware and disaggregated serving techniques within a unified, runtime-driven framework. This paper presents LLMServingSim 2.0, a unified system-level simulator designed to make runtime-driven hardware-software interactions in heterogeneous and disaggregated LLM serving infrastructures explicit and analyzable. LLMServingSim 2.0 embeds serving decisions and hardware behavior into a single runtime loop, enabling interaction-aware modeling of batching, routing, offloading, memory, and power. The simulator supports extensible integration of emerging accelerators and memory systems through profile-based modeling, while capturing dynamic serving behavior and system-level effects. We validate LLMServingSim 2.0 against real deployments, showing that it reproduces key performance, memory, and power metrics with an average error of 0.97%, while maintaining simulation times of around 10 minutes even for complex configurations. These results demonstrate that LLMServingSim 2.0 provides a practical bridge between hardware innovation and serving-system design, enabling systematic exploration and co-design for next-generation LLM serving infrastructures. Comments: 12 pages, 10 figures Subjects: Distributed, Parallel, and Cluster Computing (cs.DC) ; Artificial Intelligence (cs.AI) Cite as: arXiv:2602.23036 [cs.DC] (or arXiv:2602.23036v1 [cs.DC] for this version) https://doi.org/10.48550/arXiv.2602.23036 Focus to learn more arXiv-issued DOI via DataCite (pending registration) Submission history From: Jaehong Cho [ view email ] [v1] Thu, 26 Feb 2026 14:22:17 UTC (850 KB) Full-text links: Access Paper: View a PDF of the paper titled LLMServingSim 2.0: A Unified Simulator for Heterogeneous and Disaggregated LLM Serving Infrastructure, by Jaehong Cho and 3 other authors View PDF HTML (experimental) TeX Source view license Current browse context: cs.DC &lt; prev | next &gt; new | recent | 2026-02 Change to browse by: cs cs.AI References &amp; Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation × loading... Data provided by: Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer ( What is the Explorer? ) Connected Papers Toggle Connected Papers ( What is Connected Papers? ) Litmaps Toggle Litmaps ( What is Litmaps? ) scite.ai Toggle scite Smart Citations ( What are Smart Citations? ) Code, Data, Media Code, Data and Media Associated with this Article alphaXiv Toggle alphaXiv ( What is alphaXiv? ) Links to Code Toggle CatalyzeX Code Finder for Papers ( What is CatalyzeX? ) DagsHub Toggle DagsHub ( What is DagsHub? ) GotitPub Toggle Gotit.pub ( What is GotitPub? ) Huggingface Toggle Hugging Face ( What is Huggingface? ) Links to Code Toggle Papers with Code ( What is Papers with Code? ) ScienceCast Toggle ScienceCast ( What is ScienceCast? ) Demos Demos Replicate Toggle Replicate ( What is Replicate? ) Spaces Toggle Hugging Face Spaces ( What is Spaces? ) Spaces Toggle TXYZ.AI ( What is TXYZ.AI? ) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower ( What are Influence Flowers? ) Core recommender toggle CORE Recommender ( What is CORE? ) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs . Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )</p></div></details>
</div>
<script>
var READING_HIGHLIGHT_CLASS='reading-highlight';
function getBlocksInOrder(container){
 var blocks=[]; var blockTags=['P','DIV','H2','H3','H4','LI','PRE'];
 function walk(el){
  if(!el||!container.contains(el))return;
  if(blockTags.indexOf(el.tagName)!==-1){
   var hasBlockChild=false;
   for(var k=0;k<el.children.length;k++){ var c=el.children[k]; if(blockTags.indexOf(c.tagName)!==-1){ hasBlockChild=true; break; } }
   if(!hasBlockChild){ var t=(el.innerText||'').trim().replace(/\\s+/g,' '); if(t)blocks.push({el:el,text:t}); }
   else for(k=0;k<el.children.length;k++)walk(el.children[k]);
  } else for(k=0;k<el.children.length;k++)walk(el.children[k]);
 }
 walk(container); return blocks;
}
function speakText(t,onDone){ if(!t){ document.getElementById('readStatus').textContent=''; if(onDone)onDone(); return; }
 speechSynthesis.cancel(); var status=document.getElementById('readStatus'); status.textContent='准备中…';
 var chunks=[]; var maxLen=280; for(var i=0;i<t.length;i+=maxLen){ var s=t.slice(i,i+maxLen); var j=s.lastIndexOf('。'); if(j>80){ chunks.push(s.slice(0,j+1)); i-=s.length-(j+1); } else chunks.push(s); }
 if(chunks.length===0)chunks=[t]; var idx=0;
 function speakNext(){ if(idx>=chunks.length){ status.textContent=''; if(onDone)onDone(); return; } var u=new SpeechSynthesisUtterance(chunks[idx]); u.lang='zh-CN'; u.rate=0.95; var v=speechSynthesis.getVoices().filter(function(x){ return x.lang.indexOf('zh')>=0; })[0]; if(v)u.voice=v;
  u.onend=function(){ idx++; setTimeout(speakNext,80); }; u.onerror=function(){ idx++; setTimeout(speakNext,80); }; status.textContent='朗读中 '+(idx+1)+'/'+chunks.length+'…'; speechSynthesis.speak(u); }
 if(speechSynthesis.getVoices().length)speakNext(); else speechSynthesis.onvoiceschanged=function(){ speechSynthesis.onvoiceschanged=null; speakNext(); }; }
function readFullText(){ var c=document.querySelector('.content'); if(!c){ document.getElementById('readStatus').textContent='无可读内容'; return; }
 var segments=getBlocksInOrder(c); if(!segments.length){ document.getElementById('readStatus').textContent='无可读内容'; return; }
 speechSynthesis.cancel(); document.querySelectorAll('.content .'+READING_HIGHLIGHT_CLASS).forEach(function(el){ el.classList.remove(READING_HIGHLIGHT_CLASS); });
 var status=document.getElementById('readStatus'); var idx=0;
 function runSegment(){ if(idx>=segments.length){ status.textContent=''; document.querySelectorAll('.content .'+READING_HIGHLIGHT_CLASS).forEach(function(el){ el.classList.remove(READING_HIGHLIGHT_CLASS); }); return; }
  var seg=segments[idx]; seg.el.scrollIntoView({behavior:'smooth',block:'center'}); document.querySelectorAll('.content .'+READING_HIGHLIGHT_CLASS).forEach(function(el){ el.classList.remove(READING_HIGHLIGHT_CLASS); }); seg.el.classList.add(READING_HIGHLIGHT_CLASS);
  status.textContent='朗读 '+(idx+1)+'/'+segments.length+'…';
  speakText(seg.text,function(){ seg.el.classList.remove(READING_HIGHLIGHT_CLASS); idx++; setTimeout(runSegment,120); }); }
 runSegment(); }
function getBlockForTap(el){ var c=document.querySelector('.content'); var blockTags=['P','DIV','H2','H3','H4','LI','PRE']; while(el&&el!==c){ if(c.contains(el)&&blockTags.indexOf(el.tagName)!==-1) return el; el=el.parentElement; } return null; }
function onContentTap(e){ if(e.target.closest&&e.target.closest('a')) return; var block=getBlockForTap(e.target); if(block){ var t=(block.innerText||'').trim().replace(/\\s+/g,' '); if(t){ e.preventDefault(); speechSynthesis.cancel(); document.getElementById('readStatus').textContent='朗读本段…'; speakText(t); } } }
if(document.readyState==='loading'){ document.addEventListener('DOMContentLoaded', function(){ var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }); } else { var c=document.querySelector('.content'); if(c) c.addEventListener('click', onContentTap); }
setTimeout(function(){ try{ var u=new SpeechSynthesisUtterance('\u200b'); u.volume=0; speechSynthesis.speak(u); }catch(e){} }, 300);
</script>
</body>
</html>